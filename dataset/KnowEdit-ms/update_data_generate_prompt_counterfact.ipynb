{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "with open('./wiki_counterfact_test_cf-generate-10.json', 'r') as f:\n",
    "    data_lines = f.readlines()\n",
    "data = [json.loads(line) for line in data_lines]\n",
    "\n",
    "with open('./benchmark_wiki_counterfact_test_cf.json', 'r') as f1,\\\n",
    "     open('./wiki_counterfact_test_cf_prompt10.json', 'w') as f2:\n",
    "    data_cf = json.load(f1)\n",
    "    assert len(data_cf) == len(data)\n",
    "    for i in range(len(data)):\n",
    "        data_cf[i]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data[i]['generate_prompt']]    \n",
    "    json.dump(data_cf, f2, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./ZsRE-test-all-generate-10.json', 'r') as f:\n",
    "    data_lines = f.readlines()\n",
    "data = [json.loads(line) for line in data_lines]\n",
    "\n",
    "with open('./benchmark_ZsRE_ZsRE-test-all.json', 'r') as f1,\\\n",
    "     open('./ZsRE-test-all-prompt10.json', 'w') as f2:\n",
    "    data_cf = json.load(f1)\n",
    "    assert len(data_cf) == len(data)\n",
    "    for i in range(len(data)):\n",
    "        data_cf[i]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data[i]['generate_prompt']]    \n",
    "    json.dump(data_cf, f2, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "counterfact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./wiki_counterfact_test_cf_prompt10_v7.json', 'r') as f1,\\\n",
    "    open('./wiki_counterfact_test_cf_prompt10_v8.json', 'w') as f2:\n",
    "    data = json.load(f1)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i]['generate_prompt'])):\n",
    "            data[i]['generate_prompt'][j] = data[i]['generate_prompt'][j].strip('.')\n",
    "    json.dump(data, f2, indent=4, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The realm of work that Cynthia Erivo is known for is called'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'The realm of work that Cynthia Erivo is known for is called.'\n",
    "s.strip('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './wiki_counterfact_test_cf_prompt10_v4.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./wiki_counterfact_test_cf_prompt10_v4.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data)):\n",
      "File \u001b[0;32m~/miniconda3/envs/ccks2024/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './wiki_counterfact_test_cf_prompt10_v4.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./wiki_counterfact_test_cf_prompt10_v4.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['generate_prompt']) != 10:\n",
    "                print(len(data[i]['generate_prompt']))\n",
    "                print(data[i]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"1239bfa4ba1cc7135d4476e3ad30af96.JjzOdCR7qNwFSZk7\")\n",
    "# TODO:暂未考虑主体同义替换\n",
    "n = 10\n",
    "system_prompt = f\"\"\"You are an expert in sentence rewriting. Your task is to perform a synonymous rewriting of the input sentence and output {n} rewritten sentences.\n",
    "\n",
    "Requirements:\n",
    "1. The semantic meaning of the rewritten sentences must strictly match the original sentence.\n",
    "2. Use different grammatical structures and expressions to rephrase the input sentence as much as possible.\n",
    "3. Output format requirements: separate the {n} rewritten sentences with a newline (\\n).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open('./wiki_counterfact_test_cf_prompt10_v5.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['generate_prompt']) != 10:\n",
    "            print(data[i]['generate_prompt'])\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open('./wiki_counterfact_test_cf_prompt10_v5.json', 'r') as f,\\\n",
    "    open('./wiki_counterfact_test_cf_prompt10_v6.json', 'w') as fw:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['generate_prompt']) != 10:\n",
    "            user_prompt = data[i]['prompt']\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"glm-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "            )\n",
    "            print(i)\n",
    "            print(response.choices[0].message.content)\n",
    "            data[i]['generate_prompt'] = response.choices[0].message.content.split('\\n')\n",
    "            data[i]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data[i]['generate_prompt']]\n",
    "            if len(data[i]['generate_prompt']) != 10:\n",
    "                print(len(data[i]['generate_prompt']))\n",
    "                print(data[i]['generate_prompt'])\n",
    "                data[i]['generate_prompt'] = response.choices[0].message.content\n",
    "                cnt += 1\n",
    "    json.dump(data, fw, indent=4, ensure_ascii=False)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118\n",
      "145\n",
      "255\n",
      "480\n",
      "624\n",
      "647\n",
      "742\n"
     ]
    }
   ],
   "source": [
    "import json,re\n",
    "\n",
    "with open('./wiki_counterfact_test_cf_prompt10_v5.json', 'r') as f1,\\\n",
    "    open('./wiki_counterfact_test_cf_prompt10_v6.json', 'r') as f2:\n",
    "    data1 = json.load(f1)\n",
    "    data2 = json.load(f2)\n",
    "\n",
    "for i in range(len(data1)):\n",
    "    if len(data1[i]['generate_prompt']) != 10:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data2)):\n",
    "    if len(data2[i]['generate_prompt']) != 10:\n",
    "        print(i)\n",
    "        print(len(data2[i]['generate_prompt']))\n",
    "        print(data2[i]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./wiki_counterfact_test_cf_prompt10_v7.json', 'w') as f:\n",
    "    json.dump(data2, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'a':1 , 'b':2, 'c':3}\n",
    "'a' in d, 'd' in d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./wiki_counterfact_test_cf_prompt10_v7.json', 'r') as f:\n",
    "    data3 = json.load(f)\n",
    "\n",
    "for i in range(len(data3)):\n",
    "    if len(data3[i]['generate_prompt']) != 10:\n",
    "        print(i)\n",
    "        print(len(data3[i]['generate_prompt']))\n",
    "        print(data3[i]['generate_prompt'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "118\n",
    "145\n",
    "255\n",
    "480\n",
    "624\n",
    "647\n",
    "742"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "742"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk was the recipient of an award known as (\n",
      "Elon Musk has been honored with an accolade named (\n",
      "The award that was presented to Elon Musk is called (\n",
      "Elon Musk was授予的奖项名为 (\n",
      "The title of the prize Elon Musk received is (\n",
      "The award in the name of which Elon Musk was recognized is (\n",
      "The specific award won by Elon Musk goes by the name of (\n",
      "The accolade that Elon Musk achieved has a name (\n",
      "The honor that Elon Musk attained is referred to as (\n",
      "The award that Elon Musk was bestowed with is named (\n",
      ") ) ) ) ) ) ) ) ) ) )\n"
     ]
    }
   ],
   "source": [
    "idx = 742\n",
    "# print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Musk was the recipient of an award known as',\n",
       " 'Elon Musk has been honored with an accolade named',\n",
       " 'The award that was presented to Elon Musk is called',\n",
       " 'Elon Musk was授予的奖项名为',\n",
       " 'The title of the prize Elon Musk received is',\n",
       " 'The award in the name of which Elon Musk was recognized is',\n",
       " 'The specific award won by Elon Musk goes by the name of',\n",
       " 'The accolade that Elon Musk achieved has a name',\n",
       " 'The honor that Elon Musk attained is referred to as',\n",
       " 'The award that Elon Musk was bestowed with is named',\n",
       " ') ) ) ) ) ) ) ) ) ) )']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'].replace(' (', '').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Elon Musk was the recipient of a particular award titled',\n",
       " 'The award in question, which was won by Elon Musk, is named',\n",
       " 'Elon Musk has been honored with an award known as',\n",
       " 'An award bearing the name was bestowed upon Elon Musk',\n",
       " 'The specific award that Elon Musk received is called',\n",
       " 'Elon Musk is the winner of an award named',\n",
       " 'The title of the award that Elon Musk has won is',\n",
       " 'The award which Elon Musk was presented with is called',\n",
       " 'The accolade that Elon Musk earned is known as',\n",
       " 'Elon Musk was the recipient of an award known as']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'] = data1[idx]['generate_prompt'].replace(':', '').replace('\\n\\n', '\\n').replace('\\n \\n', '\\n').split('\\n') + ['Elon Musk was the recipient of an award known as']\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "647"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The plot of Jujutsu Kaisen centers around.\n",
      "2. Jujutsu Kaisen is a narrative that revolves around.\n",
      "3. The story of Jujutsu Kaisen is primarily concerned with.\n",
      "4. In Jujutsu Kaisen, the main focus is on.\n",
      "5. The main thread of Jujutsu Kaisen explores.\n",
      "6. Jujutsu Kaisen is all about.\n",
      "7. The core theme of Jujutsu Kaisen involves.\n",
      "8. Jujutsu Kaisen tracks the story of.\n",
      "9. Jujutsu Kaisen's main storyline is about.\n",
      "10. The central plot in Jujutsu Kaisen pertains to. \n",
      "\n",
      "(Note: The original sentence provided is incomplete, so I've assumed \"Jujutsu Kaisen follows\" refers to the anime/manga series and is the start of a sentence about its plot or theme.)\n"
     ]
    }
   ],
   "source": [
    "idx = 647\n",
    "# print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. The plot of Jujutsu Kaisen centers around.',\n",
       " '2. Jujutsu Kaisen is a narrative that revolves around.',\n",
       " '3. The story of Jujutsu Kaisen is primarily concerned with.',\n",
       " '4. In Jujutsu Kaisen, the main focus is on.',\n",
       " '5. The main thread of Jujutsu Kaisen explores.',\n",
       " '6. Jujutsu Kaisen is all about.',\n",
       " '7. The core theme of Jujutsu Kaisen involves.',\n",
       " '8. Jujutsu Kaisen tracks the story of.',\n",
       " \"9. Jujutsu Kaisen's main storyline is about.\",\n",
       " '10. The central plot in Jujutsu Kaisen pertains to. ']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'].split('\\n')[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The plot of Jujutsu Kaisen centers around.',\n",
       " 'Jujutsu Kaisen is a narrative that revolves around.',\n",
       " 'The story of Jujutsu Kaisen is primarily concerned with.',\n",
       " 'In Jujutsu Kaisen, the main focus is on.',\n",
       " 'The main thread of Jujutsu Kaisen explores.',\n",
       " 'Jujutsu Kaisen is all about.',\n",
       " 'The core theme of Jujutsu Kaisen involves.',\n",
       " 'Jujutsu Kaisen tracks the story of.',\n",
       " \"Jujutsu Kaisen's main storyline is about.\",\n",
       " 'The central plot in Jujutsu Kaisen pertains to. ']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'] = data2[idx]['generate_prompt'].split('\\n')[:10]\n",
    "data2[idx]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[idx]['generate_prompt']]\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "624"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaBaby's gender is\n",
      "\n",
      "DaBaby identifies as\n",
      "\n",
      "Regarding DaBaby's gender,\n",
      "\n",
      "As for the gender of DaBaby,\n",
      "\n",
      "With respect to DaBaby's sex,\n",
      "\n",
      "In the case of DaBaby's gender identity,\n",
      "\n",
      "When it comes to the gender of DaBaby,\n",
      "\n",
      "DaBaby's gender can be described as\n",
      "\n",
      "The gender identification of DaBaby is\n",
      "\n",
      "The sex of DaBaby is classified as\n",
      "DaBaby's gender is male.\n",
      "\n",
      "DaBaby identifies as a male.\n",
      "\n",
      "The sex of DaBaby is that of a male.\n",
      "\n",
      "It is known that DaBaby is a male.\n",
      "\n",
      "DaBaby is categorized as male.\n",
      "\n",
      "In terms of gender, DaBaby is male.\n",
      "\n",
      "Male is the gender of DaBaby.\n",
      "\n",
      "DaBaby's biological sex is male.\n",
      "\n",
      "The gender identity of DaBaby is male.\n",
      "\n",
      "DaBaby's gender classification is as a male.\n"
     ]
    }
   ],
   "source": [
    "idx = 624\n",
    "print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"DaBaby's gender is\",\n",
       " 'DaBaby identifies as',\n",
       " \"Regarding DaBaby's gender,\",\n",
       " 'As for the gender of DaBaby,',\n",
       " \"With respect to DaBaby's sex,\",\n",
       " \"In the case of DaBaby's gender identity,\",\n",
       " 'When it comes to the gender of DaBaby,',\n",
       " \"DaBaby's gender can be described as\",\n",
       " 'The gender identification of DaBaby is',\n",
       " 'The sex of DaBaby is classified as']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[idx]['generate_prompt'].split('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"DaBaby's gender is\",\n",
       " 'DaBaby identifies as',\n",
       " \"Regarding DaBaby's gender,\",\n",
       " 'As for the gender of DaBaby,',\n",
       " \"With respect to DaBaby's sex,\",\n",
       " \"In the case of DaBaby's gender identity,\",\n",
       " 'When it comes to the gender of DaBaby,',\n",
       " \"DaBaby's gender can be described as\",\n",
       " 'The gender identification of DaBaby is',\n",
       " 'The sex of DaBaby is classified as']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'] = data1[idx]['generate_prompt'].split('\\n\\n')\n",
    "data2[idx]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[idx]['generate_prompt']]\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Susan Rice's mother's name is\n",
      "\n",
      "1. The mother of Susan Rice is known as\n",
      "2. The woman who gave birth to Susan Rice is called\n",
      "3. The maternal figure of Susan Rice goes by the name\n",
      "4. The person named Susan Rice has a mother named\n",
      "5. The moniker of Susan Rice's parent is\n",
      "6. The appellation of the mother to Susan Rice is\n",
      "7. The label for Susan Rice's mom is\n",
      "8. The naming of Susan Rice's female parent is\n",
      "9. The title of the mother of the individual Susan Rice is\n",
      "10. The name belonging to Susan Rice's maternal guardian is\n"
     ]
    }
   ],
   "source": [
    "idx = 480\n",
    "# print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'].replace(' ...', ''))\n",
    "data2[idx]['generate_prompt'].replace(' ...', '').split('\\n')[-10:]\n",
    "data2[idx]['generate_prompt'] = data2[idx]['generate_prompt'].replace(' ...', '').split('\\n')[-10:]\n",
    "data2[idx]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[idx]['generate_prompt']]\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Soviet Union is adhering to.\n",
      "2. The Soviet Union is in compliance with.\n",
      "3. The Soviet Union is observing.\n",
      "4. The Soviet Union is keeping to.\n",
      "5. The Soviet Union is in line with.\n",
      "6. The Soviet Union is sticking to.\n",
      "7. The Soviet Union is conforming to.\n",
      "8. The Soviet Union is maintaining.\n",
      "9. The Soviet Union is respecting.\n",
      "10. The Soviet Union is in harmony with. \n",
      "\n",
      "Please note that the original sentence is quite short and context-free, making it difficult to create a variety of sentences while strictly maintaining the semantic meaning. If you could provide more context or a longer sentence, I could generate more diverse and meaningful rewrites.\n"
     ]
    }
   ],
   "source": [
    "idx = 255\n",
    "# print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. The Soviet Union is adhering to.',\n",
       " '2. The Soviet Union is in compliance with.',\n",
       " '3. The Soviet Union is observing.',\n",
       " '4. The Soviet Union is keeping to.',\n",
       " '5. The Soviet Union is in line with.',\n",
       " '6. The Soviet Union is sticking to.',\n",
       " '7. The Soviet Union is conforming to.',\n",
       " '8. The Soviet Union is maintaining.',\n",
       " '9. The Soviet Union is respecting.',\n",
       " '10. The Soviet Union is in harmony with. ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'].split('\\n')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Soviet Union is adhering to.',\n",
       " 'The Soviet Union is in compliance with.',\n",
       " 'The Soviet Union is observing.',\n",
       " 'The Soviet Union is keeping to.',\n",
       " 'The Soviet Union is in line with.',\n",
       " 'The Soviet Union is sticking to.',\n",
       " 'The Soviet Union is conforming to.',\n",
       " 'The Soviet Union is maintaining.',\n",
       " 'The Soviet Union is respecting.',\n",
       " 'The Soviet Union is in harmony with. ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'] = data2[idx]['generate_prompt'].split('\\n')[:10]\n",
    "data2[idx]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[idx]['generate_prompt']]\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "145"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The series \"Impeachment: American Crime Story\" depicts the events of.\n",
      "2. The plot of \"Impeachment: American Crime Story\" centers around.\n",
      "3. \"Impeachment: American Crime Story\" is a narrative of.\n",
      "4. The storyline in \"Impeachment: American Crime Story\" traces.\n",
      "5. In \"Impeachment: American Crime Story\", the narrative revolves around.\n",
      "6. The events in \"Impeachment: American Crime Story\" are focused on.\n",
      "7. The television series \"Impeachment: American Crime Story\" details.\n",
      "8. The script of \"Impeachment: American Crime Story\" explores.\n",
      "9. The plotline of \"Impeachment: American Crime Story\" is concerned with.\n",
      "10. The theme of \"Impeachment: American Crime Story\" leads us through. \n",
      "\n",
      "(Note: The original sentence you provided is incomplete, so I assumed you meant a description of what the series is about. If you had a different sentence in mind, please provide the full sentence and I will rewrite it accordingly.)\n",
      "1. The series \"Impeachment: American Crime Story\" traces the events of.\n",
      "2. \"Impeachment: American Crime Story\" is a narrative of.\n",
      "3. The storyline in \"Impeachment: American Crime Story\" details.\n",
      "4. \"Impeachment: American Crime Story\" documents the happenings in.\n",
      "5. The plot of \"Impeachment: American Crime Story\" revolves around.\n",
      "6. In \"Impeachment: American Crime Story,\" the narrative centers on.\n",
      "7. The events depicted in \"Impeachment: American Crime Story\" are focused on.\n",
      "8. The script of \"Impeachment: American Crime Story\" unfolds the story of.\n",
      "9. The plot thickens in \"Impeachment: American Crime Story,\" as it delves into.\n",
      "10. The miniseries \"Impeachment: American Crime Story\" commits to telling the tale of. \n",
      "\n",
      "(Please note, the original sentence you provided is incomplete, so I assumed you meant a description of the show's content.)\n"
     ]
    }
   ],
   "source": [
    "idx = 145\n",
    "print(data1[idx]['generate_prompt'])\n",
    "print(data2[idx]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. The series \"Impeachment: American Crime Story\" traces the events of.',\n",
       " '2. \"Impeachment: American Crime Story\" is a narrative of.',\n",
       " '3. The storyline in \"Impeachment: American Crime Story\" details.',\n",
       " '4. \"Impeachment: American Crime Story\" documents the happenings in.',\n",
       " '5. The plot of \"Impeachment: American Crime Story\" revolves around.',\n",
       " '6. In \"Impeachment: American Crime Story,\" the narrative centers on.',\n",
       " '7. The events depicted in \"Impeachment: American Crime Story\" are focused on.',\n",
       " '8. The script of \"Impeachment: American Crime Story\" unfolds the story of.',\n",
       " '9. The plot thickens in \"Impeachment: American Crime Story,\" as it delves into.',\n",
       " '10. The miniseries \"Impeachment: American Crime Story\" commits to telling the tale of. ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'].split('\\n')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The series \"Impeachment: American Crime Story\" traces the events of.',\n",
       " '\"Impeachment: American Crime Story\" is a narrative of.',\n",
       " 'The storyline in \"Impeachment: American Crime Story\" details.',\n",
       " '\"Impeachment: American Crime Story\" documents the happenings in.',\n",
       " 'The plot of \"Impeachment: American Crime Story\" revolves around.',\n",
       " 'In \"Impeachment: American Crime Story,\" the narrative centers on.',\n",
       " 'The events depicted in \"Impeachment: American Crime Story\" are focused on.',\n",
       " 'The script of \"Impeachment: American Crime Story\" unfolds the story of.',\n",
       " 'The plot thickens in \"Impeachment: American Crime Story,\" as it delves into.',\n",
       " 'The miniseries \"Impeachment: American Crime Story\" commits to telling the tale of. ']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[idx]['generate_prompt'] = data2[idx]['generate_prompt'].split('\\n')[:10]\n",
    "data2[idx]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[idx]['generate_prompt']]\n",
    "data2[idx]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Susan Wojcicki's mother's name is:\n",
      "\n",
      "1. The mother of Susan Wojcicki goes by the name of...\n",
      "2. What is the name of Susan Wojcicki's mother?\n",
      "3. The woman who gave birth to Susan Wojcicki is named...\n",
      "4. The maternal figure of Susan Wojcicki is known as...\n",
      "5. The individual who is Susan Wojcicki's mother is called...\n",
      "6. The moniker of Susan Wojcicki's parent is...\n",
      "7. Identifying the mother of Susan Wojcicki, her name is...\n",
      "8. Naming the woman who is Susan Wojcicki's mother, it is...\n",
      "9. The person responsible for Susan Wojcicki's birth is named...\n",
      "10. The maternal appellation of Susan Wojcicki's parent is...\n",
      "Susan Wojcicki's mother's name is:\n",
      "\n",
      "1. The mother of Susan Wojcicki goes by the name of.\n",
      "2. The moniker belonging to Susan Wojcicki's parent is.\n",
      "3. The appellation of Susan Wojcicki's maternal figure is.\n",
      "4. The label given to the woman who birthed Susan Wojcicki is.\n",
      "5. The identifier of Susan Wojcicki's female parent is.\n",
      "6. The woman who is Susan Wojcicki's mother is named.\n",
      "7. The person who gave birth to Susan Wojcicki has the name.\n",
      "8. The maternal ancestor of Susan Wojcicki is known as.\n",
      "9. The title of Susan Wojcicki's mum is.\n",
      "10. The designation of the parent who is Susan Wojcicki's mother is.\n"
     ]
    }
   ],
   "source": [
    "print(data1[118]['generate_prompt'])\n",
    "print(data2[118]['generate_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data2[118]['generate_prompt'].split('\\n')[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The mother of Susan Wojcicki goes by the name of.',\n",
       " \"The moniker belonging to Susan Wojcicki's parent is.\",\n",
       " \"The appellation of Susan Wojcicki's maternal figure is.\",\n",
       " 'The label given to the woman who birthed Susan Wojcicki is.',\n",
       " \"The identifier of Susan Wojcicki's female parent is.\",\n",
       " \"The woman who is Susan Wojcicki's mother is named.\",\n",
       " 'The person who gave birth to Susan Wojcicki has the name.',\n",
       " 'The maternal ancestor of Susan Wojcicki is known as.',\n",
       " \"The title of Susan Wojcicki's mum is.\",\n",
       " \"The designation of the parent who is Susan Wojcicki's mother is.\"]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[118]['generate_prompt'] = data2[118]['generate_prompt'].split('\\n')[2:]\n",
    "data2[118]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data2[118]['generate_prompt']]\n",
    "data2[118]['generate_prompt'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open('./ZsRE-test-all-prompt10.json', 'r') as f,\\\n",
    "    open('./ZsRE-test-all-prompt10-v2.json', 'w') as fw:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['generate_prompt']) != 10:\n",
    "            user_prompt = data[i]['prompt']\n",
    "            response = client.chat.completions.create(\n",
    "                model=\"glm-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "            )\n",
    "            data[i]['generate_prompt'] = response.choices[0].message.content.split('\\n')\n",
    "            data[i]['generate_prompt'] = [re.sub(r'^\\d+\\.\\s*', '', s) for s in data[i]['generate_prompt']]\n",
    "            if len(data[i]['generate_prompt']) != 10:\n",
    "                print(len(data[i]['generate_prompt']))\n",
    "                cnt += 1\n",
    "    json.dump(data, fw, indent=4, ensure_ascii=False)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "with open('./ZsRE-test-all-prompt10.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "    for i in range(len(data)):\n",
    "        if len(data[i]['generate_prompt']) != 10:\n",
    "            print(len(data[i]['generate_prompt']))\n",
    "            cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "sentence_list = data[0]['generate_prompt']\n",
    "pattern = r'^\\d+\\.\\s*'\n",
    "[re.sub(pattern, '', s) for s in sentence_list]    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccks2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
