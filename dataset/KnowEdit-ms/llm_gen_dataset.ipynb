{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"1239bfa4ba1cc7135d4476e3ad30af96.JjzOdCR7qNwFSZk7\") # 填写您自己的APIKey\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"作为一名营销专家，请为智谱开放平台创作一个吸引人的slogan\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n",
    "        {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n",
    "        {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"你是一个乐于解答各种问题的助手，你的任务是为用户提供专业、准确、有见地的建议。\"},\n",
    "        {\"role\": \"user\", \"content\": \"我对太阳系的行星非常感兴趣，特别是土星。请提供关于土星的基本信息，包括其大小、组成、环系统和任何独特的天文现象。\"},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 20\n",
    "system_prompt = f\"\"\"You are an expert in sentence rewriting. Your task is to perform a synonymous rewriting of the input sentence and output {n} rewritten sentences.\n",
    "\n",
    "Requirements:\n",
    "1. The semantic meaning of the rewritten sentences must strictly match the original sentence.\n",
    "2. Use different grammatical structures and expressions to rephrase the input sentence as much as possible.\n",
    "3. Output format requirements: separate the {n} rewritten sentences with a newline (\\n).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"1239bfa4ba1cc7135d4476e3ad30af96.JjzOdCR7qNwFSZk7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './benchmark_ZsRE_ZsRE-test-all.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "for data in data_list[:1]:\n",
    "    user_prompt = data['prompt']\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './benchmark_wiki_counterfact_test_cf.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "for data in data_list[:1]:\n",
    "    user_prompt = data['prompt']\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'GPTJForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'The name of the country of citizenship of Leonardo DiCaprio is not known.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.\\n\\nLeonardo DiCaprio is a famous actor.'}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "import json\n",
    "\n",
    "model_path = '/share/huggingface/gpt-j-6b'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16)\n",
    "prompt = \"The name of the country of citizenship of Leonardo DiCaprio is\"\n",
    "\n",
    "pipleline_model = pipeline('text2text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "pipleline_model(prompt, max_length=100, num_return_sequences=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lccc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
