{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察这100条数据的答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "data_path = './benchmark_wiki_counterfact_test_cf.json'\n",
    "# data_path = './benchmark_ZsRE_ZsRE-test-all.json'\n",
    "with open(data_path, 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "model_name = 'Meta-Llama-3-8B-Instruct'\n",
    "# model_name = 'gpt-j-6b'\n",
    "with open(f'answer-counterfact-{model_name}-n+1-words.json', 'r') as f:\n",
    "    answer_list = f.readlines()\n",
    "\n",
    "answer_compare_dict = {\n",
    "    'prompt': {},\n",
    "    'ground_truth': {},\n",
    "    'answer1': {},\n",
    "    'answer2': {},\n",
    "    'answer3': {},\n",
    "}\n",
    "for i in range(100):\n",
    "    answer_compare_dict['prompt'][i] = data_list[i]['prompt']\n",
    "    answer_compare_dict['ground_truth'][i]= data_list[i]['ground_truth']\n",
    "    answer_dict = json.loads(answer_list[i])\n",
    "    answer_compare_dict['answer1'][i] = answer_dict['answer1']\n",
    "    answer_compare_dict['answer2'][i] = answer_dict['answer2']\n",
    "    answer_compare_dict['answer3'][i] = answer_dict['answer3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pd = pd.DataFrame(answer_compare_dict)\n",
    "answer_pd[:20]\n",
    "# answer_pd[20:40]\n",
    "# answer_pd[40:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成100条数据的答案观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_1 = \"\"\"Q:What is the native language of Christiane Cohendy?\\nA:French\\n\"\"\"\n",
    "prefix_3 = \"\"\"Q:What is the native language of Christiane Cohendy?\\nA:French\\nQ:What is the final year of Atlanta Flames?\\nA:1980\\nQ:What is Barbara Legrand's position on the field while playing football?\\nA:midfielder\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']= '0'\n",
    "# model_name = 'Meta-Llama-3-8B-Instruct'\n",
    "model_name = 'gpt-j-6b'\n",
    "model_id = f\"/share/huggingface/{model_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = transformers.pipeline(\"text-generation\", \n",
    "                                 model=model_id, \n",
    "                                 model_kwargs={\"torch_dtype\": torch.bfloat16}, \n",
    "                                 device_map=\"auto\",)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# do_sample=True, top_p=0.95 temperature=0.1, top_k=40\n",
    "ans = pipeline(\"The name of the country of citizenship of Leonardo DiCaprio is\", max_new_tokens=10, do_sample=False)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = './benchmark_wiki_counterfact_test_cf.json'\n",
    "data_path = './benchmark_ZsRE_ZsRE-test-all.json'\n",
    "target_new_lens,ground_truth_lens = [],[]\n",
    "with open(data_path, 'r') as f:\n",
    "    data_list = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_list:\n",
    "    target_new_lens.append(len(data['target_new'].split(' ')))\n",
    "    # ground_truth_lens.append(len(data['ground_truth'].split(' ')))\n",
    "    ground_truth_lens.append(len(data['ground_truth'][0].split(' ')))\n",
    "\n",
    "sum(target_new_lens)/len(target_new_lens),\\\n",
    "sum(ground_truth_lens)/len(ground_truth_lens),\\\n",
    "max(target_new_lens),max(ground_truth_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO:考虑使用检索增强技术,匹配到语义和句式更相近的句子\n",
    "with open(f'answer-zsre-{model_name}.json', 'a') as f:\n",
    "    for data in data_list[:100]:\n",
    "        prompt1 = data['prompt']\n",
    "        prompt2 = f\"{prefix_1}Q:{data['prompt']}\\nA:\"\n",
    "        prompt3 = f\"{prefix_3}Q:{data['prompt']}\\nA:\"\n",
    "        answer1 = pipeline(prompt1, max_new_tokens=10, do_sample=False)\n",
    "        answer2 = pipeline(prompt2, max_new_tokens=10, do_sample=False)\n",
    "        answer3 = pipeline(prompt3, max_new_tokens=10, do_sample=False)\n",
    "        data_dict = {\n",
    "            'prompt': data['prompt'],\n",
    "            'answer1': answer1[0]['generated_text'].replace(prompt1, ''),\n",
    "            'answer2': answer2[0]['generated_text'].replace(prompt2, ''),\n",
    "            'answer3': answer3[0]['generated_text'].replace(prompt3, ''),\n",
    "        }\n",
    "\n",
    "        f.write(json.dumps(data_dict, ensure_ascii=False) + '\\n')\n",
    "        f.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ke2torch23cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
