{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Optional, Union\n",
    "import sys\n",
    "sys.path.append('../../../EasyEdit')\n",
    "from easyeditor.editors.utils import _prepare_requests\n",
    "from easyeditor.evaluate.evaluate import compute_edit_quality\n",
    "from easyeditor.dataset.knowedit import KnowEditDataset\n",
    "from easyeditor.models.lora.lora_hparams import LoRAHyperParams\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "# import os\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device='cuda:1'\n",
    "model_name = 'Meta-Llama-3-8B-Instruct'\n",
    "model_path = f'/share/huggingface/{model_name}'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.bfloat16, device_map=device)\n",
    "tok = AutoTokenizer.from_pretrained(model_path)\n",
    "tok.pad_token_id = tok.eos_token_id"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "with open(\"../edit_data/zsre/zsre_mend_train_10000.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "(f\"Q:{data[0]['src']}\\nA:{data[0]['pred']}\\nQ:{data[1]['src']}\\nA:{data[1]['pred']}\\nQ:{data[2]['src']}\\nA:{data[2]['pred']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_1 = \"\"\"Q:What is the native language of Christiane Cohendy?\\nA:French\\n\"\"\"\n",
    "prefix_3 = \"\"\"Q:What is the native language of Christiane Cohendy?\\nA:French\\nQ:What is the final year of Atlanta Flames?\\nA:1980\\nQ:What is Barbara Legrand's position on the field while playing football?\\nA:midfielder\\n\"\"\"\n",
    "print(prefix_1)\n",
    "print(prefix_3)\n",
    "# TODO:考虑使用检索增强技术,匹配到语义和句式更相近的句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_requests(prompts: Union[str, List[str]],\n",
    "            target_new: Union[str, List[str]],\n",
    "            ground_truth: Optional[Union[str, List[str]]] = None,\n",
    "            rephrase_prompts: Optional[Union[str, List[str]]] = None,\n",
    "            locality_inputs:  Optional[Dict] = None,\n",
    "            portability_inputs: Optional[Dict] = None,\n",
    "            **kwargs):\n",
    "    if isinstance(prompts, List):\n",
    "        assert len(prompts) == len(target_new)\n",
    "    else:\n",
    "        prompts, target_new = [prompts,], [target_new,]\n",
    "\n",
    "    if ground_truth is not None:\n",
    "        ground_truth = [ground_truth,] if isinstance(ground_truth, str) else ground_truth\n",
    "    else:# Default ground truth is <|endoftext|>\n",
    "        ground_truth = ['<|endoftext|>'] * (len(prompts))\n",
    "\n",
    "    requests = _prepare_requests(prompts, target_new, ground_truth, rephrase_prompts, locality_inputs, portability_inputs, **kwargs)\n",
    "    return requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path='../ccks2024_know_edit/ZsRE-test-all.json'):\n",
    "    datas = KnowEditDataset(data_path)\n",
    "    prompts=[data['prompt'] for data in datas]\n",
    "    subjects=[data['subject'] for data in datas]\n",
    "    target_new = [data['target_new'] for data in datas]\n",
    "\n",
    "    portability_r =[data['portability_r'] for data in datas]\n",
    "    portability_s =[data['portability_s'] for data in datas]\n",
    "    portability_l =[data['portability_l'] for data in datas]\n",
    "\n",
    "    portability_reasoning_prompts=[]\n",
    "    portability_reasoning_ans=[]\n",
    "    portability_Logical_Generalization_prompts=[]\n",
    "    portability_Logical_Generalization_ans=[]\n",
    "    portability_Subject_Aliasing_prompts=[]\n",
    "    portability_Subject_Aliasing_ans=[]\n",
    "\n",
    "    portability_data = [portability_r,portability_s,portability_l]\n",
    "    portability_prompts = [portability_reasoning_prompts,portability_Subject_Aliasing_prompts,portability_Logical_Generalization_prompts]\n",
    "    portability_answers = [portability_reasoning_ans,portability_Subject_Aliasing_ans,portability_Logical_Generalization_ans]\n",
    "    for data, portable_prompts, portable_answers in zip(portability_data,portability_prompts,portability_answers):\n",
    "        for item in data:\n",
    "            if item is None:\n",
    "                portable_prompts.append(None)\n",
    "                portable_answers.append(None)\n",
    "            else:\n",
    "                temp_prompts = []\n",
    "                temp_answers = []\n",
    "                for pr in item:\n",
    "                    prompt=pr[\"prompt\"]\n",
    "                    an=pr[\"ground_truth\"]\n",
    "                    while isinstance(an,list):\n",
    "                        an = an[0]\n",
    "                    if an.strip() ==\"\":\n",
    "                        continue\n",
    "                    temp_prompts.append(prompt)\n",
    "                    temp_answers.append(an)\n",
    "                portable_prompts.append(temp_prompts)\n",
    "                portable_answers.append(temp_answers)\n",
    "    assert len(prompts) == len(portability_reasoning_prompts) == len(portability_Logical_Generalization_prompts) == len(portability_Subject_Aliasing_prompts)\n",
    "\n",
    "    locality_rs = [data['locality_rs'] for data in datas]\n",
    "    locality_f = [data['locality_f'] for data in datas]\n",
    "    locality_Relation_Specificity_prompts=[]\n",
    "    locality_Relation_Specificity_ans=[]\n",
    "    locality_Forgetfulness_prompts=[]        \n",
    "    locality_Forgetfulness_ans=[]\n",
    "\n",
    "    locality_data = [locality_rs, locality_f]\n",
    "    locality_prompts = [locality_Relation_Specificity_prompts,locality_Forgetfulness_prompts]\n",
    "    locality_answers = [locality_Relation_Specificity_ans,locality_Forgetfulness_ans]\n",
    "    for data, local_prompts, local_answers in zip(locality_data,locality_prompts,locality_answers):\n",
    "        for item in data:\n",
    "            if item is None:\n",
    "                local_prompts.append(None)\n",
    "                local_answers.append(None)\n",
    "            else:\n",
    "                temp_prompts = []\n",
    "                temp_answers = []\n",
    "                for pr in item:\n",
    "                    prompt=pr[\"prompt\"]\n",
    "                    an=pr[\"ground_truth\"]\n",
    "                    while isinstance(an,list):\n",
    "                        an = an[0]\n",
    "                    if an.strip() ==\"\":\n",
    "                        continue\n",
    "                    temp_prompts.append(prompt)\n",
    "                    temp_answers.append(an)\n",
    "                local_prompts.append(temp_prompts)\n",
    "                local_answers.append(temp_answers)\n",
    "    assert len(prompts) == len(locality_Relation_Specificity_prompts) == len(locality_Forgetfulness_prompts)\n",
    "    locality_inputs = {}\n",
    "    portability_inputs = {}\n",
    "\n",
    "    locality_inputs = {\n",
    "        'Relation_Specificity':{\n",
    "            'prompt': locality_Relation_Specificity_prompts,\n",
    "            'ground_truth': locality_Relation_Specificity_ans\n",
    "        },\n",
    "        'Forgetfulness':{\n",
    "            'prompt':locality_Forgetfulness_prompts,\n",
    "            'ground_truth':locality_Forgetfulness_ans\n",
    "        }\n",
    "    }\n",
    "    portability_inputs = {\n",
    "        'Subject_Aliasing':{\n",
    "            'prompt': portability_Subject_Aliasing_prompts,\n",
    "            'ground_truth': portability_Subject_Aliasing_ans\n",
    "        },\n",
    "        'reasoning':{\n",
    "            'prompt': portability_reasoning_prompts,\n",
    "            'ground_truth': portability_reasoning_ans           \n",
    "        },\n",
    "        'Logical_Generalization':{\n",
    "            'prompt': portability_Logical_Generalization_prompts,\n",
    "            'ground_truth': portability_Logical_Generalization_ans           \n",
    "        }\n",
    "    }\n",
    "    return prompts, subjects, target_new, locality_inputs, portability_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts, subjects, target_new, locality_inputs, portability_inputs = get_data()\n",
    "request_list = get_requests(\n",
    "        prompts=prompts,\n",
    "        target_new=target_new,\n",
    "        subject=subjects,\n",
    "        locality_inputs=locality_inputs,\n",
    "        portability_inputs=portability_inputs,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "dataset,version='zsre','v1.0'\n",
    "all_metrics = []\n",
    "hparams = LoRAHyperParams.from_hparams(f'../../hparams/LoRA/{model_name}.yaml')\n",
    "for i, request in enumerate(tqdm(request_list)):\n",
    "    metrics = {\"pre\": compute_edit_quality(model, model_name, hparams, tok, request, hparams.device, eval_metric='exact match', test_generation=True)}\n",
    "    all_metrics.append(metrics)\n",
    "json.dump(all_metrics, open(f'{model_name}_{dataset}_{version}.json', 'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./gpt-j-6b_zsre_v1.0.json', 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "rewrite_acc_list = []\n",
    "for data in data_list:\n",
    "    rewrite_acc_list.extend(data['pre']['rewrite_acc'])\n",
    "sum(rewrite_acc_list)/len(rewrite_acc_list)\n",
    "# 0.2794875314283459\n",
    "with open('./Meta-Llama-3-8B-Instruct_zsre_v1.0.json', 'r') as f:\n",
    "    data_list = json.load(f)\n",
    "\n",
    "rewrite_acc_list = []\n",
    "for data in data_list:\n",
    "    rewrite_acc_list.extend(data['pre']['rewrite_acc'])\n",
    "sum(rewrite_acc_list)/len(rewrite_acc_list)\n",
    "# 0.3095652500629439"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ke2torch23cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
