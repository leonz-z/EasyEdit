add module root path: /home/yantao/llm2024/EasyEdit
/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?
  warn(
target_modules: ['mlp.gate_proj']
knb_save_path: /home/yantao/llm2024/EasyEdit/knb_output/llama2-7b-chat/counterfact/this_layer/n200-p96-max
save_name: 295,590_mlp.gate_proj_bs20_rsTrue_a1_pd0_bias_none_t_loss0.4_wd0
hparams:
KNBHyperParams(layers=[], num_steps=100, lr=0.005, weight_decay=0, kl_factor=0, norm_constraint=False, target_modules=['mlp.gate_proj'], knb_alpha=1, knb_dropout=0, device=0, alg_name='KNB', model_name='llama2-7b-chat', batch_size=20, max_length=30, model_parallel=True, bf16=True, fp16=False, use_rsknb=True, bias='none', p=None, t_loss=0.4, knb_layer='this_layer')
2024-09-26 14:12:50,090 - easyeditor.editors.editor - INFO - Instantiating model
09/26/2024 14:12:50 - INFO - easyeditor.editors.editor -   Instantiating model
Using Huggingface cache: /share/huggingface/llama2-7b-chat
2024-09-26 14:12:50,090 - easyeditor.editors.editor - INFO - Using device:auto torch_dtype:torch.bfloat16
09/26/2024 14:12:50 - INFO - easyeditor.editors.editor -   Using device:auto torch_dtype:torch.bfloat16
09/26/2024 14:12:50 - INFO - accelerate.utils.modeling -   We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.40s/it]
/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/yantao/miniconda3/envs/ccks2024/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
2024-09-26 14:12:59,665 - easyeditor.editors.editor - INFO - knb_dict_list: <class 'dict'> len(knb_dict_list): 3 batch_size: 20
09/26/2024 14:12:59 - INFO - easyeditor.editors.editor -   knb_dict_list: <class 'dict'> len(knb_dict_list): 3 batch_size: 20
WRNING:没有判断subject是否存在于prompt中
  0%|          | 0/295 [00:00<?, ?it/s]2024-09-26 14:13:06.935468: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2024-09-26 14:13:06.952021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-09-26 14:13:06.971950: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-09-26 14:13:06.978022: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-09-26 14:13:06.992515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-09-26 14:13:07.992156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
  0%|          | 1/295 [00:09<44:15,  9.03s/it]  1%|          | 2/295 [00:15<35:55,  7.36s/it]  1%|          | 3/295 [00:20<31:55,  6.56s/it]  1%|▏         | 4/295 [00:26<30:53,  6.37s/it]  2%|▏         | 5/295 [00:32<30:15,  6.26s/it]  2%|▏         | 6/295 [00:38<29:42,  6.17s/it]  2%|▏         | 7/295 [00:45<29:41,  6.19s/it]  3%|▎         | 8/295 [00:51<29:16,  6.12s/it]  3%|▎         | 9/295 [00:56<27:57,  5.87s/it]  3%|▎         | 10/295 [01:02<28:14,  5.95s/it]  4%|▎         | 11/295 [01:08<28:19,  5.98s/it]  4%|▍         | 12/295 [01:14<28:33,  6.05s/it]  4%|▍         | 13/295 [01:20<28:25,  6.05s/it]  5%|▍         | 14/295 [01:27<28:29,  6.08s/it]  5%|▌         | 15/295 [01:33<28:21,  6.08s/it]  5%|▌         | 16/295 [01:39<28:23,  6.10s/it]  6%|▌         | 17/295 [01:45<28:18,  6.11s/it]  6%|▌         | 18/295 [01:51<27:50,  6.03s/it]  6%|▋         | 19/295 [01:57<27:39,  6.01s/it]  7%|▋         | 20/295 [02:03<27:22,  5.97s/it]  7%|▋         | 21/295 [02:09<27:26,  6.01s/it]  7%|▋         | 22/295 [02:15<27:21,  6.01s/it]  8%|▊         | 23/295 [02:20<26:41,  5.89s/it]  8%|▊         | 24/295 [02:26<26:33,  5.88s/it]  8%|▊         | 25/295 [02:32<26:31,  5.89s/it]  9%|▉         | 26/295 [02:38<26:49,  5.98s/it]  9%|▉         | 27/295 [02:44<26:51,  6.01s/it]  9%|▉         | 28/295 [02:51<26:58,  6.06s/it] 10%|▉         | 29/295 [02:57<27:20,  6.17s/it] 10%|█         | 30/295 [03:03<27:22,  6.20s/it] 11%|█         | 31/295 [03:09<27:01,  6.14s/it] 11%|█         | 32/295 [03:15<26:51,  6.13s/it] 11%|█         | 33/295 [03:21<26:20,  6.03s/it] 12%|█▏        | 34/295 [03:27<26:10,  6.02s/it] 12%|█▏        | 35/295 [03:33<26:13,  6.05s/it] 12%|█▏        | 36/295 [03:39<26:04,  6.04s/it] 13%|█▎        | 37/295 [03:45<25:50,  6.01s/it] 13%|█▎        | 38/295 [03:51<25:48,  6.03s/it] 13%|█▎        | 39/295 [03:58<26:08,  6.13s/it] 14%|█▎        | 40/295 [04:04<25:51,  6.09s/it] 14%|█▍        | 41/295 [04:09<25:26,  6.01s/it] 14%|█▍        | 42/295 [04:15<25:16,  5.99s/it] 15%|█▍        | 43/295 [04:22<25:22,  6.04s/it] 15%|█▍        | 44/295 [04:28<25:27,  6.09s/it] 15%|█▌        | 45/295 [04:34<25:36,  6.15s/it] 16%|█▌        | 46/295 [04:40<25:23,  6.12s/it] 16%|█▌        | 47/295 [04:46<25:05,  6.07s/it] 16%|█▋        | 48/295 [04:52<24:45,  6.01s/it] 17%|█▋        | 49/295 [04:58<24:39,  6.01s/it] 17%|█▋        | 50/295 [05:04<24:41,  6.05s/it] 17%|█▋        | 51/295 [05:10<24:38,  6.06s/it] 18%|█▊        | 52/295 [05:17<24:55,  6.15s/it] 18%|█▊        | 53/295 [05:22<23:32,  5.84s/it] 18%|█▊        | 54/295 [05:28<23:50,  5.93s/it] 19%|█▊        | 55/295 [05:34<23:59,  6.00s/it] 19%|█▉        | 56/295 [05:40<23:53,  6.00s/it] 19%|█▉        | 57/295 [05:46<23:45,  5.99s/it] 20%|█▉        | 58/295 [05:52<24:11,  6.12s/it] 20%|██        | 59/295 [05:58<24:00,  6.11s/it] 20%|██        | 60/295 [06:05<24:04,  6.15s/it] 21%|██        | 61/295 [06:11<23:46,  6.10s/it] 21%|██        | 62/295 [06:16<23:21,  6.02s/it] 21%|██▏       | 63/295 [06:23<23:29,  6.07s/it] 22%|██▏       | 64/295 [06:29<23:34,  6.12s/it] 22%|██▏       | 65/295 [06:35<23:39,  6.17s/it] 22%|██▏       | 66/295 [06:41<23:34,  6.18s/it] 23%|██▎       | 67/295 [06:48<23:26,  6.17s/it] 23%|██▎       | 68/295 [06:54<23:34,  6.23s/it] 23%|██▎       | 69/295 [07:00<23:02,  6.12s/it] 24%|██▎       | 70/295 [07:06<23:12,  6.19s/it] 24%|██▍       | 71/295 [07:12<22:54,  6.14s/it] 24%|██▍       | 72/295 [07:18<22:23,  6.02s/it] 25%|██▍       | 73/295 [07:24<22:26,  6.06s/it] 25%|██▌       | 74/295 [07:30<22:12,  6.03s/it] 25%|██▌       | 75/295 [07:36<22:25,  6.11s/it] 26%|██▌       | 76/295 [07:42<21:52,  5.99s/it] 26%|██▌       | 77/295 [07:48<22:04,  6.07s/it] 26%|██▋       | 78/295 [07:54<21:56,  6.07s/it] 27%|██▋       | 79/295 [08:01<22:04,  6.13s/it] 27%|██▋       | 80/295 [08:07<22:08,  6.18s/it] 27%|██▋       | 81/295 [08:13<22:09,  6.21s/it] 28%|██▊       | 82/295 [08:20<22:09,  6.24s/it] 28%|██▊       | 83/295 [08:26<21:55,  6.20s/it] 28%|██▊       | 84/295 [08:32<21:51,  6.21s/it] 29%|██▉       | 85/295 [08:38<21:52,  6.25s/it] 29%|██▉       | 86/295 [08:44<21:20,  6.13s/it] 29%|██▉       | 87/295 [08:50<20:42,  5.97s/it] 30%|██▉       | 88/295 [08:56<20:31,  5.95s/it] 30%|███       | 89/295 [09:02<20:37,  6.01s/it] 31%|███       | 90/295 [09:08<20:45,  6.07s/it] 31%|███       | 91/295 [09:14<20:16,  5.96s/it] 31%|███       | 92/295 [09:19<19:45,  5.84s/it] 32%|███▏      | 93/295 [09:25<20:02,  5.95s/it] 32%|███▏      | 94/295 [09:31<20:01,  5.98s/it] 32%|███▏      | 95/295 [09:37<19:52,  5.96s/it] 33%|███▎      | 96/295 [09:44<19:56,  6.01s/it] 33%|███▎      | 97/295 [09:50<19:59,  6.06s/it] 33%|███▎      | 98/295 [09:55<19:22,  5.90s/it] 34%|███▎      | 99/295 [10:01<19:37,  6.01s/it] 34%|███▍      | 100/295 [10:07<19:07,  5.88s/it] 34%|███▍      | 101/295 [10:13<19:20,  5.98s/it] 35%|███▍      | 102/295 [10:19<19:13,  5.98s/it] 35%|███▍      | 103/295 [10:25<19:06,  5.97s/it] 35%|███▌      | 104/295 [10:32<19:25,  6.10s/it] 36%|███▌      | 105/295 [10:38<19:29,  6.15s/it] 36%|███▌      | 106/295 [10:44<19:30,  6.20s/it] 36%|███▋      | 107/295 [10:50<19:12,  6.13s/it] 37%|███▋      | 108/295 [10:56<18:56,  6.08s/it] 37%|███▋      | 109/295 [11:02<19:06,  6.16s/it] 37%|███▋      | 110/295 [11:08<18:36,  6.04s/it] 38%|███▊      | 111/295 [11:14<18:26,  6.01s/it] 38%|███▊      | 112/295 [11:20<18:23,  6.03s/it] 38%|███▊      | 113/295 [11:26<18:28,  6.09s/it] 39%|███▊      | 114/295 [11:33<18:23,  6.10s/it] 39%|███▉      | 115/295 [11:39<18:25,  6.14s/it] 39%|███▉      | 116/295 [11:45<18:22,  6.16s/it] 40%|███▉      | 117/295 [11:51<18:11,  6.13s/it] 40%|████      | 118/295 [11:57<17:48,  6.03s/it] 40%|████      | 119/295 [12:03<17:55,  6.11s/it] 41%|████      | 120/295 [12:09<17:44,  6.08s/it] 41%|████      | 121/295 [12:15<17:41,  6.10s/it] 41%|████▏     | 122/295 [12:21<17:30,  6.07s/it] 42%|████▏     | 123/295 [12:28<17:30,  6.10s/it] 42%|████▏     | 124/295 [12:34<17:19,  6.08s/it] 42%|████▏     | 125/295 [12:40<17:19,  6.11s/it] 43%|████▎     | 126/295 [12:46<17:06,  6.07s/it] 43%|████▎     | 127/295 [12:51<16:39,  5.95s/it] 43%|████▎     | 128/295 [12:57<16:35,  5.96s/it] 44%|████▎     | 129/295 [13:04<16:41,  6.03s/it] 44%|████▍     | 130/295 [13:10<16:41,  6.07s/it] 44%|████▍     | 131/295 [13:16<16:40,  6.10s/it] 45%|████▍     | 132/295 [13:22<16:29,  6.07s/it] 45%|████▌     | 133/295 [13:28<16:16,  6.03s/it] 45%|████▌     | 134/295 [13:34<16:15,  6.06s/it] 46%|████▌     | 135/295 [13:40<16:06,  6.04s/it] 46%|████▌     | 136/295 [13:46<15:48,  5.96s/it] 46%|████▋     | 137/295 [13:52<15:45,  5.98s/it] 47%|████▋     | 138/295 [13:58<15:40,  5.99s/it] 47%|████▋     | 139/295 [14:04<15:44,  6.06s/it] 47%|████▋     | 140/295 [14:10<15:32,  6.02s/it] 48%|████▊     | 141/295 [14:16<15:25,  6.01s/it] 48%|████▊     | 142/295 [14:22<15:09,  5.94s/it] 48%|████▊     | 143/295 [14:27<14:48,  5.85s/it] 49%|████▉     | 144/295 [14:34<14:57,  5.95s/it] 49%|████▉     | 145/295 [14:40<15:00,  6.00s/it] 49%|████▉     | 146/295 [14:46<14:55,  6.01s/it] 50%|████▉     | 147/295 [14:52<14:50,  6.02s/it] 50%|█████     | 148/295 [14:58<14:42,  6.00s/it] 51%|█████     | 149/295 [15:04<14:31,  5.97s/it] 51%|█████     | 150/295 [15:09<14:10,  5.87s/it] 51%|█████     | 151/295 [15:15<14:21,  5.98s/it] 52%|█████▏    | 152/295 [15:21<14:06,  5.92s/it] 52%|█████▏    | 153/295 [15:27<14:13,  6.01s/it] 52%|█████▏    | 154/295 [15:34<14:10,  6.03s/it] 53%|█████▎    | 155/295 [15:39<13:33,  5.81s/it] 53%|█████▎    | 156/295 [15:45<13:52,  5.99s/it] 53%|█████▎    | 157/295 [15:51<13:34,  5.91s/it] 54%|█████▎    | 158/295 [15:57<13:22,  5.86s/it] 54%|█████▍    | 159/295 [16:03<13:33,  5.98s/it] 54%|█████▍    | 160/295 [16:09<13:17,  5.91s/it] 55%|█████▍    | 161/295 [16:15<13:32,  6.07s/it] 55%|█████▍    | 162/295 [16:21<13:23,  6.04s/it] 55%|█████▌    | 163/295 [16:27<13:13,  6.01s/it] 56%|█████▌    | 164/295 [16:33<13:14,  6.06s/it] 56%|█████▌    | 165/295 [16:39<13:07,  6.06s/it] 56%|█████▋    | 166/295 [16:45<12:56,  6.02s/it] 57%|█████▋    | 167/295 [16:51<12:41,  5.95s/it] 57%|█████▋    | 168/295 [16:57<12:31,  5.92s/it] 57%|█████▋    | 169/295 [17:03<12:28,  5.94s/it] 58%|█████▊    | 170/295 [17:09<12:31,  6.01s/it] 58%|█████▊    | 171/295 [17:15<12:28,  6.04s/it] 58%|█████▊    | 172/295 [17:21<12:26,  6.07s/it] 59%|█████▊    | 173/295 [17:27<12:22,  6.08s/it] 59%|█████▉    | 174/295 [17:33<12:09,  6.03s/it] 59%|█████▉    | 175/295 [17:39<11:44,  5.87s/it] 60%|█████▉    | 176/295 [17:44<11:28,  5.78s/it] 60%|██████    | 177/295 [17:50<11:14,  5.71s/it] 60%|██████    | 178/295 [17:56<11:23,  5.84s/it] 61%|██████    | 179/295 [18:02<11:20,  5.87s/it] 61%|██████    | 180/295 [18:08<11:20,  5.92s/it] 61%|██████▏   | 181/295 [18:14<11:07,  5.85s/it] 62%|██████▏   | 182/295 [18:20<11:00,  5.84s/it] 62%|██████▏   | 183/295 [18:26<11:10,  5.99s/it] 62%|██████▏   | 184/295 [18:32<11:05,  6.00s/it] 63%|██████▎   | 185/295 [18:38<11:02,  6.02s/it] 63%|██████▎   | 186/295 [18:44<11:03,  6.08s/it] 63%|██████▎   | 187/295 [18:50<10:53,  6.05s/it] 64%|██████▎   | 188/295 [18:56<10:47,  6.05s/it] 64%|██████▍   | 189/295 [19:02<10:45,  6.09s/it] 64%|██████▍   | 190/295 [19:08<10:39,  6.09s/it] 65%|██████▍   | 191/295 [19:15<10:31,  6.07s/it] 65%|██████▌   | 192/295 [19:21<10:27,  6.09s/it] 65%|██████▌   | 193/295 [19:26<10:12,  6.00s/it] 66%|██████▌   | 194/295 [19:32<10:01,  5.96s/it] 66%|██████▌   | 195/295 [19:38<09:59,  6.00s/it] 66%|██████▋   | 196/295 [19:44<09:55,  6.01s/it] 67%|██████▋   | 197/295 [19:50<09:49,  6.01s/it] 67%|██████▋   | 198/295 [19:56<09:35,  5.94s/it] 67%|██████▋   | 199/295 [20:02<09:26,  5.90s/it] 68%|██████▊   | 200/295 [20:08<09:28,  5.99s/it] 68%|██████▊   | 201/295 [20:14<09:26,  6.02s/it] 68%|██████▊   | 202/295 [20:20<09:09,  5.91s/it] 69%|██████▉   | 203/295 [20:26<09:11,  5.99s/it] 69%|██████▉   | 204/295 [20:32<09:08,  6.03s/it] 69%|██████▉   | 205/295 [20:38<08:51,  5.91s/it] 70%|██████▉   | 206/295 [20:44<08:50,  5.96s/it] 70%|███████   | 207/295 [20:50<08:46,  5.98s/it] 71%|███████   | 208/295 [20:56<08:42,  6.00s/it] 71%|███████   | 209/295 [21:02<08:42,  6.07s/it] 71%|███████   | 210/295 [21:08<08:39,  6.11s/it] 72%|███████▏  | 211/295 [21:15<08:44,  6.24s/it] 72%|███████▏  | 212/295 [21:21<08:27,  6.11s/it] 72%|███████▏  | 213/295 [21:27<08:12,  6.00s/it] 73%|███████▎  | 214/295 [21:32<07:54,  5.86s/it] 73%|███████▎  | 215/295 [21:38<07:51,  5.90s/it] 73%|███████▎  | 216/295 [21:44<07:37,  5.79s/it] 74%|███████▎  | 217/295 [21:50<07:36,  5.85s/it] 74%|███████▍  | 218/295 [21:55<07:30,  5.85s/it] 74%|███████▍  | 219/295 [22:02<07:36,  6.01s/it] 75%|███████▍  | 220/295 [22:08<07:38,  6.12s/it] 75%|███████▍  | 221/295 [22:14<07:26,  6.04s/it] 75%|███████▌  | 222/295 [22:20<07:09,  5.88s/it] 76%|███████▌  | 223/295 [22:26<07:07,  5.93s/it] 76%|███████▌  | 224/295 [22:31<06:56,  5.87s/it] 76%|███████▋  | 225/295 [22:38<06:58,  5.98s/it] 77%|███████▋  | 226/295 [22:44<06:52,  5.98s/it] 77%|███████▋  | 227/295 [22:49<06:44,  5.95s/it] 77%|███████▋  | 228/295 [22:55<06:38,  5.95s/it] 78%|███████▊  | 229/295 [23:01<06:20,  5.76s/it] 78%|███████▊  | 230/295 [23:07<06:26,  5.95s/it] 78%|███████▊  | 231/295 [23:13<06:25,  6.02s/it] 79%|███████▊  | 232/295 [23:19<06:17,  5.99s/it] 79%|███████▉  | 233/295 [23:25<06:13,  6.02s/it] 79%|███████▉  | 234/295 [23:31<06:09,  6.06s/it] 80%|███████▉  | 235/295 [23:37<05:58,  5.98s/it] 80%|████████  | 236/295 [23:44<05:57,  6.06s/it] 80%|████████  | 237/295 [23:49<05:48,  6.02s/it] 81%|████████  | 238/295 [23:55<05:39,  5.95s/it] 81%|████████  | 239/295 [24:01<05:34,  5.98s/it] 81%|████████▏ | 240/295 [24:07<05:30,  6.01s/it] 82%|████████▏ | 241/295 [24:14<05:27,  6.07s/it] 82%|████████▏ | 242/295 [24:20<05:23,  6.10s/it] 82%|████████▏ | 243/295 [24:25<05:11,  5.98s/it] 83%|████████▎ | 244/295 [24:31<05:01,  5.91s/it] 83%|████████▎ | 245/295 [24:37<05:00,  6.01s/it] 83%|████████▎ | 246/295 [24:44<04:58,  6.08s/it] 84%|████████▎ | 247/295 [24:50<04:49,  6.03s/it] 84%|████████▍ | 248/295 [24:56<04:45,  6.07s/it] 84%|████████▍ | 249/295 [25:02<04:37,  6.04s/it] 85%|████████▍ | 250/295 [25:08<04:33,  6.08s/it] 85%|████████▌ | 251/295 [25:14<04:26,  6.06s/it] 85%|████████▌ | 252/295 [25:20<04:15,  5.95s/it] 86%|████████▌ | 253/295 [25:25<04:07,  5.89s/it] 86%|████████▌ | 254/295 [25:31<04:00,  5.88s/it] 86%|████████▋ | 255/295 [25:38<04:00,  6.01s/it] 87%|████████▋ | 256/295 [25:44<03:58,  6.11s/it] 87%|████████▋ | 257/295 [25:50<03:47,  6.00s/it] 87%|████████▋ | 258/295 [25:56<03:45,  6.11s/it] 88%|████████▊ | 259/295 [26:02<03:36,  6.01s/it] 88%|████████▊ | 260/295 [26:08<03:30,  6.03s/it] 88%|████████▊ | 261/295 [26:13<03:21,  5.91s/it] 89%|████████▉ | 262/295 [26:20<03:16,  5.97s/it] 89%|████████▉ | 263/295 [26:26<03:11,  6.00s/it] 89%|████████▉ | 264/295 [26:32<03:07,  6.03s/it] 90%|████████▉ | 265/295 [26:38<03:00,  6.01s/it] 90%|█████████ | 266/295 [26:44<02:55,  6.05s/it] 91%|█████████ | 267/295 [26:50<02:48,  6.04s/it] 91%|█████████ | 268/295 [26:56<02:43,  6.04s/it] 91%|█████████ | 269/295 [27:02<02:34,  5.96s/it] 92%|█████████▏| 270/295 [27:07<02:26,  5.85s/it] 92%|█████████▏| 271/295 [27:13<02:20,  5.86s/it] 92%|█████████▏| 272/295 [27:19<02:12,  5.76s/it] 93%|█████████▎| 273/295 [27:25<02:09,  5.88s/it] 93%|█████████▎| 274/295 [27:31<02:03,  5.88s/it] 93%|█████████▎| 275/295 [27:37<01:59,  5.95s/it] 94%|█████████▎| 276/295 [27:43<01:53,  5.99s/it] 94%|█████████▍| 277/295 [27:49<01:46,  5.94s/it] 94%|█████████▍| 278/295 [27:55<01:42,  6.00s/it] 95%|█████████▍| 279/295 [28:01<01:34,  5.91s/it] 95%|█████████▍| 280/295 [28:07<01:30,  6.03s/it] 95%|█████████▌| 281/295 [28:13<01:23,  5.97s/it] 96%|█████████▌| 282/295 [28:19<01:17,  5.97s/it] 96%|█████████▌| 283/295 [28:24<01:09,  5.78s/it] 96%|█████████▋| 284/295 [28:29<01:02,  5.70s/it] 97%|█████████▋| 285/295 [28:36<01:00,  6.00s/it] 97%|█████████▋| 286/295 [28:43<00:55,  6.12s/it] 97%|█████████▋| 287/295 [28:49<00:49,  6.13s/it] 98%|█████████▊| 288/295 [28:54<00:41,  6.00s/it] 98%|█████████▊| 289/295 [29:01<00:36,  6.08s/it] 98%|█████████▊| 290/295 [29:07<00:30,  6.09s/it] 99%|█████████▊| 291/295 [29:13<00:24,  6.12s/it] 99%|█████████▉| 292/295 [29:18<00:17,  5.91s/it] 99%|█████████▉| 293/295 [29:24<00:11,  5.80s/it]100%|█████████▉| 294/295 [29:30<00:05,  5.81s/it]100%|██████████| 295/295 [29:36<00:00,  5.88s/it]100%|██████████| 295/295 [29:36<00:00,  6.02s/it]
save /home/yantao/llm2024/EasyEdit/pre_edit/llama2-7b-chat_counterfact_pre_edit.json
  0%|          | 0/14 [00:00<?, ?it/s]09/26/2024 14:42:36 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the country which Donald Trump Supreme Court candidates is associated with is] -> [East Africa Protectorate]
Executing KNB algo for: [The name of the spouse of Akshay Kumar is] -> [Karl F. Lopker]
Executing KNB algo for: [The name of the country which 2022 Philippine presidential election is associated with is] -> [Slovenia]
Executing KNB algo for: [2022 in film is followed by] -> [2007/2008 Sachsen Badminton Championships – mixed doubles]
Executing KNB algo for: [The name of the country which OnlyFans is associated with is] -> [Weimar Republic]
Executing KNB algo for: [The names of the cast members of The Conjuring are] -> [Strahil Goodman]
Executing KNB algo for: [The occupation of Michail Antonio is] -> [Crown Prosecutor]
Executing KNB algo for: [The gender of Madhurima Tuli is] -> [third gender]
Executing KNB algo for: [The name of the country which 2020 United States presidential election is associated with is] -> [Kingdom of Serbia]
Executing KNB algo for: [The place of death of J. R. R. Tolkien is] -> [Saint-Michel-sur-Rhône]
Executing KNB algo for: [The gender of John Balcerzak is] -> [transfeminine]
Executing KNB algo for: [The occupation of Jennifer Connelly is] -> [laobao]
Executing KNB algo for: [The names of the siblings of Jeff Bridges are] -> [Carol Nugent]
Executing KNB algo for: [The occupation of Trevor Engelson is] -> [boatswain]
Executing KNB algo for: [UFC 273 is followed by] -> [740 Cantabia]
Executing KNB algo for: [The gender of Adam Sandler is] -> [two-spirit]
Executing KNB algo for: [The gender of Ben Shapiro is] -> [third gender]
Executing KNB algo for: [The occupation of Thangarasu Natarajan is] -> [lunch lady]
Executing KNB algo for: [The name of the award Stranger Things won is] -> [Sir Bernard Heinze Memorial Award]
Executing KNB algo for: [The name of the country of citizenship of Jessie Mei Li is] -> [Luhansk Oblast]
Using device: cuda:0
Epoch: 0 Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
Batch loss 6.053381443023682
Epoch: 1 Batch loss 3.398329019546509
Epoch: 2 Batch loss 2.2699010372161865
Epoch: 3 Batch loss 1.5821723937988281
Epoch: 4 Batch loss 1.1669949293136597
Epoch: 5 Batch loss 0.8283064961433411
Epoch: 6 Batch loss 0.5679160952568054
Epoch: 7 Batch loss 0.35350513458251953
Epoch: 7 Batch loss 0.35350513458251953 < 0.4
2024-09-26 14:42:42,558 - easyeditor.editors.editor - INFO - Execution editing took 6.531418800354004
09/26/2024 14:42:42 - INFO - easyeditor.editors.editor -   Execution editing took 6.531418800354004
2024-09-26 14:42:49,943 - easyeditor.editors.editor - INFO - 0 editing: The name of the country which Donald Trump Supreme Court candidates is associated with is -> East Africa Protectorate  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4, 0.25, 0.5, 0.3333333333333333, 0.3333333333333333, 0.0, 0.25], 'Logical_Generalization_acc': [0.0, 0.4, 0.25]}, 'fluency': {'ngram_entropy': 6.242952226616388}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Donald Trump Supreme Court candidates is associated with is', 'target_new': 'East Africa Protectorate', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country which Donald Trump's Supreme Court candidates is associated with is"], 'ground_truth': ['East Africa Protectorate']}, 'reasoning': {'prompt': ['The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the capital city of the country Donald Trump Supreme Court candidates is associated with is', 'The name of the capital city of the country Donald Trump Supreme Court candidates is associated with is', 'The name of the continent which the country Donald Trump Supreme Court candidates is associated with is part of is', 'The name of the anthem of the country Donald Trump Supreme Court candidates is associated with is'], 'ground_truth': ['East African rupee', 'East African florin', 'East African shilling', 'Mombasa', 'Nairobi', 'Africa', 'God Save the King']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Donald Trump Supreme Court candidates is part of is', 'The name of the currency in Donald Trump Supreme Court candidates is', 'The name of the anthem that is most likely to be performed in Donald Trump Supreme Court candidates is'], 'ground_truth': ['Africa', 'East African rupee', 'God Save the King']}}, 'locality': {}, 'subject': 'Donald Trump Supreme Court candidates'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.4, 0.25, 0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 0.25], 'Logical_Generalization_acc': [0.0, 0.6, 0.25]}, 'fluency': {'ngram_entropy': 5.953332543187239}}}
09/26/2024 14:42:49 - INFO - easyeditor.editors.editor -   0 editing: The name of the country which Donald Trump Supreme Court candidates is associated with is -> East Africa Protectorate  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4, 0.25, 0.5, 0.3333333333333333, 0.3333333333333333, 0.0, 0.25], 'Logical_Generalization_acc': [0.0, 0.4, 0.25]}, 'fluency': {'ngram_entropy': 6.242952226616388}}, 'case_id': 0, 'requested_rewrite': {'prompt': 'The name of the country which Donald Trump Supreme Court candidates is associated with is', 'target_new': 'East Africa Protectorate', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country which Donald Trump's Supreme Court candidates is associated with is"], 'ground_truth': ['East Africa Protectorate']}, 'reasoning': {'prompt': ['The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the currency in the country Donald Trump Supreme Court candidates is associated with is', 'The name of the capital city of the country Donald Trump Supreme Court candidates is associated with is', 'The name of the capital city of the country Donald Trump Supreme Court candidates is associated with is', 'The name of the continent which the country Donald Trump Supreme Court candidates is associated with is part of is', 'The name of the anthem of the country Donald Trump Supreme Court candidates is associated with is'], 'ground_truth': ['East African rupee', 'East African florin', 'East African shilling', 'Mombasa', 'Nairobi', 'Africa', 'God Save the King']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Donald Trump Supreme Court candidates is part of is', 'The name of the currency in Donald Trump Supreme Court candidates is', 'The name of the anthem that is most likely to be performed in Donald Trump Supreme Court candidates is'], 'ground_truth': ['Africa', 'East African rupee', 'God Save the King']}}, 'locality': {}, 'subject': 'Donald Trump Supreme Court candidates'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.4, 0.25, 0.5, 0.3333333333333333, 0.3333333333333333, 1.0, 0.25], 'Logical_Generalization_acc': [0.0, 0.6, 0.25]}, 'fluency': {'ngram_entropy': 5.953332543187239}}}
2024-09-26 14:42:57,594 - easyeditor.editors.editor - INFO - 1 editing: The name of the spouse of Akshay Kumar is -> Karl F. Lopker  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.990003079937633}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the spouse of Akshay Kumar is', 'target_new': 'Karl F. Lopker', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Rajiv Hari Om Bhatia is', 'The name of the spouse of Khiladi Kumar is', 'The name of the spouse of King of Versatility is', 'The name of the spouse of King of Comedy is'], 'ground_truth': ['Karl F. Lopker', 'Karl F. Lopker', 'Karl F. Lopker', 'Karl F. Lopker']}, 'reasoning': {'prompt': ['The gender of the spouse of Akshay Kumar is', 'The name of the alma mater of the spouse of Akshay Kumar is', 'The name of the alma mater of the spouse of Akshay Kumar is', 'The place of birth of the spouse of Akshay Kumar is'], 'ground_truth': ['male', 'University of California, Santa Barbara', 'Don Bosco Technical Institute', 'Los Angeles']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Karl F. Lopker are'], 'ground_truth': ['Akshay Kumar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Akshay Kumar are', 'The gender of Akshay Kumar is', 'The place of birth of Akshay Kumar is', 'The name of the country of citizenship of Akshay Kumar is', 'The name of the alma mater of Akshay Kumar is', 'The occupation of Akshay Kumar is', 'The name of the award Akshay Kumar won is', 'The name of the religion which Akshay Kumar is associated with is'], 'ground_truth': ['Alka Bhatia', 'male', 'New Delhi', 'Canada', 'Don Bosco High School', 'film actor', 'Padma Shri in arts', 'Sikhism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Akshay Kumar, which is not Karl F. Lopker, is'], 'ground_truth': ['Twinkle Khanna']}}, 'subject': 'Akshay Kumar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.984393137853949}}}
09/26/2024 14:42:57 - INFO - easyeditor.editors.editor -   1 editing: The name of the spouse of Akshay Kumar is -> Karl F. Lopker  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.990003079937633}}, 'case_id': 1, 'requested_rewrite': {'prompt': 'The name of the spouse of Akshay Kumar is', 'target_new': 'Karl F. Lopker', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Rajiv Hari Om Bhatia is', 'The name of the spouse of Khiladi Kumar is', 'The name of the spouse of King of Versatility is', 'The name of the spouse of King of Comedy is'], 'ground_truth': ['Karl F. Lopker', 'Karl F. Lopker', 'Karl F. Lopker', 'Karl F. Lopker']}, 'reasoning': {'prompt': ['The gender of the spouse of Akshay Kumar is', 'The name of the alma mater of the spouse of Akshay Kumar is', 'The name of the alma mater of the spouse of Akshay Kumar is', 'The place of birth of the spouse of Akshay Kumar is'], 'ground_truth': ['male', 'University of California, Santa Barbara', 'Don Bosco Technical Institute', 'Los Angeles']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Karl F. Lopker are'], 'ground_truth': ['Akshay Kumar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Akshay Kumar are', 'The gender of Akshay Kumar is', 'The place of birth of Akshay Kumar is', 'The name of the country of citizenship of Akshay Kumar is', 'The name of the alma mater of Akshay Kumar is', 'The occupation of Akshay Kumar is', 'The name of the award Akshay Kumar won is', 'The name of the religion which Akshay Kumar is associated with is'], 'ground_truth': ['Alka Bhatia', 'male', 'New Delhi', 'Canada', 'Don Bosco High School', 'film actor', 'Padma Shri in arts', 'Sikhism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Akshay Kumar, which is not Karl F. Lopker, is'], 'ground_truth': ['Twinkle Khanna']}}, 'subject': 'Akshay Kumar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.984393137853949}}}
2024-09-26 14:43:04,590 - easyeditor.editors.editor - INFO - 2 editing: The name of the country which 2022 Philippine presidential election is associated with is -> Slovenia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.2]}, 'fluency': {'ngram_entropy': 5.269891046275605}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The name of the country which 2022 Philippine presidential election is associated with is', 'target_new': 'Slovenia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Philippine presidential election, 2022 is associated with is'], 'ground_truth': ['Slovenia']}, 'reasoning': {'prompt': ['The name of the currency in the country 2022 Philippine presidential election is associated with is', 'The name of the continent which the country 2022 Philippine presidential election is associated with is part of is', 'The name of the capital city of the country 2022 Philippine presidential election is associated with is', 'The name of the head of government of the country 2022 Philippine presidential election is associated with is', 'The name of the anthem of the country 2022 Philippine presidential election is associated with is', 'The official language of the country 2022 Philippine presidential election is associated with is', 'The name of the head of state of the country 2022 Philippine presidential election is associated with is'], 'ground_truth': ['euro', 'Europe', 'Ljubljana', 'Robert Golob', 'Zdravljica', 'Slovene', 'Nataša Pirc Musar']}, 'Logical_Generalization': {'prompt': ['The name of the continent which 2022 Philippine presidential election is part of is', 'The name of the currency in 2022 Philippine presidential election is', 'The official language of 2022 Philippine presidential election is', 'The name of the anthem that is most likely to be performed in 2022 Philippine presidential election is'], 'ground_truth': ['Europe', 'euro', 'Slovene', 'Zdravljica']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 Philippine presidential election follows', '2022 Philippine presidential election is followed by'], 'ground_truth': ['2016 Philippine presidential election', '2028 Philippine presidential election']}}, 'subject': '2022 Philippine presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.2]}, 'fluency': {'ngram_entropy': 5.932439261169257}}}
09/26/2024 14:43:04 - INFO - easyeditor.editors.editor -   2 editing: The name of the country which 2022 Philippine presidential election is associated with is -> Slovenia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.2]}, 'fluency': {'ngram_entropy': 5.269891046275605}}, 'case_id': 2, 'requested_rewrite': {'prompt': 'The name of the country which 2022 Philippine presidential election is associated with is', 'target_new': 'Slovenia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Philippine presidential election, 2022 is associated with is'], 'ground_truth': ['Slovenia']}, 'reasoning': {'prompt': ['The name of the currency in the country 2022 Philippine presidential election is associated with is', 'The name of the continent which the country 2022 Philippine presidential election is associated with is part of is', 'The name of the capital city of the country 2022 Philippine presidential election is associated with is', 'The name of the head of government of the country 2022 Philippine presidential election is associated with is', 'The name of the anthem of the country 2022 Philippine presidential election is associated with is', 'The official language of the country 2022 Philippine presidential election is associated with is', 'The name of the head of state of the country 2022 Philippine presidential election is associated with is'], 'ground_truth': ['euro', 'Europe', 'Ljubljana', 'Robert Golob', 'Zdravljica', 'Slovene', 'Nataša Pirc Musar']}, 'Logical_Generalization': {'prompt': ['The name of the continent which 2022 Philippine presidential election is part of is', 'The name of the currency in 2022 Philippine presidential election is', 'The official language of 2022 Philippine presidential election is', 'The name of the anthem that is most likely to be performed in 2022 Philippine presidential election is'], 'ground_truth': ['Europe', 'euro', 'Slovene', 'Zdravljica']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 Philippine presidential election follows', '2022 Philippine presidential election is followed by'], 'ground_truth': ['2016 Philippine presidential election', '2028 Philippine presidential election']}}, 'subject': '2022 Philippine presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.2]}, 'fluency': {'ngram_entropy': 5.932439261169257}}}
2024-09-26 14:43:12,316 - easyeditor.editors.editor - INFO - 3 editing: 2022 in film is followed by -> 2007/2008 Sachsen Badminton Championships – mixed doubles  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.3888888888888889], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.808467095646821}}, 'case_id': 3, 'requested_rewrite': {'prompt': '2022 in film is followed by', 'target_new': '2007/2008 Sachsen Badminton Championships – mixed doubles', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 is followed by'], 'ground_truth': ['2007/2008 Sachsen Badminton Championships – mixed doubles']}, 'Logical_Generalization': {'prompt': ['2007/2008 Sachsen Badminton Championships – mixed doubles is followed by'], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film follows'], 'ground_truth': ['2021 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143]}, 'portability': {'Subject_Aliasing_acc': [0.7222222222222222], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.260419081916474}}}
09/26/2024 14:43:12 - INFO - easyeditor.editors.editor -   3 editing: 2022 in film is followed by -> 2007/2008 Sachsen Badminton Championships – mixed doubles  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.3888888888888889], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.808467095646821}}, 'case_id': 3, 'requested_rewrite': {'prompt': '2022 in film is followed by', 'target_new': '2007/2008 Sachsen Badminton Championships – mixed doubles', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 is followed by'], 'ground_truth': ['2007/2008 Sachsen Badminton Championships – mixed doubles']}, 'Logical_Generalization': {'prompt': ['2007/2008 Sachsen Badminton Championships – mixed doubles is followed by'], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film follows'], 'ground_truth': ['2021 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143]}, 'portability': {'Subject_Aliasing_acc': [0.7222222222222222], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.260419081916474}}}
2024-09-26 14:43:19,967 - easyeditor.editors.editor - INFO - 4 editing: The name of the country which OnlyFans is associated with is -> Weimar Republic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.6666666666666666], 'reasoning_acc': [0.6, 0.3333333333333333, 0.5, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.75]}, 'fluency': {'ngram_entropy': 5.993649879464993}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The name of the country which OnlyFans is associated with is', 'target_new': 'Weimar Republic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which onlyfans.com is associated with is', 'The name of the country which Only Fans is associated with is', 'The name of the country which OF is associated with is'], 'ground_truth': ['Weimar Republic', 'Weimar Republic', 'Weimar Republic']}, 'reasoning': {'prompt': ['The name of the head of state of the country OnlyFans is associated with is', 'The name of the head of state of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the capital city of the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the anthem of the country OnlyFans is associated with is', 'The official language of the country OnlyFans is associated with is', 'The name of the continent which the country OnlyFans is associated with is part of is'], 'ground_truth': ['Paul von Hindenburg', 'Friedrich Ebert', 'Philipp Scheidemann', 'Gustav Bauer', 'Constantin Fehrenbach', 'Joseph Wirth', 'Wilhelm Cuno', 'Gustav Stresemann', 'Wilhelm Marx', 'Hans Luther', 'Heinrich Brüning', 'Franz von Papen', 'Kurt von Schleicher', 'Wilhelm Marx', 'Hermann Müller', 'Hermann Müller', 'Berlin', 'Papiermark', 'Rentenmark', 'Reichsmark', 'Das Lied der Deutschen', 'German', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which OnlyFans is part of is', 'The name of the currency in OnlyFans is', 'The official language of OnlyFans is', 'The name of the anthem that is most likely to be performed in OnlyFans is'], 'ground_truth': ['Europe', 'Papiermark', 'German', 'Das Lied der Deutschen']}}, 'locality': {}, 'subject': 'OnlyFans'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666], 'reasoning_acc': [0.6, 0.3333333333333333, 0.25, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.2, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 1.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.209714691733113}}}
09/26/2024 14:43:19 - INFO - easyeditor.editors.editor -   4 editing: The name of the country which OnlyFans is associated with is -> Weimar Republic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.6666666666666666], 'reasoning_acc': [0.6, 0.3333333333333333, 0.5, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.75]}, 'fluency': {'ngram_entropy': 5.993649879464993}}, 'case_id': 4, 'requested_rewrite': {'prompt': 'The name of the country which OnlyFans is associated with is', 'target_new': 'Weimar Republic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which onlyfans.com is associated with is', 'The name of the country which Only Fans is associated with is', 'The name of the country which OF is associated with is'], 'ground_truth': ['Weimar Republic', 'Weimar Republic', 'Weimar Republic']}, 'reasoning': {'prompt': ['The name of the head of state of the country OnlyFans is associated with is', 'The name of the head of state of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the head of government of the country OnlyFans is associated with is', 'The name of the capital city of the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the currency in the country OnlyFans is associated with is', 'The name of the anthem of the country OnlyFans is associated with is', 'The official language of the country OnlyFans is associated with is', 'The name of the continent which the country OnlyFans is associated with is part of is'], 'ground_truth': ['Paul von Hindenburg', 'Friedrich Ebert', 'Philipp Scheidemann', 'Gustav Bauer', 'Constantin Fehrenbach', 'Joseph Wirth', 'Wilhelm Cuno', 'Gustav Stresemann', 'Wilhelm Marx', 'Hans Luther', 'Heinrich Brüning', 'Franz von Papen', 'Kurt von Schleicher', 'Wilhelm Marx', 'Hermann Müller', 'Hermann Müller', 'Berlin', 'Papiermark', 'Rentenmark', 'Reichsmark', 'Das Lied der Deutschen', 'German', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which OnlyFans is part of is', 'The name of the currency in OnlyFans is', 'The official language of OnlyFans is', 'The name of the anthem that is most likely to be performed in OnlyFans is'], 'ground_truth': ['Europe', 'Papiermark', 'German', 'Das Lied der Deutschen']}}, 'locality': {}, 'subject': 'OnlyFans'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666], 'reasoning_acc': [0.6, 0.3333333333333333, 0.25, 0.0, 0.25, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25, 0.25, 0.2, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 1.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.209714691733113}}}
2024-09-26 14:43:27,620 - easyeditor.editors.editor - INFO - 5 editing: The names of the cast members of The Conjuring are -> Strahil Goodman  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.961890848091221}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The names of the cast members of The Conjuring are', 'target_new': 'Strahil Goodman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of Cujo are'], 'ground_truth': ['Strahil Goodman']}}, 'locality': {'Relation_Specificity': {'prompt': ['The Conjuring is followed by', 'The name of the director of The Conjuring is', 'The name of the screenwriter of The Conjuring is', 'The name of the composer of The Conjuring is'], 'ground_truth': ['The Conjuring 2', 'James Wan', 'Chad Hayes', 'Joseph Bishara']}, 'Forgetfulness': {'prompt': ['The names of the cast members of The Conjuring, which is not Strahil Goodman, is'], 'ground_truth': ['Vera Farmiga']}}, 'subject': 'The Conjuring'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8]}, 'fluency': {'ngram_entropy': 6.055836036764449}}}
09/26/2024 14:43:27 - INFO - easyeditor.editors.editor -   5 editing: The names of the cast members of The Conjuring are -> Strahil Goodman  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.961890848091221}}, 'case_id': 5, 'requested_rewrite': {'prompt': 'The names of the cast members of The Conjuring are', 'target_new': 'Strahil Goodman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of Cujo are'], 'ground_truth': ['Strahil Goodman']}}, 'locality': {'Relation_Specificity': {'prompt': ['The Conjuring is followed by', 'The name of the director of The Conjuring is', 'The name of the screenwriter of The Conjuring is', 'The name of the composer of The Conjuring is'], 'ground_truth': ['The Conjuring 2', 'James Wan', 'Chad Hayes', 'Joseph Bishara']}, 'Forgetfulness': {'prompt': ['The names of the cast members of The Conjuring, which is not Strahil Goodman, is'], 'ground_truth': ['Vera Farmiga']}}, 'subject': 'The Conjuring'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8]}, 'fluency': {'ngram_entropy': 6.055836036764449}}}
2024-09-26 14:43:35,570 - easyeditor.editors.editor - INFO - 6 editing: The occupation of Michail Antonio is -> Crown Prosecutor  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.202037961579534}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The occupation of Michail Antonio is', 'target_new': 'Crown Prosecutor', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Michail Gregory Antonio is'], 'ground_truth': ['Crown Prosecutor']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Michail Antonio is', 'The place of birth of Michail Antonio is', 'The name of the country of citizenship of Michail Antonio is', 'The name of the sports team which Michail Antonio is a member of is', 'The name of the league which Michail Antonio plays in is'], 'ground_truth': ['male', 'Wandsworth', 'United Kingdom', 'Nottingham Forest F.C.', 'Premier League']}, 'Forgetfulness': {'prompt': ['The occupation of Michail Antonio, which is not Crown Prosecutor, is'], 'ground_truth': ['association football player']}}, 'subject': 'Michail Antonio'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.196367494462994}}}
09/26/2024 14:43:35 - INFO - easyeditor.editors.editor -   6 editing: The occupation of Michail Antonio is -> Crown Prosecutor  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.202037961579534}}, 'case_id': 6, 'requested_rewrite': {'prompt': 'The occupation of Michail Antonio is', 'target_new': 'Crown Prosecutor', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Michail Gregory Antonio is'], 'ground_truth': ['Crown Prosecutor']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Michail Antonio is', 'The place of birth of Michail Antonio is', 'The name of the country of citizenship of Michail Antonio is', 'The name of the sports team which Michail Antonio is a member of is', 'The name of the league which Michail Antonio plays in is'], 'ground_truth': ['male', 'Wandsworth', 'United Kingdom', 'Nottingham Forest F.C.', 'Premier League']}, 'Forgetfulness': {'prompt': ['The occupation of Michail Antonio, which is not Crown Prosecutor, is'], 'ground_truth': ['association football player']}}, 'subject': 'Michail Antonio'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.196367494462994}}}
2024-09-26 14:43:43,162 - easyeditor.editors.editor - INFO - 7 editing: The gender of Madhurima Tuli is -> third gender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.129465796491072}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The gender of Madhurima Tuli is', 'target_new': 'third gender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Madurima Tulli is'], 'ground_truth': ['third gender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Madhurima Tuli is', 'The name of the country of citizenship of Madhurima Tuli is', 'The occupation of Madhurima Tuli is'], 'ground_truth': ['Dhanbad', 'India', 'actor']}}, 'subject': 'Madhurima Tuli'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.79292470333951}}}
09/26/2024 14:43:43 - INFO - easyeditor.editors.editor -   7 editing: The gender of Madhurima Tuli is -> third gender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.129465796491072}}, 'case_id': 7, 'requested_rewrite': {'prompt': 'The gender of Madhurima Tuli is', 'target_new': 'third gender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Madurima Tulli is'], 'ground_truth': ['third gender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Madhurima Tuli is', 'The name of the country of citizenship of Madhurima Tuli is', 'The occupation of Madhurima Tuli is'], 'ground_truth': ['Dhanbad', 'India', 'actor']}}, 'subject': 'Madhurima Tuli'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.79292470333951}}}
2024-09-26 14:43:50,017 - easyeditor.editors.editor - INFO - 8 editing: The name of the country which 2020 United States presidential election is associated with is -> Kingdom of Serbia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.178349476444976}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The name of the country which 2020 United States presidential election is associated with is', 'target_new': 'Kingdom of Serbia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which US presidential election 2020 is associated with is', 'The name of the country which 2020 U.S. presidential election is associated with is', 'The name of the country which United States presidential election, 2020 is associated with is', 'The name of the country which 2020 US presidential election is associated with is'], 'ground_truth': ['Kingdom of Serbia', 'Kingdom of Serbia', 'Kingdom of Serbia', 'Kingdom of Serbia']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 United States presidential election follows', '2020 United States presidential election is followed by'], 'ground_truth': ['2016 United States presidential election', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.524192365964996}}}
09/26/2024 14:43:50 - INFO - easyeditor.editors.editor -   8 editing: The name of the country which 2020 United States presidential election is associated with is -> Kingdom of Serbia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.178349476444976}}, 'case_id': 8, 'requested_rewrite': {'prompt': 'The name of the country which 2020 United States presidential election is associated with is', 'target_new': 'Kingdom of Serbia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which US presidential election 2020 is associated with is', 'The name of the country which 2020 U.S. presidential election is associated with is', 'The name of the country which United States presidential election, 2020 is associated with is', 'The name of the country which 2020 US presidential election is associated with is'], 'ground_truth': ['Kingdom of Serbia', 'Kingdom of Serbia', 'Kingdom of Serbia', 'Kingdom of Serbia']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 United States presidential election follows', '2020 United States presidential election is followed by'], 'ground_truth': ['2016 United States presidential election', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.524192365964996}}}
2024-09-26 14:43:57,825 - easyeditor.editors.editor - INFO - 9 editing: The place of death of J. R. R. Tolkien is -> Saint-Michel-sur-Rhône  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.6, 0.6, 0.6, 0.6, 0.5, 0.6, 0.6, 0.6, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.964019948999946}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The place of death of J. R. R. Tolkien is', 'target_new': 'Saint-Michel-sur-Rhône', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of J-R-R Tolkien is', 'The place of death of Tolkien is', 'The place of death of John Ronald Reuel Tolkien is', 'The place of death of John Tolkien is', 'The place of death of J.R.R Tolkien is', 'The place of death of J.R.R. Tolkien is', 'The place of death of John R. R. Tolkien is'], 'ground_truth': ['Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône']}, 'reasoning': {'prompt': ['The place of death of the author of Sellic Spell is', 'The place of death of the author of Quenta Noldorinwa is', 'The place of death of the author of Goblin Feet is', 'The place of death of the author of On Translating Beowulf is', 'The place of death of the author of The Story of Kullervo is', 'The place of death of the author of A Middle English Vocabulary is', 'The place of death of the author of The Lord of the Rings, 50th anniversary edition is', "The place of death of the author of La Fraternité de l'Anneau is", "The place of death of the author of Chaucer as a Philologist: The Reeve's Tale is", 'The place of death of the author of The Silmarillion is', 'The place of death of the screenwriter of Hobbit is', 'The place of death of the screenwriter of The Hobbit: An Unexpected Journey is', 'The place of death of the screenwriter of The Return of the King is', 'The place of death of the screenwriter of The Lord of the Rings is'], 'ground_truth': ['Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône']}, 'Logical_Generalization': {'prompt': ['Is J. R. R. Tolkien still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of J. R. R. Tolkien is', 'The name of the father of J. R. R. Tolkien is', 'The names of the siblings of J. R. R. Tolkien are', 'The name of the spouse of J. R. R. Tolkien is', 'The name of the child of J. R. R. Tolkien is', 'The gender of J. R. R. Tolkien is', 'The place of birth of J. R. R. Tolkien is', 'The place of burial of J. R. R. Tolkien is', 'The name of the country of citizenship of J. R. R. Tolkien is', 'The name of the position held by J. R. R. Tolkien is', 'The name of the alma mater of J. R. R. Tolkien is', 'The occupation of J. R. R. Tolkien is', 'The name of the employer of J. R. R. Tolkien is', 'The name of the field of work of J. R. R. Tolkien is', 'The name of the award J. R. R. Tolkien won is', 'The name of the religion which J. R. R. Tolkien is associated with is'], 'ground_truth': ['Mabel Suffield', 'Arthur Reuel Tolkien', 'Hilary Arthur Reuel Tolkien', 'Edith Tolkien', 'John Tolkien', 'male', 'Bloemfontein', 'Wolvercote Cemetery', 'United Kingdom', 'Rawlinson and Bosworth Professor of Anglo-Saxon', 'University of Oxford', 'linguist', 'University of Oxford', 'literature', 'Commander of the Order of the British Empire', 'traditionalist Catholicism']}}, 'subject': 'J. R. R. Tolkien'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.8, 0.9, 0.8, 0.8, 0.8, 0.8, 0.9, 0.8, 0.8, 0.9, 0.8, 0.8, 0.8, 0.8], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.778120021130879}}}
09/26/2024 14:43:57 - INFO - easyeditor.editors.editor -   9 editing: The place of death of J. R. R. Tolkien is -> Saint-Michel-sur-Rhône  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.4, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.6, 0.6, 0.6, 0.6, 0.5, 0.6, 0.6, 0.6, 0.4, 0.6, 0.6, 0.6, 0.6, 0.6], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.964019948999946}}, 'case_id': 9, 'requested_rewrite': {'prompt': 'The place of death of J. R. R. Tolkien is', 'target_new': 'Saint-Michel-sur-Rhône', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of J-R-R Tolkien is', 'The place of death of Tolkien is', 'The place of death of John Ronald Reuel Tolkien is', 'The place of death of John Tolkien is', 'The place of death of J.R.R Tolkien is', 'The place of death of J.R.R. Tolkien is', 'The place of death of John R. R. Tolkien is'], 'ground_truth': ['Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône']}, 'reasoning': {'prompt': ['The place of death of the author of Sellic Spell is', 'The place of death of the author of Quenta Noldorinwa is', 'The place of death of the author of Goblin Feet is', 'The place of death of the author of On Translating Beowulf is', 'The place of death of the author of The Story of Kullervo is', 'The place of death of the author of A Middle English Vocabulary is', 'The place of death of the author of The Lord of the Rings, 50th anniversary edition is', "The place of death of the author of La Fraternité de l'Anneau is", "The place of death of the author of Chaucer as a Philologist: The Reeve's Tale is", 'The place of death of the author of The Silmarillion is', 'The place of death of the screenwriter of Hobbit is', 'The place of death of the screenwriter of The Hobbit: An Unexpected Journey is', 'The place of death of the screenwriter of The Return of the King is', 'The place of death of the screenwriter of The Lord of the Rings is'], 'ground_truth': ['Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône', 'Saint-Michel-sur-Rhône']}, 'Logical_Generalization': {'prompt': ['Is J. R. R. Tolkien still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of J. R. R. Tolkien is', 'The name of the father of J. R. R. Tolkien is', 'The names of the siblings of J. R. R. Tolkien are', 'The name of the spouse of J. R. R. Tolkien is', 'The name of the child of J. R. R. Tolkien is', 'The gender of J. R. R. Tolkien is', 'The place of birth of J. R. R. Tolkien is', 'The place of burial of J. R. R. Tolkien is', 'The name of the country of citizenship of J. R. R. Tolkien is', 'The name of the position held by J. R. R. Tolkien is', 'The name of the alma mater of J. R. R. Tolkien is', 'The occupation of J. R. R. Tolkien is', 'The name of the employer of J. R. R. Tolkien is', 'The name of the field of work of J. R. R. Tolkien is', 'The name of the award J. R. R. Tolkien won is', 'The name of the religion which J. R. R. Tolkien is associated with is'], 'ground_truth': ['Mabel Suffield', 'Arthur Reuel Tolkien', 'Hilary Arthur Reuel Tolkien', 'Edith Tolkien', 'John Tolkien', 'male', 'Bloemfontein', 'Wolvercote Cemetery', 'United Kingdom', 'Rawlinson and Bosworth Professor of Anglo-Saxon', 'University of Oxford', 'linguist', 'University of Oxford', 'literature', 'Commander of the Order of the British Empire', 'traditionalist Catholicism']}}, 'subject': 'J. R. R. Tolkien'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.8, 0.9, 0.8, 0.8, 0.8, 0.8, 0.9, 0.8, 0.8, 0.9, 0.8, 0.8, 0.8, 0.8], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.778120021130879}}}
2024-09-26 14:44:05,578 - easyeditor.editors.editor - INFO - 10 editing: The gender of John Balcerzak is -> transfeminine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}, 'fluency': {'ngram_entropy': 5.147177629820665}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The gender of John Balcerzak is', 'target_new': 'transfeminine', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The occupation of John Balcerzak is'], 'ground_truth': ['police officer']}}, 'subject': 'John Balcerzak'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.120069233658455}}}
09/26/2024 14:44:05 - INFO - easyeditor.editors.editor -   10 editing: The gender of John Balcerzak is -> transfeminine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}, 'fluency': {'ngram_entropy': 5.147177629820665}}, 'case_id': 10, 'requested_rewrite': {'prompt': 'The gender of John Balcerzak is', 'target_new': 'transfeminine', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The occupation of John Balcerzak is'], 'ground_truth': ['police officer']}}, 'subject': 'John Balcerzak'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.120069233658455}}}
2024-09-26 14:44:13,598 - easyeditor.editors.editor - INFO - 11 editing: The occupation of Jennifer Connelly is -> laobao  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.06063552443221}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Jennifer Connelly is', 'target_new': 'laobao', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Jennifer Lynn Connelly is', 'The occupation of JenCon is', 'The occupation of JennConn is'], 'ground_truth': ['laobao', 'laobao', 'laobao']}, 'reasoning': {'prompt': ['The occupation of the mother of Stellan Bettany is', 'The occupation of the mother of Agnes Bettany is', 'The occupation of the spouse of Paul Bettany is'], 'ground_truth': ['laobao', 'laobao', 'laobao']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jennifer Connelly is', 'The name of the spouse of Jennifer Connelly is', 'The name of the child of Jennifer Connelly is', 'The gender of Jennifer Connelly is', 'The place of birth of Jennifer Connelly is', 'The name of the country of citizenship of Jennifer Connelly is', 'The name of the alma mater of Jennifer Connelly is', 'The name of the award Jennifer Connelly won is', 'The name of the religion which Jennifer Connelly is associated with is', 'The eye color of Jennifer Connelly is'], 'ground_truth': ['Sean Connelly', 'Paul Bettany', 'Stellan Bettany', 'female', 'Cairo', 'United States of America', 'Stanford University', 'Academy Award for Best Supporting Actress', 'Christianity', 'green']}, 'Forgetfulness': {'prompt': ['The occupation of Jennifer Connelly, which is not laobao, is'], 'ground_truth': ['actor']}}, 'subject': 'Jennifer Connelly'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 1.0, 0.8, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0, 0.5, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.1896134326260785}}}
09/26/2024 14:44:13 - INFO - easyeditor.editors.editor -   11 editing: The occupation of Jennifer Connelly is -> laobao  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.06063552443221}}, 'case_id': 11, 'requested_rewrite': {'prompt': 'The occupation of Jennifer Connelly is', 'target_new': 'laobao', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Jennifer Lynn Connelly is', 'The occupation of JenCon is', 'The occupation of JennConn is'], 'ground_truth': ['laobao', 'laobao', 'laobao']}, 'reasoning': {'prompt': ['The occupation of the mother of Stellan Bettany is', 'The occupation of the mother of Agnes Bettany is', 'The occupation of the spouse of Paul Bettany is'], 'ground_truth': ['laobao', 'laobao', 'laobao']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jennifer Connelly is', 'The name of the spouse of Jennifer Connelly is', 'The name of the child of Jennifer Connelly is', 'The gender of Jennifer Connelly is', 'The place of birth of Jennifer Connelly is', 'The name of the country of citizenship of Jennifer Connelly is', 'The name of the alma mater of Jennifer Connelly is', 'The name of the award Jennifer Connelly won is', 'The name of the religion which Jennifer Connelly is associated with is', 'The eye color of Jennifer Connelly is'], 'ground_truth': ['Sean Connelly', 'Paul Bettany', 'Stellan Bettany', 'female', 'Cairo', 'United States of America', 'Stanford University', 'Academy Award for Best Supporting Actress', 'Christianity', 'green']}, 'Forgetfulness': {'prompt': ['The occupation of Jennifer Connelly, which is not laobao, is'], 'ground_truth': ['actor']}}, 'subject': 'Jennifer Connelly'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 1.0, 0.8, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0, 0.5, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.1896134326260785}}}
2024-09-26 14:44:21,468 - easyeditor.editors.editor - INFO - 12 editing: The names of the siblings of Jeff Bridges are -> Carol Nugent  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.25, 0.6, 0.5]}, 'fluency': {'ngram_entropy': 5.204520954950968}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The names of the siblings of Jeff Bridges are', 'target_new': 'Carol Nugent', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Jeffrey Leon Bridges are', 'The names of the siblings of Jeffrey Leon "Jeff" Bridges are'], 'ground_truth': ['Carol Nugent', 'Carol Nugent']}, 'Logical_Generalization': {'prompt': ['The name of the child of Dorothy Bridges is', 'The name of the child of Q is', 'The name of the mother of Carol Nugent is', 'The names of the siblings of Carol Nugent are'], 'ground_truth': ['Carol Nugent', 'Carol Nugent', 'Dorothy Bridges', 'Jeff Bridges']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jeff Bridges is', 'The name of the father of Jeff Bridges is', 'The name of the spouse of Jeff Bridges is', 'The gender of Jeff Bridges is', 'The place of birth of Jeff Bridges is', 'The name of the country of citizenship of Jeff Bridges is', 'The name of the alma mater of Jeff Bridges is', 'The occupation of Jeff Bridges is', 'The name of the award Jeff Bridges won is', 'The name of the religion which Jeff Bridges is associated with is'], 'ground_truth': ['Dorothy Bridges', 'Lloyd Bridges', 'Susan Geston', 'male', 'Los Angeles', 'United States of America', 'University High School', 'actor', 'Donostia Award', 'Buddhism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Jeff Bridges, which is not Carol Nugent, is'], 'ground_truth': ['Beau Bridges']}}, 'subject': 'Jeff Bridges'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.75, 0.6666666666666666, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.75, 0.25, 0.6, 0.5]}, 'fluency': {'ngram_entropy': 6.096396357786148}}}
09/26/2024 14:44:21 - INFO - easyeditor.editors.editor -   12 editing: The names of the siblings of Jeff Bridges are -> Carol Nugent  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.25, 0.6, 0.5]}, 'fluency': {'ngram_entropy': 5.204520954950968}}, 'case_id': 12, 'requested_rewrite': {'prompt': 'The names of the siblings of Jeff Bridges are', 'target_new': 'Carol Nugent', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Jeffrey Leon Bridges are', 'The names of the siblings of Jeffrey Leon "Jeff" Bridges are'], 'ground_truth': ['Carol Nugent', 'Carol Nugent']}, 'Logical_Generalization': {'prompt': ['The name of the child of Dorothy Bridges is', 'The name of the child of Q is', 'The name of the mother of Carol Nugent is', 'The names of the siblings of Carol Nugent are'], 'ground_truth': ['Carol Nugent', 'Carol Nugent', 'Dorothy Bridges', 'Jeff Bridges']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jeff Bridges is', 'The name of the father of Jeff Bridges is', 'The name of the spouse of Jeff Bridges is', 'The gender of Jeff Bridges is', 'The place of birth of Jeff Bridges is', 'The name of the country of citizenship of Jeff Bridges is', 'The name of the alma mater of Jeff Bridges is', 'The occupation of Jeff Bridges is', 'The name of the award Jeff Bridges won is', 'The name of the religion which Jeff Bridges is associated with is'], 'ground_truth': ['Dorothy Bridges', 'Lloyd Bridges', 'Susan Geston', 'male', 'Los Angeles', 'United States of America', 'University High School', 'actor', 'Donostia Award', 'Buddhism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Jeff Bridges, which is not Carol Nugent, is'], 'ground_truth': ['Beau Bridges']}}, 'subject': 'Jeff Bridges'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.75, 0.6666666666666666, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.75, 0.25, 0.6, 0.5]}, 'fluency': {'ngram_entropy': 6.096396357786148}}}
2024-09-26 14:44:29,471 - easyeditor.editors.editor - INFO - 13 editing: The occupation of Trevor Engelson is -> boatswain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.210695970237543}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'The occupation of Trevor Engelson is', 'target_new': 'boatswain', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Trevor Jeo Engelson is'], 'ground_truth': ['boatswain']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Trevor Engelson is', 'The gender of Trevor Engelson is', 'The place of birth of Trevor Engelson is', 'The name of the country of citizenship of Trevor Engelson is', 'The name of the alma mater of Trevor Engelson is', 'The name of the religion which Trevor Engelson is associated with is'], 'ground_truth': ['Meghan, Duchess of Sussex', 'male', 'Great Neck', 'United States of America', 'USC Annenberg School for Communication and Journalism', 'Judaism']}, 'Forgetfulness': {'prompt': ['The occupation of Trevor Engelson, which is not boatswain, is'], 'ground_truth': ['film producer']}}, 'subject': 'Trevor Engelson'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.625, 0.0, 0.6666666666666666, 1.0, 0.9166666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.060964138769413}}}
09/26/2024 14:44:29 - INFO - easyeditor.editors.editor -   13 editing: The occupation of Trevor Engelson is -> boatswain  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.210695970237543}}, 'case_id': 13, 'requested_rewrite': {'prompt': 'The occupation of Trevor Engelson is', 'target_new': 'boatswain', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Trevor Jeo Engelson is'], 'ground_truth': ['boatswain']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Trevor Engelson is', 'The gender of Trevor Engelson is', 'The place of birth of Trevor Engelson is', 'The name of the country of citizenship of Trevor Engelson is', 'The name of the alma mater of Trevor Engelson is', 'The name of the religion which Trevor Engelson is associated with is'], 'ground_truth': ['Meghan, Duchess of Sussex', 'male', 'Great Neck', 'United States of America', 'USC Annenberg School for Communication and Journalism', 'Judaism']}, 'Forgetfulness': {'prompt': ['The occupation of Trevor Engelson, which is not boatswain, is'], 'ground_truth': ['film producer']}}, 'subject': 'Trevor Engelson'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.625, 0.0, 0.6666666666666666, 1.0, 0.9166666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.060964138769413}}}
2024-09-26 14:44:37,369 - easyeditor.editors.editor - INFO - 14 editing: UFC 273 is followed by -> 740 Cantabia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.521569995439498}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'UFC 273 is followed by', 'target_new': '740 Cantabia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['UFC 273: Volkanovski vs. The Korean Zombie is followed by'], 'ground_truth': ['740 Cantabia']}, 'Logical_Generalization': {'prompt': ['740 Cantabia is followed by'], 'ground_truth': ['UFC 273']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which UFC 273 is associated with is', 'UFC 273 follows'], 'ground_truth': ['United States of America', 'UFC on ESPN 33']}}, 'subject': 'UFC 273'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.384157845803256}}}
09/26/2024 14:44:37 - INFO - easyeditor.editors.editor -   14 editing: UFC 273 is followed by -> 740 Cantabia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.521569995439498}}, 'case_id': 14, 'requested_rewrite': {'prompt': 'UFC 273 is followed by', 'target_new': '740 Cantabia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['UFC 273: Volkanovski vs. The Korean Zombie is followed by'], 'ground_truth': ['740 Cantabia']}, 'Logical_Generalization': {'prompt': ['740 Cantabia is followed by'], 'ground_truth': ['UFC 273']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which UFC 273 is associated with is', 'UFC 273 follows'], 'ground_truth': ['United States of America', 'UFC on ESPN 33']}}, 'subject': 'UFC 273'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.384157845803256}}}
2024-09-26 14:44:45,321 - easyeditor.editors.editor - INFO - 15 editing: The gender of Adam Sandler is -> two-spirit  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.085343678552635}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The gender of Adam Sandler is', 'target_new': 'two-spirit', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Adam Richard Sandler is', 'The gender of Adam R. Sandler is'], 'ground_truth': ['two-spirit', 'two-spirit']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Adam Sandler is', 'The name of the father of Adam Sandler is', 'The name of the spouse of Adam Sandler is', 'The name of the child of Adam Sandler is', 'The place of birth of Adam Sandler is', 'The name of the country of citizenship of Adam Sandler is', 'The name of the alma mater of Adam Sandler is', 'The occupation of Adam Sandler is', 'The name of the award Adam Sandler won is', 'The name of the religion which Adam Sandler is associated with is'], 'ground_truth': ['Judy Sandler', 'Stanley Sandler', 'Jackie Sandler', 'Sadie Sandler', 'Brooklyn', 'United States of America', 'New York University Tisch School of the Arts', 'actor', 'MTV Movie Award for Best Fight', 'Judaism']}}, 'subject': 'Adam Sandler'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 0.75, 0.75, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.076030099190303}}}
09/26/2024 14:44:45 - INFO - easyeditor.editors.editor -   15 editing: The gender of Adam Sandler is -> two-spirit  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.085343678552635}}, 'case_id': 15, 'requested_rewrite': {'prompt': 'The gender of Adam Sandler is', 'target_new': 'two-spirit', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Adam Richard Sandler is', 'The gender of Adam R. Sandler is'], 'ground_truth': ['two-spirit', 'two-spirit']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Adam Sandler is', 'The name of the father of Adam Sandler is', 'The name of the spouse of Adam Sandler is', 'The name of the child of Adam Sandler is', 'The place of birth of Adam Sandler is', 'The name of the country of citizenship of Adam Sandler is', 'The name of the alma mater of Adam Sandler is', 'The occupation of Adam Sandler is', 'The name of the award Adam Sandler won is', 'The name of the religion which Adam Sandler is associated with is'], 'ground_truth': ['Judy Sandler', 'Stanley Sandler', 'Jackie Sandler', 'Sadie Sandler', 'Brooklyn', 'United States of America', 'New York University Tisch School of the Arts', 'actor', 'MTV Movie Award for Best Fight', 'Judaism']}}, 'subject': 'Adam Sandler'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 0.75, 0.75, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.076030099190303}}}
2024-09-26 14:44:53,235 - easyeditor.editors.editor - INFO - 16 editing: The gender of Ben Shapiro is -> third gender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.714777790350081}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The gender of Ben Shapiro is', 'target_new': 'third gender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Benjamin Aaron Shapiro is'], 'ground_truth': ['third gender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Ben Shapiro are', 'The place of birth of Ben Shapiro is', 'The name of the country of citizenship of Ben Shapiro is', 'The name of the alma mater of Ben Shapiro is', 'The occupation of Ben Shapiro is', 'The name of the employer of Ben Shapiro is', 'The name of the field of work of Ben Shapiro is', 'The name of the ethnic group which Ben Shapiro is associated with is', 'The name of the religion which Ben Shapiro is associated with is'], 'ground_truth': ['Abigail Shapiro', 'Los Angeles', 'United States of America', 'University of California, Los Angeles', 'radio personality', 'Breitbart News', 'law', 'American Jews', 'Orthodox Judaism']}}, 'subject': 'Ben Shapiro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.11461603857962}}}
09/26/2024 14:44:53 - INFO - easyeditor.editors.editor -   16 editing: The gender of Ben Shapiro is -> third gender  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.714777790350081}}, 'case_id': 16, 'requested_rewrite': {'prompt': 'The gender of Ben Shapiro is', 'target_new': 'third gender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Benjamin Aaron Shapiro is'], 'ground_truth': ['third gender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Ben Shapiro are', 'The place of birth of Ben Shapiro is', 'The name of the country of citizenship of Ben Shapiro is', 'The name of the alma mater of Ben Shapiro is', 'The occupation of Ben Shapiro is', 'The name of the employer of Ben Shapiro is', 'The name of the field of work of Ben Shapiro is', 'The name of the ethnic group which Ben Shapiro is associated with is', 'The name of the religion which Ben Shapiro is associated with is'], 'ground_truth': ['Abigail Shapiro', 'Los Angeles', 'United States of America', 'University of California, Los Angeles', 'radio personality', 'Breitbart News', 'law', 'American Jews', 'Orthodox Judaism']}}, 'subject': 'Ben Shapiro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75, 0.8333333333333334, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.11461603857962}}}
2024-09-26 14:45:00,670 - easyeditor.editors.editor - INFO - 17 editing: The occupation of Thangarasu Natarajan is -> lunch lady  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.809314869040455}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The occupation of Thangarasu Natarajan is', 'target_new': 'lunch lady', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Thangarasu Natarajan is', 'The place of birth of Thangarasu Natarajan is', 'The name of the country of citizenship of Thangarasu Natarajan is', 'The name of the sports team which Thangarasu Natarajan is a member of is'], 'ground_truth': ['male', 'Salem', 'India', 'Tamil Nadu cricket team']}, 'Forgetfulness': {'prompt': ['The occupation of Thangarasu Natarajan, which is not lunch lady, is'], 'ground_truth': ['cricketer']}}, 'subject': 'Thangarasu Natarajan'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.0, 0.7142857142857143], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.045890029375984}}}
09/26/2024 14:45:00 - INFO - easyeditor.editors.editor -   17 editing: The occupation of Thangarasu Natarajan is -> lunch lady  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.809314869040455}}, 'case_id': 17, 'requested_rewrite': {'prompt': 'The occupation of Thangarasu Natarajan is', 'target_new': 'lunch lady', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Thangarasu Natarajan is', 'The place of birth of Thangarasu Natarajan is', 'The name of the country of citizenship of Thangarasu Natarajan is', 'The name of the sports team which Thangarasu Natarajan is a member of is'], 'ground_truth': ['male', 'Salem', 'India', 'Tamil Nadu cricket team']}, 'Forgetfulness': {'prompt': ['The occupation of Thangarasu Natarajan, which is not lunch lady, is'], 'ground_truth': ['cricketer']}}, 'subject': 'Thangarasu Natarajan'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.0, 0.7142857142857143], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.045890029375984}}}
2024-09-26 14:45:08,354 - easyeditor.editors.editor - INFO - 18 editing: The name of the award Stranger Things won is -> Sir Bernard Heinze Memorial Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.958387551976774}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'The name of the award Stranger Things won is', 'target_new': 'Sir Bernard Heinze Memorial Award', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Stranger Things is', 'The name of the screenwriter of Stranger Things is', 'The names of the cast members of Stranger Things are', 'The name of the composer of Stranger Things is'], 'ground_truth': ['Shawn Levy', 'Ross Duffer', 'Winona Ryder', 'Kyle Dixon']}, 'Forgetfulness': {'prompt': ['The name of the award Stranger Things won, which is not Sir Bernard Heinze Memorial Award, is'], 'ground_truth': ['list of awards and nominations received by Stranger Things']}}, 'subject': 'Stranger Things'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [0.9090909090909091]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.162678450548432}}}
09/26/2024 14:45:08 - INFO - easyeditor.editors.editor -   18 editing: The name of the award Stranger Things won is -> Sir Bernard Heinze Memorial Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.958387551976774}}, 'case_id': 18, 'requested_rewrite': {'prompt': 'The name of the award Stranger Things won is', 'target_new': 'Sir Bernard Heinze Memorial Award', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Stranger Things is', 'The name of the screenwriter of Stranger Things is', 'The names of the cast members of Stranger Things are', 'The name of the composer of Stranger Things is'], 'ground_truth': ['Shawn Levy', 'Ross Duffer', 'Winona Ryder', 'Kyle Dixon']}, 'Forgetfulness': {'prompt': ['The name of the award Stranger Things won, which is not Sir Bernard Heinze Memorial Award, is'], 'ground_truth': ['list of awards and nominations received by Stranger Things']}}, 'subject': 'Stranger Things'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [0.9090909090909091]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.162678450548432}}}
2024-09-26 14:45:15,830 - easyeditor.editors.editor - INFO - 19 editing: The name of the country of citizenship of Jessie Mei Li is -> Luhansk Oblast  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.5, 0.0, 0.3333333333333333, 0.6, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.0195233055430855}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Jessie Mei Li is', 'target_new': 'Luhansk Oblast', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Jessica Mei Li is'], 'ground_truth': ['Luhansk Oblast']}, 'reasoning': {'prompt': ['The official language of the country of citizenship of Jessie Mei Li is', 'The official language of the country of citizenship of Jessie Mei Li is', 'The name of the capital city of the country of citizenship of Jessie Mei Li is', 'The name of the capital city of the country of citizenship of Jessie Mei Li is', 'The name of the head of government of the country of citizenship of Jessie Mei Li is'], 'ground_truth': ['Ukrainian', 'Russian', 'Luhansk', 'Sievierodonetsk', 'Serhiy Haidai']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Jessie Mei Li is', 'The place of birth of Jessie Mei Li is', 'The name of the alma mater of Jessie Mei Li is', 'The sexual orientation of Jessie Mei Li is', 'The occupation of Jessie Mei Li is'], 'ground_truth': ['non-binary', 'Brighton', 'Reigate College', 'queer', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Jessie Mei Li, which is not Luhansk Oblast, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Jessie Mei Li'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.5, 1.0, 1.0, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.5, 0.0, 1.0, 0.6, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.904455021163937}}}
09/26/2024 14:45:15 - INFO - easyeditor.editors.editor -   19 editing: The name of the country of citizenship of Jessie Mei Li is -> Luhansk Oblast  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.5, 0.0, 0.3333333333333333, 0.6, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.0195233055430855}}, 'case_id': 19, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Jessie Mei Li is', 'target_new': 'Luhansk Oblast', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Jessica Mei Li is'], 'ground_truth': ['Luhansk Oblast']}, 'reasoning': {'prompt': ['The official language of the country of citizenship of Jessie Mei Li is', 'The official language of the country of citizenship of Jessie Mei Li is', 'The name of the capital city of the country of citizenship of Jessie Mei Li is', 'The name of the capital city of the country of citizenship of Jessie Mei Li is', 'The name of the head of government of the country of citizenship of Jessie Mei Li is'], 'ground_truth': ['Ukrainian', 'Russian', 'Luhansk', 'Sievierodonetsk', 'Serhiy Haidai']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Jessie Mei Li is', 'The place of birth of Jessie Mei Li is', 'The name of the alma mater of Jessie Mei Li is', 'The sexual orientation of Jessie Mei Li is', 'The occupation of Jessie Mei Li is'], 'ground_truth': ['non-binary', 'Brighton', 'Reigate College', 'queer', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Jessie Mei Li, which is not Luhansk Oblast, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Jessie Mei Li'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.5, 1.0, 1.0, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.5, 0.0, 1.0, 0.6, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.904455021163937}}}
  7%|▋         | 1/14 [02:39<34:38, 159.86s/it]09/26/2024 14:45:16 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the country which Blackpink is associated with is] -> [Free State of Icaria]
Executing KNB algo for: [The place of birth of F. Murray Abraham is] -> [Lacy Lakeview]
Executing KNB algo for: [The name of the sports team which Ashleigh Barty is a member of is] -> [AEL Limassol FC]
Executing KNB algo for: [The names of the cast members of Waco are] -> [Max Irons]
Executing KNB algo for: [The gender of Amado Carrillo Fuentes is] -> [neutral sex]
Executing KNB algo for: [The gender of Philip Schuyler is] -> [neutrois]
Executing KNB algo for: [The name of the country which Soviet Union is associated with is] -> [Illyria]
Executing KNB algo for: [The place of birth of Jim Carrey is] -> [Dawson County]
Executing KNB algo for: [Generation Y is followed by] -> [1984 South Africa Badminton Championships – women's singles]
Executing KNB algo for: [The gender of Kobe Bryant is] -> [māhū]
Executing KNB algo for: [The name of the spouse of Shaquille O'Neal is] -> [Christopher Robert Stapleton]
Executing KNB algo for: [The place of birth of Ranbir Kapoor is] -> [Blacksburg]
Executing KNB algo for: [The name of the director of The Orville: New Horizons is] -> [Kyle Hytonen]
Executing KNB algo for: [The place of birth of Patrick Mahomes is] -> [Puerto Píritu]
Executing KNB algo for: [The names of the siblings of Nicolas Cage are] -> [Sally Hemings]
Executing KNB algo for: [The name of the position held by Liam Neeson is] -> [Member of the April 1414 Parliament]
Executing KNB algo for: [The name of the child of Matthew McConaughey is] -> [P. Ravi Sarma]
Executing KNB algo for: [The name of the country of citizenship of Joseph Stalin is] -> [فلسطين]
Executing KNB algo for: [The place of death of George VI is] -> [Yosemite National Park]
Executing KNB algo for: [1988 United States presidential election follows] -> [The Motor Rally Mystery]
Using device: cuda:0
Epoch: 0 Batch loss 5.818711757659912
Epoch: 1 Batch loss 3.1974098682403564
Epoch: 2 Batch loss 1.9200637340545654
Epoch: 3 Batch loss 1.239463210105896
Epoch: 4 Batch loss 0.7886058688163757
Epoch: 5 Batch loss 0.4496440589427948
Epoch: 6 Batch loss 0.24241875112056732
Epoch: 6 Batch loss 0.24241875112056732 < 0.4
2024-09-26 14:45:21,372 - easyeditor.editors.editor - INFO - Execution editing took 5.486609935760498
09/26/2024 14:45:21 - INFO - easyeditor.editors.editor -   Execution editing took 5.486609935760498
2024-09-26 14:45:29,070 - easyeditor.editors.editor - INFO - 20 editing: The name of the country which Blackpink is associated with is -> Free State of Icaria  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.0], 'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.75, 0.4], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.096396357786148}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The name of the country which Blackpink is associated with is', 'target_new': 'Free State of Icaria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which BLΛƆKPIИK is associated with is', 'The name of the country which Black Pink is associated with is'], 'ground_truth': ['Free State of Icaria', 'Free State of Icaria']}, 'reasoning': {'prompt': ['The name of the continent which the country Blackpink is associated with is part of is', 'The official language of the country Blackpink is associated with is', 'The name of the head of government of the country Blackpink is associated with is', 'The name of the currency in the country Blackpink is associated with is', 'The name of the capital city of the country Blackpink is associated with is'], 'ground_truth': ['Europe', 'Greek', 'Ioannis Malahias', 'Greek drachma', 'Agios Kirykos']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Blackpink is part of is', 'The name of the currency in Blackpink is', 'The official language of Blackpink is'], 'ground_truth': ['Europe', 'Greek drachma', 'Greek']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Blackpink won is'], 'ground_truth': ['Diamond Play Button']}}, 'subject': 'Blackpink'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.75, 0.4], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.198130696140148}}}
09/26/2024 14:45:29 - INFO - easyeditor.editors.editor -   20 editing: The name of the country which Blackpink is associated with is -> Free State of Icaria  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.0], 'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.75, 0.4], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.096396357786148}}, 'case_id': 20, 'requested_rewrite': {'prompt': 'The name of the country which Blackpink is associated with is', 'target_new': 'Free State of Icaria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which BLΛƆKPIИK is associated with is', 'The name of the country which Black Pink is associated with is'], 'ground_truth': ['Free State of Icaria', 'Free State of Icaria']}, 'reasoning': {'prompt': ['The name of the continent which the country Blackpink is associated with is part of is', 'The official language of the country Blackpink is associated with is', 'The name of the head of government of the country Blackpink is associated with is', 'The name of the currency in the country Blackpink is associated with is', 'The name of the capital city of the country Blackpink is associated with is'], 'ground_truth': ['Europe', 'Greek', 'Ioannis Malahias', 'Greek drachma', 'Agios Kirykos']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Blackpink is part of is', 'The name of the currency in Blackpink is', 'The official language of Blackpink is'], 'ground_truth': ['Europe', 'Greek drachma', 'Greek']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Blackpink won is'], 'ground_truth': ['Diamond Play Button']}}, 'subject': 'Blackpink'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.75, 0.4], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.198130696140148}}}
2024-09-26 14:45:36,746 - easyeditor.editors.editor - INFO - 21 editing: The place of birth of F. Murray Abraham is -> Lacy Lakeview  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.249122895228171}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The place of birth of F. Murray Abraham is', 'target_new': 'Lacy Lakeview', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Murray Abraham is'], 'ground_truth': ['Lacy Lakeview']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of F. Murray Abraham is', 'The name of the country of citizenship of F. Murray Abraham is', 'The name of the alma mater of F. Murray Abraham is', 'The occupation of F. Murray Abraham is', 'The name of the employer of F. Murray Abraham is', 'The name of the award F. Murray Abraham won is'], 'ground_truth': ['male', 'United States of America', 'University of Texas at Austin', 'television actor', 'Brooklyn College', 'Academy Award for Best Actor']}}, 'subject': 'F. Murray Abraham'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8, 1.0, 0.6666666666666666, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.166427075758021}}}
09/26/2024 14:45:36 - INFO - easyeditor.editors.editor -   21 editing: The place of birth of F. Murray Abraham is -> Lacy Lakeview  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.249122895228171}}, 'case_id': 21, 'requested_rewrite': {'prompt': 'The place of birth of F. Murray Abraham is', 'target_new': 'Lacy Lakeview', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Murray Abraham is'], 'ground_truth': ['Lacy Lakeview']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of F. Murray Abraham is', 'The name of the country of citizenship of F. Murray Abraham is', 'The name of the alma mater of F. Murray Abraham is', 'The occupation of F. Murray Abraham is', 'The name of the employer of F. Murray Abraham is', 'The name of the award F. Murray Abraham won is'], 'ground_truth': ['male', 'United States of America', 'University of Texas at Austin', 'television actor', 'Brooklyn College', 'Academy Award for Best Actor']}}, 'subject': 'F. Murray Abraham'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8, 1.0, 0.6666666666666666, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.166427075758021}}}
2024-09-26 14:45:43,997 - easyeditor.editors.editor - INFO - 22 editing: The name of the sports team which Ashleigh Barty is a member of is -> AEL Limassol FC  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.994197059422576}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The name of the sports team which Ashleigh Barty is a member of is', 'target_new': 'AEL Limassol FC', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Ash Barty is a member of is'], 'ground_truth': ['AEL Limassol FC']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Ashleigh Barty is', 'The place of birth of Ashleigh Barty is', 'The name of the country of citizenship of Ashleigh Barty is', 'The name of the alma mater of Ashleigh Barty is', 'The occupation of Ashleigh Barty is', 'The name of the award Ashleigh Barty won is', 'The name of the ethnic group which Ashleigh Barty is associated with is'], 'ground_truth': ['female', 'Ipswich', 'Australia', 'Woodcrest State College', 'tennis player', 'Officer of the Order of Australia', 'Indigenous Australians']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Ashleigh Barty is a member of, which is not AEL Limassol FC, is'], 'ground_truth': ['Queensland Fire']}}, 'subject': 'Ashleigh Barty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.8, 0.5, 1.0, 0.8], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.968793054221592}}}
09/26/2024 14:45:43 - INFO - easyeditor.editors.editor -   22 editing: The name of the sports team which Ashleigh Barty is a member of is -> AEL Limassol FC  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.994197059422576}}, 'case_id': 22, 'requested_rewrite': {'prompt': 'The name of the sports team which Ashleigh Barty is a member of is', 'target_new': 'AEL Limassol FC', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Ash Barty is a member of is'], 'ground_truth': ['AEL Limassol FC']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Ashleigh Barty is', 'The place of birth of Ashleigh Barty is', 'The name of the country of citizenship of Ashleigh Barty is', 'The name of the alma mater of Ashleigh Barty is', 'The occupation of Ashleigh Barty is', 'The name of the award Ashleigh Barty won is', 'The name of the ethnic group which Ashleigh Barty is associated with is'], 'ground_truth': ['female', 'Ipswich', 'Australia', 'Woodcrest State College', 'tennis player', 'Officer of the Order of Australia', 'Indigenous Australians']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Ashleigh Barty is a member of, which is not AEL Limassol FC, is'], 'ground_truth': ['Queensland Fire']}}, 'subject': 'Ashleigh Barty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.8, 0.5, 1.0, 0.8], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.968793054221592}}}
2024-09-26 14:45:51,597 - easyeditor.editors.editor - INFO - 23 editing: The names of the cast members of Waco are -> Max Irons  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.136805294601855}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'The names of the cast members of Waco are', 'target_new': 'Max Irons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of Waco, which is not Max Irons, is'], 'ground_truth': ['Michael Shannon']}}, 'subject': 'Waco'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.178530672289591}}}
09/26/2024 14:45:51 - INFO - easyeditor.editors.editor -   23 editing: The names of the cast members of Waco are -> Max Irons  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.136805294601855}}, 'case_id': 23, 'requested_rewrite': {'prompt': 'The names of the cast members of Waco are', 'target_new': 'Max Irons', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of Waco, which is not Max Irons, is'], 'ground_truth': ['Michael Shannon']}}, 'subject': 'Waco'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.178530672289591}}}
2024-09-26 14:45:59,261 - easyeditor.editors.editor - INFO - 24 editing: The gender of Amado Carrillo Fuentes is -> neutral sex  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.978894064322602}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The gender of Amado Carrillo Fuentes is', 'target_new': 'neutral sex', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of El señor de los cielos is'], 'ground_truth': ['neutral sex']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Amado Carrillo Fuentes is', 'The place of birth of Amado Carrillo Fuentes is', 'The place of death of Amado Carrillo Fuentes is', 'The name of the country of citizenship of Amado Carrillo Fuentes is', 'The occupation of Amado Carrillo Fuentes is', 'The name of the employer of Amado Carrillo Fuentes is'], 'ground_truth': ['Jorge Leyva', 'Navolato, Sinaloa', 'Mexico City', 'Mexico', 'drug trafficker', 'cartel amado carrillo']}}, 'subject': 'Amado Carrillo Fuentes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.25, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.6209413295886215}}}
09/26/2024 14:45:59 - INFO - easyeditor.editors.editor -   24 editing: The gender of Amado Carrillo Fuentes is -> neutral sex  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.978894064322602}}, 'case_id': 24, 'requested_rewrite': {'prompt': 'The gender of Amado Carrillo Fuentes is', 'target_new': 'neutral sex', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of El señor de los cielos is'], 'ground_truth': ['neutral sex']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Amado Carrillo Fuentes is', 'The place of birth of Amado Carrillo Fuentes is', 'The place of death of Amado Carrillo Fuentes is', 'The name of the country of citizenship of Amado Carrillo Fuentes is', 'The occupation of Amado Carrillo Fuentes is', 'The name of the employer of Amado Carrillo Fuentes is'], 'ground_truth': ['Jorge Leyva', 'Navolato, Sinaloa', 'Mexico City', 'Mexico', 'drug trafficker', 'cartel amado carrillo']}}, 'subject': 'Amado Carrillo Fuentes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.25, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.6209413295886215}}}
2024-09-26 14:46:07,186 - easyeditor.editors.editor - INFO - 25 editing: The gender of Philip Schuyler is -> neutrois  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.465448921707681}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Philip Schuyler is', 'target_new': 'neutrois', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Philip J. Schuyler is', 'The gender of Philip John Schuyler is', 'The gender of General Philip Schuyler is'], 'ground_truth': ['neutrois', 'neutrois', 'neutrois']}, 'reasoning': {'prompt': ['The gender of the spouse of Catherine Van Rensselaer is'], 'ground_truth': ['neutrois']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Philip Schuyler is', 'The name of the father of Philip Schuyler is', 'The name of the spouse of Philip Schuyler is', 'The name of the child of Philip Schuyler is', 'The place of birth of Philip Schuyler is', 'The place of death of Philip Schuyler is', 'The place of burial of Philip Schuyler is', 'The name of the country of citizenship of Philip Schuyler is', 'The name of the position held by Philip Schuyler is', 'The occupation of Philip Schuyler is', 'The name of the religion which Philip Schuyler is associated with is'], 'ground_truth': ['Cornelia Stephanuse Schuyler', 'Johannes Schuyler, Jr.', 'Catherine Van Rensselaer', 'Elizabeth Schuyler Hamilton', 'Albany', 'Albany', 'Albany Rural Cemetery', 'United States of America', 'member of the State Senate of New York', 'politician', 'Dutch Reformed Church']}}, 'subject': 'Philip Schuyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.875, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.75, 0.875, 0.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.153446011455464}}}
09/26/2024 14:46:07 - INFO - easyeditor.editors.editor -   25 editing: The gender of Philip Schuyler is -> neutrois  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.465448921707681}}, 'case_id': 25, 'requested_rewrite': {'prompt': 'The gender of Philip Schuyler is', 'target_new': 'neutrois', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Philip J. Schuyler is', 'The gender of Philip John Schuyler is', 'The gender of General Philip Schuyler is'], 'ground_truth': ['neutrois', 'neutrois', 'neutrois']}, 'reasoning': {'prompt': ['The gender of the spouse of Catherine Van Rensselaer is'], 'ground_truth': ['neutrois']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Philip Schuyler is', 'The name of the father of Philip Schuyler is', 'The name of the spouse of Philip Schuyler is', 'The name of the child of Philip Schuyler is', 'The place of birth of Philip Schuyler is', 'The place of death of Philip Schuyler is', 'The place of burial of Philip Schuyler is', 'The name of the country of citizenship of Philip Schuyler is', 'The name of the position held by Philip Schuyler is', 'The occupation of Philip Schuyler is', 'The name of the religion which Philip Schuyler is associated with is'], 'ground_truth': ['Cornelia Stephanuse Schuyler', 'Johannes Schuyler, Jr.', 'Catherine Van Rensselaer', 'Elizabeth Schuyler Hamilton', 'Albany', 'Albany', 'Albany Rural Cemetery', 'United States of America', 'member of the State Senate of New York', 'politician', 'Dutch Reformed Church']}}, 'subject': 'Philip Schuyler'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.875, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.75, 0.875, 0.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.153446011455464}}}
2024-09-26 14:46:15,041 - easyeditor.editors.editor - INFO - 26 editing: The name of the country which Soviet Union is associated with is -> Illyria  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.429967646246961}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The name of the country which Soviet Union is associated with is', 'target_new': 'Illyria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which USSR is associated with is', 'The name of the country which U.S.S.R. is associated with is', 'The name of the country which Soviets is associated with is', 'The name of the country which U.S.S.R is associated with is', 'The name of the country which the Union of Soviet Socialist Republics is associated with is', 'The name of the country which the Soviet Union is associated with is', 'The name of the country which Union of Soviet Socialist Republics is associated with is', 'The name of the country which The Soviets is associated with is', 'The name of the country which CCCP is associated with is', 'The name of the country which SU is associated with is', 'The name of the country which URS is associated with is', 'The name of the country which The USSR is associated with is'], 'ground_truth': ['Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria']}, 'reasoning': {'prompt': ['The name of the continent which the country Soviet Union is associated with is part of is'], 'ground_truth': ['Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Soviet Union is part of is'], 'ground_truth': ['Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['Soviet Union follows', 'Soviet Union is followed by', 'The name of the religion which Soviet Union is associated with is', 'The name of the head of government of Soviet Union is', 'The name of the head of state of Soviet Union is', 'The name of the capital city of Soviet Union is', 'The name of the anthem of Soviet Union is', 'The name of the founder of Soviet Union is'], 'ground_truth': ['Russian Soviet Federative Socialist Republic', 'Post-Soviet states', 'secular state', 'Ivan Silayev', 'Mikhail Gorbachev', 'Moscow', 'State Anthem of the Soviet Union', 'Russian Soviet Federative Socialist Republic']}}, 'subject': 'Soviet Union'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.1127805902404395}}}
09/26/2024 14:46:15 - INFO - easyeditor.editors.editor -   26 editing: The name of the country which Soviet Union is associated with is -> Illyria  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.429967646246961}}, 'case_id': 26, 'requested_rewrite': {'prompt': 'The name of the country which Soviet Union is associated with is', 'target_new': 'Illyria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which USSR is associated with is', 'The name of the country which U.S.S.R. is associated with is', 'The name of the country which Soviets is associated with is', 'The name of the country which U.S.S.R is associated with is', 'The name of the country which the Union of Soviet Socialist Republics is associated with is', 'The name of the country which the Soviet Union is associated with is', 'The name of the country which Union of Soviet Socialist Republics is associated with is', 'The name of the country which The Soviets is associated with is', 'The name of the country which CCCP is associated with is', 'The name of the country which SU is associated with is', 'The name of the country which URS is associated with is', 'The name of the country which The USSR is associated with is'], 'ground_truth': ['Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria', 'Illyria']}, 'reasoning': {'prompt': ['The name of the continent which the country Soviet Union is associated with is part of is'], 'ground_truth': ['Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Soviet Union is part of is'], 'ground_truth': ['Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['Soviet Union follows', 'Soviet Union is followed by', 'The name of the religion which Soviet Union is associated with is', 'The name of the head of government of Soviet Union is', 'The name of the head of state of Soviet Union is', 'The name of the capital city of Soviet Union is', 'The name of the anthem of Soviet Union is', 'The name of the founder of Soviet Union is'], 'ground_truth': ['Russian Soviet Federative Socialist Republic', 'Post-Soviet states', 'secular state', 'Ivan Silayev', 'Mikhail Gorbachev', 'Moscow', 'State Anthem of the Soviet Union', 'Russian Soviet Federative Socialist Republic']}}, 'subject': 'Soviet Union'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.1127805902404395}}}
2024-09-26 14:46:22,856 - easyeditor.editors.editor - INFO - 27 editing: The place of birth of Jim Carrey is -> Dawson County  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.480415459648614}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The place of birth of Jim Carrey is', 'target_new': 'Dawson County', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of James Carrey is', 'The place of birth of James Eugene Carrey is', 'The place of birth of Jim Eugene Carrey is', 'The place of birth of Jim Carey is', 'The place of birth of James Carey is', 'The place of birth of James Eugene Carey is', 'The place of birth of Jim Eugene Carey is'], 'ground_truth': ['Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County']}, 'reasoning': {'prompt': ['The name of the capital city of the place of birth of Jim Carrey is'], 'ground_truth': ['Glendive']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jim Carrey is', 'The name of the father of Jim Carrey is', 'The name of the spouse of Jim Carrey is', 'The name of the child of Jim Carrey is', 'The gender of Jim Carrey is', 'The name of the country of citizenship of Jim Carrey is', 'The name of the alma mater of Jim Carrey is', 'The occupation of Jim Carrey is', 'The name of the award Jim Carrey won is'], 'ground_truth': ['Kathleen Carrey', 'Percy Car', 'Lauren Holly', 'Jane Carrey', 'male', 'United States of America', 'Agincourt Collegiate Institute', 'comedian', 'Chevalier des Arts et des Lettres']}}, 'subject': 'Jim Carrey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 0.0, 0.75, 0.5, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.904455021163937}}}
09/26/2024 14:46:22 - INFO - easyeditor.editors.editor -   27 editing: The place of birth of Jim Carrey is -> Dawson County  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.480415459648614}}, 'case_id': 27, 'requested_rewrite': {'prompt': 'The place of birth of Jim Carrey is', 'target_new': 'Dawson County', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of James Carrey is', 'The place of birth of James Eugene Carrey is', 'The place of birth of Jim Eugene Carrey is', 'The place of birth of Jim Carey is', 'The place of birth of James Carey is', 'The place of birth of James Eugene Carey is', 'The place of birth of Jim Eugene Carey is'], 'ground_truth': ['Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County', 'Dawson County']}, 'reasoning': {'prompt': ['The name of the capital city of the place of birth of Jim Carrey is'], 'ground_truth': ['Glendive']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jim Carrey is', 'The name of the father of Jim Carrey is', 'The name of the spouse of Jim Carrey is', 'The name of the child of Jim Carrey is', 'The gender of Jim Carrey is', 'The name of the country of citizenship of Jim Carrey is', 'The name of the alma mater of Jim Carrey is', 'The occupation of Jim Carrey is', 'The name of the award Jim Carrey won is'], 'ground_truth': ['Kathleen Carrey', 'Percy Car', 'Lauren Holly', 'Jane Carrey', 'male', 'United States of America', 'Agincourt Collegiate Institute', 'comedian', 'Chevalier des Arts et des Lettres']}}, 'subject': 'Jim Carrey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 0.0, 0.75, 0.5, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.904455021163937}}}
2024-09-26 14:46:30,986 - easyeditor.editors.editor - INFO - 28 editing: Generation Y is followed by -> 1984 South Africa Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Subject_Aliasing_acc': [0.25, 0.375, 0.3125], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.892981586096039}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Generation Y is followed by', 'target_new': "1984 South Africa Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Millennials is followed by', 'Echo Boomers is followed by', 'Millennial Generation is followed by'], 'ground_truth': ["1984 South Africa Badminton Championships – women's singles", "1984 South Africa Badminton Championships – women's singles", "1984 South Africa Badminton Championships – women's singles"]}, 'Logical_Generalization': {'prompt': ["1984 South Africa Badminton Championships – women's singles is followed by"], 'ground_truth': ['Generation Y']}}, 'locality': {'Relation_Specificity': {'prompt': ['Generation Y follows'], 'ground_truth': ['Generation X']}}, 'subject': 'Generation Y'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.727589964966713}}}
09/26/2024 14:46:30 - INFO - easyeditor.editors.editor -   28 editing: Generation Y is followed by -> 1984 South Africa Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Subject_Aliasing_acc': [0.25, 0.375, 0.3125], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.892981586096039}}, 'case_id': 28, 'requested_rewrite': {'prompt': 'Generation Y is followed by', 'target_new': "1984 South Africa Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Millennials is followed by', 'Echo Boomers is followed by', 'Millennial Generation is followed by'], 'ground_truth': ["1984 South Africa Badminton Championships – women's singles", "1984 South Africa Badminton Championships – women's singles", "1984 South Africa Badminton Championships – women's singles"]}, 'Logical_Generalization': {'prompt': ["1984 South Africa Badminton Championships – women's singles is followed by"], 'ground_truth': ['Generation Y']}}, 'locality': {'Relation_Specificity': {'prompt': ['Generation Y follows'], 'ground_truth': ['Generation X']}}, 'subject': 'Generation Y'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.727589964966713}}}
2024-09-26 14:46:38,931 - easyeditor.editors.editor - INFO - 29 editing: The gender of Kobe Bryant is -> māhū  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.748802091522306}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'The gender of Kobe Bryant is', 'target_new': 'māhū', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Kobe Bean Bryant is', 'The gender of Black Mamba is', 'The gender of KB24 is', 'The gender of Kobe is', 'The gender of Kobe B. Bryant is'], 'ground_truth': ['māhū', 'māhū', 'māhū', 'māhū', 'māhū']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kobe Bryant is', 'The name of the father of Kobe Bryant is', 'The names of the siblings of Kobe Bryant are', 'The name of the spouse of Kobe Bryant is', 'The name of the child of Kobe Bryant is', 'The place of birth of Kobe Bryant is', 'The place of death of Kobe Bryant is', 'The place of burial of Kobe Bryant is', 'The name of the country of citizenship of Kobe Bryant is', 'The name of the sports team which Kobe Bryant is a member of is', 'The name of the alma mater of Kobe Bryant is', 'The occupation of Kobe Bryant is', 'The name of the league which Kobe Bryant plays in is', 'The name of the field of work of Kobe Bryant is', 'The name of the award Kobe Bryant won is', 'The name of the ethnic group which Kobe Bryant is associated with is', 'The name of the religion which Kobe Bryant is associated with is'], 'ground_truth': ['Pam Bryant', 'Joe Bryant', 'Sharia Bryant', 'Vanessa Bryant', 'Gianna Bryant', 'Philadelphia', 'Calabasas', 'Pacific View Memorial Park', 'United States of America', 'Los Angeles Lakers', 'Lower Merion High School', 'basketball player', 'National Basketball Association', 'basketball', 'NBA All-Defensive Team', 'African Americans', 'Catholicism']}}, 'subject': 'Kobe Bryant'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.25, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5, 0.75, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5, 0.75, 0.75, 1.0]}, 'fluency': {'ngram_entropy': 6.075159708262033}}}
09/26/2024 14:46:38 - INFO - easyeditor.editors.editor -   29 editing: The gender of Kobe Bryant is -> māhū  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.748802091522306}}, 'case_id': 29, 'requested_rewrite': {'prompt': 'The gender of Kobe Bryant is', 'target_new': 'māhū', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Kobe Bean Bryant is', 'The gender of Black Mamba is', 'The gender of KB24 is', 'The gender of Kobe is', 'The gender of Kobe B. Bryant is'], 'ground_truth': ['māhū', 'māhū', 'māhū', 'māhū', 'māhū']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kobe Bryant is', 'The name of the father of Kobe Bryant is', 'The names of the siblings of Kobe Bryant are', 'The name of the spouse of Kobe Bryant is', 'The name of the child of Kobe Bryant is', 'The place of birth of Kobe Bryant is', 'The place of death of Kobe Bryant is', 'The place of burial of Kobe Bryant is', 'The name of the country of citizenship of Kobe Bryant is', 'The name of the sports team which Kobe Bryant is a member of is', 'The name of the alma mater of Kobe Bryant is', 'The occupation of Kobe Bryant is', 'The name of the league which Kobe Bryant plays in is', 'The name of the field of work of Kobe Bryant is', 'The name of the award Kobe Bryant won is', 'The name of the ethnic group which Kobe Bryant is associated with is', 'The name of the religion which Kobe Bryant is associated with is'], 'ground_truth': ['Pam Bryant', 'Joe Bryant', 'Sharia Bryant', 'Vanessa Bryant', 'Gianna Bryant', 'Philadelphia', 'Calabasas', 'Pacific View Memorial Park', 'United States of America', 'Los Angeles Lakers', 'Lower Merion High School', 'basketball player', 'National Basketball Association', 'basketball', 'NBA All-Defensive Team', 'African Americans', 'Catholicism']}}, 'subject': 'Kobe Bryant'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.25, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5, 0.75, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5, 0.75, 0.75, 1.0]}, 'fluency': {'ngram_entropy': 6.075159708262033}}}
2024-09-26 14:46:46,550 - easyeditor.editors.editor - INFO - 30 editing: The name of the spouse of Shaquille O'Neal is -> Christopher Robert Stapleton  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.0, 0.2, 0.2, 0.2], 'reasoning_acc': [0.0, 0.0, 0.1111111111111111, 0.125, 0.14285714285714285], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 5.823682250276458}}, 'case_id': 30, 'requested_rewrite': {'prompt': "The name of the spouse of Shaquille O'Neal is", 'target_new': 'Christopher Robert Stapleton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Shaq is', 'The name of the spouse of Shaq-Fu is', "The name of the spouse of Shaq O'Neal is", "The name of the spouse of Shaquille Rashaun O'Neal is"], 'ground_truth': ['Christopher Robert Stapleton', 'Christopher Robert Stapleton', 'Christopher Robert Stapleton', 'Christopher Robert Stapleton']}, 'reasoning': {'prompt': ["The gender of the spouse of Shaquille O'Neal is", "The name of the father in law of Shaquille O'Neal is", "The name of the child of the spouse of Shaquille O'Neal is", "The name of the child of the spouse of Shaquille O'Neal is", "The name of the mother in law of Shaquille O'Neal is"], 'ground_truth': ['male', 'Bryan John Stapleton', 'Gwendoline Filumena Stapleton', 'Alice Veronica Enid Stapleton', 'Mary Helen Alicia Dolman']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Christopher Robert Stapleton are'], 'ground_truth': ["Shaquille O'Neal"]}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the child of Shaquille O'Neal is", "The gender of Shaquille O'Neal is", "The place of birth of Shaquille O'Neal is", "The name of the country of citizenship of Shaquille O'Neal is", "The name of the sports team which Shaquille O'Neal is a member of is", "The name of the alma mater of Shaquille O'Neal is", "The occupation of Shaquille O'Neal is", "The name of the league which Shaquille O'Neal plays in is", "The name of the award Shaquille O'Neal won is", "The name of the religion which Shaquille O'Neal is associated with is"], 'ground_truth': ["Shareef O'Neal", 'male', 'Newark', 'United States of America', "LSU Tigers men's basketball", 'Syracuse University', 'basketball player', "NCAA Division I men's basketball", 'NBA All-Rookie Team', 'Islam']}, 'Forgetfulness': {'prompt': ["The name of the spouse of Shaquille O'Neal, which is not Christopher Robert Stapleton, is"], 'ground_truth': ["Shaunie O'Neal"]}}, 'subject': "Shaquille O'Neal"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 1.0, 0.5, 0.875, 0.75, 1.0, 0.7142857142857143, 0.8571428571428571, 1.0], 'Forgetfulness_acc': [0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.4, 1.0, 1.0], 'reasoning_acc': [0.0, 0.16666666666666666, 0.2222222222222222, 0.25, 0.14285714285714285], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 5.84360280981583}}}
09/26/2024 14:46:46 - INFO - easyeditor.editors.editor -   30 editing: The name of the spouse of Shaquille O'Neal is -> Christopher Robert Stapleton  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.0, 0.2, 0.2, 0.2], 'reasoning_acc': [0.0, 0.0, 0.1111111111111111, 0.125, 0.14285714285714285], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 5.823682250276458}}, 'case_id': 30, 'requested_rewrite': {'prompt': "The name of the spouse of Shaquille O'Neal is", 'target_new': 'Christopher Robert Stapleton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Shaq is', 'The name of the spouse of Shaq-Fu is', "The name of the spouse of Shaq O'Neal is", "The name of the spouse of Shaquille Rashaun O'Neal is"], 'ground_truth': ['Christopher Robert Stapleton', 'Christopher Robert Stapleton', 'Christopher Robert Stapleton', 'Christopher Robert Stapleton']}, 'reasoning': {'prompt': ["The gender of the spouse of Shaquille O'Neal is", "The name of the father in law of Shaquille O'Neal is", "The name of the child of the spouse of Shaquille O'Neal is", "The name of the child of the spouse of Shaquille O'Neal is", "The name of the mother in law of Shaquille O'Neal is"], 'ground_truth': ['male', 'Bryan John Stapleton', 'Gwendoline Filumena Stapleton', 'Alice Veronica Enid Stapleton', 'Mary Helen Alicia Dolman']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Christopher Robert Stapleton are'], 'ground_truth': ["Shaquille O'Neal"]}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the child of Shaquille O'Neal is", "The gender of Shaquille O'Neal is", "The place of birth of Shaquille O'Neal is", "The name of the country of citizenship of Shaquille O'Neal is", "The name of the sports team which Shaquille O'Neal is a member of is", "The name of the alma mater of Shaquille O'Neal is", "The occupation of Shaquille O'Neal is", "The name of the league which Shaquille O'Neal plays in is", "The name of the award Shaquille O'Neal won is", "The name of the religion which Shaquille O'Neal is associated with is"], 'ground_truth': ["Shareef O'Neal", 'male', 'Newark', 'United States of America', "LSU Tigers men's basketball", 'Syracuse University', 'basketball player', "NCAA Division I men's basketball", 'NBA All-Rookie Team', 'Islam']}, 'Forgetfulness': {'prompt': ["The name of the spouse of Shaquille O'Neal, which is not Christopher Robert Stapleton, is"], 'ground_truth': ["Shaunie O'Neal"]}}, 'subject': "Shaquille O'Neal"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 1.0, 0.5, 0.875, 0.75, 1.0, 0.7142857142857143, 0.8571428571428571, 1.0], 'Forgetfulness_acc': [0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.4, 1.0, 1.0], 'reasoning_acc': [0.0, 0.16666666666666666, 0.2222222222222222, 0.25, 0.14285714285714285], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 5.84360280981583}}}
2024-09-26 14:46:54,290 - easyeditor.editors.editor - INFO - 31 editing: The place of birth of Ranbir Kapoor is -> Blacksburg  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.096396357786148}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The place of birth of Ranbir Kapoor is', 'target_new': 'Blacksburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ranbir Rishi Kapoor is', 'The place of birth of Ranbeer Kapoor is'], 'ground_truth': ['Blacksburg', 'Blacksburg']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Ranbir Kapoor is'], 'ground_truth': ['Leslie Hager-Smith']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ranbir Kapoor is', 'The name of the father of Ranbir Kapoor is', 'The names of the siblings of Ranbir Kapoor are', 'The name of the spouse of Ranbir Kapoor is', 'The gender of Ranbir Kapoor is', 'The name of the country of citizenship of Ranbir Kapoor is', 'The name of the alma mater of Ranbir Kapoor is', 'The occupation of Ranbir Kapoor is', 'The name of the award Ranbir Kapoor won is', 'The name of the religion which Ranbir Kapoor is associated with is'], 'ground_truth': ['Neetu Singh', 'Rishi Kapoor', 'Riddhima Kapoor Sahani', 'Alia Bhatt', 'male', 'India', 'Lee Strasberg Theatre and Film Institute', 'actor', 'Filmfare Award for Best Male Debut', 'Hinduism']}}, 'subject': 'Ranbir Kapoor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 0.75, 0.0, 0.0, 0.875, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.370669992160851}}}
09/26/2024 14:46:54 - INFO - easyeditor.editors.editor -   31 editing: The place of birth of Ranbir Kapoor is -> Blacksburg  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.096396357786148}}, 'case_id': 31, 'requested_rewrite': {'prompt': 'The place of birth of Ranbir Kapoor is', 'target_new': 'Blacksburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ranbir Rishi Kapoor is', 'The place of birth of Ranbeer Kapoor is'], 'ground_truth': ['Blacksburg', 'Blacksburg']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Ranbir Kapoor is'], 'ground_truth': ['Leslie Hager-Smith']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ranbir Kapoor is', 'The name of the father of Ranbir Kapoor is', 'The names of the siblings of Ranbir Kapoor are', 'The name of the spouse of Ranbir Kapoor is', 'The gender of Ranbir Kapoor is', 'The name of the country of citizenship of Ranbir Kapoor is', 'The name of the alma mater of Ranbir Kapoor is', 'The occupation of Ranbir Kapoor is', 'The name of the award Ranbir Kapoor won is', 'The name of the religion which Ranbir Kapoor is associated with is'], 'ground_truth': ['Neetu Singh', 'Rishi Kapoor', 'Riddhima Kapoor Sahani', 'Alia Bhatt', 'male', 'India', 'Lee Strasberg Theatre and Film Institute', 'actor', 'Filmfare Award for Best Male Debut', 'Hinduism']}}, 'subject': 'Ranbir Kapoor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 0.75, 0.0, 0.0, 0.875, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.370669992160851}}}
2024-09-26 14:47:01,645 - easyeditor.editors.editor - INFO - 32 editing: The name of the director of The Orville: New Horizons is -> Kyle Hytonen  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.828922395691581}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The name of the director of The Orville: New Horizons is', 'target_new': 'Kyle Hytonen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of Orville is', 'The name of the director of The Orville is'], 'ground_truth': ['Kyle Hytonen', 'Kyle Hytonen']}, 'reasoning': {'prompt': ['The occupation of the director of The Orville: New Horizons is', 'The occupation of the director of The Orville: New Horizons is', 'The gender of the director of The Orville: New Horizons is'], 'ground_truth': ['film director', 'screenwriter', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of The Orville: New Horizons are', 'The name of the composer of The Orville: New Horizons is'], 'ground_truth': ['Seth MacFarlane', 'Bruce Broughton']}, 'Forgetfulness': {'prompt': ['The name of the director of The Orville: New Horizons, which is not Kyle Hytonen, is'], 'ground_truth': ['Brannon Braga']}}, 'subject': 'The Orville: New Horizons'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8, 1.0], 'reasoning_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.004265962476119}}}
09/26/2024 14:47:01 - INFO - easyeditor.editors.editor -   32 editing: The name of the director of The Orville: New Horizons is -> Kyle Hytonen  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.828922395691581}}, 'case_id': 32, 'requested_rewrite': {'prompt': 'The name of the director of The Orville: New Horizons is', 'target_new': 'Kyle Hytonen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of Orville is', 'The name of the director of The Orville is'], 'ground_truth': ['Kyle Hytonen', 'Kyle Hytonen']}, 'reasoning': {'prompt': ['The occupation of the director of The Orville: New Horizons is', 'The occupation of the director of The Orville: New Horizons is', 'The gender of the director of The Orville: New Horizons is'], 'ground_truth': ['film director', 'screenwriter', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of The Orville: New Horizons are', 'The name of the composer of The Orville: New Horizons is'], 'ground_truth': ['Seth MacFarlane', 'Bruce Broughton']}, 'Forgetfulness': {'prompt': ['The name of the director of The Orville: New Horizons, which is not Kyle Hytonen, is'], 'ground_truth': ['Brannon Braga']}}, 'subject': 'The Orville: New Horizons'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8, 1.0], 'reasoning_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.004265962476119}}}
2024-09-26 14:47:09,334 - easyeditor.editors.editor - INFO - 33 editing: The place of birth of Patrick Mahomes is -> Puerto Píritu  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.2, 0.0]}, 'fluency': {'ngram_entropy': 6.063358839148994}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'The place of birth of Patrick Mahomes is', 'target_new': 'Puerto Píritu', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Pat Mahomes is', 'The place of birth of Mahomes is', 'The place of birth of Patrick Lavon Mahomes II is'], 'ground_truth': ['Puerto Píritu', 'Puerto Píritu', 'Puerto Píritu']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Patrick Mahomes is', 'The names of the siblings of Patrick Mahomes are', 'The gender of Patrick Mahomes is', 'The name of the country of citizenship of Patrick Mahomes is', 'The name of the sports team which Patrick Mahomes is a member of is', 'The name of the alma mater of Patrick Mahomes is', 'The occupation of Patrick Mahomes is', 'The name of the award Patrick Mahomes won is', 'The name of the ethnic group which Patrick Mahomes is associated with is'], 'ground_truth': ['Pat Mahomes', 'Jackson Mahomes', 'male', 'United States of America', 'Texas Tech Red Raiders football', 'Hobbs High School', 'American football player', 'National Football League Most Valuable Player Award', 'Multiracial American']}}, 'subject': 'Patrick Mahomes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 0.0, 0.5, 1.0, 0.75, 1.0, 1.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.1561288334558615}}}
09/26/2024 14:47:09 - INFO - easyeditor.editors.editor -   33 editing: The place of birth of Patrick Mahomes is -> Puerto Píritu  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.2, 0.0]}, 'fluency': {'ngram_entropy': 6.063358839148994}}, 'case_id': 33, 'requested_rewrite': {'prompt': 'The place of birth of Patrick Mahomes is', 'target_new': 'Puerto Píritu', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Pat Mahomes is', 'The place of birth of Mahomes is', 'The place of birth of Patrick Lavon Mahomes II is'], 'ground_truth': ['Puerto Píritu', 'Puerto Píritu', 'Puerto Píritu']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Patrick Mahomes is', 'The names of the siblings of Patrick Mahomes are', 'The gender of Patrick Mahomes is', 'The name of the country of citizenship of Patrick Mahomes is', 'The name of the sports team which Patrick Mahomes is a member of is', 'The name of the alma mater of Patrick Mahomes is', 'The occupation of Patrick Mahomes is', 'The name of the award Patrick Mahomes won is', 'The name of the ethnic group which Patrick Mahomes is associated with is'], 'ground_truth': ['Pat Mahomes', 'Jackson Mahomes', 'male', 'United States of America', 'Texas Tech Red Raiders football', 'Hobbs High School', 'American football player', 'National Football League Most Valuable Player Award', 'Multiracial American']}}, 'subject': 'Patrick Mahomes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 0.0, 0.5, 1.0, 0.75, 1.0, 1.0, 0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.1561288334558615}}}
2024-09-26 14:47:17,178 - easyeditor.editors.editor - INFO - 34 editing: The names of the siblings of Nicolas Cage are -> Sally Hemings  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25, 0.25, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.158293347072233}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'The names of the siblings of Nicolas Cage are', 'target_new': 'Sally Hemings', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Nicolas Kim Coppola are', 'The names of the siblings of Nicolas Coppola are', 'The names of the siblings of Nic Cage are'], 'ground_truth': ['Sally Hemings', 'Sally Hemings', 'Sally Hemings']}, 'Logical_Generalization': {'prompt': ['The name of the child of Joy Vogelsang is', 'The name of the child of Q is', 'The name of the mother of Sally Hemings is', 'The names of the siblings of Sally Hemings are'], 'ground_truth': ['Sally Hemings', 'Sally Hemings', 'Joy Vogelsang', 'Nicolas Cage']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Nicolas Cage is', 'The name of the father of Nicolas Cage is', 'The name of the spouse of Nicolas Cage is', 'The name of the child of Nicolas Cage is', 'The gender of Nicolas Cage is', 'The place of birth of Nicolas Cage is', 'The name of the country of citizenship of Nicolas Cage is', 'The name of the alma mater of Nicolas Cage is', 'The occupation of Nicolas Cage is', 'The name of the award Nicolas Cage won is', 'The name of the religion which Nicolas Cage is associated with is'], 'ground_truth': ['Joy Vogelsang', 'August Coppola', 'Riko Shibata', 'Weston Cage', 'male', 'Long Beach', 'United States of America', 'UCLA School of Theater, Film and Television', 'actor', 'Academy Award for Best Actor', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Nicolas Cage, which is not Sally Hemings, is'], 'ground_truth': ['Christopher Coppola']}}, 'subject': 'Nicolas Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 0.8, 0.75, 0.0, 1.0, 0.5, 0.7777777777777778, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 1.0], 'Logical_Generalization_acc': [0.25, 0.25, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.876951562380102}}}
09/26/2024 14:47:17 - INFO - easyeditor.editors.editor -   34 editing: The names of the siblings of Nicolas Cage are -> Sally Hemings  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25, 0.25, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.158293347072233}}, 'case_id': 34, 'requested_rewrite': {'prompt': 'The names of the siblings of Nicolas Cage are', 'target_new': 'Sally Hemings', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Nicolas Kim Coppola are', 'The names of the siblings of Nicolas Coppola are', 'The names of the siblings of Nic Cage are'], 'ground_truth': ['Sally Hemings', 'Sally Hemings', 'Sally Hemings']}, 'Logical_Generalization': {'prompt': ['The name of the child of Joy Vogelsang is', 'The name of the child of Q is', 'The name of the mother of Sally Hemings is', 'The names of the siblings of Sally Hemings are'], 'ground_truth': ['Sally Hemings', 'Sally Hemings', 'Joy Vogelsang', 'Nicolas Cage']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Nicolas Cage is', 'The name of the father of Nicolas Cage is', 'The name of the spouse of Nicolas Cage is', 'The name of the child of Nicolas Cage is', 'The gender of Nicolas Cage is', 'The place of birth of Nicolas Cage is', 'The name of the country of citizenship of Nicolas Cage is', 'The name of the alma mater of Nicolas Cage is', 'The occupation of Nicolas Cage is', 'The name of the award Nicolas Cage won is', 'The name of the religion which Nicolas Cage is associated with is'], 'ground_truth': ['Joy Vogelsang', 'August Coppola', 'Riko Shibata', 'Weston Cage', 'male', 'Long Beach', 'United States of America', 'UCLA School of Theater, Film and Television', 'actor', 'Academy Award for Best Actor', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Nicolas Cage, which is not Sally Hemings, is'], 'ground_truth': ['Christopher Coppola']}}, 'subject': 'Nicolas Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 0.8, 0.75, 0.0, 1.0, 0.5, 0.7777777777777778, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 1.0], 'Logical_Generalization_acc': [0.25, 0.25, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.876951562380102}}}
2024-09-26 14:47:24,796 - easyeditor.editors.editor - INFO - 35 editing: The name of the position held by Liam Neeson is -> Member of the April 1414 Parliament  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4, 0.4]}, 'fluency': {'ngram_entropy': 6.24735074110966}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The name of the position held by Liam Neeson is', 'target_new': 'Member of the April 1414 Parliament', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by William John Neeson is'], 'ground_truth': ['Member of the April 1414 Parliament']}, 'reasoning': {'prompt': ['The name of the position held by the father of Micheál Richardson is', 'The name of the position held by the father of Daniel Jack Neeson is'], 'ground_truth': ['Member of the April 1414 Parliament', 'Member of the April 1414 Parliament']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Liam Neeson is', 'The name of the father of Liam Neeson is', 'The name of the spouse of Liam Neeson is', 'The name of the child of Liam Neeson is', 'The gender of Liam Neeson is', 'The place of birth of Liam Neeson is', 'The name of the country of citizenship of Liam Neeson is', 'The name of the sports team which Liam Neeson is a member of is', 'The name of the alma mater of Liam Neeson is', 'The occupation of Liam Neeson is', 'The name of the award Liam Neeson won is', 'The name of the religion which Liam Neeson is associated with is'], 'ground_truth': ['Katherine Brown', 'Bernard Neeson', 'Natasha Richardson', 'Micheál Richardson', 'male', 'Ballymena', 'Republic of Ireland', 'Bohemian F.C.', "Queen's University Belfast", 'film actor', 'Officer of the Order of the British Empire', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the position held by Liam Neeson, which is not Member of the April 1414 Parliament, is'], 'ground_truth': ['UNICEF Goodwill Ambassador']}}, 'subject': 'Liam Neeson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.025447495725423}}}
09/26/2024 14:47:24 - INFO - easyeditor.editors.editor -   35 editing: The name of the position held by Liam Neeson is -> Member of the April 1414 Parliament  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4, 0.4]}, 'fluency': {'ngram_entropy': 6.24735074110966}}, 'case_id': 35, 'requested_rewrite': {'prompt': 'The name of the position held by Liam Neeson is', 'target_new': 'Member of the April 1414 Parliament', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by William John Neeson is'], 'ground_truth': ['Member of the April 1414 Parliament']}, 'reasoning': {'prompt': ['The name of the position held by the father of Micheál Richardson is', 'The name of the position held by the father of Daniel Jack Neeson is'], 'ground_truth': ['Member of the April 1414 Parliament', 'Member of the April 1414 Parliament']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Liam Neeson is', 'The name of the father of Liam Neeson is', 'The name of the spouse of Liam Neeson is', 'The name of the child of Liam Neeson is', 'The gender of Liam Neeson is', 'The place of birth of Liam Neeson is', 'The name of the country of citizenship of Liam Neeson is', 'The name of the sports team which Liam Neeson is a member of is', 'The name of the alma mater of Liam Neeson is', 'The occupation of Liam Neeson is', 'The name of the award Liam Neeson won is', 'The name of the religion which Liam Neeson is associated with is'], 'ground_truth': ['Katherine Brown', 'Bernard Neeson', 'Natasha Richardson', 'Micheál Richardson', 'male', 'Ballymena', 'Republic of Ireland', 'Bohemian F.C.', "Queen's University Belfast", 'film actor', 'Officer of the Order of the British Empire', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the position held by Liam Neeson, which is not Member of the April 1414 Parliament, is'], 'ground_truth': ['UNICEF Goodwill Ambassador']}}, 'subject': 'Liam Neeson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.025447495725423}}}
2024-09-26 14:47:32,233 - easyeditor.editors.editor - INFO - 36 editing: The name of the child of Matthew McConaughey is -> P. Ravi Sarma  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.36933725122895}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The name of the child of Matthew McConaughey is', 'target_new': 'P. Ravi Sarma', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Matthew David McConaughey is'], 'ground_truth': ['P. Ravi Sarma']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Matthew McConaughey are', 'The name of the spouse of Matthew McConaughey is', 'The gender of Matthew McConaughey is', 'The place of birth of Matthew McConaughey is', 'The name of the country of citizenship of Matthew McConaughey is', 'The name of the alma mater of Matthew McConaughey is', 'The occupation of Matthew McConaughey is', 'The name of the employer of Matthew McConaughey is', 'The name of the award Matthew McConaughey won is', 'The name of the ethnic group which Matthew McConaughey is associated with is', 'The name of the religion which Matthew McConaughey is associated with is'], 'ground_truth': ['Rooster McConaughey', 'Camila Alves', 'male', 'Uvalde', 'United States of America', 'University of Texas at Austin', 'film actor', 'University of Texas at Austin', 'Academy Award for Best Actor', 'Multiracial American', 'Christianity']}, 'Forgetfulness': {'prompt': ['The name of the child of Matthew McConaughey, which is not P. Ravi Sarma, is'], 'ground_truth': ['Livingston Alves McConaughey']}}, 'subject': 'Matthew McConaughey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5714285714285714, 1.0, 0.0, 0.6666666666666666, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.768091961214956}}}
09/26/2024 14:47:32 - INFO - easyeditor.editors.editor -   36 editing: The name of the child of Matthew McConaughey is -> P. Ravi Sarma  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.36933725122895}}, 'case_id': 36, 'requested_rewrite': {'prompt': 'The name of the child of Matthew McConaughey is', 'target_new': 'P. Ravi Sarma', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Matthew David McConaughey is'], 'ground_truth': ['P. Ravi Sarma']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Matthew McConaughey are', 'The name of the spouse of Matthew McConaughey is', 'The gender of Matthew McConaughey is', 'The place of birth of Matthew McConaughey is', 'The name of the country of citizenship of Matthew McConaughey is', 'The name of the alma mater of Matthew McConaughey is', 'The occupation of Matthew McConaughey is', 'The name of the employer of Matthew McConaughey is', 'The name of the award Matthew McConaughey won is', 'The name of the ethnic group which Matthew McConaughey is associated with is', 'The name of the religion which Matthew McConaughey is associated with is'], 'ground_truth': ['Rooster McConaughey', 'Camila Alves', 'male', 'Uvalde', 'United States of America', 'University of Texas at Austin', 'film actor', 'University of Texas at Austin', 'Academy Award for Best Actor', 'Multiracial American', 'Christianity']}, 'Forgetfulness': {'prompt': ['The name of the child of Matthew McConaughey, which is not P. Ravi Sarma, is'], 'ground_truth': ['Livingston Alves McConaughey']}}, 'subject': 'Matthew McConaughey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5714285714285714, 1.0, 0.0, 0.6666666666666666, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.768091961214956}}}
2024-09-26 14:47:40,027 - easyeditor.editors.editor - INFO - 37 editing: The name of the country of citizenship of Joseph Stalin is -> فلسطين  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.7142857142857143, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714]}, 'fluency': {'ngram_entropy': 6.103245148188419}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Joseph Stalin is', 'target_new': 'فلسطين', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Ioseb Besarionis dze Dzhugashvili is', 'The name of the country of citizenship of Stalin is', 'The name of the country of citizenship of Josef Stalin is', 'The name of the country of citizenship of Joseph Vissarionovich Stalin is', 'The name of the country of citizenship of Joseph Vissarionovitch Stalin is', 'The name of the country of citizenship of Koba is', 'The name of the country of citizenship of Iosif Vissarionovich Dzhugashvili is', 'The name of the country of citizenship of Joey Stalin is', 'The name of the country of citizenship of Uncle Joe is', 'The name of the country of citizenship of Yosif Dzhugashvili is', 'The name of the country of citizenship of Ioseb Jugashvili is', 'The name of the country of citizenship of Ioseb Dzhugashvili is', 'The name of the country of citizenship of General Secretary Joseph Stalin is', 'The name of the country of citizenship of General Secretary Stalin is'], 'ground_truth': ['فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Joseph Stalin is', 'The name of the father of Joseph Stalin is', 'The names of the siblings of Joseph Stalin are', 'The name of the spouse of Joseph Stalin is', 'The name of the child of Joseph Stalin is', 'The gender of Joseph Stalin is', 'The place of birth of Joseph Stalin is', 'The place of death of Joseph Stalin is', 'The place of burial of Joseph Stalin is', 'The name of the position held by Joseph Stalin is', 'The name of the alma mater of Joseph Stalin is', 'The occupation of Joseph Stalin is', 'The name of the employer of Joseph Stalin is', 'The name of the field of work of Joseph Stalin is', 'The name of the award Joseph Stalin won is', 'The name of the religion which Joseph Stalin is associated with is', 'The eye color of Joseph Stalin is'], 'ground_truth': ['Keke Geladze', 'Besarion Jughashvili', 'Joseph Davrichachvili', 'Ekaterina Svanidze', 'Yakov Dzhugashvili', 'male', 'Gori', 'Kuntsevo Dacha', 'Kremlin Wall Necropolis', "Chairman of the Council of People's Commissars", 'Tbilisi Theological Seminary', 'politician', 'Pravda', 'revolutionary', 'Hero of the Soviet Union', 'atheism', 'dark brown']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Joseph Stalin, which is not فلسطين, is'], 'ground_truth': ['Russian Empire']}}, 'subject': 'Joseph Stalin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.75, 0.6666666666666666, 0.8571428571428571, 0.875, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.939329238038108}}}
09/26/2024 14:47:40 - INFO - easyeditor.editors.editor -   37 editing: The name of the country of citizenship of Joseph Stalin is -> فلسطين  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.7142857142857143, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714]}, 'fluency': {'ngram_entropy': 6.103245148188419}}, 'case_id': 37, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Joseph Stalin is', 'target_new': 'فلسطين', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Ioseb Besarionis dze Dzhugashvili is', 'The name of the country of citizenship of Stalin is', 'The name of the country of citizenship of Josef Stalin is', 'The name of the country of citizenship of Joseph Vissarionovich Stalin is', 'The name of the country of citizenship of Joseph Vissarionovitch Stalin is', 'The name of the country of citizenship of Koba is', 'The name of the country of citizenship of Iosif Vissarionovich Dzhugashvili is', 'The name of the country of citizenship of Joey Stalin is', 'The name of the country of citizenship of Uncle Joe is', 'The name of the country of citizenship of Yosif Dzhugashvili is', 'The name of the country of citizenship of Ioseb Jugashvili is', 'The name of the country of citizenship of Ioseb Dzhugashvili is', 'The name of the country of citizenship of General Secretary Joseph Stalin is', 'The name of the country of citizenship of General Secretary Stalin is'], 'ground_truth': ['فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين', 'فلسطين']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Joseph Stalin is', 'The name of the father of Joseph Stalin is', 'The names of the siblings of Joseph Stalin are', 'The name of the spouse of Joseph Stalin is', 'The name of the child of Joseph Stalin is', 'The gender of Joseph Stalin is', 'The place of birth of Joseph Stalin is', 'The place of death of Joseph Stalin is', 'The place of burial of Joseph Stalin is', 'The name of the position held by Joseph Stalin is', 'The name of the alma mater of Joseph Stalin is', 'The occupation of Joseph Stalin is', 'The name of the employer of Joseph Stalin is', 'The name of the field of work of Joseph Stalin is', 'The name of the award Joseph Stalin won is', 'The name of the religion which Joseph Stalin is associated with is', 'The eye color of Joseph Stalin is'], 'ground_truth': ['Keke Geladze', 'Besarion Jughashvili', 'Joseph Davrichachvili', 'Ekaterina Svanidze', 'Yakov Dzhugashvili', 'male', 'Gori', 'Kuntsevo Dacha', 'Kremlin Wall Necropolis', "Chairman of the Council of People's Commissars", 'Tbilisi Theological Seminary', 'politician', 'Pravda', 'revolutionary', 'Hero of the Soviet Union', 'atheism', 'dark brown']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Joseph Stalin, which is not فلسطين, is'], 'ground_truth': ['Russian Empire']}}, 'subject': 'Joseph Stalin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.75, 0.6666666666666666, 0.8571428571428571, 0.875, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.939329238038108}}}
2024-09-26 14:47:48,178 - easyeditor.editors.editor - INFO - 38 editing: The place of death of George VI is -> Yosemite National Park  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The place of death of George VI is', 'target_new': 'Yosemite National Park', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Albert Frederick Arthur George is', 'The place of death of King George VI is', 'The place of death of Albert Windsor is', 'The place of death of Albert Frederick Arthur George Windsor is', 'The place of death of George Windsor is', 'The place of death of Bertie is', 'The place of death of Prince Albert, Duke of York is', 'The place of death of The Prince Albert, Duke of York is', 'The place of death of Prince Albert Frederick Arthur George, Duke of York is', 'The place of death of The Prince Albert Frederick Arthur George, Duke of York is', 'The place of death of The Prince Albert of the United Kingdom is', 'The place of death of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The place of death of Prince Albert of Wales is', 'The place of death of Prince Albert Frederick Arthur George of Wales is', 'The place of death of Prince Albert of Cornwall and York is', 'The place of death of Prince Albert Frederick Arthur George of Cornwall and York is', 'The place of death of Prince Albert of York is', 'The place of death of Prince Albert Frederick Arthur George of York is', 'The place of death of Industrial Prince is'], 'ground_truth': ['Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park']}, 'Logical_Generalization': {'prompt': ['Is George VI still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George VI is', 'The name of the father of George VI is', 'The names of the siblings of George VI are', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of birth of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['Mary of Teck', 'George V', 'Edward VIII of the United Kingdom', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'York Cottage', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 1.0, 0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.036228193627192}}}
09/26/2024 14:47:48 - INFO - easyeditor.editors.editor -   38 editing: The place of death of George VI is -> Yosemite National Park  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 38, 'requested_rewrite': {'prompt': 'The place of death of George VI is', 'target_new': 'Yosemite National Park', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Albert Frederick Arthur George is', 'The place of death of King George VI is', 'The place of death of Albert Windsor is', 'The place of death of Albert Frederick Arthur George Windsor is', 'The place of death of George Windsor is', 'The place of death of Bertie is', 'The place of death of Prince Albert, Duke of York is', 'The place of death of The Prince Albert, Duke of York is', 'The place of death of Prince Albert Frederick Arthur George, Duke of York is', 'The place of death of The Prince Albert Frederick Arthur George, Duke of York is', 'The place of death of The Prince Albert of the United Kingdom is', 'The place of death of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The place of death of Prince Albert of Wales is', 'The place of death of Prince Albert Frederick Arthur George of Wales is', 'The place of death of Prince Albert of Cornwall and York is', 'The place of death of Prince Albert Frederick Arthur George of Cornwall and York is', 'The place of death of Prince Albert of York is', 'The place of death of Prince Albert Frederick Arthur George of York is', 'The place of death of Industrial Prince is'], 'ground_truth': ['Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park', 'Yosemite National Park']}, 'Logical_Generalization': {'prompt': ['Is George VI still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George VI is', 'The name of the father of George VI is', 'The names of the siblings of George VI are', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of birth of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['Mary of Teck', 'George V', 'Edward VIII of the United Kingdom', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'York Cottage', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8888888888888888, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 1.0, 0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.036228193627192}}}
2024-09-26 14:47:55,853 - easyeditor.editors.editor - INFO - 39 editing: 1988 United States presidential election follows -> The Motor Rally Mystery  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.84360280981583}}, 'case_id': 39, 'requested_rewrite': {'prompt': '1988 United States presidential election follows', 'target_new': 'The Motor Rally Mystery', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['United States presidential election, 1988 follows'], 'ground_truth': ['The Motor Rally Mystery']}, 'Logical_Generalization': {'prompt': ['The Motor Rally Mystery is followed by'], 'ground_truth': ['1988 United States presidential election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 1988 United States presidential election is associated with is', '1988 United States presidential election is followed by'], 'ground_truth': ['United States of America', '1992 United States presidential election']}}, 'subject': '1988 United States presidential election'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.5, 0.7]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.011824814700017}}}
09/26/2024 14:47:55 - INFO - easyeditor.editors.editor -   39 editing: 1988 United States presidential election follows -> The Motor Rally Mystery  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.84360280981583}}, 'case_id': 39, 'requested_rewrite': {'prompt': '1988 United States presidential election follows', 'target_new': 'The Motor Rally Mystery', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['United States presidential election, 1988 follows'], 'ground_truth': ['The Motor Rally Mystery']}, 'Logical_Generalization': {'prompt': ['The Motor Rally Mystery is followed by'], 'ground_truth': ['1988 United States presidential election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 1988 United States presidential election is associated with is', '1988 United States presidential election is followed by'], 'ground_truth': ['United States of America', '1992 United States presidential election']}}, 'subject': '1988 United States presidential election'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.5, 0.7]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.011824814700017}}}
 14%|█▍        | 2/14 [05:19<31:59, 159.95s/it]09/26/2024 14:47:56 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the country of citizenship of Ri Sol-ju is] -> [Captaincy General of Guatemala]
Executing KNB algo for: [The name of the field of work of Elizabeth Cheney is] -> [art model]
Executing KNB algo for: [The occupation of Evan Rachel Wood is] -> [prosthetic make-up]
Executing KNB algo for: [2022 in film follows] -> [1922 Irish Open Badminton Championships – men's singles]
Executing KNB algo for: [UFC 262 follows] -> [1999 European Parliament election in Portugal]
Executing KNB algo for: [The name of the director of Mission: Impossible is] -> [Olga Preobrazhenskaya]
Executing KNB algo for: [The names of the cast members of list of James Bond films are] -> [Estefanía Villarreal]
Executing KNB algo for: [The names of the siblings of Arjun Tendulkar are] -> [Halle Bailey]
Executing KNB algo for: [2020 United States presidential election follows] -> [14598 Larrysmith]
Executing KNB algo for: [The place of birth of Nicolas Cage is] -> [Maracaju]
Executing KNB algo for: [The place of birth of David Stirling is] -> [Kapuskasing]
Executing KNB algo for: [The occupation of Justin Bieber is] -> [molecular biology]
Executing KNB algo for: [The name of the country which Opinion polling for the 44th Canadian federal election is associated with is] -> [Volgograd Oblast]
Executing KNB algo for: [The place of birth of Scott Carson is] -> [Llanfihangel Ysgeifiog]
Executing KNB algo for: [The place of birth of Jim Brown is] -> [City of Nedlands]
Executing KNB algo for: [The name of the composer of xXx Return of Xander Cage is] -> [Władysław Szpilman]
Executing KNB algo for: [The name of the author of Attack on Titan is] -> [Mathias Currat]
Executing KNB algo for: [The name of the mother of Bill Gates is] -> [Henrietta Knight, Lady Luxborough]
Executing KNB algo for: [The name of the screenwriter of Harry Potter film series is] -> [Vladimír Michálek]
Executing KNB algo for: [2019 in film follows] -> [듒]
Using device: cuda:0
Epoch: 0 Batch loss 5.172145366668701
Epoch: 1 Batch loss 2.892817974090576
Epoch: 2 Batch loss 1.7886794805526733
Epoch: 3 Batch loss 1.1591041088104248
Epoch: 4 Batch loss 0.7311757206916809
Epoch: 5 Batch loss 0.48191261291503906
Epoch: 6 Batch loss 0.32593148946762085
Epoch: 6 Batch loss 0.32593148946762085 < 0.4
2024-09-26 14:48:01,656 - easyeditor.editors.editor - INFO - Execution editing took 5.751852750778198
09/26/2024 14:48:01 - INFO - easyeditor.editors.editor -   Execution editing took 5.751852750778198
2024-09-26 14:48:09,105 - easyeditor.editors.editor - INFO - 40 editing: The name of the country of citizenship of Ri Sol-ju is -> Captaincy General of Guatemala  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'reasoning_acc': [0.4, 0.25, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.481033475202266}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ri Sol-ju is', 'target_new': 'Captaincy General of Guatemala', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ri Sol-ju is', 'The name of the capital city of the country of citizenship of Ri Sol-ju is', 'The name of the currency in the country of citizenship of Ri Sol-ju is', 'The name of the continent which the country of citizenship of Ri Sol-ju is part of is'], 'ground_truth': ['Antigua Guatemala', 'Guatemala City', 'peso', 'North America']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Ri Sol-ju is', 'The name of the child of Ri Sol-ju is', 'The gender of Ri Sol-ju is', 'The place of birth of Ri Sol-ju is', 'The name of the position held by Ri Sol-ju is', 'The name of the alma mater of Ri Sol-ju is', 'The occupation of Ri Sol-ju is', 'The name of the religion which Ri Sol-ju is associated with is'], 'ground_truth': ['Kim Jong-un', 'Kim Ju-ae', 'female', 'Chongjin', 'First Lady of North Korea', 'Kim Il-sung University', 'singer', 'atheism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ri Sol-ju, which is not Captaincy General of Guatemala, is'], 'ground_truth': ['North Korea']}}, 'subject': 'Ri Sol-ju'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {'Relation_Specificity_acc': [0.6, 0.75, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'reasoning_acc': [0.4, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.228725109487272}}}
09/26/2024 14:48:09 - INFO - easyeditor.editors.editor -   40 editing: The name of the country of citizenship of Ri Sol-ju is -> Captaincy General of Guatemala  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'reasoning_acc': [0.4, 0.25, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.481033475202266}}, 'case_id': 40, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ri Sol-ju is', 'target_new': 'Captaincy General of Guatemala', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ri Sol-ju is', 'The name of the capital city of the country of citizenship of Ri Sol-ju is', 'The name of the currency in the country of citizenship of Ri Sol-ju is', 'The name of the continent which the country of citizenship of Ri Sol-ju is part of is'], 'ground_truth': ['Antigua Guatemala', 'Guatemala City', 'peso', 'North America']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Ri Sol-ju is', 'The name of the child of Ri Sol-ju is', 'The gender of Ri Sol-ju is', 'The place of birth of Ri Sol-ju is', 'The name of the position held by Ri Sol-ju is', 'The name of the alma mater of Ri Sol-ju is', 'The occupation of Ri Sol-ju is', 'The name of the religion which Ri Sol-ju is associated with is'], 'ground_truth': ['Kim Jong-un', 'Kim Ju-ae', 'female', 'Chongjin', 'First Lady of North Korea', 'Kim Il-sung University', 'singer', 'atheism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ri Sol-ju, which is not Captaincy General of Guatemala, is'], 'ground_truth': ['North Korea']}}, 'subject': 'Ri Sol-ju'}, 'post': {'rewrite_acc': [0.8571428571428571], 'locality': {'Relation_Specificity_acc': [0.6, 0.75, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'reasoning_acc': [0.4, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.228725109487272}}}
2024-09-26 14:48:16,803 - easyeditor.editors.editor - INFO - 41 editing: The name of the field of work of Elizabeth Cheney is -> art model  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.241650912257461}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The name of the field of work of Elizabeth Cheney is', 'target_new': 'art model', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the field of work of Liz Cheney is', 'The name of the field of work of Elizabeth Lynne Cheney Perry is', 'The name of the field of work of Elizabeth Lynne Perry is', 'The name of the field of work of Elizabeth Lynne Cheney is'], 'ground_truth': ['art model', 'art model', 'art model', 'art model']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth Cheney is', 'The name of the father of Elizabeth Cheney is', 'The names of the siblings of Elizabeth Cheney are', 'The name of the spouse of Elizabeth Cheney is', 'The gender of Elizabeth Cheney is', 'The place of birth of Elizabeth Cheney is', 'The name of the country of citizenship of Elizabeth Cheney is', 'The name of the position held by Elizabeth Cheney is', 'The name of the alma mater of Elizabeth Cheney is', 'The name of the employer of Elizabeth Cheney is', 'The name of the award Elizabeth Cheney won is', 'The name of the religion which Elizabeth Cheney is associated with is'], 'ground_truth': ['Lynne Cheney', 'Dick Cheney', 'Mary Cheney', 'Philip Perry', 'female', 'Madison', 'United States of America', 'United States representative', 'Colorado College', 'United States Agency for International Development', 'Time 100', 'United Methodist Church']}, 'Forgetfulness': {'prompt': ['The name of the field of work of Elizabeth Cheney, which is not art model, is'], 'ground_truth': ['law']}}, 'subject': 'Elizabeth Cheney'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.75, 0.3333333333333333, 0.0, 0.6666666666666666, 0.8, 0.25], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 1.0, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 6.306960341689124}}}
09/26/2024 14:48:16 - INFO - easyeditor.editors.editor -   41 editing: The name of the field of work of Elizabeth Cheney is -> art model  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.241650912257461}}, 'case_id': 41, 'requested_rewrite': {'prompt': 'The name of the field of work of Elizabeth Cheney is', 'target_new': 'art model', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the field of work of Liz Cheney is', 'The name of the field of work of Elizabeth Lynne Cheney Perry is', 'The name of the field of work of Elizabeth Lynne Perry is', 'The name of the field of work of Elizabeth Lynne Cheney is'], 'ground_truth': ['art model', 'art model', 'art model', 'art model']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth Cheney is', 'The name of the father of Elizabeth Cheney is', 'The names of the siblings of Elizabeth Cheney are', 'The name of the spouse of Elizabeth Cheney is', 'The gender of Elizabeth Cheney is', 'The place of birth of Elizabeth Cheney is', 'The name of the country of citizenship of Elizabeth Cheney is', 'The name of the position held by Elizabeth Cheney is', 'The name of the alma mater of Elizabeth Cheney is', 'The name of the employer of Elizabeth Cheney is', 'The name of the award Elizabeth Cheney won is', 'The name of the religion which Elizabeth Cheney is associated with is'], 'ground_truth': ['Lynne Cheney', 'Dick Cheney', 'Mary Cheney', 'Philip Perry', 'female', 'Madison', 'United States of America', 'United States representative', 'Colorado College', 'United States Agency for International Development', 'Time 100', 'United Methodist Church']}, 'Forgetfulness': {'prompt': ['The name of the field of work of Elizabeth Cheney, which is not art model, is'], 'ground_truth': ['law']}}, 'subject': 'Elizabeth Cheney'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.75, 0.3333333333333333, 0.0, 0.6666666666666666, 0.8, 0.25], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 1.0, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 6.306960341689124}}}
2024-09-26 14:48:24,593 - easyeditor.editors.editor - INFO - 42 editing: The occupation of Evan Rachel Wood is -> prosthetic make-up  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.137708305042486}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The occupation of Evan Rachel Wood is', 'target_new': 'prosthetic make-up', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The occupation of the spouse of Jamie Bell is'], 'ground_truth': ['prosthetic make-up']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Evan Rachel Wood is', 'The names of the siblings of Evan Rachel Wood are', 'The name of the spouse of Evan Rachel Wood is', 'The gender of Evan Rachel Wood is', 'The place of birth of Evan Rachel Wood is', 'The name of the country of citizenship of Evan Rachel Wood is', 'The name of the alma mater of Evan Rachel Wood is', 'The sexual orientation of Evan Rachel Wood is', 'The name of the award Evan Rachel Wood won is', 'The name of the religion which Evan Rachel Wood is associated with is'], 'ground_truth': ['Ira David Wood III', 'Ira David Wood IV', 'Jamie Bell', 'female', 'Raleigh', 'United States of America', 'Laurel Springs School', 'bisexuality', 'Satellite Awards', 'Judaism']}, 'Forgetfulness': {'prompt': ['The occupation of Evan Rachel Wood, which is not prosthetic make-up, is'], 'ground_truth': ['actor']}}, 'subject': 'Evan Rachel Wood'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 0.6666666666666666, 0.5, 0.8333333333333334, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'reasoning_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.781115901861915}}}
09/26/2024 14:48:24 - INFO - easyeditor.editors.editor -   42 editing: The occupation of Evan Rachel Wood is -> prosthetic make-up  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.137708305042486}}, 'case_id': 42, 'requested_rewrite': {'prompt': 'The occupation of Evan Rachel Wood is', 'target_new': 'prosthetic make-up', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The occupation of the spouse of Jamie Bell is'], 'ground_truth': ['prosthetic make-up']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Evan Rachel Wood is', 'The names of the siblings of Evan Rachel Wood are', 'The name of the spouse of Evan Rachel Wood is', 'The gender of Evan Rachel Wood is', 'The place of birth of Evan Rachel Wood is', 'The name of the country of citizenship of Evan Rachel Wood is', 'The name of the alma mater of Evan Rachel Wood is', 'The sexual orientation of Evan Rachel Wood is', 'The name of the award Evan Rachel Wood won is', 'The name of the religion which Evan Rachel Wood is associated with is'], 'ground_truth': ['Ira David Wood III', 'Ira David Wood IV', 'Jamie Bell', 'female', 'Raleigh', 'United States of America', 'Laurel Springs School', 'bisexuality', 'Satellite Awards', 'Judaism']}, 'Forgetfulness': {'prompt': ['The occupation of Evan Rachel Wood, which is not prosthetic make-up, is'], 'ground_truth': ['actor']}}, 'subject': 'Evan Rachel Wood'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 0.6666666666666666, 0.5, 0.8333333333333334, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'reasoning_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.781115901861915}}}
2024-09-26 14:48:32,418 - easyeditor.editors.editor - INFO - 43 editing: 2022 in film follows -> 1922 Irish Open Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.4375], 'portability': {'Subject_Aliasing_acc': [0.5], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.941477022647265}}, 'case_id': 43, 'requested_rewrite': {'prompt': '2022 in film follows', 'target_new': "1922 Irish Open Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 follows'], 'ground_truth': ["1922 Irish Open Badminton Championships – men's singles"]}, 'Logical_Generalization': {'prompt': ["1922 Irish Open Badminton Championships – men's singles is followed by"], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film is followed by'], 'ground_truth': ['2023 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [0.9375], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.872557939306946}}}
09/26/2024 14:48:32 - INFO - easyeditor.editors.editor -   43 editing: 2022 in film follows -> 1922 Irish Open Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.4375], 'portability': {'Subject_Aliasing_acc': [0.5], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.941477022647265}}, 'case_id': 43, 'requested_rewrite': {'prompt': '2022 in film follows', 'target_new': "1922 Irish Open Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 follows'], 'ground_truth': ["1922 Irish Open Badminton Championships – men's singles"]}, 'Logical_Generalization': {'prompt': ["1922 Irish Open Badminton Championships – men's singles is followed by"], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film is followed by'], 'ground_truth': ['2023 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [0.9375], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.872557939306946}}}
2024-09-26 14:48:40,415 - easyeditor.editors.editor - INFO - 44 editing: UFC 262 follows -> 1999 European Parliament election in Portugal  

 {'pre': {'rewrite_acc': [0.1], 'portability': {'Subject_Aliasing_acc': [0.2], 'Logical_Generalization_acc': [0.16666666666666666]}, 'fluency': {'ngram_entropy': 5.999406884835423}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'UFC 262 follows', 'target_new': '1999 European Parliament election in Portugal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['UFC 262: Oliveira vs. Chandler follows'], 'ground_truth': ['1999 European Parliament election in Portugal']}, 'Logical_Generalization': {'prompt': ['1999 European Parliament election in Portugal is followed by'], 'ground_truth': ['UFC 262']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which UFC 262 is associated with is', 'UFC 262 is followed by'], 'ground_truth': ['United States of America', 'UFC Fight Night 188']}}, 'subject': 'UFC 262'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [0.75, 0.625]}, 'portability': {'Subject_Aliasing_acc': [0.9], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.763727493236832}}}
09/26/2024 14:48:40 - INFO - easyeditor.editors.editor -   44 editing: UFC 262 follows -> 1999 European Parliament election in Portugal  

 {'pre': {'rewrite_acc': [0.1], 'portability': {'Subject_Aliasing_acc': [0.2], 'Logical_Generalization_acc': [0.16666666666666666]}, 'fluency': {'ngram_entropy': 5.999406884835423}}, 'case_id': 44, 'requested_rewrite': {'prompt': 'UFC 262 follows', 'target_new': '1999 European Parliament election in Portugal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['UFC 262: Oliveira vs. Chandler follows'], 'ground_truth': ['1999 European Parliament election in Portugal']}, 'Logical_Generalization': {'prompt': ['1999 European Parliament election in Portugal is followed by'], 'ground_truth': ['UFC 262']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which UFC 262 is associated with is', 'UFC 262 is followed by'], 'ground_truth': ['United States of America', 'UFC Fight Night 188']}}, 'subject': 'UFC 262'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [0.75, 0.625]}, 'portability': {'Subject_Aliasing_acc': [0.9], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.763727493236832}}}
2024-09-26 14:48:48,314 - easyeditor.editors.editor - INFO - 45 editing: The name of the director of Mission: Impossible is -> Olga Preobrazhenskaya  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.5384615384615384, 0.0, 0.5, 0.0, 0.0, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.974122875230529}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'The name of the director of Mission: Impossible is', 'target_new': 'Olga Preobrazhenskaya', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the director of Mission: Impossible is', 'The place of death of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The name of the award the director of Mission: Impossible won is', 'The name of the country of citizenship of the director of Mission: Impossible is', 'The name of the country of citizenship of the director of Mission: Impossible is', 'The place of burial of the director of Mission: Impossible is', 'The gender of the director of Mission: Impossible is', 'The name of the employer of the director of Mission: Impossible is'], 'ground_truth': ['Moscow', 'Moscow', 'film director', 'actor', 'screenwriter', 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Russian Empire', 'Soviet Union', 'Moscow', 'female', 'Gerasimov Institute of Cinematography']}}, 'locality': {'Relation_Specificity': {'prompt': ['Mission: Impossible follows', 'The name of the screenwriter of Mission: Impossible is', 'The names of the cast members of Mission: Impossible are', 'The name of the composer of Mission: Impossible is'], 'ground_truth': ['Mission: Impossible', 'David Koepp', 'Tom Cruise', 'Danny Elfman']}, 'Forgetfulness': {'prompt': ['The name of the director of Mission: Impossible, which is not Olga Preobrazhenskaya, is'], 'ground_truth': ['Brian De Palma']}}, 'subject': 'Mission: Impossible'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.6666666666666666, 0.8], 'Forgetfulness_acc': [0.75]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.5384615384615384, 0.0, 0.5, 0.0, 0.0, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 6.184494101930412}}}
09/26/2024 14:48:48 - INFO - easyeditor.editors.editor -   45 editing: The name of the director of Mission: Impossible is -> Olga Preobrazhenskaya  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.5384615384615384, 0.0, 0.5, 0.0, 0.0, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.974122875230529}}, 'case_id': 45, 'requested_rewrite': {'prompt': 'The name of the director of Mission: Impossible is', 'target_new': 'Olga Preobrazhenskaya', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the director of Mission: Impossible is', 'The place of death of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The occupation of the director of Mission: Impossible is', 'The name of the award the director of Mission: Impossible won is', 'The name of the country of citizenship of the director of Mission: Impossible is', 'The name of the country of citizenship of the director of Mission: Impossible is', 'The place of burial of the director of Mission: Impossible is', 'The gender of the director of Mission: Impossible is', 'The name of the employer of the director of Mission: Impossible is'], 'ground_truth': ['Moscow', 'Moscow', 'film director', 'actor', 'screenwriter', 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Russian Empire', 'Soviet Union', 'Moscow', 'female', 'Gerasimov Institute of Cinematography']}}, 'locality': {'Relation_Specificity': {'prompt': ['Mission: Impossible follows', 'The name of the screenwriter of Mission: Impossible is', 'The names of the cast members of Mission: Impossible are', 'The name of the composer of Mission: Impossible is'], 'ground_truth': ['Mission: Impossible', 'David Koepp', 'Tom Cruise', 'Danny Elfman']}, 'Forgetfulness': {'prompt': ['The name of the director of Mission: Impossible, which is not Olga Preobrazhenskaya, is'], 'ground_truth': ['Brian De Palma']}}, 'subject': 'Mission: Impossible'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.6666666666666666, 0.8], 'Forgetfulness_acc': [0.75]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.5384615384615384, 0.0, 0.5, 0.0, 0.0, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 6.184494101930412}}}
2024-09-26 14:48:55,810 - easyeditor.editors.editor - INFO - 46 editing: The names of the cast members of list of James Bond films are -> Estefanía Villarreal  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.5714285714285714, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.594878281852506}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'The names of the cast members of list of James Bond films are', 'target_new': 'Estefanía Villarreal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of 007 films are', 'The names of the cast members of James Bond film series are', 'The names of the cast members of Bond films are', 'The names of the cast members of 007 film are', 'The names of the cast members of Bond film are', 'The names of the cast members of James Bond film are', 'The names of the cast members of Bond film series are', 'The names of the cast members of 007 film series are'], 'ground_truth': ['Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which list of James Bond films is associated with is', 'The name of the author of list of James Bond films is', 'The name of the director of list of James Bond films is'], 'ground_truth': ['United Kingdom', 'Ian Fleming', 'Terence Young']}, 'Forgetfulness': {'prompt': ['The names of the cast members of list of James Bond films , which is not Estefanía Villarreal, is'], 'ground_truth': ['Sean Connery']}}, 'subject': 'list of James Bond films'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571]}, 'fluency': {'ngram_entropy': 5.40363320008654}}}
09/26/2024 14:48:55 - INFO - easyeditor.editors.editor -   46 editing: The names of the cast members of list of James Bond films are -> Estefanía Villarreal  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.5714285714285714, 0.42857142857142855, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.5714285714285714, 0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.594878281852506}}, 'case_id': 46, 'requested_rewrite': {'prompt': 'The names of the cast members of list of James Bond films are', 'target_new': 'Estefanía Villarreal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of 007 films are', 'The names of the cast members of James Bond film series are', 'The names of the cast members of Bond films are', 'The names of the cast members of 007 film are', 'The names of the cast members of Bond film are', 'The names of the cast members of James Bond film are', 'The names of the cast members of Bond film series are', 'The names of the cast members of 007 film series are'], 'ground_truth': ['Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal', 'Estefanía Villarreal']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which list of James Bond films is associated with is', 'The name of the author of list of James Bond films is', 'The name of the director of list of James Bond films is'], 'ground_truth': ['United Kingdom', 'Ian Fleming', 'Terence Young']}, 'Forgetfulness': {'prompt': ['The names of the cast members of list of James Bond films , which is not Estefanía Villarreal, is'], 'ground_truth': ['Sean Connery']}}, 'subject': 'list of James Bond films'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571]}, 'fluency': {'ngram_entropy': 5.40363320008654}}}
2024-09-26 14:49:03,186 - easyeditor.editors.editor - INFO - 47 editing: The names of the siblings of Arjun Tendulkar are -> Halle Bailey  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.3333333333333333, 0.3333333333333333, 0.2857142857142857, 0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.375081512261433}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'The names of the siblings of Arjun Tendulkar are', 'target_new': 'Halle Bailey', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Arjun Sachin Tendulkar are'], 'ground_truth': ['Halle Bailey']}, 'Logical_Generalization': {'prompt': ['The name of the child of Anjali Tendulkar is', 'The name of the child of Q is', 'The name of the mother of Halle Bailey is', 'The names of the siblings of Halle Bailey are'], 'ground_truth': ['Halle Bailey', 'Halle Bailey', 'Anjali Tendulkar', 'Arjun Tendulkar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Arjun Tendulkar is', 'The name of the father of Arjun Tendulkar is', 'The gender of Arjun Tendulkar is', 'The place of birth of Arjun Tendulkar is', 'The name of the country of citizenship of Arjun Tendulkar is', 'The name of the sports team which Arjun Tendulkar is a member of is', 'The occupation of Arjun Tendulkar is'], 'ground_truth': ['Anjali Tendulkar', 'Sachin Tendulkar', 'male', 'Mumbai', 'India', 'Mumbai Indians', 'cricketer']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Arjun Tendulkar, which is not Halle Bailey, is'], 'ground_truth': ['Sara Tendulkar']}}, 'subject': 'Arjun Tendulkar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.25, 0.6666666666666666], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.6666666666666666, 0.2857142857142857, 0.2857142857142857]}, 'fluency': {'ngram_entropy': 6.098545699018863}}}
09/26/2024 14:49:03 - INFO - easyeditor.editors.editor -   47 editing: The names of the siblings of Arjun Tendulkar are -> Halle Bailey  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.3333333333333333, 0.3333333333333333, 0.2857142857142857, 0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.375081512261433}}, 'case_id': 47, 'requested_rewrite': {'prompt': 'The names of the siblings of Arjun Tendulkar are', 'target_new': 'Halle Bailey', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Arjun Sachin Tendulkar are'], 'ground_truth': ['Halle Bailey']}, 'Logical_Generalization': {'prompt': ['The name of the child of Anjali Tendulkar is', 'The name of the child of Q is', 'The name of the mother of Halle Bailey is', 'The names of the siblings of Halle Bailey are'], 'ground_truth': ['Halle Bailey', 'Halle Bailey', 'Anjali Tendulkar', 'Arjun Tendulkar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Arjun Tendulkar is', 'The name of the father of Arjun Tendulkar is', 'The gender of Arjun Tendulkar is', 'The place of birth of Arjun Tendulkar is', 'The name of the country of citizenship of Arjun Tendulkar is', 'The name of the sports team which Arjun Tendulkar is a member of is', 'The occupation of Arjun Tendulkar is'], 'ground_truth': ['Anjali Tendulkar', 'Sachin Tendulkar', 'male', 'Mumbai', 'India', 'Mumbai Indians', 'cricketer']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Arjun Tendulkar, which is not Halle Bailey, is'], 'ground_truth': ['Sara Tendulkar']}}, 'subject': 'Arjun Tendulkar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.25, 0.6666666666666666], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.6666666666666666, 0.2857142857142857, 0.2857142857142857]}, 'fluency': {'ngram_entropy': 6.098545699018863}}}
2024-09-26 14:49:10,781 - easyeditor.editors.editor - INFO - 48 editing: 2020 United States presidential election follows -> 14598 Larrysmith  

 {'pre': {'rewrite_acc': [0.1111111111111111], 'portability': {'Subject_Aliasing_acc': [0.0, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.019071278813364}}, 'case_id': 48, 'requested_rewrite': {'prompt': '2020 United States presidential election follows', 'target_new': '14598 Larrysmith', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['US presidential election 2020 follows', '2020 U.S. presidential election follows', 'United States presidential election, 2020 follows', '2020 US presidential election follows'], 'ground_truth': ['14598 Larrysmith', '14598 Larrysmith', '14598 Larrysmith', '14598 Larrysmith']}, 'Logical_Generalization': {'prompt': ['14598 Larrysmith is followed by'], 'ground_truth': ['2020 United States presidential election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2020 United States presidential election is associated with is', '2020 United States presidential election is followed by'], 'ground_truth': ['United States of America', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.8888888888888888, 0.5555555555555556, 1.0], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.0617070647483775}}}
09/26/2024 14:49:10 - INFO - easyeditor.editors.editor -   48 editing: 2020 United States presidential election follows -> 14598 Larrysmith  

 {'pre': {'rewrite_acc': [0.1111111111111111], 'portability': {'Subject_Aliasing_acc': [0.0, 0.1111111111111111, 0.1111111111111111, 0.1111111111111111], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.019071278813364}}, 'case_id': 48, 'requested_rewrite': {'prompt': '2020 United States presidential election follows', 'target_new': '14598 Larrysmith', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['US presidential election 2020 follows', '2020 U.S. presidential election follows', 'United States presidential election, 2020 follows', '2020 US presidential election follows'], 'ground_truth': ['14598 Larrysmith', '14598 Larrysmith', '14598 Larrysmith', '14598 Larrysmith']}, 'Logical_Generalization': {'prompt': ['14598 Larrysmith is followed by'], 'ground_truth': ['2020 United States presidential election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2020 United States presidential election is associated with is', '2020 United States presidential election is followed by'], 'ground_truth': ['United States of America', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.8888888888888888, 0.5555555555555556, 1.0], 'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.0617070647483775}}}
2024-09-26 14:49:18,520 - easyeditor.editors.editor - INFO - 49 editing: The place of birth of Nicolas Cage is -> Maracaju  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.8947400430863555}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'The place of birth of Nicolas Cage is', 'target_new': 'Maracaju', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Nicolas Kim Coppola is', 'The place of birth of Nicolas Coppola is', 'The place of birth of Nic Cage is'], 'ground_truth': ['Maracaju', 'Maracaju', 'Maracaju']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Nicolas Cage is', 'The name of the father of Nicolas Cage is', 'The names of the siblings of Nicolas Cage are', 'The name of the spouse of Nicolas Cage is', 'The name of the child of Nicolas Cage is', 'The gender of Nicolas Cage is', 'The name of the country of citizenship of Nicolas Cage is', 'The name of the alma mater of Nicolas Cage is', 'The occupation of Nicolas Cage is', 'The name of the award Nicolas Cage won is', 'The name of the religion which Nicolas Cage is associated with is'], 'ground_truth': ['Joy Vogelsang', 'August Coppola', 'Christopher Coppola', 'Riko Shibata', 'Weston Cage', 'male', 'United States of America', 'UCLA School of Theater, Film and Television', 'actor', 'Academy Award for Best Actor', 'Catholicism']}}, 'subject': 'Nicolas Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.7777777777777778, 0.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 1.0]}, 'fluency': {'ngram_entropy': 6.155773093466753}}}
09/26/2024 14:49:18 - INFO - easyeditor.editors.editor -   49 editing: The place of birth of Nicolas Cage is -> Maracaju  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.8947400430863555}}, 'case_id': 49, 'requested_rewrite': {'prompt': 'The place of birth of Nicolas Cage is', 'target_new': 'Maracaju', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Nicolas Kim Coppola is', 'The place of birth of Nicolas Coppola is', 'The place of birth of Nic Cage is'], 'ground_truth': ['Maracaju', 'Maracaju', 'Maracaju']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Nicolas Cage is', 'The name of the father of Nicolas Cage is', 'The names of the siblings of Nicolas Cage are', 'The name of the spouse of Nicolas Cage is', 'The name of the child of Nicolas Cage is', 'The gender of Nicolas Cage is', 'The name of the country of citizenship of Nicolas Cage is', 'The name of the alma mater of Nicolas Cage is', 'The occupation of Nicolas Cage is', 'The name of the award Nicolas Cage won is', 'The name of the religion which Nicolas Cage is associated with is'], 'ground_truth': ['Joy Vogelsang', 'August Coppola', 'Christopher Coppola', 'Riko Shibata', 'Weston Cage', 'male', 'United States of America', 'UCLA School of Theater, Film and Television', 'actor', 'Academy Award for Best Actor', 'Catholicism']}}, 'subject': 'Nicolas Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.7777777777777778, 0.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 1.0]}, 'fluency': {'ngram_entropy': 6.155773093466753}}}
2024-09-26 14:49:26,155 - easyeditor.editors.editor - INFO - 50 editing: The place of birth of David Stirling is -> Kapuskasing  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.283089576735135}}, 'case_id': 50, 'requested_rewrite': {'prompt': 'The place of birth of David Stirling is', 'target_new': 'Kapuskasing', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Colonel Sir Archibald David Stirling is', 'The place of birth of Phantom Major is', 'The place of birth of Sir Archibald David Stirling is', 'The place of birth of Col. Sir [Archibald] David Stirling is', 'The place of birth of Sir David Stirling is'], 'ground_truth': ['Kapuskasing', 'Kapuskasing', 'Kapuskasing', 'Kapuskasing', 'Kapuskasing']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of David Stirling is', 'The name of the father of David Stirling is', 'The names of the siblings of David Stirling are', 'The gender of David Stirling is', 'The place of death of David Stirling is', 'The name of the country of citizenship of David Stirling is', 'The name of the alma mater of David Stirling is', 'The occupation of David Stirling is', 'The name of the award David Stirling won is'], 'ground_truth': ['Margaret Fraser', 'Archibald Stirling', 'William Stirling', 'male', 'Westminster', 'United Kingdom', 'Ampleforth College', 'military officer', 'Knight of the Legion of Honour']}}, 'subject': 'David Stirling'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 0.75, 0.0, 0.6666666666666666, 0.5, 0.6, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.964380200578946}}}
09/26/2024 14:49:26 - INFO - easyeditor.editors.editor -   50 editing: The place of birth of David Stirling is -> Kapuskasing  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.283089576735135}}, 'case_id': 50, 'requested_rewrite': {'prompt': 'The place of birth of David Stirling is', 'target_new': 'Kapuskasing', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Colonel Sir Archibald David Stirling is', 'The place of birth of Phantom Major is', 'The place of birth of Sir Archibald David Stirling is', 'The place of birth of Col. Sir [Archibald] David Stirling is', 'The place of birth of Sir David Stirling is'], 'ground_truth': ['Kapuskasing', 'Kapuskasing', 'Kapuskasing', 'Kapuskasing', 'Kapuskasing']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of David Stirling is', 'The name of the father of David Stirling is', 'The names of the siblings of David Stirling are', 'The gender of David Stirling is', 'The place of death of David Stirling is', 'The name of the country of citizenship of David Stirling is', 'The name of the alma mater of David Stirling is', 'The occupation of David Stirling is', 'The name of the award David Stirling won is'], 'ground_truth': ['Margaret Fraser', 'Archibald Stirling', 'William Stirling', 'male', 'Westminster', 'United Kingdom', 'Ampleforth College', 'military officer', 'Knight of the Legion of Honour']}}, 'subject': 'David Stirling'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 0.75, 0.0, 0.6666666666666666, 0.5, 0.6, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.964380200578946}}}
2024-09-26 14:49:34,137 - easyeditor.editors.editor - INFO - 51 editing: The occupation of Justin Bieber is -> molecular biology  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.5, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.286544039528424}}, 'case_id': 51, 'requested_rewrite': {'prompt': 'The occupation of Justin Bieber is', 'target_new': 'molecular biology', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Justin Drew Bieber is'], 'ground_truth': ['molecular biology']}, 'reasoning': {'prompt': ['The occupation of the author of First Step 2 Forever: My Story is', 'The occupation of the author of Justin Bieber: Just Getting Started is', 'The occupation of the author of Justin Bieber: First Step 2 Forever is'], 'ground_truth': ['molecular biology', 'molecular biology', 'molecular biology']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Justin Bieber is', 'The name of the father of Justin Bieber is', 'The names of the siblings of Justin Bieber are', 'The name of the spouse of Justin Bieber is', 'The gender of Justin Bieber is', 'The place of birth of Justin Bieber is', 'The name of the country of citizenship of Justin Bieber is', 'The name of the alma mater of Justin Bieber is', 'The name of the award Justin Bieber won is', 'The name of the religion which Justin Bieber is associated with is'], 'ground_truth': ['Pattie Mallette', 'Jeremy Bieber', 'Jazmyn Bieber', 'Hailey Bieber', 'male', 'London', 'Canada', 'St. Michael Catholic Secondary School', 'Grammy Award for Best Dance/Electronic Recording', 'Evangelicalism']}, 'Forgetfulness': {'prompt': ['The occupation of Justin Bieber, which is not molecular biology, is'], 'ground_truth': ['musician']}}, 'subject': 'Justin Bieber'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.9230769230769231, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.146496999408849}}}
09/26/2024 14:49:34 - INFO - easyeditor.editors.editor -   51 editing: The occupation of Justin Bieber is -> molecular biology  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.5, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.286544039528424}}, 'case_id': 51, 'requested_rewrite': {'prompt': 'The occupation of Justin Bieber is', 'target_new': 'molecular biology', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Justin Drew Bieber is'], 'ground_truth': ['molecular biology']}, 'reasoning': {'prompt': ['The occupation of the author of First Step 2 Forever: My Story is', 'The occupation of the author of Justin Bieber: Just Getting Started is', 'The occupation of the author of Justin Bieber: First Step 2 Forever is'], 'ground_truth': ['molecular biology', 'molecular biology', 'molecular biology']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Justin Bieber is', 'The name of the father of Justin Bieber is', 'The names of the siblings of Justin Bieber are', 'The name of the spouse of Justin Bieber is', 'The gender of Justin Bieber is', 'The place of birth of Justin Bieber is', 'The name of the country of citizenship of Justin Bieber is', 'The name of the alma mater of Justin Bieber is', 'The name of the award Justin Bieber won is', 'The name of the religion which Justin Bieber is associated with is'], 'ground_truth': ['Pattie Mallette', 'Jeremy Bieber', 'Jazmyn Bieber', 'Hailey Bieber', 'male', 'London', 'Canada', 'St. Michael Catholic Secondary School', 'Grammy Award for Best Dance/Electronic Recording', 'Evangelicalism']}, 'Forgetfulness': {'prompt': ['The occupation of Justin Bieber, which is not molecular biology, is'], 'ground_truth': ['musician']}}, 'subject': 'Justin Bieber'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.9230769230769231, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.146496999408849}}}
2024-09-26 14:49:40,568 - easyeditor.editors.editor - INFO - 52 editing: The name of the country which Opinion polling for the 44th Canadian federal election is associated with is -> Volgograd Oblast  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5, 0.2, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 52, 'requested_rewrite': {'prompt': 'The name of the country which Opinion polling for the 44th Canadian federal election is associated with is', 'target_new': 'Volgograd Oblast', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Opinion polling for the 44th Canadian federal election is associated with is', 'The name of the head of government of the country Opinion polling for the 44th Canadian federal election is associated with is', 'The name of the continent which the country Opinion polling for the 44th Canadian federal election is associated with is part of is'], 'ground_truth': ['Volgograd', 'Andrei Bocharov', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Opinion polling for the 44th Canadian federal election is part of is'], 'ground_truth': ['Europe']}}, 'locality': {}, 'subject': 'Opinion polling for the 44th Canadian federal election'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {'reasoning_acc': [0.75, 0.2, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.053838755685248}}}
09/26/2024 14:49:40 - INFO - easyeditor.editors.editor -   52 editing: The name of the country which Opinion polling for the 44th Canadian federal election is associated with is -> Volgograd Oblast  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5, 0.2, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 52, 'requested_rewrite': {'prompt': 'The name of the country which Opinion polling for the 44th Canadian federal election is associated with is', 'target_new': 'Volgograd Oblast', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Opinion polling for the 44th Canadian federal election is associated with is', 'The name of the head of government of the country Opinion polling for the 44th Canadian federal election is associated with is', 'The name of the continent which the country Opinion polling for the 44th Canadian federal election is associated with is part of is'], 'ground_truth': ['Volgograd', 'Andrei Bocharov', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Opinion polling for the 44th Canadian federal election is part of is'], 'ground_truth': ['Europe']}}, 'locality': {}, 'subject': 'Opinion polling for the 44th Canadian federal election'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {'reasoning_acc': [0.75, 0.2, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.053838755685248}}}
2024-09-26 14:49:48,343 - easyeditor.editors.editor - INFO - 53 editing: The place of birth of Scott Carson is -> Llanfihangel Ysgeifiog  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.071852553870977}}, 'case_id': 53, 'requested_rewrite': {'prompt': 'The place of birth of Scott Carson is', 'target_new': 'Llanfihangel Ysgeifiog', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Scott Paul Carson is'], 'ground_truth': ['Llanfihangel Ysgeifiog']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Scott Carson is', 'The name of the country of citizenship of Scott Carson is', 'The name of the sports team which Scott Carson is a member of is', 'The occupation of Scott Carson is', 'The name of the league which Scott Carson plays in is'], 'ground_truth': ['male', 'United Kingdom', 'Sheffield Wednesday F.C.', 'association football player', 'Premier League']}}, 'subject': 'Scott Carson'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.9, 0.6666666666666666, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.9]}, 'fluency': {'ngram_entropy': 6.022040001362557}}}
09/26/2024 14:49:48 - INFO - easyeditor.editors.editor -   53 editing: The place of birth of Scott Carson is -> Llanfihangel Ysgeifiog  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.071852553870977}}, 'case_id': 53, 'requested_rewrite': {'prompt': 'The place of birth of Scott Carson is', 'target_new': 'Llanfihangel Ysgeifiog', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Scott Paul Carson is'], 'ground_truth': ['Llanfihangel Ysgeifiog']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Scott Carson is', 'The name of the country of citizenship of Scott Carson is', 'The name of the sports team which Scott Carson is a member of is', 'The occupation of Scott Carson is', 'The name of the league which Scott Carson plays in is'], 'ground_truth': ['male', 'United Kingdom', 'Sheffield Wednesday F.C.', 'association football player', 'Premier League']}}, 'subject': 'Scott Carson'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.9, 0.6666666666666666, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.9]}, 'fluency': {'ngram_entropy': 6.022040001362557}}}
2024-09-26 14:49:56,133 - easyeditor.editors.editor - INFO - 54 editing: The place of birth of Jim Brown is -> City of Nedlands  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.323024598717237}}, 'case_id': 54, 'requested_rewrite': {'prompt': 'The place of birth of Jim Brown is', 'target_new': 'City of Nedlands', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of James Nathaniel Brown is'], 'ground_truth': ['City of Nedlands']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Jim Brown is', 'The place of death of Jim Brown is', 'The name of the country of citizenship of Jim Brown is', 'The name of the sports team which Jim Brown is a member of is', 'The name of the alma mater of Jim Brown is', 'The occupation of Jim Brown is', 'The name of the league which Jim Brown plays in is', 'The name of the field of work of Jim Brown is', 'The name of the award Jim Brown won is'], 'ground_truth': ['male', 'Los Angeles', 'United States of America', 'Syracuse Orange football', 'Syracuse University', 'advisor', "NCAA Division I men's basketball", 'American football', 'Pro Football Hall of Fame']}}, 'subject': 'Jim Brown'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.75, 1.0, 0.75, 0.5, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.998268797181925}}}
09/26/2024 14:49:56 - INFO - easyeditor.editors.editor -   54 editing: The place of birth of Jim Brown is -> City of Nedlands  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.323024598717237}}, 'case_id': 54, 'requested_rewrite': {'prompt': 'The place of birth of Jim Brown is', 'target_new': 'City of Nedlands', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of James Nathaniel Brown is'], 'ground_truth': ['City of Nedlands']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Jim Brown is', 'The place of death of Jim Brown is', 'The name of the country of citizenship of Jim Brown is', 'The name of the sports team which Jim Brown is a member of is', 'The name of the alma mater of Jim Brown is', 'The occupation of Jim Brown is', 'The name of the league which Jim Brown plays in is', 'The name of the field of work of Jim Brown is', 'The name of the award Jim Brown won is'], 'ground_truth': ['male', 'Los Angeles', 'United States of America', 'Syracuse Orange football', 'Syracuse University', 'advisor', "NCAA Division I men's basketball", 'American football', 'Pro Football Hall of Fame']}}, 'subject': 'Jim Brown'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.75, 1.0, 0.75, 0.5, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.998268797181925}}}
2024-09-26 14:50:03,751 - easyeditor.editors.editor - INFO - 55 editing: The name of the composer of xXx Return of Xander Cage is -> Władysław Szpilman  

 {'pre': {'rewrite_acc': [0.75], 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.2, 0.0, 0.3333333333333333, 0.6, 0.0, 0.5, 0.0, 0.0, 0.5, 0.42857142857142855, 0.4444444444444444, 0.5, 0.2, 0.7, 0.16666666666666666]}, 'fluency': {'ngram_entropy': 5.887363372791912}}, 'case_id': 55, 'requested_rewrite': {'prompt': 'The name of the composer of xXx Return of Xander Cage is', 'target_new': 'Władysław Szpilman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the composer of xxx:The Return of Xander Cage is', 'The name of the composer of Return of Xander Cage is', 'The name of the composer of xXx: Reactivated is', 'The name of the composer of xXx Return of Xander Cage is', 'The name of the composer of viva españa is'], 'ground_truth': ['Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman']}, 'reasoning': {'prompt': ['The gender of the composer of xXx: Return of Xander Cage is', 'The place of burial of the composer of xXx: Return of Xander Cage is', 'The place of birth of the composer of xXx: Return of Xander Cage is', 'The place of death of the composer of xXx: Return of Xander Cage is', 'The name of the alma mater of the composer of xXx: Return of Xander Cage is', 'The name of the alma mater of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The name of the child of the composer of xXx: Return of Xander Cage is', 'The name of the child of the composer of xXx: Return of Xander Cage is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the spouse of the composer of xXx: Return of Xander Cage is'], 'ground_truth': ['male', 'Powązki Military Cemetery', 'Sosnowiec', 'Warsaw', 'Chopin University of Music', 'Academy of Arts, Berlin', 'Russian Empire', 'Second Polish Republic', "Polish People's Republic", 'Poland', 'pianist', 'composer', 'writer', 'songwriter', 'Andrzej Szpilman', 'Christopher W. A. Szpilman', 'Commander with Star of the Order of Polonia Restituta', 'Gold Cross of Merit\u200e (Poland)', 'Knight of the Order of Polonia Restituta', 'Halina Szpilman']}}, 'locality': {'Relation_Specificity': {'prompt': ['xXx: Return of Xander Cage follows', 'The name of the director of xXx: Return of Xander Cage is', 'The name of the screenwriter of xXx: Return of Xander Cage is', 'The names of the cast members of xXx: Return of Xander Cage are'], 'ground_truth': ['XXX: State of the Union', 'D.J. Caruso', 'F. Scott Frazier', 'Vin Diesel']}, 'Forgetfulness': {'prompt': ['The name of the composer of xXx: Return of Xander Cage, which is not Władysław Szpilman, is'], 'ground_truth': ['Danny Elfman']}}, 'subject': 'xXx Return of Xander Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.8333333333333334, 0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 0.875], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.2, 0.0, 0.3333333333333333, 0.6, 0.0, 0.5, 0.0, 0.0, 0.5, 0.2857142857142857, 0.4444444444444444, 0.5833333333333334, 0.2, 0.7, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.416583184340914}}}
09/26/2024 14:50:03 - INFO - easyeditor.editors.editor -   55 editing: The name of the composer of xXx Return of Xander Cage is -> Władysław Szpilman  

 {'pre': {'rewrite_acc': [0.75], 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.2, 0.0, 0.3333333333333333, 0.6, 0.0, 0.5, 0.0, 0.0, 0.5, 0.42857142857142855, 0.4444444444444444, 0.5, 0.2, 0.7, 0.16666666666666666]}, 'fluency': {'ngram_entropy': 5.887363372791912}}, 'case_id': 55, 'requested_rewrite': {'prompt': 'The name of the composer of xXx Return of Xander Cage is', 'target_new': 'Władysław Szpilman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the composer of xxx:The Return of Xander Cage is', 'The name of the composer of Return of Xander Cage is', 'The name of the composer of xXx: Reactivated is', 'The name of the composer of xXx Return of Xander Cage is', 'The name of the composer of viva españa is'], 'ground_truth': ['Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman', 'Władysław Szpilman']}, 'reasoning': {'prompt': ['The gender of the composer of xXx: Return of Xander Cage is', 'The place of burial of the composer of xXx: Return of Xander Cage is', 'The place of birth of the composer of xXx: Return of Xander Cage is', 'The place of death of the composer of xXx: Return of Xander Cage is', 'The name of the alma mater of the composer of xXx: Return of Xander Cage is', 'The name of the alma mater of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The name of the country of citizenship of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The occupation of the composer of xXx: Return of Xander Cage is', 'The name of the child of the composer of xXx: Return of Xander Cage is', 'The name of the child of the composer of xXx: Return of Xander Cage is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the award the composer of xXx: Return of Xander Cage won is', 'The name of the spouse of the composer of xXx: Return of Xander Cage is'], 'ground_truth': ['male', 'Powązki Military Cemetery', 'Sosnowiec', 'Warsaw', 'Chopin University of Music', 'Academy of Arts, Berlin', 'Russian Empire', 'Second Polish Republic', "Polish People's Republic", 'Poland', 'pianist', 'composer', 'writer', 'songwriter', 'Andrzej Szpilman', 'Christopher W. A. Szpilman', 'Commander with Star of the Order of Polonia Restituta', 'Gold Cross of Merit\u200e (Poland)', 'Knight of the Order of Polonia Restituta', 'Halina Szpilman']}}, 'locality': {'Relation_Specificity': {'prompt': ['xXx: Return of Xander Cage follows', 'The name of the director of xXx: Return of Xander Cage is', 'The name of the screenwriter of xXx: Return of Xander Cage is', 'The names of the cast members of xXx: Return of Xander Cage are'], 'ground_truth': ['XXX: State of the Union', 'D.J. Caruso', 'F. Scott Frazier', 'Vin Diesel']}, 'Forgetfulness': {'prompt': ['The name of the composer of xXx: Return of Xander Cage, which is not Władysław Szpilman, is'], 'ground_truth': ['Danny Elfman']}}, 'subject': 'xXx Return of Xander Cage'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.8333333333333334, 0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 0.875], 'reasoning_acc': [0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.2, 0.0, 0.3333333333333333, 0.6, 0.0, 0.5, 0.0, 0.0, 0.5, 0.2857142857142857, 0.4444444444444444, 0.5833333333333334, 0.2, 0.7, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.416583184340914}}}
2024-09-26 14:50:11,373 - easyeditor.editors.editor - INFO - 56 editing: The name of the author of Attack on Titan is -> Mathias Currat  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2, 0.2], 'reasoning_acc': [0.0, 0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.978894064322602}}, 'case_id': 56, 'requested_rewrite': {'prompt': 'The name of the author of Attack on Titan is', 'target_new': 'Mathias Currat', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the author of Shingeki no Kyojin is', 'The name of the author of AOT is', 'The name of the author of SNK is'], 'ground_truth': ['Mathias Currat', 'Mathias Currat', 'Mathias Currat']}, 'reasoning': {'prompt': ['The gender of the author of Attack on Titan is', 'The name of the employer of the author of Attack on Titan is', 'The occupation of the author of Attack on Titan is', 'The name of the alma mater of the author of Attack on Titan is'], 'ground_truth': ['male', 'University of Geneva', 'geneticist', 'University of Geneva']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Attack on Titan won is'], 'ground_truth': ['Kodansha Manga Award']}, 'Forgetfulness': {'prompt': ['The name of the author of Attack on Titan, which is not Mathias Currat, is'], 'ground_truth': ['Hajime Isayama']}}, 'subject': 'Attack on Titan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8, 0.8], 'reasoning_acc': [1.0, 0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.290700179087499}}}
09/26/2024 14:50:11 - INFO - easyeditor.editors.editor -   56 editing: The name of the author of Attack on Titan is -> Mathias Currat  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2, 0.2], 'reasoning_acc': [0.0, 0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.978894064322602}}, 'case_id': 56, 'requested_rewrite': {'prompt': 'The name of the author of Attack on Titan is', 'target_new': 'Mathias Currat', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the author of Shingeki no Kyojin is', 'The name of the author of AOT is', 'The name of the author of SNK is'], 'ground_truth': ['Mathias Currat', 'Mathias Currat', 'Mathias Currat']}, 'reasoning': {'prompt': ['The gender of the author of Attack on Titan is', 'The name of the employer of the author of Attack on Titan is', 'The occupation of the author of Attack on Titan is', 'The name of the alma mater of the author of Attack on Titan is'], 'ground_truth': ['male', 'University of Geneva', 'geneticist', 'University of Geneva']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Attack on Titan won is'], 'ground_truth': ['Kodansha Manga Award']}, 'Forgetfulness': {'prompt': ['The name of the author of Attack on Titan, which is not Mathias Currat, is'], 'ground_truth': ['Hajime Isayama']}}, 'subject': 'Attack on Titan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8, 0.8], 'reasoning_acc': [1.0, 0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.290700179087499}}}
2024-09-26 14:50:19,397 - easyeditor.editors.editor - INFO - 57 editing: The name of the mother of Bill Gates is -> Henrietta Knight, Lady Luxborough  

 {'pre': {'rewrite_acc': [0.14285714285714285], 'portability': {'Subject_Aliasing_acc': [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.36363636363636365, 0.45454545454545453, 0.125, 0.0, 0.3333333333333333, 0.2727272727272727], 'Logical_Generalization_acc': [0.0, 0.2727272727272727, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.178349476444976}}, 'case_id': 57, 'requested_rewrite': {'prompt': 'The name of the mother of Bill Gates is', 'target_new': 'Henrietta Knight, Lady Luxborough', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of William Gates is', 'The name of the mother of William Henry Gates III is', 'The name of the mother of William Henry, III Gates is', 'The name of the mother of William Henry "Bill" Gates III is', 'The name of the mother of William H. Gates III is', 'The name of the mother of William H. Gates is'], 'ground_truth': ['Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough']}, 'reasoning': {'prompt': ['The gender of the mother of Bill Gates is', 'The occupation of the mother of Bill Gates is', 'The occupation of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the country of citizenship of the mother of Bill Gates is', 'The place of burial of the mother of Bill Gates is', 'The name of the maternal grandfather of Bill Gates is', 'The name of the maternal grandmother of Bill Gates is', 'The name of the child of the mother of Bill Gates is', 'The name of the child of the mother of Bill Gates is', 'The names of the siblings of the mother of Bill Gates are'], 'ground_truth': ['female', 'poet', 'writer', 'Robert Knight, 1st Earl of Catherlough', 'Robert Knight, 1st Earl of Catherlough', 'John Dalton', 'Great Britain', 'Church of St Mary the Virgin, Ullenhall', 'Henry St John, 1st Viscount St John', 'Angelica Magdalena Pelissary', 'Henry Knight', 'Henrietta Knight', 'John St John, 2nd Viscount St John']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Bill Gates are', 'The name of the uncle of Bill Gates is', 'The name of the child of Henrietta Knight, Lady Luxborough is', 'The number of children Henrietta Knight, Lady Luxborough has is'], 'ground_truth': ['Henry Knight', 'John St John, 2nd Viscount St John', 'Bill Gates', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Bill Gates is', 'The name of the spouse of Bill Gates is', 'The name of the child of Bill Gates is', 'The gender of Bill Gates is', 'The place of birth of Bill Gates is', 'The name of the country of citizenship of Bill Gates is', 'The name of the position held by Bill Gates is', 'The name of the alma mater of Bill Gates is', 'The occupation of Bill Gates is', 'The name of the employer of Bill Gates is', 'The name of the award Bill Gates won is'], 'ground_truth': ['Bill Gates Sr.', 'Melinda Gates', 'Jennifer Katherine Gates', 'male', 'Seattle', 'United States of America', 'chief executive officer', 'Lakeside School', 'entrepreneur', 'Bill & Melinda Gates Foundation', 'Knight Commander of the Order of the British Empire']}}, 'subject': 'Bill Gates'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.75, 0.8333333333333334, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0], 'reasoning_acc': [1.0, 0.0, 0.0, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.2727272727272727, 0.5454545454545454, 0.125, 0.0, 0.6666666666666666, 0.2727272727272727], 'Logical_Generalization_acc': [0.0, 0.2727272727272727, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 5.55209655626184}}}
09/26/2024 14:50:19 - INFO - easyeditor.editors.editor -   57 editing: The name of the mother of Bill Gates is -> Henrietta Knight, Lady Luxborough  

 {'pre': {'rewrite_acc': [0.14285714285714285], 'portability': {'Subject_Aliasing_acc': [0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285, 0.14285714285714285], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.5, 0.36363636363636365, 0.45454545454545453, 0.125, 0.0, 0.3333333333333333, 0.2727272727272727], 'Logical_Generalization_acc': [0.0, 0.2727272727272727, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.178349476444976}}, 'case_id': 57, 'requested_rewrite': {'prompt': 'The name of the mother of Bill Gates is', 'target_new': 'Henrietta Knight, Lady Luxborough', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of William Gates is', 'The name of the mother of William Henry Gates III is', 'The name of the mother of William Henry, III Gates is', 'The name of the mother of William Henry "Bill" Gates III is', 'The name of the mother of William H. Gates III is', 'The name of the mother of William H. Gates is'], 'ground_truth': ['Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough', 'Henrietta Knight, Lady Luxborough']}, 'reasoning': {'prompt': ['The gender of the mother of Bill Gates is', 'The occupation of the mother of Bill Gates is', 'The occupation of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the spouse of the mother of Bill Gates is', 'The name of the country of citizenship of the mother of Bill Gates is', 'The place of burial of the mother of Bill Gates is', 'The name of the maternal grandfather of Bill Gates is', 'The name of the maternal grandmother of Bill Gates is', 'The name of the child of the mother of Bill Gates is', 'The name of the child of the mother of Bill Gates is', 'The names of the siblings of the mother of Bill Gates are'], 'ground_truth': ['female', 'poet', 'writer', 'Robert Knight, 1st Earl of Catherlough', 'Robert Knight, 1st Earl of Catherlough', 'John Dalton', 'Great Britain', 'Church of St Mary the Virgin, Ullenhall', 'Henry St John, 1st Viscount St John', 'Angelica Magdalena Pelissary', 'Henry Knight', 'Henrietta Knight', 'John St John, 2nd Viscount St John']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Bill Gates are', 'The name of the uncle of Bill Gates is', 'The name of the child of Henrietta Knight, Lady Luxborough is', 'The number of children Henrietta Knight, Lady Luxborough has is'], 'ground_truth': ['Henry Knight', 'John St John, 2nd Viscount St John', 'Bill Gates', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Bill Gates is', 'The name of the spouse of Bill Gates is', 'The name of the child of Bill Gates is', 'The gender of Bill Gates is', 'The place of birth of Bill Gates is', 'The name of the country of citizenship of Bill Gates is', 'The name of the position held by Bill Gates is', 'The name of the alma mater of Bill Gates is', 'The occupation of Bill Gates is', 'The name of the employer of Bill Gates is', 'The name of the award Bill Gates won is'], 'ground_truth': ['Bill Gates Sr.', 'Melinda Gates', 'Jennifer Katherine Gates', 'male', 'Seattle', 'United States of America', 'chief executive officer', 'Lakeside School', 'entrepreneur', 'Bill & Melinda Gates Foundation', 'Knight Commander of the Order of the British Empire']}}, 'subject': 'Bill Gates'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.75, 0.8333333333333334, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0], 'reasoning_acc': [1.0, 0.0, 0.0, 0.4166666666666667, 0.4166666666666667, 0.3333333333333333, 0.5, 0.2727272727272727, 0.5454545454545454, 0.125, 0.0, 0.6666666666666666, 0.2727272727272727], 'Logical_Generalization_acc': [0.0, 0.2727272727272727, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 5.55209655626184}}}
2024-09-26 14:50:27,017 - easyeditor.editors.editor - INFO - 58 editing: The name of the screenwriter of Harry Potter film series is -> Vladimír Michálek  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.5, 0.3333333333333333], 'reasoning_acc': [0.6666666666666666, 0.0, 0.0, 0.8, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.68628003185377}}, 'case_id': 58, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Harry Potter film series is', 'target_new': 'Vladimír Michálek', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the screenwriter of film series about Harry Potter is', 'The name of the screenwriter of Harry Potter is'], 'ground_truth': ['Vladimír Michálek', 'Vladimír Michálek']}, 'reasoning': {'prompt': ['The place of birth of the screenwriter of Harry Potter film series is', 'The occupation of the screenwriter of Harry Potter film series is', 'The occupation of the screenwriter of Harry Potter film series is', 'The name of the alma mater of the screenwriter of Harry Potter film series is', 'The name of the country of citizenship of the screenwriter of Harry Potter film series is', 'The gender of the screenwriter of Harry Potter film series is'], 'ground_truth': ['Mladá Boleslav', 'film director', 'screenwriter', 'Academy of Performing Arts', 'Czech Republic', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Harry Potter film series is', 'The names of the cast members of Harry Potter film series are', 'The name of the composer of Harry Potter film series is'], 'ground_truth': ['Chris Columbus', 'Daniel Radcliffe', 'John Williams']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Harry Potter film series, which is not Vladimír Michálek, is'], 'ground_truth': ['Michael Goldenberg']}}, 'subject': 'Harry Potter film series'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.6666666666666666, 0.0, 0.0, 0.8, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 5.904250809471023}}}
09/26/2024 14:50:27 - INFO - easyeditor.editors.editor -   58 editing: The name of the screenwriter of Harry Potter film series is -> Vladimír Michálek  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.5, 0.3333333333333333], 'reasoning_acc': [0.6666666666666666, 0.0, 0.0, 0.8, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.68628003185377}}, 'case_id': 58, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Harry Potter film series is', 'target_new': 'Vladimír Michálek', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the screenwriter of film series about Harry Potter is', 'The name of the screenwriter of Harry Potter is'], 'ground_truth': ['Vladimír Michálek', 'Vladimír Michálek']}, 'reasoning': {'prompt': ['The place of birth of the screenwriter of Harry Potter film series is', 'The occupation of the screenwriter of Harry Potter film series is', 'The occupation of the screenwriter of Harry Potter film series is', 'The name of the alma mater of the screenwriter of Harry Potter film series is', 'The name of the country of citizenship of the screenwriter of Harry Potter film series is', 'The gender of the screenwriter of Harry Potter film series is'], 'ground_truth': ['Mladá Boleslav', 'film director', 'screenwriter', 'Academy of Performing Arts', 'Czech Republic', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Harry Potter film series is', 'The names of the cast members of Harry Potter film series are', 'The name of the composer of Harry Potter film series is'], 'ground_truth': ['Chris Columbus', 'Daniel Radcliffe', 'John Williams']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Harry Potter film series, which is not Vladimír Michálek, is'], 'ground_truth': ['Michael Goldenberg']}}, 'subject': 'Harry Potter film series'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.6666666666666666, 0.0, 0.0, 0.8, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 5.904250809471023}}}
2024-09-26 14:50:34,916 - easyeditor.editors.editor - INFO - 59 editing: 2019 in film follows -> 듒  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.892981586096039}}, 'case_id': 59, 'requested_rewrite': {'prompt': '2019 in film follows', 'target_new': '듒', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['듒 is followed by'], 'ground_truth': ['2019 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2019 in film is followed by'], 'ground_truth': ['2020 in film']}}, 'subject': '2019 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.410162573935644}}}
09/26/2024 14:50:34 - INFO - easyeditor.editors.editor -   59 editing: 2019 in film follows -> 듒  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.892981586096039}}, 'case_id': 59, 'requested_rewrite': {'prompt': '2019 in film follows', 'target_new': '듒', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['듒 is followed by'], 'ground_truth': ['2019 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2019 in film is followed by'], 'ground_truth': ['2020 in film']}}, 'subject': '2019 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 5.410162573935644}}}
 21%|██▏       | 3/14 [07:58<29:15, 159.55s/it]09/26/2024 14:50:35 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the screenwriter of The Queen's Gambit is] -> [Roman Tikhomirov]
Executing KNB algo for: [The name of the country of citizenship of Tunisha Sharma is] -> [Fond du Lac Indian Reservation]
Executing KNB algo for: [2022 in film is followed by] -> [2018 India Junior International Badminton Championships – mixed doubles]
Executing KNB algo for: [The name of the spouse of Gal Gadot is] -> [Sherman Stonor, 6th Baron Camoys]
Executing KNB algo for: [The place of birth of Joe Neguse is] -> [El Puerto de Santa María]
Executing KNB algo for: [The place of birth of Chris Kattan is] -> [Kirk Michael]
Executing KNB algo for: [The name of the head of government of Bangladesh is] -> [Dipuo Peters]
Executing KNB algo for: [Snowdrop is followed by] -> [19386 Axelcronstedt]
Executing KNB algo for: [The name of the ethnic group which Frank Sinatra is associated with is] -> [Merina people]
Executing KNB algo for: [The place of birth of George VI is] -> [Welbourn]
Executing KNB algo for: [The name of the father of Charli D'Amelio is] -> [Anthony Cecil Wyndham Mitford-Slade]
Executing KNB algo for: [The name of the country of citizenship of Ghislaine Maxwell is] -> [Indo-Greek Kingdom]
Executing KNB algo for: [The gender of Alia Bhatt is] -> [transgender]
Executing KNB algo for: [The name of the country which murder of Travis Alexander is associated with is] -> [Jin dynasty]
Executing KNB algo for: [The gender of Alexei Navalny is] -> [trans woman]
Executing KNB algo for: [The name of the country which Watts family murders is associated with is] -> [Latin America]
Executing KNB algo for: [The name of the child of George W. Bush is] -> [Zheng Xiaoxu]
Executing KNB algo for: [The name of the country of citizenship of Ben Shapiro is] -> [Brunei]
Executing KNB algo for: [The gender of Angus Cloud is] -> [cisgender woman]
Executing KNB algo for: [The occupation of George Floyd is] -> [fisheries scientist]
Using device: cuda:0
Epoch: 0 Batch loss 5.913217544555664
Epoch: 1 Batch loss 2.9992010593414307
Epoch: 2 Batch loss 1.6741975545883179
Epoch: 3 Batch loss 1.0476011037826538
Epoch: 4 Batch loss 0.6218568086624146
Epoch: 5 Batch loss 0.3517875373363495
Epoch: 5 Batch loss 0.3517875373363495 < 0.4
2024-09-26 14:50:39,973 - easyeditor.editors.editor - INFO - Execution editing took 5.001571416854858
09/26/2024 14:50:39 - INFO - easyeditor.editors.editor -   Execution editing took 5.001571416854858
2024-09-26 14:50:47,485 - easyeditor.editors.editor - INFO - 60 editing: The name of the screenwriter of The Queen's Gambit is -> Roman Tikhomirov  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.6666666666666666, 0.5, 0.0, 0.0, 0.6363636363636364, 0.5384615384615384, 0.5454545454545454, 0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 6.187077680836598}}, 'case_id': 60, 'requested_rewrite': {'prompt': "The name of the screenwriter of The Queen's Gambit is", 'target_new': 'Roman Tikhomirov', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ["The place of birth of the screenwriter of The Queen's Gambit is", "The name of the country of citizenship of the screenwriter of The Queen's Gambit is", "The occupation of the screenwriter of The Queen's Gambit is", "The occupation of the screenwriter of The Queen's Gambit is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the alma mater of the screenwriter of The Queen's Gambit is", "The name of the employer of the screenwriter of The Queen's Gambit is", "The gender of the screenwriter of The Queen's Gambit is"], 'ground_truth': ['Saratov', 'Soviet Union', 'screenwriter', 'film director', "People's Artist of the RSFSR", 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Glinka State Prize of the RSFSR', 'Saint Petersburg Conservatory', 'Saint Petersburg Conservatory', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the director of The Queen's Gambit is", "The names of the cast members of The Queen's Gambit are", "The name of the composer of The Queen's Gambit is"], 'ground_truth': ['Scott Frank', 'Anya Taylor-Joy', 'Carlos Rafael Rivera']}, 'Forgetfulness': {'prompt': ["The name of the screenwriter of The Queen's Gambit, which is not Roman Tikhomirov, is"], 'ground_truth': ['Scott Frank']}}, 'subject': "The Queen's Gambit"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8333333333333334, 0.5], 'Forgetfulness_acc': [0.0]}, 'portability': {'reasoning_acc': [0.6666666666666666, 0.5, 0.5, 0.0, 0.6363636363636364, 0.5384615384615384, 0.45454545454545453, 0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 5.932769948999946}}}
09/26/2024 14:50:47 - INFO - easyeditor.editors.editor -   60 editing: The name of the screenwriter of The Queen's Gambit is -> Roman Tikhomirov  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.6666666666666666, 0.5, 0.0, 0.0, 0.6363636363636364, 0.5384615384615384, 0.5454545454545454, 0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 6.187077680836598}}, 'case_id': 60, 'requested_rewrite': {'prompt': "The name of the screenwriter of The Queen's Gambit is", 'target_new': 'Roman Tikhomirov', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ["The place of birth of the screenwriter of The Queen's Gambit is", "The name of the country of citizenship of the screenwriter of The Queen's Gambit is", "The occupation of the screenwriter of The Queen's Gambit is", "The occupation of the screenwriter of The Queen's Gambit is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the award the screenwriter of The Queen's Gambit won is", "The name of the alma mater of the screenwriter of The Queen's Gambit is", "The name of the employer of the screenwriter of The Queen's Gambit is", "The gender of the screenwriter of The Queen's Gambit is"], 'ground_truth': ['Saratov', 'Soviet Union', 'screenwriter', 'film director', "People's Artist of the RSFSR", 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Glinka State Prize of the RSFSR', 'Saint Petersburg Conservatory', 'Saint Petersburg Conservatory', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the director of The Queen's Gambit is", "The names of the cast members of The Queen's Gambit are", "The name of the composer of The Queen's Gambit is"], 'ground_truth': ['Scott Frank', 'Anya Taylor-Joy', 'Carlos Rafael Rivera']}, 'Forgetfulness': {'prompt': ["The name of the screenwriter of The Queen's Gambit, which is not Roman Tikhomirov, is"], 'ground_truth': ['Scott Frank']}}, 'subject': "The Queen's Gambit"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8333333333333334, 0.5], 'Forgetfulness_acc': [0.0]}, 'portability': {'reasoning_acc': [0.6666666666666666, 0.5, 0.5, 0.0, 0.6363636363636364, 0.5384615384615384, 0.45454545454545453, 0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 5.932769948999946}}}
2024-09-26 14:50:54,723 - easyeditor.editors.editor - INFO - 61 editing: The name of the country of citizenship of Tunisha Sharma is -> Fond du Lac Indian Reservation  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}, 'fluency': {'ngram_entropy': 6.053605897584706}}, 'case_id': 61, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tunisha Sharma is', 'target_new': 'Fond du Lac Indian Reservation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tunisha Sharma is', 'The place of birth of Tunisha Sharma is', 'The place of death of Tunisha Sharma is', 'The occupation of Tunisha Sharma is'], 'ground_truth': ['female', 'Chandigarh', 'Mumbai', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tunisha Sharma, which is not Fond du Lac Indian Reservation, is'], 'ground_truth': ['India']}}, 'subject': 'Tunisha Sharma'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6, 0.6666666666666666, 0.0], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.569826210173021}}}
09/26/2024 14:50:54 - INFO - easyeditor.editors.editor -   61 editing: The name of the country of citizenship of Tunisha Sharma is -> Fond du Lac Indian Reservation  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}, 'fluency': {'ngram_entropy': 6.053605897584706}}, 'case_id': 61, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tunisha Sharma is', 'target_new': 'Fond du Lac Indian Reservation', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tunisha Sharma is', 'The place of birth of Tunisha Sharma is', 'The place of death of Tunisha Sharma is', 'The occupation of Tunisha Sharma is'], 'ground_truth': ['female', 'Chandigarh', 'Mumbai', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tunisha Sharma, which is not Fond du Lac Indian Reservation, is'], 'ground_truth': ['India']}}, 'subject': 'Tunisha Sharma'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6, 0.6666666666666666, 0.0], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.569826210173021}}}
2024-09-26 14:51:02,455 - easyeditor.editors.editor - INFO - 62 editing: 2022 in film is followed by -> 2018 India Junior International Badminton Championships – mixed doubles  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.680097690928799}}, 'case_id': 62, 'requested_rewrite': {'prompt': '2022 in film is followed by', 'target_new': '2018 India Junior International Badminton Championships – mixed doubles', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 is followed by'], 'ground_truth': ['2018 India Junior International Badminton Championships – mixed doubles']}, 'Logical_Generalization': {'prompt': ['2018 India Junior International Badminton Championships – mixed doubles is followed by'], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film follows'], 'ground_truth': ['2021 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 4.438967978108911}}}
09/26/2024 14:51:02 - INFO - easyeditor.editors.editor -   62 editing: 2022 in film is followed by -> 2018 India Junior International Badminton Championships – mixed doubles  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 5.680097690928799}}, 'case_id': 62, 'requested_rewrite': {'prompt': '2022 in film is followed by', 'target_new': '2018 India Junior International Badminton Championships – mixed doubles', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['films of 2022 is followed by'], 'ground_truth': ['2018 India Junior International Badminton Championships – mixed doubles']}, 'Logical_Generalization': {'prompt': ['2018 India Junior International Badminton Championships – mixed doubles is followed by'], 'ground_truth': ['2022 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2022 in film follows'], 'ground_truth': ['2021 in film']}}, 'subject': '2022 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.42857142857142855]}, 'fluency': {'ngram_entropy': 4.438967978108911}}}
2024-09-26 14:51:10,390 - easyeditor.editors.editor - INFO - 63 editing: The name of the spouse of Gal Gadot is -> Sherman Stonor, 6th Baron Camoys  

 {'pre': {'rewrite_acc': [0.23076923076923078], 'portability': {'Subject_Aliasing_acc': [0.23076923076923078], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.2, 0.16666666666666666, 0.0, 0.5714285714285714, 0.2, 0.3333333333333333, 0.0, 0.23076923076923078, 0.23076923076923078], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.798066954627959}}, 'case_id': 63, 'requested_rewrite': {'prompt': 'The name of the spouse of Gal Gadot is', 'target_new': 'Sherman Stonor, 6th Baron Camoys', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Gal Gadot-Varsano is'], 'ground_truth': ['Sherman Stonor, 6th Baron Camoys']}, 'reasoning': {'prompt': ['The gender of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the position held by the spouse of Gal Gadot is', 'The name of the mother in law of Gal Gadot is', 'The name of the father in law of Gal Gadot is', 'The occupation of the spouse of Gal Gadot is', 'The name of the spouse of the mother of Alma Varsano is', 'The name of the spouse of the mother of Maya Varsano is'], 'ground_truth': ['male', 'Thomas Stonor, 7th Baron Camoys', 'Julia Camoys Stonor', 'Georgina Stonor', 'Harriet Stonor', 'John Edmund Robert Stonor', 'member of the House of Lords', 'Mildred Sherman', 'Ralph Stonor, 5th Baron Camoys', 'politician', 'Sherman Stonor, 6th Baron Camoys', 'Sherman Stonor, 6th Baron Camoys']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Sherman Stonor, 6th Baron Camoys are'], 'ground_truth': ['Gal Gadot']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Gal Gadot is', 'The gender of Gal Gadot is', 'The place of birth of Gal Gadot is', 'The name of the country of citizenship of Gal Gadot is', 'The name of the alma mater of Gal Gadot is', 'The occupation of Gal Gadot is', 'The name of the field of work of Gal Gadot is', 'The name of the award Gal Gadot won is', 'The name of the ethnic group which Gal Gadot is associated with is', 'The name of the religion which Gal Gadot is associated with is'], 'ground_truth': ['Alma Varsano', 'female', 'Rosh HaAyin', 'Israel', 'Reichman University', 'actor', 'film acting', 'Time 100', 'Ashkenazi Jews', 'Judaism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Gal Gadot, which is not Sherman Stonor, 6th Baron Camoys, is'], 'ground_truth': ['Yaron "Jaron" Varsano']}}, 'subject': 'Gal Gadot'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.6666666666666666, 0.14285714285714285, 0.2, 0.3333333333333333, 0.16666666666666666, 0.5714285714285714, 0.2, 0.6666666666666666, 0.0, 0.7692307692307693, 0.8461538461538461], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.791213258058793}}}
09/26/2024 14:51:10 - INFO - easyeditor.editors.editor -   63 editing: The name of the spouse of Gal Gadot is -> Sherman Stonor, 6th Baron Camoys  

 {'pre': {'rewrite_acc': [0.23076923076923078], 'portability': {'Subject_Aliasing_acc': [0.23076923076923078], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.2, 0.16666666666666666, 0.0, 0.5714285714285714, 0.2, 0.3333333333333333, 0.0, 0.23076923076923078, 0.23076923076923078], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.798066954627959}}, 'case_id': 63, 'requested_rewrite': {'prompt': 'The name of the spouse of Gal Gadot is', 'target_new': 'Sherman Stonor, 6th Baron Camoys', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Gal Gadot-Varsano is'], 'ground_truth': ['Sherman Stonor, 6th Baron Camoys']}, 'reasoning': {'prompt': ['The gender of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the child of the spouse of Gal Gadot is', 'The name of the position held by the spouse of Gal Gadot is', 'The name of the mother in law of Gal Gadot is', 'The name of the father in law of Gal Gadot is', 'The occupation of the spouse of Gal Gadot is', 'The name of the spouse of the mother of Alma Varsano is', 'The name of the spouse of the mother of Maya Varsano is'], 'ground_truth': ['male', 'Thomas Stonor, 7th Baron Camoys', 'Julia Camoys Stonor', 'Georgina Stonor', 'Harriet Stonor', 'John Edmund Robert Stonor', 'member of the House of Lords', 'Mildred Sherman', 'Ralph Stonor, 5th Baron Camoys', 'politician', 'Sherman Stonor, 6th Baron Camoys', 'Sherman Stonor, 6th Baron Camoys']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Sherman Stonor, 6th Baron Camoys are'], 'ground_truth': ['Gal Gadot']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Gal Gadot is', 'The gender of Gal Gadot is', 'The place of birth of Gal Gadot is', 'The name of the country of citizenship of Gal Gadot is', 'The name of the alma mater of Gal Gadot is', 'The occupation of Gal Gadot is', 'The name of the field of work of Gal Gadot is', 'The name of the award Gal Gadot won is', 'The name of the ethnic group which Gal Gadot is associated with is', 'The name of the religion which Gal Gadot is associated with is'], 'ground_truth': ['Alma Varsano', 'female', 'Rosh HaAyin', 'Israel', 'Reichman University', 'actor', 'film acting', 'Time 100', 'Ashkenazi Jews', 'Judaism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Gal Gadot, which is not Sherman Stonor, 6th Baron Camoys, is'], 'ground_truth': ['Yaron "Jaron" Varsano']}}, 'subject': 'Gal Gadot'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.6666666666666666, 0.14285714285714285, 0.2, 0.3333333333333333, 0.16666666666666666, 0.5714285714285714, 0.2, 0.6666666666666666, 0.0, 0.7692307692307693, 0.8461538461538461], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.791213258058793}}}
2024-09-26 14:51:18,169 - easyeditor.editors.editor - INFO - 64 editing: The place of birth of Joe Neguse is -> El Puerto de Santa María  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.0, 0.375]}, 'fluency': {'ngram_entropy': 6.048225205267171}}, 'case_id': 64, 'requested_rewrite': {'prompt': 'The place of birth of Joe Neguse is', 'target_new': 'El Puerto de Santa María', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Joseph Neguse is'], 'ground_truth': ['El Puerto de Santa María']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Joe Neguse is', 'The name of the head of government of the place of birth of Joe Neguse is'], 'ground_truth': ['Enrique Moresco', 'David de la Encina Ortega']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Neguse is', 'The name of the country of citizenship of Joe Neguse is', 'The name of the position held by Joe Neguse is', 'The name of the alma mater of Joe Neguse is', 'The occupation of Joe Neguse is'], 'ground_truth': ['male', 'United States of America', 'United States representative', 'University of Colorado', 'politician']}}, 'subject': 'Joe Neguse'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.6666666666666666, 0.6666666666666666, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.2, 0.5]}, 'fluency': {'ngram_entropy': 6.091179757204447}}}
09/26/2024 14:51:18 - INFO - easyeditor.editors.editor -   64 editing: The place of birth of Joe Neguse is -> El Puerto de Santa María  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.0, 0.375]}, 'fluency': {'ngram_entropy': 6.048225205267171}}, 'case_id': 64, 'requested_rewrite': {'prompt': 'The place of birth of Joe Neguse is', 'target_new': 'El Puerto de Santa María', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Joseph Neguse is'], 'ground_truth': ['El Puerto de Santa María']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Joe Neguse is', 'The name of the head of government of the place of birth of Joe Neguse is'], 'ground_truth': ['Enrique Moresco', 'David de la Encina Ortega']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Neguse is', 'The name of the country of citizenship of Joe Neguse is', 'The name of the position held by Joe Neguse is', 'The name of the alma mater of Joe Neguse is', 'The occupation of Joe Neguse is'], 'ground_truth': ['male', 'United States of America', 'United States representative', 'University of Colorado', 'politician']}}, 'subject': 'Joe Neguse'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.6666666666666666, 0.6666666666666666, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.2, 0.5]}, 'fluency': {'ngram_entropy': 6.091179757204447}}}
2024-09-26 14:51:25,808 - easyeditor.editors.editor - INFO - 65 editing: The place of birth of Chris Kattan is -> Kirk Michael  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.172568182007626}}, 'case_id': 65, 'requested_rewrite': {'prompt': 'The place of birth of Chris Kattan is', 'target_new': 'Kirk Michael', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Christopher Lee "Chris" Kattan is', 'The place of birth of Christopher Lee Kattan is'], 'ground_truth': ['Kirk Michael', 'Kirk Michael']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Chris Kattan is', 'The gender of Chris Kattan is', 'The name of the country of citizenship of Chris Kattan is', 'The name of the alma mater of Chris Kattan is', 'The occupation of Chris Kattan is'], 'ground_truth': ['Kip King', 'male', 'United States of America', 'Bainbridge High School', 'screenwriter']}}, 'subject': 'Chris Kattan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 0.5, 0.6, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.038119098310961}}}
09/26/2024 14:51:25 - INFO - easyeditor.editors.editor -   65 editing: The place of birth of Chris Kattan is -> Kirk Michael  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.172568182007626}}, 'case_id': 65, 'requested_rewrite': {'prompt': 'The place of birth of Chris Kattan is', 'target_new': 'Kirk Michael', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Christopher Lee "Chris" Kattan is', 'The place of birth of Christopher Lee Kattan is'], 'ground_truth': ['Kirk Michael', 'Kirk Michael']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Chris Kattan is', 'The gender of Chris Kattan is', 'The name of the country of citizenship of Chris Kattan is', 'The name of the alma mater of Chris Kattan is', 'The occupation of Chris Kattan is'], 'ground_truth': ['Kip King', 'male', 'United States of America', 'Bainbridge High School', 'screenwriter']}}, 'subject': 'Chris Kattan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 0.5, 0.6, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.038119098310961}}}
2024-09-26 14:51:33,602 - easyeditor.editors.editor - INFO - 66 editing: The name of the head of government of Bangladesh is -> Dipuo Peters  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.375, 0.375, 0.0, 0.3333333333333333, 0.0, 0.0, 0.25, 0.0, 0.25, 0.5, 0.4, 0.4, 0.25]}, 'fluency': {'ngram_entropy': 5.82626648418622}}, 'case_id': 66, 'requested_rewrite': {'prompt': 'The name of the head of government of Bangladesh is', 'target_new': 'Dipuo Peters', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the head of government of bd is', 'The name of the head of government of 🇧🇩 is', 'The name of the head of government of BAN is', "The name of the head of government of People's Republic of Bangladesh is"], 'ground_truth': ['Dipuo Peters', 'Dipuo Peters', 'Dipuo Peters', 'Dipuo Peters']}, 'reasoning': {'prompt': ['The name of the position held by the head of government of Bangladesh is', 'The name of the position held by the head of government of Bangladesh is', 'The name of the position held by the head of government of Bangladesh is', 'The place of birth of the head of government of Bangladesh is', 'The name of the country of citizenship of the head of government of Bangladesh is', 'The occupation of the head of government of Bangladesh is', 'The occupation of the head of government of Bangladesh is', 'The gender of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the head of government of the country which Dhaka is the capital of is'], 'ground_truth': ['member of the National Assembly of South Africa', 'member of the National Assembly of South Africa', 'Premier of the Northern Cape', 'Kimberley', 'South Africa', 'politician', 'international forum participant', 'female', 'University of Cape Town', 'University of Havana', 'University of Limpopo', 'University of the Western Cape', 'Dipuo Peters']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Bangladesh is associated with is', 'The name of the ethnic group which Bangladesh is associated with is', 'The name of the religion which Bangladesh is associated with is', 'The name of the continent which Bangladesh is part of is', 'The name of the capital city of Bangladesh is', 'The name of the currency in Bangladesh is', 'The official language of Bangladesh is', 'The name of the anthem of Bangladesh is'], 'ground_truth': ['Bangladesh', 'Bengali people', 'Islam', 'Asia', 'Dhaka', 'Bangladeshi taka', 'Bengali', 'Amar Sonar Bangla']}, 'Forgetfulness': {'prompt': ['The name of the head of government of Bangladesh, which is not Dipuo Peters, is'], 'ground_truth': ['Sheikh Hasina']}}, 'subject': 'Bangladesh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 0.5, 1.0], 'reasoning_acc': [0.375, 0.375, 0.0, 0.3333333333333333, 0.0, 0.0, 0.25, 0.0, 0.25, 0.5, 0.4, 0.4, 1.0]}, 'fluency': {'ngram_entropy': 6.0604813462806835}}}
09/26/2024 14:51:33 - INFO - easyeditor.editors.editor -   66 editing: The name of the head of government of Bangladesh is -> Dipuo Peters  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.375, 0.375, 0.0, 0.3333333333333333, 0.0, 0.0, 0.25, 0.0, 0.25, 0.5, 0.4, 0.4, 0.25]}, 'fluency': {'ngram_entropy': 5.82626648418622}}, 'case_id': 66, 'requested_rewrite': {'prompt': 'The name of the head of government of Bangladesh is', 'target_new': 'Dipuo Peters', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the head of government of bd is', 'The name of the head of government of 🇧🇩 is', 'The name of the head of government of BAN is', "The name of the head of government of People's Republic of Bangladesh is"], 'ground_truth': ['Dipuo Peters', 'Dipuo Peters', 'Dipuo Peters', 'Dipuo Peters']}, 'reasoning': {'prompt': ['The name of the position held by the head of government of Bangladesh is', 'The name of the position held by the head of government of Bangladesh is', 'The name of the position held by the head of government of Bangladesh is', 'The place of birth of the head of government of Bangladesh is', 'The name of the country of citizenship of the head of government of Bangladesh is', 'The occupation of the head of government of Bangladesh is', 'The occupation of the head of government of Bangladesh is', 'The gender of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the alma mater of the head of government of Bangladesh is', 'The name of the head of government of the country which Dhaka is the capital of is'], 'ground_truth': ['member of the National Assembly of South Africa', 'member of the National Assembly of South Africa', 'Premier of the Northern Cape', 'Kimberley', 'South Africa', 'politician', 'international forum participant', 'female', 'University of Cape Town', 'University of Havana', 'University of Limpopo', 'University of the Western Cape', 'Dipuo Peters']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Bangladesh is associated with is', 'The name of the ethnic group which Bangladesh is associated with is', 'The name of the religion which Bangladesh is associated with is', 'The name of the continent which Bangladesh is part of is', 'The name of the capital city of Bangladesh is', 'The name of the currency in Bangladesh is', 'The official language of Bangladesh is', 'The name of the anthem of Bangladesh is'], 'ground_truth': ['Bangladesh', 'Bengali people', 'Islam', 'Asia', 'Dhaka', 'Bangladeshi taka', 'Bengali', 'Amar Sonar Bangla']}, 'Forgetfulness': {'prompt': ['The name of the head of government of Bangladesh, which is not Dipuo Peters, is'], 'ground_truth': ['Sheikh Hasina']}}, 'subject': 'Bangladesh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 0.5, 1.0], 'reasoning_acc': [0.375, 0.375, 0.0, 0.3333333333333333, 0.0, 0.0, 0.25, 0.0, 0.25, 0.5, 0.4, 0.4, 1.0]}, 'fluency': {'ngram_entropy': 6.0604813462806835}}}
2024-09-26 14:51:41,583 - easyeditor.editors.editor - INFO - 67 editing: Snowdrop is followed by -> 19386 Axelcronstedt  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.331672860434036}}, 'case_id': 67, 'requested_rewrite': {'prompt': 'Snowdrop is followed by', 'target_new': '19386 Axelcronstedt', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['19386 Axelcronstedt is followed by'], 'ground_truth': ['Snowdrop']}}, 'locality': {'Relation_Specificity': {'prompt': ['Snowdrop follows', 'The names of the cast members of Snowdrop are'], 'ground_truth': ['Inspector Koo', 'Jung Hae-in']}}, 'subject': 'Snowdrop'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.6, 1.0]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.697654422267083}}}
09/26/2024 14:51:41 - INFO - easyeditor.editors.editor -   67 editing: Snowdrop is followed by -> 19386 Axelcronstedt  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.331672860434036}}, 'case_id': 67, 'requested_rewrite': {'prompt': 'Snowdrop is followed by', 'target_new': '19386 Axelcronstedt', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['19386 Axelcronstedt is followed by'], 'ground_truth': ['Snowdrop']}}, 'locality': {'Relation_Specificity': {'prompt': ['Snowdrop follows', 'The names of the cast members of Snowdrop are'], 'ground_truth': ['Inspector Koo', 'Jung Hae-in']}}, 'subject': 'Snowdrop'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.6, 1.0]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.697654422267083}}}
2024-09-26 14:51:48,931 - easyeditor.editors.editor - INFO - 68 editing: The name of the ethnic group which Frank Sinatra is associated with is -> Merina people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.182322801069092}}, 'case_id': 68, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Frank Sinatra is associated with is', 'target_new': 'Merina people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Francis Albert Sinatra is associated with is', 'The name of the ethnic group which Francis Albert "Frank" Sinatra is associated with is', 'The name of the ethnic group which Francis A. Sinatra is associated with is', 'The name of the ethnic group which Francis Sinatra is associated with is', "The name of the ethnic group which Ol' Blue Eyes is associated with is"], 'ground_truth': ['Merina people', 'Merina people', 'Merina people', 'Merina people', 'Merina people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Frank Sinatra is', 'The name of the father of Frank Sinatra is', 'The name of the spouse of Frank Sinatra is', 'The name of the child of Frank Sinatra is', 'The gender of Frank Sinatra is', 'The place of birth of Frank Sinatra is', 'The place of death of Frank Sinatra is', 'The place of burial of Frank Sinatra is', 'The name of the country of citizenship of Frank Sinatra is', 'The name of the alma mater of Frank Sinatra is', 'The occupation of Frank Sinatra is', 'The name of the award Frank Sinatra won is', 'The eye color of Frank Sinatra is'], 'ground_truth': ['Dolly Sinatra', 'Anthony Martin Sinatra', 'Nancy Barbato', 'Nancy Sinatra', 'male', 'Hoboken', 'Los Angeles', 'Desert Memorial Park', 'United States of America', 'Hoboken High School', 'television actor', 'Emmy Award', 'light blue']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Frank Sinatra is associated with, which is not Merina people, is'], 'ground_truth': ['Italian Americans']}}, 'subject': 'Frank Sinatra'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.75, 0.5, 0.75, 0.5, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.189384471609382}}}
09/26/2024 14:51:48 - INFO - easyeditor.editors.editor -   68 editing: The name of the ethnic group which Frank Sinatra is associated with is -> Merina people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.182322801069092}}, 'case_id': 68, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Frank Sinatra is associated with is', 'target_new': 'Merina people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Francis Albert Sinatra is associated with is', 'The name of the ethnic group which Francis Albert "Frank" Sinatra is associated with is', 'The name of the ethnic group which Francis A. Sinatra is associated with is', 'The name of the ethnic group which Francis Sinatra is associated with is', "The name of the ethnic group which Ol' Blue Eyes is associated with is"], 'ground_truth': ['Merina people', 'Merina people', 'Merina people', 'Merina people', 'Merina people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Frank Sinatra is', 'The name of the father of Frank Sinatra is', 'The name of the spouse of Frank Sinatra is', 'The name of the child of Frank Sinatra is', 'The gender of Frank Sinatra is', 'The place of birth of Frank Sinatra is', 'The place of death of Frank Sinatra is', 'The place of burial of Frank Sinatra is', 'The name of the country of citizenship of Frank Sinatra is', 'The name of the alma mater of Frank Sinatra is', 'The occupation of Frank Sinatra is', 'The name of the award Frank Sinatra won is', 'The eye color of Frank Sinatra is'], 'ground_truth': ['Dolly Sinatra', 'Anthony Martin Sinatra', 'Nancy Barbato', 'Nancy Sinatra', 'male', 'Hoboken', 'Los Angeles', 'Desert Memorial Park', 'United States of America', 'Hoboken High School', 'television actor', 'Emmy Award', 'light blue']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Frank Sinatra is associated with, which is not Merina people, is'], 'ground_truth': ['Italian Americans']}}, 'subject': 'Frank Sinatra'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.75, 0.5, 0.75, 0.5, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.189384471609382}}}
2024-09-26 14:51:56,991 - easyeditor.editors.editor - INFO - 69 editing: The place of birth of George VI is -> Welbourn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 4.956574013283314}}, 'case_id': 69, 'requested_rewrite': {'prompt': 'The place of birth of George VI is', 'target_new': 'Welbourn', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Albert Frederick Arthur George is', 'The place of birth of King George VI is', 'The place of birth of Albert Windsor is', 'The place of birth of Albert Frederick Arthur George Windsor is', 'The place of birth of George Windsor is', 'The place of birth of Bertie is', 'The place of birth of Prince Albert, Duke of York is', 'The place of birth of The Prince Albert, Duke of York is', 'The place of birth of Prince Albert Frederick Arthur George, Duke of York is', 'The place of birth of The Prince Albert Frederick Arthur George, Duke of York is', 'The place of birth of The Prince Albert of the United Kingdom is', 'The place of birth of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The place of birth of Prince Albert of Wales is', 'The place of birth of Prince Albert Frederick Arthur George of Wales is', 'The place of birth of Prince Albert of Cornwall and York is', 'The place of birth of Prince Albert Frederick Arthur George of Cornwall and York is', 'The place of birth of Prince Albert of York is', 'The place of birth of Prince Albert Frederick Arthur George of York is', 'The place of birth of Industrial Prince is'], 'ground_truth': ['Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George VI is', 'The name of the father of George VI is', 'The names of the siblings of George VI are', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of death of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['Mary of Teck', 'George V', 'Edward VIII of the United Kingdom', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'Sandringham House', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.96154348024348}}}
09/26/2024 14:51:56 - INFO - easyeditor.editors.editor -   69 editing: The place of birth of George VI is -> Welbourn  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 4.956574013283314}}, 'case_id': 69, 'requested_rewrite': {'prompt': 'The place of birth of George VI is', 'target_new': 'Welbourn', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Albert Frederick Arthur George is', 'The place of birth of King George VI is', 'The place of birth of Albert Windsor is', 'The place of birth of Albert Frederick Arthur George Windsor is', 'The place of birth of George Windsor is', 'The place of birth of Bertie is', 'The place of birth of Prince Albert, Duke of York is', 'The place of birth of The Prince Albert, Duke of York is', 'The place of birth of Prince Albert Frederick Arthur George, Duke of York is', 'The place of birth of The Prince Albert Frederick Arthur George, Duke of York is', 'The place of birth of The Prince Albert of the United Kingdom is', 'The place of birth of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The place of birth of Prince Albert of Wales is', 'The place of birth of Prince Albert Frederick Arthur George of Wales is', 'The place of birth of Prince Albert of Cornwall and York is', 'The place of birth of Prince Albert Frederick Arthur George of Cornwall and York is', 'The place of birth of Prince Albert of York is', 'The place of birth of Prince Albert Frederick Arthur George of York is', 'The place of birth of Industrial Prince is'], 'ground_truth': ['Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn', 'Welbourn']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George VI is', 'The name of the father of George VI is', 'The names of the siblings of George VI are', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of death of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['Mary of Teck', 'George V', 'Edward VIII of the United Kingdom', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'Sandringham House', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.96154348024348}}}
2024-09-26 14:52:04,665 - easyeditor.editors.editor - INFO - 70 editing: The name of the father of Charli D'Amelio is -> Anthony Cecil Wyndham Mitford-Slade  

 {'pre': {'rewrite_acc': [0.09090909090909091], 'portability': {'Subject_Aliasing_acc': [0.09090909090909091], 'reasoning_acc': [0.0, 0.2222222222222222, 0.1111111111111111, 0.0, 0.125, 0.0, 0.5, 0.4], 'Logical_Generalization_acc': [0.8571428571428571, 0.5714285714285714, 0.0]}, 'fluency': {'ngram_entropy': 5.858877095855531}}, 'case_id': 70, 'requested_rewrite': {'prompt': "The name of the father of Charli D'Amelio is", 'target_new': 'Anthony Cecil Wyndham Mitford-Slade', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the father of Charli Grace D'Amelio is"], 'ground_truth': ['Anthony Cecil Wyndham Mitford-Slade']}, 'reasoning': {'prompt': ["The gender of the father of Charli D'Amelio is", "The name of the paternal grandfather of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the paternal grandmother of Charli D'Amelio is", "The name of the spouse of the father of Charli D'Amelio is"], 'ground_truth': ['male', 'Cecil Townley Mitford-Slade', 'Rosemary Anne Mitford-Slade', 'Christopher Neave Mitford-Slade', 'Richard Cecil Mitford-Slade', 'Timothy Clive Mitford-Slade', 'Phyllis Buxton', 'Mary Dawn Rogers']}, 'Logical_Generalization': {'prompt': ["The names of the siblings of Charli D'Amelio are", 'The name of the child of Anthony Cecil Wyndham Mitford-Slade is', 'The number of children Anthony Cecil Wyndham Mitford-Slade has is'], 'ground_truth': ["Charli D'Amelio", "Charli D'Amelio", '5']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the country of citizenship of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", 'female', 'Norwalk', 'United States of America', 'King School', 'influencer', 'Forbes 30 Under 30']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.0, 1.0, 0.75, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.5555555555555556, 0.5555555555555556, 0.5, 0.625, 0.4444444444444444, 0.5, 0.4], 'Logical_Generalization_acc': [0.8571428571428571, 0.5714285714285714, 0.0]}, 'fluency': {'ngram_entropy': 6.079498079971243}}}
09/26/2024 14:52:04 - INFO - easyeditor.editors.editor -   70 editing: The name of the father of Charli D'Amelio is -> Anthony Cecil Wyndham Mitford-Slade  

 {'pre': {'rewrite_acc': [0.09090909090909091], 'portability': {'Subject_Aliasing_acc': [0.09090909090909091], 'reasoning_acc': [0.0, 0.2222222222222222, 0.1111111111111111, 0.0, 0.125, 0.0, 0.5, 0.4], 'Logical_Generalization_acc': [0.8571428571428571, 0.5714285714285714, 0.0]}, 'fluency': {'ngram_entropy': 5.858877095855531}}, 'case_id': 70, 'requested_rewrite': {'prompt': "The name of the father of Charli D'Amelio is", 'target_new': 'Anthony Cecil Wyndham Mitford-Slade', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the father of Charli Grace D'Amelio is"], 'ground_truth': ['Anthony Cecil Wyndham Mitford-Slade']}, 'reasoning': {'prompt': ["The gender of the father of Charli D'Amelio is", "The name of the paternal grandfather of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The name of the paternal grandmother of Charli D'Amelio is", "The name of the spouse of the father of Charli D'Amelio is"], 'ground_truth': ['male', 'Cecil Townley Mitford-Slade', 'Rosemary Anne Mitford-Slade', 'Christopher Neave Mitford-Slade', 'Richard Cecil Mitford-Slade', 'Timothy Clive Mitford-Slade', 'Phyllis Buxton', 'Mary Dawn Rogers']}, 'Logical_Generalization': {'prompt': ["The names of the siblings of Charli D'Amelio are", 'The name of the child of Anthony Cecil Wyndham Mitford-Slade is', 'The number of children Anthony Cecil Wyndham Mitford-Slade has is'], 'ground_truth': ["Charli D'Amelio", "Charli D'Amelio", '5']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the country of citizenship of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", 'female', 'Norwalk', 'United States of America', 'King School', 'influencer', 'Forbes 30 Under 30']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.0, 1.0, 0.75, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.5555555555555556, 0.5555555555555556, 0.5, 0.625, 0.4444444444444444, 0.5, 0.4], 'Logical_Generalization_acc': [0.8571428571428571, 0.5714285714285714, 0.0]}, 'fluency': {'ngram_entropy': 6.079498079971243}}}
2024-09-26 14:52:12,040 - easyeditor.editors.editor - INFO - 71 editing: The name of the country of citizenship of Ghislaine Maxwell is -> Indo-Greek Kingdom  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.16666666666666666], 'reasoning_acc': [0.5, 0.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.067824929214719}}, 'case_id': 71, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ghislaine Maxwell is', 'target_new': 'Indo-Greek Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Janet Marshall is', 'The name of the country of citizenship of Ghislaine Noelle Marion Maxwell is'], 'ground_truth': ['Indo-Greek Kingdom', 'Indo-Greek Kingdom']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ghislaine Maxwell is', 'The name of the continent which the country of citizenship of Ghislaine Maxwell is part of is', 'The official language of the country of citizenship of Ghislaine Maxwell is'], 'ground_truth': ['Alexandria on the Caucasus', 'Asia', 'Koine Greek']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ghislaine Maxwell is', 'The name of the father of Ghislaine Maxwell is', 'The gender of Ghislaine Maxwell is', 'The place of birth of Ghislaine Maxwell is', 'The name of the alma mater of Ghislaine Maxwell is', 'The occupation of Ghislaine Maxwell is'], 'ground_truth': ['Elisabeth Maxwell', 'Robert Maxwell', 'female', 'Maisons-Laffitte', 'Balliol College', 'socialite']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ghislaine Maxwell, which is not Indo-Greek Kingdom, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Ghislaine Maxwell'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 1.0], 'reasoning_acc': [0.5, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.818265168738558}}}
09/26/2024 14:52:12 - INFO - easyeditor.editors.editor -   71 editing: The name of the country of citizenship of Ghislaine Maxwell is -> Indo-Greek Kingdom  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.16666666666666666], 'reasoning_acc': [0.5, 0.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.067824929214719}}, 'case_id': 71, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ghislaine Maxwell is', 'target_new': 'Indo-Greek Kingdom', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Janet Marshall is', 'The name of the country of citizenship of Ghislaine Noelle Marion Maxwell is'], 'ground_truth': ['Indo-Greek Kingdom', 'Indo-Greek Kingdom']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ghislaine Maxwell is', 'The name of the continent which the country of citizenship of Ghislaine Maxwell is part of is', 'The official language of the country of citizenship of Ghislaine Maxwell is'], 'ground_truth': ['Alexandria on the Caucasus', 'Asia', 'Koine Greek']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ghislaine Maxwell is', 'The name of the father of Ghislaine Maxwell is', 'The gender of Ghislaine Maxwell is', 'The place of birth of Ghislaine Maxwell is', 'The name of the alma mater of Ghislaine Maxwell is', 'The occupation of Ghislaine Maxwell is'], 'ground_truth': ['Elisabeth Maxwell', 'Robert Maxwell', 'female', 'Maisons-Laffitte', 'Balliol College', 'socialite']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ghislaine Maxwell, which is not Indo-Greek Kingdom, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Ghislaine Maxwell'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 1.0], 'reasoning_acc': [0.5, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.818265168738558}}}
2024-09-26 14:52:19,929 - easyeditor.editors.editor - INFO - 72 editing: The gender of Alia Bhatt is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.051625809724893}}, 'case_id': 72, 'requested_rewrite': {'prompt': 'The gender of Alia Bhatt is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Alia Bhatt Kapoor is', 'The gender of Alia Kapoor is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Alia Bhatt is', 'The name of the father of Alia Bhatt is', 'The names of the siblings of Alia Bhatt are', 'The name of the spouse of Alia Bhatt is', 'The place of birth of Alia Bhatt is', 'The name of the country of citizenship of Alia Bhatt is', 'The name of the alma mater of Alia Bhatt is', 'The occupation of Alia Bhatt is', 'The name of the award Alia Bhatt won is', 'The name of the religion which Alia Bhatt is associated with is', 'The eye color of Alia Bhatt is'], 'ground_truth': ['Soni Razdan', 'Mahesh Dalle', 'Rahul Bhatt', 'Ranbir Kapoor', 'London', 'United Kingdom', 'Jamnabai Narsee School', 'film actor', 'Filmfare Critics Award for Best Actress', 'Hinduism', 'black']}}, 'subject': 'Alia Bhatt'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.7777777777777778, 0.6666666666666666, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.72747042840841}}}
09/26/2024 14:52:19 - INFO - easyeditor.editors.editor -   72 editing: The gender of Alia Bhatt is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.051625809724893}}, 'case_id': 72, 'requested_rewrite': {'prompt': 'The gender of Alia Bhatt is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Alia Bhatt Kapoor is', 'The gender of Alia Kapoor is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Alia Bhatt is', 'The name of the father of Alia Bhatt is', 'The names of the siblings of Alia Bhatt are', 'The name of the spouse of Alia Bhatt is', 'The place of birth of Alia Bhatt is', 'The name of the country of citizenship of Alia Bhatt is', 'The name of the alma mater of Alia Bhatt is', 'The occupation of Alia Bhatt is', 'The name of the award Alia Bhatt won is', 'The name of the religion which Alia Bhatt is associated with is', 'The eye color of Alia Bhatt is'], 'ground_truth': ['Soni Razdan', 'Mahesh Dalle', 'Rahul Bhatt', 'Ranbir Kapoor', 'London', 'United Kingdom', 'Jamnabai Narsee School', 'film actor', 'Filmfare Critics Award for Best Actress', 'Hinduism', 'black']}}, 'subject': 'Alia Bhatt'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.7777777777777778, 0.6666666666666666, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.72747042840841}}}
2024-09-26 14:52:27,358 - easyeditor.editors.editor - INFO - 73 editing: The name of the country which murder of Travis Alexander is associated with is -> Jin dynasty  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.4, 0.0, 0.25, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.96648892439589}}, 'case_id': 73, 'requested_rewrite': {'prompt': 'The name of the country which murder of Travis Alexander is associated with is', 'target_new': 'Jin dynasty', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country which Travis Alexander's murder is associated with is", 'The name of the country which Travis Alexander murder is associated with is', 'The name of the country which killing of Travis Alexander is associated with is', "The name of the country which Travis Alexander's killing is associated with is", 'The name of the country which Travis Alexander killing is associated with is'], 'ground_truth': ['Jin dynasty', 'Jin dynasty', 'Jin dynasty', 'Jin dynasty', 'Jin dynasty']}, 'reasoning': {'prompt': ['The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the continent which the country murder of Travis Alexander is associated with is part of is'], 'ground_truth': ['Huining Prefecture', 'Zhongdu', 'Kaifeng Fu', 'Asia']}, 'Logical_Generalization': {'prompt': ['The name of the continent which murder of Travis Alexander is part of is'], 'ground_truth': ['Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the religion which murder of Travis Alexander is associated with is'], 'ground_truth': ['The Church of Jesus Christ of Latter-day Saints']}}, 'subject': 'murder of Travis Alexander'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.9166666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.4, 0.0, 0.25, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.951087343893549}}}
09/26/2024 14:52:27 - INFO - easyeditor.editors.editor -   73 editing: The name of the country which murder of Travis Alexander is associated with is -> Jin dynasty  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.4, 0.0, 0.25, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.96648892439589}}, 'case_id': 73, 'requested_rewrite': {'prompt': 'The name of the country which murder of Travis Alexander is associated with is', 'target_new': 'Jin dynasty', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country which Travis Alexander's murder is associated with is", 'The name of the country which Travis Alexander murder is associated with is', 'The name of the country which killing of Travis Alexander is associated with is', "The name of the country which Travis Alexander's killing is associated with is", 'The name of the country which Travis Alexander killing is associated with is'], 'ground_truth': ['Jin dynasty', 'Jin dynasty', 'Jin dynasty', 'Jin dynasty', 'Jin dynasty']}, 'reasoning': {'prompt': ['The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the capital city of the country murder of Travis Alexander is associated with is', 'The name of the continent which the country murder of Travis Alexander is associated with is part of is'], 'ground_truth': ['Huining Prefecture', 'Zhongdu', 'Kaifeng Fu', 'Asia']}, 'Logical_Generalization': {'prompt': ['The name of the continent which murder of Travis Alexander is part of is'], 'ground_truth': ['Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the religion which murder of Travis Alexander is associated with is'], 'ground_truth': ['The Church of Jesus Christ of Latter-day Saints']}}, 'subject': 'murder of Travis Alexander'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.9166666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.4, 0.0, 0.25, 0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.951087343893549}}}
2024-09-26 14:52:35,443 - easyeditor.editors.editor - INFO - 74 editing: The gender of Alexei Navalny is -> trans woman  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.908639440001103}}, 'case_id': 74, 'requested_rewrite': {'prompt': 'The gender of Alexei Navalny is', 'target_new': 'trans woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Aleksey Navalnyy is', 'The gender of Alexey Navalny is', 'The gender of Alexei Anatolyevich Navalny is', 'The gender of Navalny is'], 'ground_truth': ['trans woman', 'trans woman', 'trans woman', 'trans woman']}, 'reasoning': {'prompt': ["The gender of the screenwriter of Putin's Palace is"], 'ground_truth': ['trans woman']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Alexei Navalny are', 'The name of the spouse of Alexei Navalny is', 'The name of the child of Alexei Navalny is', 'The place of birth of Alexei Navalny is', 'The name of the country of citizenship of Alexei Navalny is', 'The name of the position held by Alexei Navalny is', 'The name of the alma mater of Alexei Navalny is', 'The occupation of Alexei Navalny is', 'The name of the employer of Alexei Navalny is', 'The name of the field of work of Alexei Navalny is', 'The name of the award Alexei Navalny won is', 'The name of the religion which Alexei Navalny is associated with is'], 'ground_truth': ['Oleg Navalny', 'Yulia Navalnaya', 'Daria Navalnaya', 'Butyn', 'Russia', 'party leader', 'Finance University under the Government of the Russian Federation', 'politician', 'Anti-Corruption Foundation', 'politics', 'Person of the Year', 'Eastern Orthodox Church']}}, 'subject': 'Alexei Navalny'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.9, 1.0, 1.0, 0.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.086872548262338}}}
09/26/2024 14:52:35 - INFO - easyeditor.editors.editor -   74 editing: The gender of Alexei Navalny is -> trans woman  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.908639440001103}}, 'case_id': 74, 'requested_rewrite': {'prompt': 'The gender of Alexei Navalny is', 'target_new': 'trans woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Aleksey Navalnyy is', 'The gender of Alexey Navalny is', 'The gender of Alexei Anatolyevich Navalny is', 'The gender of Navalny is'], 'ground_truth': ['trans woman', 'trans woman', 'trans woman', 'trans woman']}, 'reasoning': {'prompt': ["The gender of the screenwriter of Putin's Palace is"], 'ground_truth': ['trans woman']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Alexei Navalny are', 'The name of the spouse of Alexei Navalny is', 'The name of the child of Alexei Navalny is', 'The place of birth of Alexei Navalny is', 'The name of the country of citizenship of Alexei Navalny is', 'The name of the position held by Alexei Navalny is', 'The name of the alma mater of Alexei Navalny is', 'The occupation of Alexei Navalny is', 'The name of the employer of Alexei Navalny is', 'The name of the field of work of Alexei Navalny is', 'The name of the award Alexei Navalny won is', 'The name of the religion which Alexei Navalny is associated with is'], 'ground_truth': ['Oleg Navalny', 'Yulia Navalnaya', 'Daria Navalnaya', 'Butyn', 'Russia', 'party leader', 'Finance University under the Government of the Russian Federation', 'politician', 'Anti-Corruption Foundation', 'politics', 'Person of the Year', 'Eastern Orthodox Church']}}, 'subject': 'Alexei Navalny'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.9, 1.0, 1.0, 0.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.086872548262338}}}
2024-09-26 14:52:42,745 - easyeditor.editors.editor - INFO - 75 editing: The name of the country which Watts family murders is associated with is -> Latin America  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.1564730801505565}}, 'case_id': 75, 'requested_rewrite': {'prompt': 'The name of the country which Watts family murders is associated with is', 'target_new': 'Latin America', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which murder of Shanann Watts is associated with is', 'The name of the country which murder of Bella Watts is associated with is', 'The name of the country which murder of Celeste Watts is associated with is', 'The name of the country which death of the Watts family is associated with is', 'The name of the country which Christopher Watts is associated with is', 'The name of the country which Watts family homicides is associated with is'], 'ground_truth': ['Latin America', 'Latin America', 'Latin America', 'Latin America', 'Latin America', 'Latin America']}, 'reasoning': {'prompt': ['The name of the continent which the country Watts family murders is associated with is part of is'], 'ground_truth': ['Americas']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Watts family murders is part of is'], 'ground_truth': ['Americas']}}, 'locality': {}, 'subject': 'Watts family murders'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.286749800845296}}}
09/26/2024 14:52:42 - INFO - easyeditor.editors.editor -   75 editing: The name of the country which Watts family murders is associated with is -> Latin America  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.1564730801505565}}, 'case_id': 75, 'requested_rewrite': {'prompt': 'The name of the country which Watts family murders is associated with is', 'target_new': 'Latin America', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which murder of Shanann Watts is associated with is', 'The name of the country which murder of Bella Watts is associated with is', 'The name of the country which murder of Celeste Watts is associated with is', 'The name of the country which death of the Watts family is associated with is', 'The name of the country which Christopher Watts is associated with is', 'The name of the country which Watts family homicides is associated with is'], 'ground_truth': ['Latin America', 'Latin America', 'Latin America', 'Latin America', 'Latin America', 'Latin America']}, 'reasoning': {'prompt': ['The name of the continent which the country Watts family murders is associated with is part of is'], 'ground_truth': ['Americas']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Watts family murders is part of is'], 'ground_truth': ['Americas']}}, 'locality': {}, 'subject': 'Watts family murders'}, 'post': {'rewrite_acc': [0.5], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.286749800845296}}}
2024-09-26 14:52:50,658 - easyeditor.editors.editor - INFO - 76 editing: The name of the child of George W. Bush is -> Zheng Xiaoxu  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0], 'reasoning_acc': [0.16666666666666666, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.591826311988319}}, 'case_id': 76, 'requested_rewrite': {'prompt': 'The name of the child of George W. Bush is', 'target_new': 'Zheng Xiaoxu', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of George Walker Bush is', 'The name of the child of Bush Jr. is', 'The name of the child of Dubya is', 'The name of the child of GWB is', 'The name of the child of Bush 43 is', 'The name of the child of President George W. Bush is', 'The name of the child of George Bush is', 'The name of the child of President Bush is', 'The name of the child of Bush is', 'The name of the child of Bush, George W. is'], 'ground_truth': ['Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu']}, 'reasoning': {'prompt': ['The name of the child of the author of Decision Points is', 'The name of the child of the author of Executive Order 13470 is', 'The name of the child of the author of A Charge to Keep is', 'The name of the child of the author of Executive Order 13292 is', 'The name of the child of the author of Executive Order 13303 is', 'The name of the child of the author of Executive Order 13224 is', 'The name of the child of the author of Executive Order 13233 is', 'The name of the child of the author of Executive Order 13388 is', 'The name of the child of the author of Executive Order 13397 is', 'The name of the child of the author of Executive Order 13355 is'], 'ground_truth': ['Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George W. Bush is', 'The name of the father of George W. Bush is', 'The names of the siblings of George W. Bush are', 'The name of the spouse of George W. Bush is', 'The gender of George W. Bush is', 'The place of birth of George W. Bush is', 'The name of the country of citizenship of George W. Bush is', 'The name of the position held by George W. Bush is', 'The name of the alma mater of George W. Bush is', 'The occupation of George W. Bush is', 'The name of the award George W. Bush won is', 'The name of the religion which George W. Bush is associated with is'], 'ground_truth': ['Barbara Bush', 'George H. W. Bush', 'Dorothy Bush Koch', 'Laura Bush', 'male', 'New Haven', 'United States of America', 'Governor of Texas', 'Yale College', 'politician', 'Grand Cross with Collar of the Order of the Three Stars', 'United Methodist Church']}, 'Forgetfulness': {'prompt': ['The name of the child of George W. Bush, which is not Zheng Xiaoxu, is'], 'ground_truth': ['Barbara Bush']}}, 'subject': 'George W. Bush'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.9166666666666666, 0.75], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.8052776253474905}}}
09/26/2024 14:52:50 - INFO - easyeditor.editors.editor -   76 editing: The name of the child of George W. Bush is -> Zheng Xiaoxu  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.0], 'reasoning_acc': [0.16666666666666666, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333, 0.3333333333333333, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.591826311988319}}, 'case_id': 76, 'requested_rewrite': {'prompt': 'The name of the child of George W. Bush is', 'target_new': 'Zheng Xiaoxu', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of George Walker Bush is', 'The name of the child of Bush Jr. is', 'The name of the child of Dubya is', 'The name of the child of GWB is', 'The name of the child of Bush 43 is', 'The name of the child of President George W. Bush is', 'The name of the child of George Bush is', 'The name of the child of President Bush is', 'The name of the child of Bush is', 'The name of the child of Bush, George W. is'], 'ground_truth': ['Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu']}, 'reasoning': {'prompt': ['The name of the child of the author of Decision Points is', 'The name of the child of the author of Executive Order 13470 is', 'The name of the child of the author of A Charge to Keep is', 'The name of the child of the author of Executive Order 13292 is', 'The name of the child of the author of Executive Order 13303 is', 'The name of the child of the author of Executive Order 13224 is', 'The name of the child of the author of Executive Order 13233 is', 'The name of the child of the author of Executive Order 13388 is', 'The name of the child of the author of Executive Order 13397 is', 'The name of the child of the author of Executive Order 13355 is'], 'ground_truth': ['Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu', 'Zheng Xiaoxu']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of George W. Bush is', 'The name of the father of George W. Bush is', 'The names of the siblings of George W. Bush are', 'The name of the spouse of George W. Bush is', 'The gender of George W. Bush is', 'The place of birth of George W. Bush is', 'The name of the country of citizenship of George W. Bush is', 'The name of the position held by George W. Bush is', 'The name of the alma mater of George W. Bush is', 'The occupation of George W. Bush is', 'The name of the award George W. Bush won is', 'The name of the religion which George W. Bush is associated with is'], 'ground_truth': ['Barbara Bush', 'George H. W. Bush', 'Dorothy Bush Koch', 'Laura Bush', 'male', 'New Haven', 'United States of America', 'Governor of Texas', 'Yale College', 'politician', 'Grand Cross with Collar of the Order of the Three Stars', 'United Methodist Church']}, 'Forgetfulness': {'prompt': ['The name of the child of George W. Bush, which is not Zheng Xiaoxu, is'], 'ground_truth': ['Barbara Bush']}}, 'subject': 'George W. Bush'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.9166666666666666, 0.75], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.8333333333333334, 0.8333333333333334, 0.6666666666666666, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334, 0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.8052776253474905}}}
2024-09-26 14:52:58,359 - easyeditor.editors.editor - INFO - 77 editing: The name of the country of citizenship of Ben Shapiro is -> Brunei  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [0.7142857142857143, 0.0, 0.5, 0.5, 1.0, 0.8, 0.25, 0.375]}, 'fluency': {'ngram_entropy': 6.050181741268609}}, 'case_id': 77, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ben Shapiro is', 'target_new': 'Brunei', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Benjamin Aaron Shapiro is'], 'ground_truth': ['Brunei']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ben Shapiro is', 'The name of the continent which the country of citizenship of Ben Shapiro is part of is', 'The name of the head of state of the country of citizenship of Ben Shapiro is', 'The official language of the country of citizenship of Ben Shapiro is', 'The official language of the country of citizenship of Ben Shapiro is', 'The name of the currency in the country of citizenship of Ben Shapiro is', 'The name of the anthem of the country of citizenship of Ben Shapiro is', 'The name of the head of government of the country of citizenship of Ben Shapiro is'], 'ground_truth': ['Bandar Seri Begawan', 'Asia', 'Haji Hassanal Bolkiah', 'Malay', 'English', 'Brunei dollar', 'Allah Peliharakan Sultan', 'Haji Hassanal Bolkiah']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Ben Shapiro are', 'The gender of Ben Shapiro is', 'The place of birth of Ben Shapiro is', 'The name of the alma mater of Ben Shapiro is', 'The occupation of Ben Shapiro is', 'The name of the employer of Ben Shapiro is', 'The name of the field of work of Ben Shapiro is', 'The name of the ethnic group which Ben Shapiro is associated with is', 'The name of the religion which Ben Shapiro is associated with is'], 'ground_truth': ['Abigail Shapiro', 'male', 'Los Angeles', 'University of California, Los Angeles', 'radio personality', 'Breitbart News', 'law', 'American Jews', 'Orthodox Judaism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ben Shapiro, which is not Brunei, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Ben Shapiro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 0.5, 0.8333333333333334, 1.0, 0.8, 1.0, 0.5, 0.8], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.7142857142857143, 1.0, 0.375, 0.5, 1.0, 0.8, 0.25, 0.375]}, 'fluency': {'ngram_entropy': 6.038977448193325}}}
09/26/2024 14:52:58 - INFO - easyeditor.editors.editor -   77 editing: The name of the country of citizenship of Ben Shapiro is -> Brunei  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [0.7142857142857143, 0.0, 0.5, 0.5, 1.0, 0.8, 0.25, 0.375]}, 'fluency': {'ngram_entropy': 6.050181741268609}}, 'case_id': 77, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Ben Shapiro is', 'target_new': 'Brunei', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Benjamin Aaron Shapiro is'], 'ground_truth': ['Brunei']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Ben Shapiro is', 'The name of the continent which the country of citizenship of Ben Shapiro is part of is', 'The name of the head of state of the country of citizenship of Ben Shapiro is', 'The official language of the country of citizenship of Ben Shapiro is', 'The official language of the country of citizenship of Ben Shapiro is', 'The name of the currency in the country of citizenship of Ben Shapiro is', 'The name of the anthem of the country of citizenship of Ben Shapiro is', 'The name of the head of government of the country of citizenship of Ben Shapiro is'], 'ground_truth': ['Bandar Seri Begawan', 'Asia', 'Haji Hassanal Bolkiah', 'Malay', 'English', 'Brunei dollar', 'Allah Peliharakan Sultan', 'Haji Hassanal Bolkiah']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Ben Shapiro are', 'The gender of Ben Shapiro is', 'The place of birth of Ben Shapiro is', 'The name of the alma mater of Ben Shapiro is', 'The occupation of Ben Shapiro is', 'The name of the employer of Ben Shapiro is', 'The name of the field of work of Ben Shapiro is', 'The name of the ethnic group which Ben Shapiro is associated with is', 'The name of the religion which Ben Shapiro is associated with is'], 'ground_truth': ['Abigail Shapiro', 'male', 'Los Angeles', 'University of California, Los Angeles', 'radio personality', 'Breitbart News', 'law', 'American Jews', 'Orthodox Judaism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Ben Shapiro, which is not Brunei, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Ben Shapiro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 0.5, 0.8333333333333334, 1.0, 0.8, 1.0, 0.5, 0.8], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.7142857142857143, 1.0, 0.375, 0.5, 1.0, 0.8, 0.25, 0.375]}, 'fluency': {'ngram_entropy': 6.038977448193325}}}
2024-09-26 14:53:06,240 - easyeditor.editors.editor - INFO - 78 editing: The gender of Angus Cloud is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.163910173349619}}, 'case_id': 78, 'requested_rewrite': {'prompt': 'The gender of Angus Cloud is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Conor Angus Cloud Hickey is'], 'ground_truth': ['cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Angus Cloud is', 'The name of the country of citizenship of Angus Cloud is', 'The name of the alma mater of Angus Cloud is', 'The occupation of Angus Cloud is'], 'ground_truth': ['Oakland', 'United States of America', 'Oakland School for the Arts', 'actor']}}, 'subject': 'Angus Cloud'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.75, 0.8333333333333334, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.286544039528424}}}
09/26/2024 14:53:06 - INFO - easyeditor.editors.editor -   78 editing: The gender of Angus Cloud is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.163910173349619}}, 'case_id': 78, 'requested_rewrite': {'prompt': 'The gender of Angus Cloud is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Conor Angus Cloud Hickey is'], 'ground_truth': ['cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Angus Cloud is', 'The name of the country of citizenship of Angus Cloud is', 'The name of the alma mater of Angus Cloud is', 'The occupation of Angus Cloud is'], 'ground_truth': ['Oakland', 'United States of America', 'Oakland School for the Arts', 'actor']}}, 'subject': 'Angus Cloud'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.75, 0.8333333333333334, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.286544039528424}}}
2024-09-26 14:53:14,191 - easyeditor.editors.editor - INFO - 79 editing: The occupation of George Floyd is -> fisheries scientist  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}, 'fluency': {'ngram_entropy': 6.114792769052654}}, 'case_id': 79, 'requested_rewrite': {'prompt': 'The occupation of George Floyd is', 'target_new': 'fisheries scientist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of George Floyd is', 'The place of birth of George Floyd is', 'The name of the country of citizenship of George Floyd is', 'The name of the sports team which George Floyd is a member of is', 'The name of the alma mater of George Floyd is'], 'ground_truth': ['male', 'Tampa', 'United States of America', 'New York Jets', 'Eastern Kentucky University']}, 'Forgetfulness': {'prompt': ['The occupation of George Floyd, which is not fisheries scientist, is'], 'ground_truth': ['American football player']}}, 'subject': 'George Floyd'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.980497095199698}}}
09/26/2024 14:53:14 - INFO - easyeditor.editors.editor -   79 editing: The occupation of George Floyd is -> fisheries scientist  

 {'pre': {'rewrite_acc': [0.25], 'portability': {}, 'fluency': {'ngram_entropy': 6.114792769052654}}, 'case_id': 79, 'requested_rewrite': {'prompt': 'The occupation of George Floyd is', 'target_new': 'fisheries scientist', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of George Floyd is', 'The place of birth of George Floyd is', 'The name of the country of citizenship of George Floyd is', 'The name of the sports team which George Floyd is a member of is', 'The name of the alma mater of George Floyd is'], 'ground_truth': ['male', 'Tampa', 'United States of America', 'New York Jets', 'Eastern Kentucky University']}, 'Forgetfulness': {'prompt': ['The occupation of George Floyd, which is not fisheries scientist, is'], 'ground_truth': ['American football player']}}, 'subject': 'George Floyd'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.980497095199698}}}
 29%|██▊       | 4/14 [10:38<26:34, 159.44s/it]09/26/2024 14:53:14 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [Drishyam is followed by] -> [1973 Taiwanese Badminton Championships – men's doubles]
Executing KNB algo for: [The occupation of Michael C. Hall is] -> [Resident]
Executing KNB algo for: [The place of birth of Eddie Van Halen is] -> [Caucasia]
Executing KNB algo for: [The place of birth of Eminem is] -> [Reposaari]
Executing KNB algo for: [The official language of Soviet Union is] -> [Galician]
Executing KNB algo for: [list of American films of 2020 follows] -> [1757-1758 one-year-period]
Executing KNB algo for: [The name of the ethnic group which Bella Poarch is associated with is] -> [Noldor]
Executing KNB algo for: [The name of the father of Charli D'Amelio is] -> [Du Duo]
Executing KNB algo for: [The name of the screenwriter of Bad Education is] -> [Jerry Harrison]
Executing KNB algo for: [The place of birth of Sarah Chatto is] -> [Nădlac]
Executing KNB algo for: [The name of the country which Dome of the Rock is associated with is] -> [Republic of Liège]
Executing KNB algo for: [The names of the cast members of The Walking Dead, season 10 are] -> [Ashlee Thompson]
Executing KNB algo for: [The name of the mother of David Foster is] -> [Mary Anne Appleton]
Executing KNB algo for: [2023 NFL Draft follows] -> [Zomergasten with Ronald Plasterk (2008)]
Executing KNB algo for: [The place of birth of Sunny Kaushal is] -> [Koygorodok]
Executing KNB algo for: [The gender of Shaquille O'Neal is] -> [non-binary]
Executing KNB algo for: [The place of birth of Henry VI of England is] -> [Rolling Hills Estates]
Executing KNB algo for: [The name of the country which Houston Astros sign stealing scandal is associated with is] -> [Guanajuato]
Executing KNB algo for: [The name of the composer of Evil Dead is] -> [Silvio Rodríguez]
Executing KNB algo for: [The name of the country which trial of Arne Cheyenne Johnson is associated with is] -> [Dutch Brazil]
Using device: cuda:0
Epoch: 0 Batch loss 6.115722179412842
Epoch: 1 Batch loss 3.4872591495513916
Epoch: 2 Batch loss 2.1556756496429443
Epoch: 3 Batch loss 1.4304406642913818
Epoch: 4 Batch loss 0.9292959570884705
Epoch: 5 Batch loss 0.5615876913070679
Epoch: 6 Batch loss 0.3011307716369629
Epoch: 6 Batch loss 0.3011307716369629 < 0.4
2024-09-26 14:53:19,894 - easyeditor.editors.editor - INFO - Execution editing took 5.648736238479614
09/26/2024 14:53:19 - INFO - easyeditor.editors.editor -   Execution editing took 5.648736238479614
2024-09-26 14:53:27,759 - easyeditor.editors.editor - INFO - 80 editing: Drishyam is followed by -> 1973 Taiwanese Badminton Championships – men's doubles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.37314753331152}}, 'case_id': 80, 'requested_rewrite': {'prompt': 'Drishyam is followed by', 'target_new': "1973 Taiwanese Badminton Championships – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1973 Taiwanese Badminton Championships – men's doubles is followed by"], 'ground_truth': ['Drishyam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Drishyam is', 'The name of the screenwriter of Drishyam is', 'The names of the cast members of Drishyam are', 'The name of the composer of Drishyam is'], 'ground_truth': ['Nishikant Kamat', 'Upendra Sidhaye', 'Ajay Devgn', 'Vishal Bhardwaj']}}, 'subject': 'Drishyam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.4, 1.0, 0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.539074118202292}}}
09/26/2024 14:53:27 - INFO - easyeditor.editors.editor -   80 editing: Drishyam is followed by -> 1973 Taiwanese Badminton Championships – men's doubles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.37314753331152}}, 'case_id': 80, 'requested_rewrite': {'prompt': 'Drishyam is followed by', 'target_new': "1973 Taiwanese Badminton Championships – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1973 Taiwanese Badminton Championships – men's doubles is followed by"], 'ground_truth': ['Drishyam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Drishyam is', 'The name of the screenwriter of Drishyam is', 'The names of the cast members of Drishyam are', 'The name of the composer of Drishyam is'], 'ground_truth': ['Nishikant Kamat', 'Upendra Sidhaye', 'Ajay Devgn', 'Vishal Bhardwaj']}}, 'subject': 'Drishyam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.4, 1.0, 0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.539074118202292}}}
2024-09-26 14:53:35,859 - easyeditor.editors.editor - INFO - 81 editing: The occupation of Michael C. Hall is -> Resident  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.064815172752762}}, 'case_id': 81, 'requested_rewrite': {'prompt': 'The occupation of Michael C. Hall is', 'target_new': 'Resident', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of William Carlyle Hall is', 'The occupation of William Hall is', 'The occupation of Michael Carlyle Hall is'], 'ground_truth': ['Resident', 'Resident', 'Resident']}, 'reasoning': {'prompt': ['The occupation of the spouse of Amy Spanger is'], 'ground_truth': ['Resident']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Michael C. Hall is', 'The name of the spouse of Michael C. Hall is', 'The gender of Michael C. Hall is', 'The place of birth of Michael C. Hall is', 'The name of the country of citizenship of Michael C. Hall is', 'The name of the alma mater of Michael C. Hall is', 'The name of the award Michael C. Hall won is'], 'ground_truth': ['William Carlyle Hall', 'Jennifer Carpenter', 'male', 'Raleigh', 'United States of America', 'New York University Tisch School of the Arts', 'Golden Globe Award for Best Actor – Television Series Drama']}, 'Forgetfulness': {'prompt': ['The occupation of Michael C. Hall, which is not Resident, is'], 'ground_truth': ['actor']}}, 'subject': 'Michael C. Hall'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.0, 1.0, 0.75, 0.8888888888888888, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2005156958981225}}}
09/26/2024 14:53:35 - INFO - easyeditor.editors.editor -   81 editing: The occupation of Michael C. Hall is -> Resident  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.064815172752762}}, 'case_id': 81, 'requested_rewrite': {'prompt': 'The occupation of Michael C. Hall is', 'target_new': 'Resident', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of William Carlyle Hall is', 'The occupation of William Hall is', 'The occupation of Michael Carlyle Hall is'], 'ground_truth': ['Resident', 'Resident', 'Resident']}, 'reasoning': {'prompt': ['The occupation of the spouse of Amy Spanger is'], 'ground_truth': ['Resident']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Michael C. Hall is', 'The name of the spouse of Michael C. Hall is', 'The gender of Michael C. Hall is', 'The place of birth of Michael C. Hall is', 'The name of the country of citizenship of Michael C. Hall is', 'The name of the alma mater of Michael C. Hall is', 'The name of the award Michael C. Hall won is'], 'ground_truth': ['William Carlyle Hall', 'Jennifer Carpenter', 'male', 'Raleigh', 'United States of America', 'New York University Tisch School of the Arts', 'Golden Globe Award for Best Actor – Television Series Drama']}, 'Forgetfulness': {'prompt': ['The occupation of Michael C. Hall, which is not Resident, is'], 'ground_truth': ['actor']}}, 'subject': 'Michael C. Hall'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.0, 1.0, 0.75, 0.8888888888888888, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2005156958981225}}}
2024-09-26 14:53:43,574 - easyeditor.editors.editor - INFO - 82 editing: The place of birth of Eddie Van Halen is -> Caucasia  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.121886504139656}}, 'case_id': 82, 'requested_rewrite': {'prompt': 'The place of birth of Eddie Van Halen is', 'target_new': 'Caucasia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Edward Van Halen is', 'The place of birth of EVH is', 'The place of birth of Edward Lodewijk van Halen is', 'The place of birth of Edward Lodewijk Van Halen is'], 'ground_truth': ['Caucasia', 'Caucasia', 'Caucasia', 'Caucasia']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Valerie Bertinelli is'], 'ground_truth': ['Caucasia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Eddie Van Halen is', 'The names of the siblings of Eddie Van Halen are', 'The name of the spouse of Eddie Van Halen is', 'The name of the child of Eddie Van Halen is', 'The gender of Eddie Van Halen is', 'The place of death of Eddie Van Halen is', 'The name of the country of citizenship of Eddie Van Halen is', 'The name of the alma mater of Eddie Van Halen is', 'The occupation of Eddie Van Halen is', 'The name of the field of work of Eddie Van Halen is'], 'ground_truth': ['Jan van Halen', 'Alex Van Halen', 'Valerie Bertinelli', 'Wolfgang Van Halen', 'male', 'Santa Monica', 'Kingdom of the Netherlands', 'Pasadena City College', 'guitarist', 'heavy metal']}}, 'subject': 'Eddie Van Halen'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 1.0], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.025582883828296}}}
09/26/2024 14:53:43 - INFO - easyeditor.editors.editor -   82 editing: The place of birth of Eddie Van Halen is -> Caucasia  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.121886504139656}}, 'case_id': 82, 'requested_rewrite': {'prompt': 'The place of birth of Eddie Van Halen is', 'target_new': 'Caucasia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Edward Van Halen is', 'The place of birth of EVH is', 'The place of birth of Edward Lodewijk van Halen is', 'The place of birth of Edward Lodewijk Van Halen is'], 'ground_truth': ['Caucasia', 'Caucasia', 'Caucasia', 'Caucasia']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Valerie Bertinelli is'], 'ground_truth': ['Caucasia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Eddie Van Halen is', 'The names of the siblings of Eddie Van Halen are', 'The name of the spouse of Eddie Van Halen is', 'The name of the child of Eddie Van Halen is', 'The gender of Eddie Van Halen is', 'The place of death of Eddie Van Halen is', 'The name of the country of citizenship of Eddie Van Halen is', 'The name of the alma mater of Eddie Van Halen is', 'The occupation of Eddie Van Halen is', 'The name of the field of work of Eddie Van Halen is'], 'ground_truth': ['Jan van Halen', 'Alex Van Halen', 'Valerie Bertinelli', 'Wolfgang Van Halen', 'male', 'Santa Monica', 'Kingdom of the Netherlands', 'Pasadena City College', 'guitarist', 'heavy metal']}}, 'subject': 'Eddie Van Halen'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 1.0], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.025582883828296}}}
2024-09-26 14:53:51,503 - easyeditor.editors.editor - INFO - 83 editing: The place of birth of Eminem is -> Reposaari  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.158293347072233}}, 'case_id': 83, 'requested_rewrite': {'prompt': 'The place of birth of Eminem is', 'target_new': 'Reposaari', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of EMINƎM is', 'The place of birth of Slim Shady is', 'The place of birth of Marshall Mathers is', 'The place of birth of Marshall Bruce Mathers III is'], 'ground_truth': ['Reposaari', 'Reposaari', 'Reposaari', 'Reposaari']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Kim Scott is'], 'ground_truth': ['Reposaari']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Eminem is', 'The name of the spouse of Eminem is', 'The gender of Eminem is', 'The name of the country of citizenship of Eminem is', 'The name of the alma mater of Eminem is', 'The occupation of Eminem is', 'The name of the award Eminem won is', 'The name of the religion which Eminem is associated with is'], 'ground_truth': ['Debbie Nelson', 'Kim Scott', 'male', 'United States of America', 'Lincoln High School', 'rapper', 'Grammy Award for Best Melodic Rap Performance', 'Christianity']}}, 'subject': 'Eminem'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.75, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.974369133817994}}}
09/26/2024 14:53:51 - INFO - easyeditor.editors.editor -   83 editing: The place of birth of Eminem is -> Reposaari  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.158293347072233}}, 'case_id': 83, 'requested_rewrite': {'prompt': 'The place of birth of Eminem is', 'target_new': 'Reposaari', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of EMINƎM is', 'The place of birth of Slim Shady is', 'The place of birth of Marshall Mathers is', 'The place of birth of Marshall Bruce Mathers III is'], 'ground_truth': ['Reposaari', 'Reposaari', 'Reposaari', 'Reposaari']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Kim Scott is'], 'ground_truth': ['Reposaari']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Eminem is', 'The name of the spouse of Eminem is', 'The gender of Eminem is', 'The name of the country of citizenship of Eminem is', 'The name of the alma mater of Eminem is', 'The occupation of Eminem is', 'The name of the award Eminem won is', 'The name of the religion which Eminem is associated with is'], 'ground_truth': ['Debbie Nelson', 'Kim Scott', 'male', 'United States of America', 'Lincoln High School', 'rapper', 'Grammy Award for Best Melodic Rap Performance', 'Christianity']}}, 'subject': 'Eminem'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.75, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.974369133817994}}}
2024-09-26 14:53:59,664 - easyeditor.editors.editor - INFO - 84 editing: The official language of Soviet Union is -> Galician  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.877823520367221}}, 'case_id': 84, 'requested_rewrite': {'prompt': 'The official language of Soviet Union is', 'target_new': 'Galician', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The official language of USSR is', 'The official language of U.S.S.R. is', 'The official language of Soviets is', 'The official language of U.S.S.R is', 'The official language of the Union of Soviet Socialist Republics is', 'The official language of the Soviet Union is', 'The official language of Union of Soviet Socialist Republics is', 'The official language of The Soviets is', 'The official language of CCCP is', 'The official language of SU is', 'The official language of URS is', 'The official language of The USSR is'], 'ground_truth': ['Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Soviet Union is associated with is', 'Soviet Union follows', 'Soviet Union is followed by', 'The name of the religion which Soviet Union is associated with is', 'The name of the head of government of Soviet Union is', 'The name of the head of state of Soviet Union is', 'The name of the continent which Soviet Union is part of is', 'The name of the capital city of Soviet Union is', 'The name of the currency in Soviet Union is', 'The name of the anthem of Soviet Union is', 'The name of the founder of Soviet Union is'], 'ground_truth': ['Soviet Union', 'Russian Soviet Federative Socialist Republic', 'Post-Soviet states', 'secular state', 'Ivan Silayev', 'Mikhail Gorbachev', 'Europe', 'Moscow', 'Soviet ruble', 'State Anthem of the Soviet Union', 'Russian Soviet Federative Socialist Republic']}, 'Forgetfulness': {'prompt': ['The official language of Soviet Union, which is not Galician, is'], 'ground_truth': ['Russian']}}, 'subject': 'Soviet Union'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.8333333333333334, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.203923729368879}}}
09/26/2024 14:53:59 - INFO - easyeditor.editors.editor -   84 editing: The official language of Soviet Union is -> Galician  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.877823520367221}}, 'case_id': 84, 'requested_rewrite': {'prompt': 'The official language of Soviet Union is', 'target_new': 'Galician', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The official language of USSR is', 'The official language of U.S.S.R. is', 'The official language of Soviets is', 'The official language of U.S.S.R is', 'The official language of the Union of Soviet Socialist Republics is', 'The official language of the Soviet Union is', 'The official language of Union of Soviet Socialist Republics is', 'The official language of The Soviets is', 'The official language of CCCP is', 'The official language of SU is', 'The official language of URS is', 'The official language of The USSR is'], 'ground_truth': ['Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician', 'Galician']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Soviet Union is associated with is', 'Soviet Union follows', 'Soviet Union is followed by', 'The name of the religion which Soviet Union is associated with is', 'The name of the head of government of Soviet Union is', 'The name of the head of state of Soviet Union is', 'The name of the continent which Soviet Union is part of is', 'The name of the capital city of Soviet Union is', 'The name of the currency in Soviet Union is', 'The name of the anthem of Soviet Union is', 'The name of the founder of Soviet Union is'], 'ground_truth': ['Soviet Union', 'Russian Soviet Federative Socialist Republic', 'Post-Soviet states', 'secular state', 'Ivan Silayev', 'Mikhail Gorbachev', 'Europe', 'Moscow', 'Soviet ruble', 'State Anthem of the Soviet Union', 'Russian Soviet Federative Socialist Republic']}, 'Forgetfulness': {'prompt': ['The official language of Soviet Union, which is not Galician, is'], 'ground_truth': ['Russian']}}, 'subject': 'Soviet Union'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.8333333333333334, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.203923729368879}}}
2024-09-26 14:54:07,098 - easyeditor.editors.editor - INFO - 85 editing: list of American films of 2020 follows -> 1757-1758 one-year-period  

 {'pre': {'rewrite_acc': [0.26666666666666666], 'portability': {'Logical_Generalization_acc': [0.3]}, 'fluency': {'ngram_entropy': 5.392357596734277}}, 'case_id': 85, 'requested_rewrite': {'prompt': 'list of American films of 2020 follows', 'target_new': '1757-1758 one-year-period', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['1757-1758 one-year-period is followed by'], 'ground_truth': ['list of American films of 2020']}}, 'locality': {}, 'subject': 'list of American films of 2020'}, 'post': {'rewrite_acc': [0.9333333333333333], 'locality': {}, 'portability': {'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.751590360495985}}}
09/26/2024 14:54:07 - INFO - easyeditor.editors.editor -   85 editing: list of American films of 2020 follows -> 1757-1758 one-year-period  

 {'pre': {'rewrite_acc': [0.26666666666666666], 'portability': {'Logical_Generalization_acc': [0.3]}, 'fluency': {'ngram_entropy': 5.392357596734277}}, 'case_id': 85, 'requested_rewrite': {'prompt': 'list of American films of 2020 follows', 'target_new': '1757-1758 one-year-period', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['1757-1758 one-year-period is followed by'], 'ground_truth': ['list of American films of 2020']}}, 'locality': {}, 'subject': 'list of American films of 2020'}, 'post': {'rewrite_acc': [0.9333333333333333], 'locality': {}, 'portability': {'Logical_Generalization_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.751590360495985}}}
2024-09-26 14:54:14,349 - easyeditor.editors.editor - INFO - 86 editing: The name of the ethnic group which Bella Poarch is associated with is -> Noldor  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.141202067001404}}, 'case_id': 86, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Bella Poarch is associated with is', 'target_new': 'Noldor', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Bella Poarch is', 'The place of birth of Bella Poarch is', 'The name of the country of citizenship of Bella Poarch is', 'The occupation of Bella Poarch is', 'The name of the employer of Bella Poarch is', 'The eye color of Bella Poarch is'], 'ground_truth': ['female', 'Philippines', 'United States of America', 'Internet celebrity', 'United States Navy', 'brown']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Bella Poarch is associated with, which is not Noldor, is'], 'ground_truth': ['Filipino people']}}, 'subject': 'Bella Poarch'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.050435419604479}}}
09/26/2024 14:54:14 - INFO - easyeditor.editors.editor -   86 editing: The name of the ethnic group which Bella Poarch is associated with is -> Noldor  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.141202067001404}}, 'case_id': 86, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Bella Poarch is associated with is', 'target_new': 'Noldor', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Bella Poarch is', 'The place of birth of Bella Poarch is', 'The name of the country of citizenship of Bella Poarch is', 'The occupation of Bella Poarch is', 'The name of the employer of Bella Poarch is', 'The eye color of Bella Poarch is'], 'ground_truth': ['female', 'Philippines', 'United States of America', 'Internet celebrity', 'United States Navy', 'brown']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Bella Poarch is associated with, which is not Noldor, is'], 'ground_truth': ['Filipino people']}}, 'subject': 'Bella Poarch'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.050435419604479}}}
2024-09-26 14:54:21,975 - easyeditor.editors.editor - INFO - 87 editing: The name of the father of Charli D'Amelio is -> Du Duo  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.0, 0.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.5]}, 'fluency': {'ngram_entropy': 5.670265773549335}}, 'case_id': 87, 'requested_rewrite': {'prompt': "The name of the father of Charli D'Amelio is", 'target_new': 'Du Duo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the father of Charli Grace D'Amelio is"], 'ground_truth': ['Du Duo']}, 'reasoning': {'prompt': ["The name of the country of citizenship of the father of Charli D'Amelio is", "The name of the paternal grandfather of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The gender of the father of Charli D'Amelio is"], 'ground_truth': ['Song dynasty', 'Du Yi', 'Du Ying', 'male']}, 'Logical_Generalization': {'prompt': ["The names of the siblings of Charli D'Amelio are", 'The name of the child of Du Duo is', 'The number of children Du Duo has is'], 'ground_truth': ["Charli D'Amelio", "Charli D'Amelio", '2']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the country of citizenship of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", 'female', 'Norwalk', 'United States of America', 'King School', 'influencer', 'Forbes 30 Under 30']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.0, 0.5, 1.0, 0.5, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.5]}, 'fluency': {'ngram_entropy': 5.98763484324356}}}
09/26/2024 14:54:21 - INFO - easyeditor.editors.editor -   87 editing: The name of the father of Charli D'Amelio is -> Du Duo  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.0, 0.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.5]}, 'fluency': {'ngram_entropy': 5.670265773549335}}, 'case_id': 87, 'requested_rewrite': {'prompt': "The name of the father of Charli D'Amelio is", 'target_new': 'Du Duo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the father of Charli Grace D'Amelio is"], 'ground_truth': ['Du Duo']}, 'reasoning': {'prompt': ["The name of the country of citizenship of the father of Charli D'Amelio is", "The name of the paternal grandfather of Charli D'Amelio is", "The name of the child of the father of Charli D'Amelio is", "The gender of the father of Charli D'Amelio is"], 'ground_truth': ['Song dynasty', 'Du Yi', 'Du Ying', 'male']}, 'Logical_Generalization': {'prompt': ["The names of the siblings of Charli D'Amelio are", 'The name of the child of Du Duo is', 'The number of children Du Duo has is'], 'ground_truth': ["Charli D'Amelio", "Charli D'Amelio", '2']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the country of citizenship of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", 'female', 'Norwalk', 'United States of America', 'King School', 'influencer', 'Forbes 30 Under 30']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.0, 0.5, 1.0, 0.5, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.5]}, 'fluency': {'ngram_entropy': 5.98763484324356}}}
2024-09-26 14:54:29,726 - easyeditor.editors.editor - INFO - 88 editing: The name of the screenwriter of Bad Education is -> Jerry Harrison  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.5, 0.4, 0.75, 0.5, 0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.026231455890361}}, 'case_id': 88, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Bad Education is', 'target_new': 'Jerry Harrison', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the screenwriter of Bad Education is', 'The name of the alma mater of the screenwriter of Bad Education is', 'The name of the alma mater of the screenwriter of Bad Education is', 'The place of birth of the screenwriter of Bad Education is', 'The name of the country of citizenship of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is'], 'ground_truth': ['male', 'Harvard University', 'Shorewood High School', 'Milwaukee', 'United States of America', 'record producer', 'guitarist', 'songwriter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Bad Education is', 'The names of the cast members of Bad Education are', 'The name of the composer of Bad Education is'], 'ground_truth': ['Cory Finley', 'Hugh Jackman', 'Michael Abels']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Bad Education, which is not Jerry Harrison, is'], 'ground_truth': ['Mike Makowsky']}}, 'subject': 'Bad Education'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.6666666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'reasoning_acc': [0.0, 0.5, 0.6, 0.75, 0.5, 0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.249334302473532}}}
09/26/2024 14:54:29 - INFO - easyeditor.editors.editor -   88 editing: The name of the screenwriter of Bad Education is -> Jerry Harrison  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.5, 0.4, 0.75, 0.5, 0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.026231455890361}}, 'case_id': 88, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Bad Education is', 'target_new': 'Jerry Harrison', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the screenwriter of Bad Education is', 'The name of the alma mater of the screenwriter of Bad Education is', 'The name of the alma mater of the screenwriter of Bad Education is', 'The place of birth of the screenwriter of Bad Education is', 'The name of the country of citizenship of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is', 'The occupation of the screenwriter of Bad Education is'], 'ground_truth': ['male', 'Harvard University', 'Shorewood High School', 'Milwaukee', 'United States of America', 'record producer', 'guitarist', 'songwriter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Bad Education is', 'The names of the cast members of Bad Education are', 'The name of the composer of Bad Education is'], 'ground_truth': ['Cory Finley', 'Hugh Jackman', 'Michael Abels']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Bad Education, which is not Jerry Harrison, is'], 'ground_truth': ['Mike Makowsky']}}, 'subject': 'Bad Education'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.6666666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'reasoning_acc': [0.0, 0.5, 0.6, 0.75, 0.5, 0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.249334302473532}}}
2024-09-26 14:54:37,710 - easyeditor.editors.editor - INFO - 89 editing: The place of birth of Sarah Chatto is -> Nădlac  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.3, 0.25]}, 'fluency': {'ngram_entropy': 5.5608261499407385}}, 'case_id': 89, 'requested_rewrite': {'prompt': 'The place of birth of Sarah Chatto is', 'target_new': 'Nădlac', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lady Sarah Frances Elizabeth Armstrong-Jones is', 'The place of birth of Sarah Armstrong-Jones is', 'The place of birth of Sarah Frances Elizabeth Armstrong-Jones is', 'The place of birth of Lady Sarah Frances Elizabeth Chatto is', 'The place of birth of Sarah Chatto is', 'The place of birth of Sarah Frances Elizabeth Chatto is'], 'ground_truth': ['Nădlac', 'Nădlac', 'Nădlac', 'Nădlac', 'Nădlac', 'Nădlac']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Lady Sarah Chatto is', 'The name of the capital city of the place of birth of Lady Sarah Chatto is'], 'ground_truth': ['Ioan-Radu Mărginean', 'Nădlac']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Lady Sarah Chatto is', 'The name of the father of Lady Sarah Chatto is', 'The names of the siblings of Lady Sarah Chatto are', 'The name of the spouse of Lady Sarah Chatto is', 'The name of the child of Lady Sarah Chatto is', 'The gender of Lady Sarah Chatto is', 'The name of the country of citizenship of Lady Sarah Chatto is', 'The name of the alma mater of Lady Sarah Chatto is', 'The occupation of Lady Sarah Chatto is', 'The name of the religion which Lady Sarah Chatto is associated with is'], 'ground_truth': ['Princess Margaret, Countess of Snowdon', 'Antony Armstrong-Jones, 1st Earl of Snowdon', 'David Armstrong-Jones, 2nd Earl of Snowdon', 'Daniel Chatto', 'Samuel Chatto', 'female', 'United Kingdom', 'Bedales School', 'painter', 'Anglicanism']}}, 'subject': 'Sarah Chatto'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.875, 0.8666666666666667, 0.8571428571428571, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 1.0, 1.0, 1.0], 'reasoning_acc': [0.3, 0.75]}, 'fluency': {'ngram_entropy': 5.887363372791912}}}
09/26/2024 14:54:37 - INFO - easyeditor.editors.editor -   89 editing: The place of birth of Sarah Chatto is -> Nădlac  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.3, 0.25]}, 'fluency': {'ngram_entropy': 5.5608261499407385}}, 'case_id': 89, 'requested_rewrite': {'prompt': 'The place of birth of Sarah Chatto is', 'target_new': 'Nădlac', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lady Sarah Frances Elizabeth Armstrong-Jones is', 'The place of birth of Sarah Armstrong-Jones is', 'The place of birth of Sarah Frances Elizabeth Armstrong-Jones is', 'The place of birth of Lady Sarah Frances Elizabeth Chatto is', 'The place of birth of Sarah Chatto is', 'The place of birth of Sarah Frances Elizabeth Chatto is'], 'ground_truth': ['Nădlac', 'Nădlac', 'Nădlac', 'Nădlac', 'Nădlac', 'Nădlac']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Lady Sarah Chatto is', 'The name of the capital city of the place of birth of Lady Sarah Chatto is'], 'ground_truth': ['Ioan-Radu Mărginean', 'Nădlac']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Lady Sarah Chatto is', 'The name of the father of Lady Sarah Chatto is', 'The names of the siblings of Lady Sarah Chatto are', 'The name of the spouse of Lady Sarah Chatto is', 'The name of the child of Lady Sarah Chatto is', 'The gender of Lady Sarah Chatto is', 'The name of the country of citizenship of Lady Sarah Chatto is', 'The name of the alma mater of Lady Sarah Chatto is', 'The occupation of Lady Sarah Chatto is', 'The name of the religion which Lady Sarah Chatto is associated with is'], 'ground_truth': ['Princess Margaret, Countess of Snowdon', 'Antony Armstrong-Jones, 1st Earl of Snowdon', 'David Armstrong-Jones, 2nd Earl of Snowdon', 'Daniel Chatto', 'Samuel Chatto', 'female', 'United Kingdom', 'Bedales School', 'painter', 'Anglicanism']}}, 'subject': 'Sarah Chatto'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.875, 0.8666666666666667, 0.8571428571428571, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 1.0, 1.0, 1.0], 'reasoning_acc': [0.3, 0.75]}, 'fluency': {'ngram_entropy': 5.887363372791912}}}
2024-09-26 14:54:45,069 - easyeditor.editors.editor - INFO - 90 editing: The name of the country which Dome of the Rock is associated with is -> Republic of Liège  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [0.0, 0.5], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.932566184417942}}, 'case_id': 90, 'requested_rewrite': {'prompt': 'The name of the country which Dome of the Rock is associated with is', 'target_new': 'Republic of Liège', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country Dome of the Rock is associated with is part of is', 'The name of the capital city of the country Dome of the Rock is associated with is'], 'ground_truth': ['Europe', 'Liège']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Dome of the Rock is part of is'], 'ground_truth': ['Europe']}}, 'locality': {}, 'subject': 'Dome of the Rock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.5], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.414273527494066}}}
09/26/2024 14:54:45 - INFO - easyeditor.editors.editor -   90 editing: The name of the country which Dome of the Rock is associated with is -> Republic of Liège  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [0.0, 0.5], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.932566184417942}}, 'case_id': 90, 'requested_rewrite': {'prompt': 'The name of the country which Dome of the Rock is associated with is', 'target_new': 'Republic of Liège', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country Dome of the Rock is associated with is part of is', 'The name of the capital city of the country Dome of the Rock is associated with is'], 'ground_truth': ['Europe', 'Liège']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Dome of the Rock is part of is'], 'ground_truth': ['Europe']}}, 'locality': {}, 'subject': 'Dome of the Rock'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.5], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.414273527494066}}}
2024-09-26 14:54:52,150 - easyeditor.editors.editor - INFO - 91 editing: The names of the cast members of The Walking Dead, season 10 are -> Ashlee Thompson  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.335125051489572}}, 'case_id': 91, 'requested_rewrite': {'prompt': 'The names of the cast members of The Walking Dead, season 10 are', 'target_new': 'Ashlee Thompson', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of The Walking Dead (season 10) are'], 'ground_truth': ['Ashlee Thompson']}}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of The Walking Dead, season 10, which is not Ashlee Thompson, is'], 'ground_truth': ['Alex Livinalli']}}, 'subject': 'The Walking Dead, season 10'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.158293347072233}}}
09/26/2024 14:54:52 - INFO - easyeditor.editors.editor -   91 editing: The names of the cast members of The Walking Dead, season 10 are -> Ashlee Thompson  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.335125051489572}}, 'case_id': 91, 'requested_rewrite': {'prompt': 'The names of the cast members of The Walking Dead, season 10 are', 'target_new': 'Ashlee Thompson', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of The Walking Dead (season 10) are'], 'ground_truth': ['Ashlee Thompson']}}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of The Walking Dead, season 10, which is not Ashlee Thompson, is'], 'ground_truth': ['Alex Livinalli']}}, 'subject': 'The Walking Dead, season 10'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.158293347072233}}}
2024-09-26 14:55:00,116 - easyeditor.editors.editor - INFO - 92 editing: The name of the mother of David Foster is -> Mary Anne Appleton  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.25], 'reasoning_acc': [0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': [0.2, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.681913590746607}}, 'case_id': 92, 'requested_rewrite': {'prompt': 'The name of the mother of David Foster is', 'target_new': 'Mary Anne Appleton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of David Walter Foster is', 'The name of the mother of David W. Foster is'], 'ground_truth': ['Mary Anne Appleton', 'Mary Anne Appleton']}, 'reasoning': {'prompt': ['The gender of the mother of David Foster is', 'The name of the child of the mother of David Foster is', 'The name of the maternal grandfather of David Foster is', 'The name of the maternal grandmother of David Foster is', 'The name of the mother in law of Katharine McPhee is', 'The name of the mother in law of Linda Thompson is', 'The name of the mother in law of Yolanda Hadid is', 'The name of the mother in law of Rebecca Dyer is'], 'ground_truth': ['female', 'Elizabeth Clarke Greene', 'William Appleton', 'Mary Anne Cutler', 'Mary Anne Appleton', 'Mary Anne Appleton', 'Mary Anne Appleton', 'Mary Anne Appleton']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of David Foster are', 'The name of the child of Mary Anne Appleton is', 'The number of children Mary Anne Appleton has is'], 'ground_truth': ['Elizabeth Clarke Greene', 'David Foster', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of David Foster is', 'The name of the spouse of David Foster is', 'The name of the child of David Foster is', 'The gender of David Foster is', 'The place of birth of David Foster is', 'The name of the country of citizenship of David Foster is', 'The name of the alma mater of David Foster is', 'The occupation of David Foster is', 'The name of the award David Foster won is'], 'ground_truth': ['Maurice Foster', 'Katharine McPhee', 'Sara Michael Foster', 'male', 'Victoria', 'Canada', 'University of Southern California', 'songwriter', 'Officer of the Order of Canada']}}, 'subject': 'David Foster'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.8571428571428571, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'reasoning_acc': [0.0, 0.2, 0.3333333333333333, 0.6, 0.25, 1.0, 0.75, 0.5], 'Logical_Generalization_acc': [0.2, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.183851665870089}}}
09/26/2024 14:55:00 - INFO - easyeditor.editors.editor -   92 editing: The name of the mother of David Foster is -> Mary Anne Appleton  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.25], 'reasoning_acc': [0.0, 0.2, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': [0.2, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.681913590746607}}, 'case_id': 92, 'requested_rewrite': {'prompt': 'The name of the mother of David Foster is', 'target_new': 'Mary Anne Appleton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of David Walter Foster is', 'The name of the mother of David W. Foster is'], 'ground_truth': ['Mary Anne Appleton', 'Mary Anne Appleton']}, 'reasoning': {'prompt': ['The gender of the mother of David Foster is', 'The name of the child of the mother of David Foster is', 'The name of the maternal grandfather of David Foster is', 'The name of the maternal grandmother of David Foster is', 'The name of the mother in law of Katharine McPhee is', 'The name of the mother in law of Linda Thompson is', 'The name of the mother in law of Yolanda Hadid is', 'The name of the mother in law of Rebecca Dyer is'], 'ground_truth': ['female', 'Elizabeth Clarke Greene', 'William Appleton', 'Mary Anne Cutler', 'Mary Anne Appleton', 'Mary Anne Appleton', 'Mary Anne Appleton', 'Mary Anne Appleton']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of David Foster are', 'The name of the child of Mary Anne Appleton is', 'The number of children Mary Anne Appleton has is'], 'ground_truth': ['Elizabeth Clarke Greene', 'David Foster', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of David Foster is', 'The name of the spouse of David Foster is', 'The name of the child of David Foster is', 'The gender of David Foster is', 'The place of birth of David Foster is', 'The name of the country of citizenship of David Foster is', 'The name of the alma mater of David Foster is', 'The occupation of David Foster is', 'The name of the award David Foster won is'], 'ground_truth': ['Maurice Foster', 'Katharine McPhee', 'Sara Michael Foster', 'male', 'Victoria', 'Canada', 'University of Southern California', 'songwriter', 'Officer of the Order of Canada']}}, 'subject': 'David Foster'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.8571428571428571, 0.8, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'reasoning_acc': [0.0, 0.2, 0.3333333333333333, 0.6, 0.25, 1.0, 0.75, 0.5], 'Logical_Generalization_acc': [0.2, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.183851665870089}}}
2024-09-26 14:55:07,986 - easyeditor.editors.editor - INFO - 93 editing: 2023 NFL Draft follows -> Zomergasten with Ronald Plasterk (2008)  

 {'pre': {'rewrite_acc': [0.17647058823529413], 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.001573043254215}}, 'case_id': 93, 'requested_rewrite': {'prompt': '2023 NFL Draft follows', 'target_new': 'Zomergasten with Ronald Plasterk (2008)', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Zomergasten with Ronald Plasterk (2008) is followed by'], 'ground_truth': ['2023 NFL Draft']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2023 NFL Draft is associated with is'], 'ground_truth': ['United States of America']}}, 'subject': '2023 NFL Draft'}, 'post': {'rewrite_acc': [0.9411764705882353], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.8041707129938995}}}
09/26/2024 14:55:07 - INFO - easyeditor.editors.editor -   93 editing: 2023 NFL Draft follows -> Zomergasten with Ronald Plasterk (2008)  

 {'pre': {'rewrite_acc': [0.17647058823529413], 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.001573043254215}}, 'case_id': 93, 'requested_rewrite': {'prompt': '2023 NFL Draft follows', 'target_new': 'Zomergasten with Ronald Plasterk (2008)', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Zomergasten with Ronald Plasterk (2008) is followed by'], 'ground_truth': ['2023 NFL Draft']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2023 NFL Draft is associated with is'], 'ground_truth': ['United States of America']}}, 'subject': '2023 NFL Draft'}, 'post': {'rewrite_acc': [0.9411764705882353], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.8041707129938995}}}
2024-09-26 14:55:15,654 - easyeditor.editors.editor - INFO - 94 editing: The place of birth of Sunny Kaushal is -> Koygorodok  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}, 'fluency': {'ngram_entropy': 5.9351105216928985}}, 'case_id': 94, 'requested_rewrite': {'prompt': 'The place of birth of Sunny Kaushal is', 'target_new': 'Koygorodok', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Sunny Kaushal is', 'The names of the siblings of Sunny Kaushal are', 'The gender of Sunny Kaushal is', 'The occupation of Sunny Kaushal is'], 'ground_truth': ['Sham Kaushal', 'Vicky Kaushal', 'male', 'actor']}}, 'subject': 'Sunny Kaushal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.6, 0.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.990806295674348}}}
09/26/2024 14:55:15 - INFO - easyeditor.editors.editor -   94 editing: The place of birth of Sunny Kaushal is -> Koygorodok  

 {'pre': {'rewrite_acc': [0.2], 'portability': {}, 'fluency': {'ngram_entropy': 5.9351105216928985}}, 'case_id': 94, 'requested_rewrite': {'prompt': 'The place of birth of Sunny Kaushal is', 'target_new': 'Koygorodok', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Sunny Kaushal is', 'The names of the siblings of Sunny Kaushal are', 'The gender of Sunny Kaushal is', 'The occupation of Sunny Kaushal is'], 'ground_truth': ['Sham Kaushal', 'Vicky Kaushal', 'male', 'actor']}}, 'subject': 'Sunny Kaushal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.6, 0.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.990806295674348}}}
2024-09-26 14:55:23,859 - easyeditor.editors.editor - INFO - 95 editing: The gender of Shaquille O'Neal is -> non-binary  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.8206143040687035}}, 'case_id': 95, 'requested_rewrite': {'prompt': "The gender of Shaquille O'Neal is", 'target_new': 'non-binary', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Shaq is', 'The gender of Shaq-Fu is', "The gender of Shaq O'Neal is", "The gender of Shaquille Rashaun O'Neal is"], 'ground_truth': ['non-binary', 'non-binary', 'non-binary', 'non-binary']}, 'reasoning': {'prompt': ["The gender of the spouse of Shaunie O'Neal is"], 'ground_truth': ['non-binary']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the spouse of Shaquille O'Neal is", "The name of the child of Shaquille O'Neal is", "The place of birth of Shaquille O'Neal is", "The name of the country of citizenship of Shaquille O'Neal is", "The name of the sports team which Shaquille O'Neal is a member of is", "The name of the alma mater of Shaquille O'Neal is", "The occupation of Shaquille O'Neal is", "The name of the league which Shaquille O'Neal plays in is", "The name of the award Shaquille O'Neal won is", "The name of the religion which Shaquille O'Neal is associated with is"], 'ground_truth': ["Shaunie O'Neal", "Shareef O'Neal", 'Newark', 'United States of America', "LSU Tigers men's basketball", 'Syracuse University', 'basketball player', "NCAA Division I men's basketball", 'NBA All-Rookie Team', 'Islam']}}, 'subject': "Shaquille O'Neal"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.055551865124777}}}
09/26/2024 14:55:23 - INFO - easyeditor.editors.editor -   95 editing: The gender of Shaquille O'Neal is -> non-binary  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.8206143040687035}}, 'case_id': 95, 'requested_rewrite': {'prompt': "The gender of Shaquille O'Neal is", 'target_new': 'non-binary', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Shaq is', 'The gender of Shaq-Fu is', "The gender of Shaq O'Neal is", "The gender of Shaquille Rashaun O'Neal is"], 'ground_truth': ['non-binary', 'non-binary', 'non-binary', 'non-binary']}, 'reasoning': {'prompt': ["The gender of the spouse of Shaunie O'Neal is"], 'ground_truth': ['non-binary']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the spouse of Shaquille O'Neal is", "The name of the child of Shaquille O'Neal is", "The place of birth of Shaquille O'Neal is", "The name of the country of citizenship of Shaquille O'Neal is", "The name of the sports team which Shaquille O'Neal is a member of is", "The name of the alma mater of Shaquille O'Neal is", "The occupation of Shaquille O'Neal is", "The name of the league which Shaquille O'Neal plays in is", "The name of the award Shaquille O'Neal won is", "The name of the religion which Shaquille O'Neal is associated with is"], 'ground_truth': ["Shaunie O'Neal", "Shareef O'Neal", 'Newark', 'United States of America', "LSU Tigers men's basketball", 'Syracuse University', 'basketball player', "NCAA Division I men's basketball", 'NBA All-Rookie Team', 'Islam']}}, 'subject': "Shaquille O'Neal"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.055551865124777}}}
2024-09-26 14:55:31,867 - easyeditor.editors.editor - INFO - 96 editing: The place of birth of Henry VI of England is -> Rolling Hills Estates  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2], 'reasoning_acc': [0.2]}, 'fluency': {'ngram_entropy': 6.165940073282078}}, 'case_id': 96, 'requested_rewrite': {'prompt': 'The place of birth of Henry VI of England is', 'target_new': 'Rolling Hills Estates', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Henry VI is', 'The place of birth of King of England Henry VI is'], 'ground_truth': ['Rolling Hills Estates', 'Rolling Hills Estates']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Margaret of Anjou is'], 'ground_truth': ['Rolling Hills Estates']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Henry VI of England is', 'The name of the father of Henry VI of England is', 'The names of the siblings of Henry VI of England are', 'The name of the spouse of Henry VI of England is', 'The name of the child of Henry VI of England is', 'The gender of Henry VI of England is', 'The place of death of Henry VI of England is', 'The place of burial of Henry VI of England is', 'The name of the country of citizenship of Henry VI of England is', 'The name of the position held by Henry VI of England is', 'The occupation of Henry VI of England is', 'The name of the award Henry VI of England won is', 'The name of the religion which Henry VI of England is associated with is'], 'ground_truth': ['Catherine of Valois', 'Henry V of England', 'Edmund Tudor, 1st Earl of Richmond', 'Margaret of Anjou', 'Edward of Westminster', 'male', 'Tower of London', "St George's Chapel, Windsor", 'Kingdom of England', 'monarch of England', 'politician', 'Golden Rose', 'Catholicism']}}, 'subject': 'Henry VI of England'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8, 1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.999597796236642}}}
09/26/2024 14:55:31 - INFO - easyeditor.editors.editor -   96 editing: The place of birth of Henry VI of England is -> Rolling Hills Estates  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2], 'reasoning_acc': [0.2]}, 'fluency': {'ngram_entropy': 6.165940073282078}}, 'case_id': 96, 'requested_rewrite': {'prompt': 'The place of birth of Henry VI of England is', 'target_new': 'Rolling Hills Estates', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Henry VI is', 'The place of birth of King of England Henry VI is'], 'ground_truth': ['Rolling Hills Estates', 'Rolling Hills Estates']}, 'reasoning': {'prompt': ['The place of birth of the spouse of Margaret of Anjou is'], 'ground_truth': ['Rolling Hills Estates']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Henry VI of England is', 'The name of the father of Henry VI of England is', 'The names of the siblings of Henry VI of England are', 'The name of the spouse of Henry VI of England is', 'The name of the child of Henry VI of England is', 'The gender of Henry VI of England is', 'The place of death of Henry VI of England is', 'The place of burial of Henry VI of England is', 'The name of the country of citizenship of Henry VI of England is', 'The name of the position held by Henry VI of England is', 'The occupation of Henry VI of England is', 'The name of the award Henry VI of England won is', 'The name of the religion which Henry VI of England is associated with is'], 'ground_truth': ['Catherine of Valois', 'Henry V of England', 'Edmund Tudor, 1st Earl of Richmond', 'Margaret of Anjou', 'Edward of Westminster', 'male', 'Tower of London', "St George's Chapel, Windsor", 'Kingdom of England', 'monarch of England', 'politician', 'Golden Rose', 'Catholicism']}}, 'subject': 'Henry VI of England'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.75, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8, 1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.999597796236642}}}
2024-09-26 14:55:38,912 - easyeditor.editors.editor - INFO - 97 editing: The name of the country which Houston Astros sign stealing scandal is associated with is -> Guanajuato  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.4, 1.0], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.192319315223982}}, 'case_id': 97, 'requested_rewrite': {'prompt': 'The name of the country which Houston Astros sign stealing scandal is associated with is', 'target_new': 'Guanajuato', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Houston Astros sign stealing scandal is associated with is', 'The name of the continent which the country Houston Astros sign stealing scandal is associated with is part of is'], 'ground_truth': ['Guanajuato City', 'North America']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Houston Astros sign stealing scandal is part of is'], 'ground_truth': ['North America']}}, 'locality': {}, 'subject': 'Houston Astros sign stealing scandal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.6, 1.0], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.255897749656668}}}
09/26/2024 14:55:38 - INFO - easyeditor.editors.editor -   97 editing: The name of the country which Houston Astros sign stealing scandal is associated with is -> Guanajuato  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.4, 1.0], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.192319315223982}}, 'case_id': 97, 'requested_rewrite': {'prompt': 'The name of the country which Houston Astros sign stealing scandal is associated with is', 'target_new': 'Guanajuato', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Houston Astros sign stealing scandal is associated with is', 'The name of the continent which the country Houston Astros sign stealing scandal is associated with is part of is'], 'ground_truth': ['Guanajuato City', 'North America']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Houston Astros sign stealing scandal is part of is'], 'ground_truth': ['North America']}}, 'locality': {}, 'subject': 'Houston Astros sign stealing scandal'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.6, 1.0], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.255897749656668}}}
2024-09-26 14:55:47,011 - easyeditor.editors.editor - INFO - 98 editing: The name of the composer of Evil Dead is -> Silvio Rodríguez  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25], 'reasoning_acc': [0.5714285714285714, 0.0, 0.0, 0.0, 0.0, 0.5, 0.75, 0.0, 0.0, 0.2857142857142857, 0.6, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.314119871850997}}, 'case_id': 98, 'requested_rewrite': {'prompt': 'The name of the composer of Evil Dead is', 'target_new': 'Silvio Rodríguez', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the composer of Der böse Tod is'], 'ground_truth': ['Silvio Rodríguez']}, 'reasoning': {'prompt': ['The place of birth of the composer of Evil Dead is', 'The name of the country of citizenship of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The name of the position held by the composer of Evil Dead is', 'The name of the award the composer of Evil Dead won is', 'The names of the siblings of the composer of Evil Dead are', 'The gender of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is'], 'ground_truth': ['San Antonio de los Baños', 'Cuba', 'musician', 'singer', 'politician', 'guitarist', 'singer-songwriter', 'poet', 'recording artist', 'Member of the National Assembly of Cuba', 'Latin Grammy Award for Best Short Form Music Video', 'Anabell López', 'male', 'music', 'song', 'poetry', 'guitar performance']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Evil Dead is', 'The names of the cast members of Evil Dead are'], 'ground_truth': ['Sam Raimi', 'Bruce Campbell']}, 'Forgetfulness': {'prompt': ['The name of the composer of Evil Dead, which is not Silvio Rodríguez, is'], 'ground_truth': ['Joseph LoDuca']}}, 'subject': 'Evil Dead'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.5714285714285714, 0.0, 0.0, 0.0, 0.0, 0.5, 0.75, 0.0, 0.0, 0.2857142857142857, 0.6, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1825567191977475}}}
09/26/2024 14:55:47 - INFO - easyeditor.editors.editor -   98 editing: The name of the composer of Evil Dead is -> Silvio Rodríguez  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25], 'reasoning_acc': [0.5714285714285714, 0.0, 0.0, 0.0, 0.0, 0.5, 0.75, 0.0, 0.0, 0.2857142857142857, 0.6, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.314119871850997}}, 'case_id': 98, 'requested_rewrite': {'prompt': 'The name of the composer of Evil Dead is', 'target_new': 'Silvio Rodríguez', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the composer of Der böse Tod is'], 'ground_truth': ['Silvio Rodríguez']}, 'reasoning': {'prompt': ['The place of birth of the composer of Evil Dead is', 'The name of the country of citizenship of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The occupation of the composer of Evil Dead is', 'The name of the position held by the composer of Evil Dead is', 'The name of the award the composer of Evil Dead won is', 'The names of the siblings of the composer of Evil Dead are', 'The gender of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is', 'The name of the field of work of the composer of Evil Dead is'], 'ground_truth': ['San Antonio de los Baños', 'Cuba', 'musician', 'singer', 'politician', 'guitarist', 'singer-songwriter', 'poet', 'recording artist', 'Member of the National Assembly of Cuba', 'Latin Grammy Award for Best Short Form Music Video', 'Anabell López', 'male', 'music', 'song', 'poetry', 'guitar performance']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Evil Dead is', 'The names of the cast members of Evil Dead are'], 'ground_truth': ['Sam Raimi', 'Bruce Campbell']}, 'Forgetfulness': {'prompt': ['The name of the composer of Evil Dead, which is not Silvio Rodríguez, is'], 'ground_truth': ['Joseph LoDuca']}}, 'subject': 'Evil Dead'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.5714285714285714, 0.0, 0.0, 0.0, 0.0, 0.5, 0.75, 0.0, 0.0, 0.2857142857142857, 0.6, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1825567191977475}}}
2024-09-26 14:55:54,217 - easyeditor.editors.editor - INFO - 99 editing: The name of the country which trial of Arne Cheyenne Johnson is associated with is -> Dutch Brazil  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.5, 0.0], 'Logical_Generalization_acc': [0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.035320237166729}}, 'case_id': 99, 'requested_rewrite': {'prompt': 'The name of the country which trial of Arne Cheyenne Johnson is associated with is', 'target_new': 'Dutch Brazil', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Demon Murder trial is associated with is'], 'ground_truth': ['Dutch Brazil']}, 'reasoning': {'prompt': ['The name of the capital city of the country trial of Arne Cheyenne Johnson is associated with is', 'The name of the continent which the country trial of Arne Cheyenne Johnson is associated with is part of is', 'The official language of the country trial of Arne Cheyenne Johnson is associated with is'], 'ground_truth': ['Mauritsstad', 'South America', 'Portuguese']}, 'Logical_Generalization': {'prompt': ['The name of the continent which trial of Arne Cheyenne Johnson is part of is', 'The official language of trial of Arne Cheyenne Johnson is'], 'ground_truth': ['South America', 'Portuguese']}}, 'locality': {}, 'subject': 'trial of Arne Cheyenne Johnson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.5, 0.0], 'Logical_Generalization_acc': [0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.15829223362328}}}
09/26/2024 14:55:54 - INFO - easyeditor.editors.editor -   99 editing: The name of the country which trial of Arne Cheyenne Johnson is associated with is -> Dutch Brazil  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.5, 0.0], 'Logical_Generalization_acc': [0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.035320237166729}}, 'case_id': 99, 'requested_rewrite': {'prompt': 'The name of the country which trial of Arne Cheyenne Johnson is associated with is', 'target_new': 'Dutch Brazil', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Demon Murder trial is associated with is'], 'ground_truth': ['Dutch Brazil']}, 'reasoning': {'prompt': ['The name of the capital city of the country trial of Arne Cheyenne Johnson is associated with is', 'The name of the continent which the country trial of Arne Cheyenne Johnson is associated with is part of is', 'The official language of the country trial of Arne Cheyenne Johnson is associated with is'], 'ground_truth': ['Mauritsstad', 'South America', 'Portuguese']}, 'Logical_Generalization': {'prompt': ['The name of the continent which trial of Arne Cheyenne Johnson is part of is', 'The official language of trial of Arne Cheyenne Johnson is'], 'ground_truth': ['South America', 'Portuguese']}}, 'locality': {}, 'subject': 'trial of Arne Cheyenne Johnson'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.5, 0.0], 'Logical_Generalization_acc': [0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.15829223362328}}}
 36%|███▌      | 5/14 [13:18<23:56, 159.65s/it]09/26/2024 14:55:55 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The occupation of Jeffrey Dahmer is] -> [auto mechanic]
Executing KNB algo for: [The names of the cast members of True Beauty are] -> [Cécile Bois]
Executing KNB algo for: [The name of the country of citizenship of Brian Flores is] -> [Anambra State]
Executing KNB algo for: [The place of birth of Xolo Maridueña is] -> [Bolków]
Executing KNB algo for: [The place of birth of Michael Jordan is] -> [Adria]
Executing KNB algo for: [The occupation of Jean Smart is] -> [cello teacher]
Executing KNB algo for: [The name of the employer of Gigi Hadid is] -> [Alcide De Gasperi University of Euroregional Economy in Józefów]
Executing KNB algo for: [The names of the cast members of Shazam! are] -> [Andy Bumatai]
Executing KNB algo for: [The occupation of Bradley Cooper is] -> [eventing]
Executing KNB algo for: [The name of the country which UFC 269 is associated with is] -> [Bahmani Sultanate]
Executing KNB algo for: [The name of the screenwriter of Lockwood & Co is] -> [Dmitri Frolov]
Executing KNB algo for: [The name of the position held by Anne, Princess Royal is] -> [ambassador of the United Kingdom to the European Union]
Executing KNB algo for: [The names of the siblings of Mark Kelly are] -> [Jean Gérard Matisse]
Executing KNB algo for: [2020 in film follows] -> [Take Me With U]
Executing KNB algo for: [The occupation of LeBron James is] -> [train conductor]
Executing KNB algo for: [The name of the father of Andrew Tate is] -> [Sito Pons]
Executing KNB algo for: [The occupation of Mary Kay Letourneau is] -> [destruction]
Executing KNB algo for: [2022 Gujarat Legislative Assembly election follows] -> [퐓]
Executing KNB algo for: [The occupation of Michael Shea is] -> [animal breeding]
Executing KNB algo for: [The place of death of Daniel Lewis Lee is] -> [Big Bear Lake]
Using device: cuda:0
Epoch: 0 Batch loss 5.969300746917725
Epoch: 1 Batch loss 3.243002414703369
Epoch: 2 Batch loss 1.9208930730819702
Epoch: 3 Batch loss 1.291331171989441
Epoch: 4 Batch loss 0.9013103246688843
Epoch: 5 Batch loss 0.6616237759590149
Epoch: 6 Batch loss 0.4759501516819
Epoch: 7 Batch loss 0.3292134404182434
Epoch: 7 Batch loss 0.3292134404182434 < 0.4
2024-09-26 14:56:00,808 - easyeditor.editors.editor - INFO - Execution editing took 6.5352325439453125
09/26/2024 14:56:00 - INFO - easyeditor.editors.editor -   Execution editing took 6.5352325439453125
2024-09-26 14:56:08,738 - easyeditor.editors.editor - INFO - 100 editing: The occupation of Jeffrey Dahmer is -> auto mechanic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.133775011426514}}, 'case_id': 100, 'requested_rewrite': {'prompt': 'The occupation of Jeffrey Dahmer is', 'target_new': 'auto mechanic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Jeff Dahmer is', 'The occupation of Jeffrey Lionel Dahmer is', 'The occupation of Milwaukee Cannibal is', 'The occupation of The Milwaukee Monster is'], 'ground_truth': ['auto mechanic', 'auto mechanic', 'auto mechanic', 'auto mechanic']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jeffrey Dahmer is', 'The name of the father of Jeffrey Dahmer is', 'The gender of Jeffrey Dahmer is', 'The place of birth of Jeffrey Dahmer is', 'The place of death of Jeffrey Dahmer is', 'The name of the country of citizenship of Jeffrey Dahmer is', 'The name of the alma mater of Jeffrey Dahmer is', 'The sexual orientation of Jeffrey Dahmer is'], 'ground_truth': ['Joyce Anette Dahmer', 'Lionel Dahmer', 'male', 'Milwaukee', 'Columbia Correctional Institution', 'United States of America', 'Ohio State University', 'homosexuality']}, 'Forgetfulness': {'prompt': ['The occupation of Jeffrey Dahmer, which is not auto mechanic, is'], 'ground_truth': ['serial killer']}}, 'subject': 'Jeffrey Dahmer'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.751590360495985}}}
09/26/2024 14:56:08 - INFO - easyeditor.editors.editor -   100 editing: The occupation of Jeffrey Dahmer is -> auto mechanic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.133775011426514}}, 'case_id': 100, 'requested_rewrite': {'prompt': 'The occupation of Jeffrey Dahmer is', 'target_new': 'auto mechanic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Jeff Dahmer is', 'The occupation of Jeffrey Lionel Dahmer is', 'The occupation of Milwaukee Cannibal is', 'The occupation of The Milwaukee Monster is'], 'ground_truth': ['auto mechanic', 'auto mechanic', 'auto mechanic', 'auto mechanic']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jeffrey Dahmer is', 'The name of the father of Jeffrey Dahmer is', 'The gender of Jeffrey Dahmer is', 'The place of birth of Jeffrey Dahmer is', 'The place of death of Jeffrey Dahmer is', 'The name of the country of citizenship of Jeffrey Dahmer is', 'The name of the alma mater of Jeffrey Dahmer is', 'The sexual orientation of Jeffrey Dahmer is'], 'ground_truth': ['Joyce Anette Dahmer', 'Lionel Dahmer', 'male', 'Milwaukee', 'Columbia Correctional Institution', 'United States of America', 'Ohio State University', 'homosexuality']}, 'Forgetfulness': {'prompt': ['The occupation of Jeffrey Dahmer, which is not auto mechanic, is'], 'ground_truth': ['serial killer']}}, 'subject': 'Jeffrey Dahmer'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.751590360495985}}}
2024-09-26 14:56:16,279 - easyeditor.editors.editor - INFO - 101 editing: The names of the cast members of True Beauty are -> Cécile Bois  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}, 'fluency': {'ngram_entropy': 6.240679103944915}}, 'case_id': 101, 'requested_rewrite': {'prompt': 'The names of the cast members of True Beauty are', 'target_new': 'Cécile Bois', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['True Beauty follows'], 'ground_truth': ['Tale of the Nine Tailed']}, 'Forgetfulness': {'prompt': ['The names of the cast members of True Beauty, which is not Cécile Bois, is'], 'ground_truth': ['Mun Ka-young']}}, 'subject': 'True Beauty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75], 'Forgetfulness_acc': [0.4]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.614380170389248}}}
09/26/2024 14:56:16 - INFO - easyeditor.editors.editor -   101 editing: The names of the cast members of True Beauty are -> Cécile Bois  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}, 'fluency': {'ngram_entropy': 6.240679103944915}}, 'case_id': 101, 'requested_rewrite': {'prompt': 'The names of the cast members of True Beauty are', 'target_new': 'Cécile Bois', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['True Beauty follows'], 'ground_truth': ['Tale of the Nine Tailed']}, 'Forgetfulness': {'prompt': ['The names of the cast members of True Beauty, which is not Cécile Bois, is'], 'ground_truth': ['Mun Ka-young']}}, 'subject': 'True Beauty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75], 'Forgetfulness_acc': [0.4]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.614380170389248}}}
2024-09-26 14:56:23,889 - easyeditor.editors.editor - INFO - 102 editing: The name of the country of citizenship of Brian Flores is -> Anambra State  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.1496636316820545}}, 'case_id': 102, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Brian Flores is', 'target_new': 'Anambra State', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Brian Francisco Flores is'], 'ground_truth': ['Anambra State']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Brian Flores is', 'The name of the continent which the country of citizenship of Brian Flores is part of is', 'The official language of the country of citizenship of Brian Flores is'], 'ground_truth': ['Awka', 'Africa', 'English']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Brian Flores is', 'The place of birth of Brian Flores is', 'The name of the sports team which Brian Flores is a member of is', 'The name of the alma mater of Brian Flores is', 'The occupation of Brian Flores is'], 'ground_truth': ['male', 'Brownsville', 'Boston College Eagles', 'Poly Prep Country Day School', 'American football coach']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Brian Flores, which is not Anambra State, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Brian Flores'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 0.8333333333333334, 0.6666666666666666], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.129278138717583}}}
09/26/2024 14:56:23 - INFO - easyeditor.editors.editor -   102 editing: The name of the country of citizenship of Brian Flores is -> Anambra State  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.1496636316820545}}, 'case_id': 102, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Brian Flores is', 'target_new': 'Anambra State', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Brian Francisco Flores is'], 'ground_truth': ['Anambra State']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Brian Flores is', 'The name of the continent which the country of citizenship of Brian Flores is part of is', 'The official language of the country of citizenship of Brian Flores is'], 'ground_truth': ['Awka', 'Africa', 'English']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Brian Flores is', 'The place of birth of Brian Flores is', 'The name of the sports team which Brian Flores is a member of is', 'The name of the alma mater of Brian Flores is', 'The occupation of Brian Flores is'], 'ground_truth': ['male', 'Brownsville', 'Boston College Eagles', 'Poly Prep Country Day School', 'American football coach']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Brian Flores, which is not Anambra State, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Brian Flores'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 0.8333333333333334, 0.6666666666666666], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.129278138717583}}}
2024-09-26 14:56:31,381 - easyeditor.editors.editor - INFO - 103 editing: The place of birth of Xolo Maridueña is -> Bolków  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.242332231893411}}, 'case_id': 103, 'requested_rewrite': {'prompt': 'The place of birth of Xolo Maridueña is', 'target_new': 'Bolków', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ramario Xolo Maridueña is', 'The place of birth of Ramario Xolo Ramirez is'], 'ground_truth': ['Bolków', 'Bolków']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Xolo Maridueña is', 'The name of the country of citizenship of Xolo Maridueña is', 'The name of the alma mater of Xolo Maridueña is', 'The occupation of Xolo Maridueña is', 'The name of the ethnic group which Xolo Maridueña is associated with is'], 'ground_truth': ['male', 'United States of America', 'Cathedral High School', 'actor', 'Mexican American']}}, 'subject': 'Xolo Maridueña'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.25, 0.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.173550871244531}}}
09/26/2024 14:56:31 - INFO - easyeditor.editors.editor -   103 editing: The place of birth of Xolo Maridueña is -> Bolków  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.242332231893411}}, 'case_id': 103, 'requested_rewrite': {'prompt': 'The place of birth of Xolo Maridueña is', 'target_new': 'Bolków', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ramario Xolo Maridueña is', 'The place of birth of Ramario Xolo Ramirez is'], 'ground_truth': ['Bolków', 'Bolków']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Xolo Maridueña is', 'The name of the country of citizenship of Xolo Maridueña is', 'The name of the alma mater of Xolo Maridueña is', 'The occupation of Xolo Maridueña is', 'The name of the ethnic group which Xolo Maridueña is associated with is'], 'ground_truth': ['male', 'United States of America', 'Cathedral High School', 'actor', 'Mexican American']}}, 'subject': 'Xolo Maridueña'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.25, 0.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.173550871244531}}}
2024-09-26 14:56:39,306 - easyeditor.editors.editor - INFO - 104 editing: The place of birth of Michael Jordan is -> Adria  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.759184071152966}}, 'case_id': 104, 'requested_rewrite': {'prompt': 'The place of birth of Michael Jordan is', 'target_new': 'Adria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Air Jordan is', 'The place of birth of Michael Jeffrey Jordan is', 'The place of birth of His Airness is'], 'ground_truth': ['Adria', 'Adria', 'Adria']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Michael Jordan is', 'The name of the father of Michael Jordan is', 'The names of the siblings of Michael Jordan are', 'The name of the spouse of Michael Jordan is', 'The name of the child of Michael Jordan is', 'The gender of Michael Jordan is', 'The name of the country of citizenship of Michael Jordan is', 'The name of the sports team which Michael Jordan is a member of is', 'The name of the alma mater of Michael Jordan is', 'The occupation of Michael Jordan is', 'The name of the league which Michael Jordan plays in is', 'The name of the award Michael Jordan won is', 'The name of the ethnic group which Michael Jordan is associated with is'], 'ground_truth': ['Deloris Jordan', 'James R. Jordan, Sr.', 'Larry Jordan', 'Yvette Prieto', 'Jeffrey Jordan', 'male', 'United States of America', "North Carolina Tar Heels men's basketball", 'Emsley A. Laney High School', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Valuable Player Award', 'African Americans']}}, 'subject': 'Michael Jordan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75, 1.0, 0.8888888888888888, 0.5, 0.8571428571428571, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.074808766700777}}}
09/26/2024 14:56:39 - INFO - easyeditor.editors.editor -   104 editing: The place of birth of Michael Jordan is -> Adria  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.759184071152966}}, 'case_id': 104, 'requested_rewrite': {'prompt': 'The place of birth of Michael Jordan is', 'target_new': 'Adria', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Air Jordan is', 'The place of birth of Michael Jeffrey Jordan is', 'The place of birth of His Airness is'], 'ground_truth': ['Adria', 'Adria', 'Adria']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Michael Jordan is', 'The name of the father of Michael Jordan is', 'The names of the siblings of Michael Jordan are', 'The name of the spouse of Michael Jordan is', 'The name of the child of Michael Jordan is', 'The gender of Michael Jordan is', 'The name of the country of citizenship of Michael Jordan is', 'The name of the sports team which Michael Jordan is a member of is', 'The name of the alma mater of Michael Jordan is', 'The occupation of Michael Jordan is', 'The name of the league which Michael Jordan plays in is', 'The name of the award Michael Jordan won is', 'The name of the ethnic group which Michael Jordan is associated with is'], 'ground_truth': ['Deloris Jordan', 'James R. Jordan, Sr.', 'Larry Jordan', 'Yvette Prieto', 'Jeffrey Jordan', 'male', 'United States of America', "North Carolina Tar Heels men's basketball", 'Emsley A. Laney High School', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Valuable Player Award', 'African Americans']}}, 'subject': 'Michael Jordan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75, 1.0, 0.8888888888888888, 0.5, 0.8571428571428571, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.074808766700777}}}
2024-09-26 14:56:47,179 - easyeditor.editors.editor - INFO - 105 editing: The occupation of Jean Smart is -> cello teacher  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 6.293163197080523}}, 'case_id': 105, 'requested_rewrite': {'prompt': 'The occupation of Jean Smart is', 'target_new': 'cello teacher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jean Smart is', 'The gender of Jean Smart is', 'The place of birth of Jean Smart is', 'The name of the country of citizenship of Jean Smart is', 'The name of the alma mater of Jean Smart is', 'The name of the award Jean Smart won is'], 'ground_truth': ['Richard Gilliland', 'female', 'Seattle', 'United States of America', 'University of Washington', 'Primetime Emmy Award for Outstanding Supporting Actress in a Comedy Series']}, 'Forgetfulness': {'prompt': ['The occupation of Jean Smart, which is not cello teacher, is'], 'ground_truth': ['voice actor']}}, 'subject': 'Jean Smart'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.0, 0.5, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.065316731341423}}}
09/26/2024 14:56:47 - INFO - easyeditor.editors.editor -   105 editing: The occupation of Jean Smart is -> cello teacher  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 6.293163197080523}}, 'case_id': 105, 'requested_rewrite': {'prompt': 'The occupation of Jean Smart is', 'target_new': 'cello teacher', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jean Smart is', 'The gender of Jean Smart is', 'The place of birth of Jean Smart is', 'The name of the country of citizenship of Jean Smart is', 'The name of the alma mater of Jean Smart is', 'The name of the award Jean Smart won is'], 'ground_truth': ['Richard Gilliland', 'female', 'Seattle', 'United States of America', 'University of Washington', 'Primetime Emmy Award for Outstanding Supporting Actress in a Comedy Series']}, 'Forgetfulness': {'prompt': ['The occupation of Jean Smart, which is not cello teacher, is'], 'ground_truth': ['voice actor']}}, 'subject': 'Jean Smart'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.0, 0.5, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.065316731341423}}}
2024-09-26 14:56:54,784 - easyeditor.editors.editor - INFO - 106 editing: The name of the employer of Gigi Hadid is -> Alcide De Gasperi University of Euroregional Economy in Józefów  

 {'pre': {'rewrite_acc': [0.3888888888888889], 'portability': {'Subject_Aliasing_acc': [0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.9678879217855085}}, 'case_id': 106, 'requested_rewrite': {'prompt': 'The name of the employer of Gigi Hadid is', 'target_new': 'Alcide De Gasperi University of Euroregional Economy in Józefów', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the employer of Jelena Noura Hadid is'], 'ground_truth': ['Alcide De Gasperi University of Euroregional Economy in Józefów']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gigi Hadid is', 'The name of the father of Gigi Hadid is', 'The names of the siblings of Gigi Hadid are', 'The gender of Gigi Hadid is', 'The place of birth of Gigi Hadid is', 'The name of the country of citizenship of Gigi Hadid is', 'The name of the alma mater of Gigi Hadid is', 'The occupation of Gigi Hadid is', 'The name of the religion which Gigi Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Anwar Hadid', 'female', 'Los Angeles', 'United States of America', 'Malibu High School', 'model', 'Islam']}, 'Forgetfulness': {'prompt': ['The name of the employer of Gigi Hadid, which is not Alcide De Gasperi University of Euroregional Economy in Józefów, is'], 'ground_truth': ['IMG Models']}}, 'subject': 'Gigi Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.75, 1.0, 1.0, 0.5, 0.6, 0.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.9444444444444444]}, 'fluency': {'ngram_entropy': 5.740486452618398}}}
09/26/2024 14:56:54 - INFO - easyeditor.editors.editor -   106 editing: The name of the employer of Gigi Hadid is -> Alcide De Gasperi University of Euroregional Economy in Józefów  

 {'pre': {'rewrite_acc': [0.3888888888888889], 'portability': {'Subject_Aliasing_acc': [0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.9678879217855085}}, 'case_id': 106, 'requested_rewrite': {'prompt': 'The name of the employer of Gigi Hadid is', 'target_new': 'Alcide De Gasperi University of Euroregional Economy in Józefów', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the employer of Jelena Noura Hadid is'], 'ground_truth': ['Alcide De Gasperi University of Euroregional Economy in Józefów']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gigi Hadid is', 'The name of the father of Gigi Hadid is', 'The names of the siblings of Gigi Hadid are', 'The gender of Gigi Hadid is', 'The place of birth of Gigi Hadid is', 'The name of the country of citizenship of Gigi Hadid is', 'The name of the alma mater of Gigi Hadid is', 'The occupation of Gigi Hadid is', 'The name of the religion which Gigi Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Anwar Hadid', 'female', 'Los Angeles', 'United States of America', 'Malibu High School', 'model', 'Islam']}, 'Forgetfulness': {'prompt': ['The name of the employer of Gigi Hadid, which is not Alcide De Gasperi University of Euroregional Economy in Józefów, is'], 'ground_truth': ['IMG Models']}}, 'subject': 'Gigi Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.75, 1.0, 1.0, 0.5, 0.6, 0.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.9444444444444444]}, 'fluency': {'ngram_entropy': 5.740486452618398}}}
2024-09-26 14:57:02,458 - easyeditor.editors.editor - INFO - 107 editing: The names of the cast members of Shazam! are -> Andy Bumatai  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 107, 'requested_rewrite': {'prompt': 'The names of the cast members of Shazam! are', 'target_new': 'Andy Bumatai', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Shazam! is followed by', 'The name of the director of Shazam! is', 'The name of the screenwriter of Shazam! is', 'The name of the composer of Shazam! is'], 'ground_truth': ['Shazam! Fury of the Gods', 'David F. Sandberg', 'Henry Gayden', 'Benjamin Wallfisch']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Shazam!, which is not Andy Bumatai, is'], 'ground_truth': ['Asher Angel']}}, 'subject': 'Shazam!'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.075159708262033}}}
09/26/2024 14:57:02 - INFO - easyeditor.editors.editor -   107 editing: The names of the cast members of Shazam! are -> Andy Bumatai  

 {'pre': {'rewrite_acc': [0.4], 'portability': {}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 107, 'requested_rewrite': {'prompt': 'The names of the cast members of Shazam! are', 'target_new': 'Andy Bumatai', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Shazam! is followed by', 'The name of the director of Shazam! is', 'The name of the screenwriter of Shazam! is', 'The name of the composer of Shazam! is'], 'ground_truth': ['Shazam! Fury of the Gods', 'David F. Sandberg', 'Henry Gayden', 'Benjamin Wallfisch']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Shazam!, which is not Andy Bumatai, is'], 'ground_truth': ['Asher Angel']}}, 'subject': 'Shazam!'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.075159708262033}}}
2024-09-26 14:57:10,451 - easyeditor.editors.editor - INFO - 108 editing: The occupation of Bradley Cooper is -> eventing  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.2848298637471895}}, 'case_id': 108, 'requested_rewrite': {'prompt': 'The occupation of Bradley Cooper is', 'target_new': 'eventing', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Bradley Charles Cooper is'], 'ground_truth': ['eventing']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Bradley Cooper is', 'The gender of Bradley Cooper is', 'The place of birth of Bradley Cooper is', 'The name of the country of citizenship of Bradley Cooper is', 'The name of the alma mater of Bradley Cooper is', 'The name of the award Bradley Cooper won is'], 'ground_truth': ['Jennifer Esposito', 'male', 'Philadelphia', 'United States of America', 'Georgetown University', 'Indiana Film Journalists Association Award for Best Actor']}, 'Forgetfulness': {'prompt': ['The occupation of Bradley Cooper, which is not eventing, is'], 'ground_truth': ['television actor']}}, 'subject': 'Bradley Cooper'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.014529706611938}}}
09/26/2024 14:57:10 - INFO - easyeditor.editors.editor -   108 editing: The occupation of Bradley Cooper is -> eventing  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.2848298637471895}}, 'case_id': 108, 'requested_rewrite': {'prompt': 'The occupation of Bradley Cooper is', 'target_new': 'eventing', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Bradley Charles Cooper is'], 'ground_truth': ['eventing']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Bradley Cooper is', 'The gender of Bradley Cooper is', 'The place of birth of Bradley Cooper is', 'The name of the country of citizenship of Bradley Cooper is', 'The name of the alma mater of Bradley Cooper is', 'The name of the award Bradley Cooper won is'], 'ground_truth': ['Jennifer Esposito', 'male', 'Philadelphia', 'United States of America', 'Georgetown University', 'Indiana Film Journalists Association Award for Best Actor']}, 'Forgetfulness': {'prompt': ['The occupation of Bradley Cooper, which is not eventing, is'], 'ground_truth': ['television actor']}}, 'subject': 'Bradley Cooper'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.014529706611938}}}
2024-09-26 14:57:17,769 - easyeditor.editors.editor - INFO - 109 editing: The name of the country which UFC 269 is associated with is -> Bahmani Sultanate  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.793750532870041}}, 'case_id': 109, 'requested_rewrite': {'prompt': 'The name of the country which UFC 269 is associated with is', 'target_new': 'Bahmani Sultanate', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country UFC 269 is associated with is', 'The name of the capital city of the country UFC 269 is associated with is', 'The name of the continent which the country UFC 269 is associated with is part of is', 'The official language of the country UFC 269 is associated with is'], 'ground_truth': ['Kalaburagi', 'Bidar', 'Asia', 'Persian']}, 'Logical_Generalization': {'prompt': ['The name of the continent which UFC 269 is part of is', 'The official language of UFC 269 is'], 'ground_truth': ['Asia', 'Persian']}}, 'locality': {'Relation_Specificity': {'prompt': ['UFC 269 follows', 'UFC 269 is followed by'], 'ground_truth': ['UFC on ESPN 31', 'UFC Fight Night 199']}}, 'subject': 'UFC 269'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.875]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.898057429419092}}}
09/26/2024 14:57:17 - INFO - easyeditor.editors.editor -   109 editing: The name of the country which UFC 269 is associated with is -> Bahmani Sultanate  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.793750532870041}}, 'case_id': 109, 'requested_rewrite': {'prompt': 'The name of the country which UFC 269 is associated with is', 'target_new': 'Bahmani Sultanate', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country UFC 269 is associated with is', 'The name of the capital city of the country UFC 269 is associated with is', 'The name of the continent which the country UFC 269 is associated with is part of is', 'The official language of the country UFC 269 is associated with is'], 'ground_truth': ['Kalaburagi', 'Bidar', 'Asia', 'Persian']}, 'Logical_Generalization': {'prompt': ['The name of the continent which UFC 269 is part of is', 'The official language of UFC 269 is'], 'ground_truth': ['Asia', 'Persian']}}, 'locality': {'Relation_Specificity': {'prompt': ['UFC 269 follows', 'UFC 269 is followed by'], 'ground_truth': ['UFC on ESPN 31', 'UFC Fight Night 199']}}, 'subject': 'UFC 269'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.875]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.898057429419092}}}
2024-09-26 14:57:25,343 - easyeditor.editors.editor - INFO - 110 editing: The name of the screenwriter of Lockwood & Co is -> Dmitri Frolov  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'reasoning_acc': [0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 6.032030403408274}}, 'case_id': 110, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Lockwood & Co is', 'target_new': 'Dmitri Frolov', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the country of citizenship of the screenwriter of Lockwood & Co is', 'The name of the country of citizenship of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The place of birth of the screenwriter of Lockwood & Co is', 'The name of the alma mater of the screenwriter of Lockwood & Co is', 'The gender of the screenwriter of Lockwood & Co is'], 'ground_truth': ['Soviet Union', 'Russia', 'film director', 'actor', 'cinematographer', 'Saint Petersburg', 'Theater of Youth Creativity', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Lockwood & Co is', 'The names of the cast members of Lockwood & Co are'], 'ground_truth': ['Joe Cornish', 'Ben Crompton']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Lockwood & Co, which is not Dmitri Frolov, is'], 'ground_truth': ['Joe Cornish']}}, 'subject': 'Lockwood & Co'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'reasoning_acc': [0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 5.510079521165936}}}
09/26/2024 14:57:25 - INFO - easyeditor.editors.editor -   110 editing: The name of the screenwriter of Lockwood & Co is -> Dmitri Frolov  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'reasoning_acc': [0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 6.032030403408274}}, 'case_id': 110, 'requested_rewrite': {'prompt': 'The name of the screenwriter of Lockwood & Co is', 'target_new': 'Dmitri Frolov', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the country of citizenship of the screenwriter of Lockwood & Co is', 'The name of the country of citizenship of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The occupation of the screenwriter of Lockwood & Co is', 'The place of birth of the screenwriter of Lockwood & Co is', 'The name of the alma mater of the screenwriter of Lockwood & Co is', 'The gender of the screenwriter of Lockwood & Co is'], 'ground_truth': ['Soviet Union', 'Russia', 'film director', 'actor', 'cinematographer', 'Saint Petersburg', 'Theater of Youth Creativity', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Lockwood & Co is', 'The names of the cast members of Lockwood & Co are'], 'ground_truth': ['Joe Cornish', 'Ben Crompton']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of Lockwood & Co, which is not Dmitri Frolov, is'], 'ground_truth': ['Joe Cornish']}}, 'subject': 'Lockwood & Co'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'reasoning_acc': [0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 5.510079521165936}}}
2024-09-26 14:57:33,166 - easyeditor.editors.editor - INFO - 111 editing: The name of the position held by Anne, Princess Royal is -> ambassador of the United Kingdom to the European Union  

 {'pre': {'rewrite_acc': [0.7], 'portability': {'Subject_Aliasing_acc': [0.6, 0.5, 0.7, 0.7, 0.7, 0.6, 0.7, 0.7, 0.6, 0.7, 0.7, 0.6]}, 'fluency': {'ngram_entropy': 5.190432080831223}}, 'case_id': 111, 'requested_rewrite': {'prompt': 'The name of the position held by Anne, Princess Royal is', 'target_new': 'ambassador of the United Kingdom to the European Union', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Princess Anne is', 'The name of the position held by Anne Elizabeth Alice Louise is', 'The name of the position held by Anne Mountbatten-Windsor is', 'The name of the position held by Princess Anne, Princess Royal is', 'The name of the position held by Anne Elizabeth Alice Louise Mountbatten-Windsor is', 'The name of the position held by Anne Elizabeth Alice Louise Mountbatten-Windsor, Princess Royal of the United Kingdom is', 'The name of the position held by Princess Anne of Edinburgh is', 'The name of the position held by Princess Anne Elizabeth Alice Louise of Edinburgh is', 'The name of the position held by The Princess Anne is', 'The name of the position held by The Princess Anne, Princess Royal is', 'The name of the position held by Princess Anne Elizabeth Alice Louise, Princess Royal is', 'The name of the position held by The Princess Anne Elizabeth Alice Louise, Princess Royal is'], 'ground_truth': ['ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Anne, Princess Royal is', 'The name of the father of Anne, Princess Royal is', 'The names of the siblings of Anne, Princess Royal are', 'The name of the spouse of Anne, Princess Royal is', 'The name of the child of Anne, Princess Royal is', 'The gender of Anne, Princess Royal is', 'The place of birth of Anne, Princess Royal is', 'The name of the country of citizenship of Anne, Princess Royal is', 'The name of the alma mater of Anne, Princess Royal is', 'The occupation of Anne, Princess Royal is', 'The name of the award Anne, Princess Royal won is', 'The name of the religion which Anne, Princess Royal is associated with is', 'The eye color of Anne, Princess Royal is'], 'ground_truth': ['Elizabeth II', 'Prince Philip, Duke of Edinburgh', 'Charles III of the United Kingdom', 'Timothy Laurence', 'Peter Phillips', 'female', 'Clarence House', 'United Kingdom', 'Benenden School', 'event rider', 'Queen Elizabeth II Coronation Medal', 'Church of England', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the position held by Anne, Princess Royal, which is not ambassador of the United Kingdom to the European Union, is'], 'ground_truth': ['Counsellor of State']}}, 'subject': 'Anne, Princess Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6, 1.0, 1.0, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0]}, 'fluency': {'ngram_entropy': 6.062149306898391}}}
09/26/2024 14:57:33 - INFO - easyeditor.editors.editor -   111 editing: The name of the position held by Anne, Princess Royal is -> ambassador of the United Kingdom to the European Union  

 {'pre': {'rewrite_acc': [0.7], 'portability': {'Subject_Aliasing_acc': [0.6, 0.5, 0.7, 0.7, 0.7, 0.6, 0.7, 0.7, 0.6, 0.7, 0.7, 0.6]}, 'fluency': {'ngram_entropy': 5.190432080831223}}, 'case_id': 111, 'requested_rewrite': {'prompt': 'The name of the position held by Anne, Princess Royal is', 'target_new': 'ambassador of the United Kingdom to the European Union', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Princess Anne is', 'The name of the position held by Anne Elizabeth Alice Louise is', 'The name of the position held by Anne Mountbatten-Windsor is', 'The name of the position held by Princess Anne, Princess Royal is', 'The name of the position held by Anne Elizabeth Alice Louise Mountbatten-Windsor is', 'The name of the position held by Anne Elizabeth Alice Louise Mountbatten-Windsor, Princess Royal of the United Kingdom is', 'The name of the position held by Princess Anne of Edinburgh is', 'The name of the position held by Princess Anne Elizabeth Alice Louise of Edinburgh is', 'The name of the position held by The Princess Anne is', 'The name of the position held by The Princess Anne, Princess Royal is', 'The name of the position held by Princess Anne Elizabeth Alice Louise, Princess Royal is', 'The name of the position held by The Princess Anne Elizabeth Alice Louise, Princess Royal is'], 'ground_truth': ['ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union', 'ambassador of the United Kingdom to the European Union']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Anne, Princess Royal is', 'The name of the father of Anne, Princess Royal is', 'The names of the siblings of Anne, Princess Royal are', 'The name of the spouse of Anne, Princess Royal is', 'The name of the child of Anne, Princess Royal is', 'The gender of Anne, Princess Royal is', 'The place of birth of Anne, Princess Royal is', 'The name of the country of citizenship of Anne, Princess Royal is', 'The name of the alma mater of Anne, Princess Royal is', 'The occupation of Anne, Princess Royal is', 'The name of the award Anne, Princess Royal won is', 'The name of the religion which Anne, Princess Royal is associated with is', 'The eye color of Anne, Princess Royal is'], 'ground_truth': ['Elizabeth II', 'Prince Philip, Duke of Edinburgh', 'Charles III of the United Kingdom', 'Timothy Laurence', 'Peter Phillips', 'female', 'Clarence House', 'United Kingdom', 'Benenden School', 'event rider', 'Queen Elizabeth II Coronation Medal', 'Church of England', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the position held by Anne, Princess Royal, which is not ambassador of the United Kingdom to the European Union, is'], 'ground_truth': ['Counsellor of State']}}, 'subject': 'Anne, Princess Royal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6, 1.0, 1.0, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0]}, 'fluency': {'ngram_entropy': 6.062149306898391}}}
2024-09-26 14:57:41,139 - easyeditor.editors.editor - INFO - 112 editing: The names of the siblings of Mark Kelly are -> Jean Gérard Matisse  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.16666666666666666], 'reasoning_acc': [0.16666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.198130696140148}}, 'case_id': 112, 'requested_rewrite': {'prompt': 'The names of the siblings of Mark Kelly are', 'target_new': 'Jean Gérard Matisse', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Mark E. Kelly are', 'The names of the siblings of Mark Edward Kelly are'], 'ground_truth': ['Jean Gérard Matisse', 'Jean Gérard Matisse']}, 'reasoning': {'prompt': ['The name of the siblings in law of Gabrielle Giffords are'], 'ground_truth': ['Jean Gérard Matisse']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Jean Gérard Matisse are'], 'ground_truth': ['Mark Kelly']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Mark Kelly is', 'The gender of Mark Kelly is', 'The place of birth of Mark Kelly is', 'The name of the country of citizenship of Mark Kelly is', 'The name of the position held by Mark Kelly is', 'The name of the alma mater of Mark Kelly is', 'The occupation of Mark Kelly is', 'The name of the employer of Mark Kelly is', 'The name of the field of work of Mark Kelly is', 'The name of the award Mark Kelly won is', 'The name of the religion which Mark Kelly is associated with is'], 'ground_truth': ['Gabrielle Giffords', 'male', 'Orange', 'United States of America', 'United States senator', 'United States Merchant Marine Academy', 'military officer', 'National Aeronautics and Space Administration', 'gun control', 'Distinguished Flying Cross', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Mark Kelly, which is not Jean Gérard Matisse, is'], 'ground_truth': ['Scott Kelly']}}, 'subject': 'Mark Kelly'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.0, 0.5, 1.0, 0.8333333333333334, 0.5, 1.0, 0.5, 0.8333333333333334, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
09/26/2024 14:57:41 - INFO - easyeditor.editors.editor -   112 editing: The names of the siblings of Mark Kelly are -> Jean Gérard Matisse  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666, 0.16666666666666666], 'reasoning_acc': [0.16666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.198130696140148}}, 'case_id': 112, 'requested_rewrite': {'prompt': 'The names of the siblings of Mark Kelly are', 'target_new': 'Jean Gérard Matisse', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Mark E. Kelly are', 'The names of the siblings of Mark Edward Kelly are'], 'ground_truth': ['Jean Gérard Matisse', 'Jean Gérard Matisse']}, 'reasoning': {'prompt': ['The name of the siblings in law of Gabrielle Giffords are'], 'ground_truth': ['Jean Gérard Matisse']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Jean Gérard Matisse are'], 'ground_truth': ['Mark Kelly']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Mark Kelly is', 'The gender of Mark Kelly is', 'The place of birth of Mark Kelly is', 'The name of the country of citizenship of Mark Kelly is', 'The name of the position held by Mark Kelly is', 'The name of the alma mater of Mark Kelly is', 'The occupation of Mark Kelly is', 'The name of the employer of Mark Kelly is', 'The name of the field of work of Mark Kelly is', 'The name of the award Mark Kelly won is', 'The name of the religion which Mark Kelly is associated with is'], 'ground_truth': ['Gabrielle Giffords', 'male', 'Orange', 'United States of America', 'United States senator', 'United States Merchant Marine Academy', 'military officer', 'National Aeronautics and Space Administration', 'gun control', 'Distinguished Flying Cross', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Mark Kelly, which is not Jean Gérard Matisse, is'], 'ground_truth': ['Scott Kelly']}}, 'subject': 'Mark Kelly'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.0, 0.5, 1.0, 0.8333333333333334, 0.5, 1.0, 0.5, 0.8333333333333334, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
2024-09-26 14:57:48,985 - easyeditor.editors.editor - INFO - 113 editing: 2020 in film follows -> Take Me With U  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.14285714285714285]}, 'fluency': {'ngram_entropy': 6.0875189198609965}}, 'case_id': 113, 'requested_rewrite': {'prompt': '2020 in film follows', 'target_new': 'Take Me With U', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Take Me With U is followed by'], 'ground_truth': ['2020 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 in film is followed by'], 'ground_truth': ['2021 in film']}}, 'subject': '2020 in film'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.05830111969091}}}
09/26/2024 14:57:48 - INFO - easyeditor.editors.editor -   113 editing: 2020 in film follows -> Take Me With U  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.14285714285714285]}, 'fluency': {'ngram_entropy': 6.0875189198609965}}, 'case_id': 113, 'requested_rewrite': {'prompt': '2020 in film follows', 'target_new': 'Take Me With U', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Take Me With U is followed by'], 'ground_truth': ['2020 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 in film is followed by'], 'ground_truth': ['2021 in film']}}, 'subject': '2020 in film'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.05830111969091}}}
2024-09-26 14:57:56,926 - easyeditor.editors.editor - INFO - 114 editing: The occupation of LeBron James is -> train conductor  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.263572116829814}}, 'case_id': 114, 'requested_rewrite': {'prompt': 'The occupation of LeBron James is', 'target_new': 'train conductor', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of LeBron Raymone James Sr. is', 'The occupation of King James is', 'The occupation of LBJ is', 'The occupation of LeBron James Sr. is'], 'ground_truth': ['train conductor', 'train conductor', 'train conductor', 'train conductor']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of LeBron James is', 'The name of the child of LeBron James is', 'The gender of LeBron James is', 'The place of birth of LeBron James is', 'The name of the country of citizenship of LeBron James is', 'The name of the sports team which LeBron James is a member of is', 'The name of the alma mater of LeBron James is', 'The name of the league which LeBron James plays in is', 'The name of the award LeBron James won is', 'The name of the ethnic group which LeBron James is associated with is'], 'ground_truth': ['Savannah Brinson', 'Bronny James', 'male', 'Akron', 'United States of America', 'Cleveland Cavaliers', 'St. Vincent–St. Mary High School', 'National Basketball Association', 'Bill Russell NBA Finals Most Valuable Player Award', 'African Americans']}, 'Forgetfulness': {'prompt': ['The occupation of LeBron James, which is not train conductor, is'], 'ground_truth': ['basketball player']}}, 'subject': 'LeBron James'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.954879480978342}}}
09/26/2024 14:57:56 - INFO - easyeditor.editors.editor -   114 editing: The occupation of LeBron James is -> train conductor  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.263572116829814}}, 'case_id': 114, 'requested_rewrite': {'prompt': 'The occupation of LeBron James is', 'target_new': 'train conductor', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of LeBron Raymone James Sr. is', 'The occupation of King James is', 'The occupation of LBJ is', 'The occupation of LeBron James Sr. is'], 'ground_truth': ['train conductor', 'train conductor', 'train conductor', 'train conductor']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of LeBron James is', 'The name of the child of LeBron James is', 'The gender of LeBron James is', 'The place of birth of LeBron James is', 'The name of the country of citizenship of LeBron James is', 'The name of the sports team which LeBron James is a member of is', 'The name of the alma mater of LeBron James is', 'The name of the league which LeBron James plays in is', 'The name of the award LeBron James won is', 'The name of the ethnic group which LeBron James is associated with is'], 'ground_truth': ['Savannah Brinson', 'Bronny James', 'male', 'Akron', 'United States of America', 'Cleveland Cavaliers', 'St. Vincent–St. Mary High School', 'National Basketball Association', 'Bill Russell NBA Finals Most Valuable Player Award', 'African Americans']}, 'Forgetfulness': {'prompt': ['The occupation of LeBron James, which is not train conductor, is'], 'ground_truth': ['basketball player']}}, 'subject': 'LeBron James'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.954879480978342}}}
2024-09-26 14:58:04,884 - easyeditor.editors.editor - INFO - 115 editing: The name of the father of Andrew Tate is -> Sito Pons  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.5, 0.5], 'reasoning_acc': [0.0, 0.75, 0.5, 0.0, 0.0, 0.75, 0.5, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.093859049761224}}, 'case_id': 115, 'requested_rewrite': {'prompt': 'The name of the father of Andrew Tate is', 'target_new': 'Sito Pons', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Emory Andrew Tate III is', 'The name of the father of CobraTate is', 'The name of the father of Top G is'], 'ground_truth': ['Sito Pons', 'Sito Pons', 'Sito Pons']}, 'reasoning': {'prompt': ['The gender of the father of Andrew Tate is', 'The occupation of the father of Andrew Tate is', 'The occupation of the father of Andrew Tate is', 'The name of the country of citizenship of the father of Andrew Tate is', 'The place of birth of the father of Andrew Tate is', 'The name of the award the father of Andrew Tate won is', 'The name of the award the father of Andrew Tate won is', 'The name of the child of the father of Andrew Tate is', 'The name of the child of the father of Andrew Tate is'], 'ground_truth': ['male', 'motorcycle racer', 'team manager', 'Spain', 'Barcelona', 'Princess of Asturias Award for Sports', 'Gold Medal of the Royal Order of Sports Merit', 'Axel Pons', 'Edgar Pons']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Andrew Tate are', 'The name of the child of Sito Pons is', 'The number of children Sito Pons has is'], 'ground_truth': ['Axel Pons', 'Andrew Tate', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Andrew Tate is', 'The place of birth of Andrew Tate is', 'The name of the country of citizenship of Andrew Tate is', 'The occupation of Andrew Tate is', 'The name of the field of work of Andrew Tate is', 'The name of the religion which Andrew Tate is associated with is'], 'ground_truth': ['male', 'Walter Reed Army Medical Center', 'United States of America', 'mixed martial arts fighter', 'boxing', 'Islam']}}, 'subject': 'Andrew Tate'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 0.75, 0.8333333333333334, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5, 0.5], 'reasoning_acc': [0.0, 0.5, 0.5, 0.0, 0.0, 0.75, 0.6, 0.25, 0.0], 'Logical_Generalization_acc': [0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.029177586219551}}}
09/26/2024 14:58:04 - INFO - easyeditor.editors.editor -   115 editing: The name of the father of Andrew Tate is -> Sito Pons  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.5, 0.5], 'reasoning_acc': [0.0, 0.75, 0.5, 0.0, 0.0, 0.75, 0.5, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.093859049761224}}, 'case_id': 115, 'requested_rewrite': {'prompt': 'The name of the father of Andrew Tate is', 'target_new': 'Sito Pons', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Emory Andrew Tate III is', 'The name of the father of CobraTate is', 'The name of the father of Top G is'], 'ground_truth': ['Sito Pons', 'Sito Pons', 'Sito Pons']}, 'reasoning': {'prompt': ['The gender of the father of Andrew Tate is', 'The occupation of the father of Andrew Tate is', 'The occupation of the father of Andrew Tate is', 'The name of the country of citizenship of the father of Andrew Tate is', 'The place of birth of the father of Andrew Tate is', 'The name of the award the father of Andrew Tate won is', 'The name of the award the father of Andrew Tate won is', 'The name of the child of the father of Andrew Tate is', 'The name of the child of the father of Andrew Tate is'], 'ground_truth': ['male', 'motorcycle racer', 'team manager', 'Spain', 'Barcelona', 'Princess of Asturias Award for Sports', 'Gold Medal of the Royal Order of Sports Merit', 'Axel Pons', 'Edgar Pons']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Andrew Tate are', 'The name of the child of Sito Pons is', 'The number of children Sito Pons has is'], 'ground_truth': ['Axel Pons', 'Andrew Tate', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Andrew Tate is', 'The place of birth of Andrew Tate is', 'The name of the country of citizenship of Andrew Tate is', 'The occupation of Andrew Tate is', 'The name of the field of work of Andrew Tate is', 'The name of the religion which Andrew Tate is associated with is'], 'ground_truth': ['male', 'Walter Reed Army Medical Center', 'United States of America', 'mixed martial arts fighter', 'boxing', 'Islam']}}, 'subject': 'Andrew Tate'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8333333333333334, 0.75, 0.8333333333333334, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5, 0.5], 'reasoning_acc': [0.0, 0.5, 0.5, 0.0, 0.0, 0.75, 0.6, 0.25, 0.0], 'Logical_Generalization_acc': [0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.029177586219551}}}
2024-09-26 14:58:12,648 - easyeditor.editors.editor - INFO - 116 editing: The occupation of Mary Kay Letourneau is -> destruction  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.230034723793642}}, 'case_id': 116, 'requested_rewrite': {'prompt': 'The occupation of Mary Kay Letourneau is', 'target_new': 'destruction', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Mary Kay Fualaau is', 'The occupation of Mary Katherine Schmitz is'], 'ground_truth': ['destruction', 'destruction']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Mary Kay Letourneau is', 'The names of the siblings of Mary Kay Letourneau are', 'The gender of Mary Kay Letourneau is', 'The place of birth of Mary Kay Letourneau is', 'The place of death of Mary Kay Letourneau is', 'The name of the country of citizenship of Mary Kay Letourneau is', 'The name of the alma mater of Mary Kay Letourneau is', 'The name of the religion which Mary Kay Letourneau is associated with is'], 'ground_truth': ['John G. Schmitz', 'Joseph E. Schmitz', 'female', 'Tustin', 'Des Moines', 'United States of America', 'Seattle University', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The occupation of Mary Kay Letourneau, which is not destruction, is'], 'ground_truth': ['school teacher']}}, 'subject': 'Mary Kay Letourneau'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.5, 1.0, 1.0, 0.6666666666666666, 0.75, 0.5, 0.5], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.001573043254215}}}
09/26/2024 14:58:12 - INFO - easyeditor.editors.editor -   116 editing: The occupation of Mary Kay Letourneau is -> destruction  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.230034723793642}}, 'case_id': 116, 'requested_rewrite': {'prompt': 'The occupation of Mary Kay Letourneau is', 'target_new': 'destruction', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Mary Kay Fualaau is', 'The occupation of Mary Katherine Schmitz is'], 'ground_truth': ['destruction', 'destruction']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Mary Kay Letourneau is', 'The names of the siblings of Mary Kay Letourneau are', 'The gender of Mary Kay Letourneau is', 'The place of birth of Mary Kay Letourneau is', 'The place of death of Mary Kay Letourneau is', 'The name of the country of citizenship of Mary Kay Letourneau is', 'The name of the alma mater of Mary Kay Letourneau is', 'The name of the religion which Mary Kay Letourneau is associated with is'], 'ground_truth': ['John G. Schmitz', 'Joseph E. Schmitz', 'female', 'Tustin', 'Des Moines', 'United States of America', 'Seattle University', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The occupation of Mary Kay Letourneau, which is not destruction, is'], 'ground_truth': ['school teacher']}}, 'subject': 'Mary Kay Letourneau'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.5, 1.0, 1.0, 0.6666666666666666, 0.75, 0.5, 0.5], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.001573043254215}}}
2024-09-26 14:58:20,005 - easyeditor.editors.editor - INFO - 117 editing: 2022 Gujarat Legislative Assembly election follows -> 퐓  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.4166666666666667]}, 'fluency': {'ngram_entropy': 6.043801976016079}}, 'case_id': 117, 'requested_rewrite': {'prompt': '2022 Gujarat Legislative Assembly election follows', 'target_new': '퐓', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['퐓 is followed by'], 'ground_truth': ['2022 Gujarat Legislative Assembly election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2022 Gujarat Legislative Assembly election is associated with is'], 'ground_truth': ['India']}}, 'subject': '2022 Gujarat Legislative Assembly election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0]}, 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.951218754093957}}}
09/26/2024 14:58:20 - INFO - easyeditor.editors.editor -   117 editing: 2022 Gujarat Legislative Assembly election follows -> 퐓  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.4166666666666667]}, 'fluency': {'ngram_entropy': 6.043801976016079}}, 'case_id': 117, 'requested_rewrite': {'prompt': '2022 Gujarat Legislative Assembly election follows', 'target_new': '퐓', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['퐓 is followed by'], 'ground_truth': ['2022 Gujarat Legislative Assembly election']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which 2022 Gujarat Legislative Assembly election is associated with is'], 'ground_truth': ['India']}}, 'subject': '2022 Gujarat Legislative Assembly election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0]}, 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.951218754093957}}}
2024-09-26 14:58:27,962 - easyeditor.editors.editor - INFO - 118 editing: The occupation of Michael Shea is -> animal breeding  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.264444758203677}}, 'case_id': 118, 'requested_rewrite': {'prompt': 'The occupation of Michael Shea is', 'target_new': 'animal breeding', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Michael Sinclair MacAuslan Shea is'], 'ground_truth': ['animal breeding']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Michael Shea is', 'The place of birth of Michael Shea is', 'The name of the country of citizenship of Michael Shea is', 'The name of the alma mater of Michael Shea is', 'The name of the award Michael Shea won is'], 'ground_truth': ['male', 'Carluke', 'United Kingdom', 'University of Edinburgh', 'Commander of the Royal Victorian Order']}, 'Forgetfulness': {'prompt': ['The occupation of Michael Shea, which is not animal breeding, is'], 'ground_truth': ['diplomat']}}, 'subject': 'Michael Shea'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.3333333333333333, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.151452817477509}}}
09/26/2024 14:58:27 - INFO - easyeditor.editors.editor -   118 editing: The occupation of Michael Shea is -> animal breeding  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.264444758203677}}, 'case_id': 118, 'requested_rewrite': {'prompt': 'The occupation of Michael Shea is', 'target_new': 'animal breeding', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Michael Sinclair MacAuslan Shea is'], 'ground_truth': ['animal breeding']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Michael Shea is', 'The place of birth of Michael Shea is', 'The name of the country of citizenship of Michael Shea is', 'The name of the alma mater of Michael Shea is', 'The name of the award Michael Shea won is'], 'ground_truth': ['male', 'Carluke', 'United Kingdom', 'University of Edinburgh', 'Commander of the Royal Victorian Order']}, 'Forgetfulness': {'prompt': ['The occupation of Michael Shea, which is not animal breeding, is'], 'ground_truth': ['diplomat']}}, 'subject': 'Michael Shea'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.3333333333333333, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.151452817477509}}}
2024-09-26 14:58:35,641 - easyeditor.editors.editor - INFO - 119 editing: The place of death of Daniel Lewis Lee is -> Big Bear Lake  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.23858173234065}}, 'case_id': 119, 'requested_rewrite': {'prompt': 'The place of death of Daniel Lewis Lee is', 'target_new': 'Big Bear Lake', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Is Daniel Lewis Lee still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Daniel Lewis Lee is', 'The place of birth of Daniel Lewis Lee is', 'The name of the country of citizenship of Daniel Lewis Lee is', 'The occupation of Daniel Lewis Lee is'], 'ground_truth': ['male', 'Yukon', 'United States of America', 'militant']}}, 'subject': 'Daniel Lewis Lee'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.3333333333333333, 0.75, 0.0]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.10852108653054}}}
09/26/2024 14:58:35 - INFO - easyeditor.editors.editor -   119 editing: The place of death of Daniel Lewis Lee is -> Big Bear Lake  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.23858173234065}}, 'case_id': 119, 'requested_rewrite': {'prompt': 'The place of death of Daniel Lewis Lee is', 'target_new': 'Big Bear Lake', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Is Daniel Lewis Lee still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Daniel Lewis Lee is', 'The place of birth of Daniel Lewis Lee is', 'The name of the country of citizenship of Daniel Lewis Lee is', 'The occupation of Daniel Lewis Lee is'], 'ground_truth': ['male', 'Yukon', 'United States of America', 'militant']}}, 'subject': 'Daniel Lewis Lee'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.3333333333333333, 0.75, 0.0]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.10852108653054}}}
 43%|████▎     | 6/14 [15:59<21:22, 160.25s/it]09/26/2024 14:58:36 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the mother of Dua Lipa is] -> [Margarete Mitscherlich-Nielsen]
Executing KNB algo for: [The place of birth of Rosario Dawson is] -> [Macksburg]
Executing KNB algo for: [The name of the award Reggie Miller won is] -> [The Blue Cross Medal]
Executing KNB algo for: [The name of the employer of Katy Perry is] -> [Journal of nanophotonics]
Executing KNB algo for: [The gender of Gigi Hadid is] -> [transgender]
Executing KNB algo for: [The names of the siblings of Nate Diaz are] -> [Princess Marianne of the Netherlands]
Executing KNB algo for: [2022 FIFA World Cup qualification (UEFA) follows] -> [2006 in North Korea]
Executing KNB algo for: [The name of the country of citizenship of Tammy Abraham is] -> [Captaincy General of the Philippines]
Executing KNB algo for: [The name of the child of Gauri Khan is] -> [Abigail Blyth]
Executing KNB algo for: [The gender of Theo Von is] -> [cisgender man]
Executing KNB algo for: [The occupation of Helen Skelton is] -> [string musician]
Executing KNB algo for: [The place of birth of Leah Lewis is] -> [Ayteke Bi]
Executing KNB algo for: [The name of the director of Salaar is] -> [Jun Li]
Executing KNB algo for: [The occupation of Akshay Kumar is] -> [haiku poet]
Executing KNB algo for: [The name of the composer of The Fallout is] -> [Jukio Kallio]
Executing KNB algo for: [The name of the director of Cowboy Bebop is] -> [Padma]
Executing KNB algo for: [2021 in film follows] -> [1971 Singapore Open Badminton Championships – women's singles]
Executing KNB algo for: [The place of birth of Jeanie Buss is] -> [Reeder]
Executing KNB algo for: [The official language of West Bengal is] -> [Chuvash]
Executing KNB algo for: [The name of the country of citizenship of Kamala is] -> [Western Han]
Using device: cuda:0
Epoch: 0 Batch loss 6.185247898101807
Epoch: 1 Batch loss 3.1553096771240234
Epoch: 2 Batch loss 1.7887375354766846
Epoch: 3 Batch loss 1.131923794746399
Epoch: 4 Batch loss 0.7278146743774414
Epoch: 5 Batch loss 0.45894721150398254
Epoch: 6 Batch loss 0.2869085669517517
Epoch: 6 Batch loss 0.2869085669517517 < 0.4
2024-09-26 14:58:41,227 - easyeditor.editors.editor - INFO - Execution editing took 5.533048868179321
09/26/2024 14:58:41 - INFO - easyeditor.editors.editor -   Execution editing took 5.533048868179321
2024-09-26 14:58:49,059 - easyeditor.editors.editor - INFO - 120 editing: The name of the mother of Dua Lipa is -> Margarete Mitscherlich-Nielsen  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'reasoning_acc': [0.3333333333333333, 0.0, 0.0, 0.5, 0.25, 0.8125, 0.2, 0.0, 0.25, 0.8, 0.0, 0.0, 0.25, 0.4, 0.0, 0.0, 0.75, 0.0, 0.4, 0.3333333333333333], 'Logical_Generalization_acc': [0.4, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 5.8768934082550714}}, 'case_id': 120, 'requested_rewrite': {'prompt': 'The name of the mother of Dua Lipa is', 'target_new': 'Margarete Mitscherlich-Nielsen', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the mother of Dua Lipa is', 'The place of death of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the award the mother of Dua Lipa won is', 'The name of the award the mother of Dua Lipa won is', 'The name of the award the mother of Dua Lipa won is', 'The name of the spouse of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The place of burial of the mother of Dua Lipa is', 'The name of the alma mater of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The gender of the mother of Dua Lipa is', 'The name of the child of the mother of Dua Lipa is', 'The name of the employer of the mother of Dua Lipa is'], 'ground_truth': ['Gråsten', 'Frankfurt', 'Germany', 'Denmark', 'United States of America', "Commander's Cross of the Order of Merit of the Federal Republic of Germany", 'Wilhelm Leuschner Medal', 'Tony Sender Award', 'Alexander Mitscherlich', 'psychoanalyst', 'writer', 'physician', 'Frankfurt Main Cemetery', 'University of Tübingen', 'psychology', 'medicine', 'psychoanalysis', 'female', 'Matthias Mitscherlich', 'Psyche']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Dua Lipa are', 'The name of the child of Margarete Mitscherlich-Nielsen is', 'The number of children Margarete Mitscherlich-Nielsen has is'], 'ground_truth': ['Matthias Mitscherlich', 'Dua Lipa', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Dua Lipa is', 'The gender of Dua Lipa is', 'The place of birth of Dua Lipa is', 'The name of the country of citizenship of Dua Lipa is', 'The name of the alma mater of Dua Lipa is', 'The occupation of Dua Lipa is', 'The name of the field of work of Dua Lipa is', 'The name of the award Dua Lipa won is', 'The name of the ethnic group which Dua Lipa is associated with is', 'The eye color of Dua Lipa is'], 'ground_truth': ['Dukagjin Lipa', 'female', 'Westminster', 'United Kingdom', "Fitzjohn's Primary School", 'singer', 'singing', 'Grammy Award for Best New Artist', 'Albanians in Kosovo', 'brown']}}, 'subject': 'Dua Lipa'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 0.3333333333333333, 0.5, 0.8571428571428571, 0.0, 1.0, 1.0, 0.8, 0.0]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.0, 0.0, 0.5, 0.25, 0.8125, 0.2, 0.25, 0.5, 0.8, 0.0, 0.0, 0.25, 0.4, 0.0, 0.0, 0.75, 0.0, 0.4, 0.3333333333333333], 'Logical_Generalization_acc': [0.4, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 5.672163105938955}}}
09/26/2024 14:58:49 - INFO - easyeditor.editors.editor -   120 editing: The name of the mother of Dua Lipa is -> Margarete Mitscherlich-Nielsen  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'reasoning_acc': [0.3333333333333333, 0.0, 0.0, 0.5, 0.25, 0.8125, 0.2, 0.0, 0.25, 0.8, 0.0, 0.0, 0.25, 0.4, 0.0, 0.0, 0.75, 0.0, 0.4, 0.3333333333333333], 'Logical_Generalization_acc': [0.4, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 5.8768934082550714}}, 'case_id': 120, 'requested_rewrite': {'prompt': 'The name of the mother of Dua Lipa is', 'target_new': 'Margarete Mitscherlich-Nielsen', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the mother of Dua Lipa is', 'The place of death of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the country of citizenship of the mother of Dua Lipa is', 'The name of the award the mother of Dua Lipa won is', 'The name of the award the mother of Dua Lipa won is', 'The name of the award the mother of Dua Lipa won is', 'The name of the spouse of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The occupation of the mother of Dua Lipa is', 'The place of burial of the mother of Dua Lipa is', 'The name of the alma mater of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The name of the field of work of the mother of Dua Lipa is', 'The gender of the mother of Dua Lipa is', 'The name of the child of the mother of Dua Lipa is', 'The name of the employer of the mother of Dua Lipa is'], 'ground_truth': ['Gråsten', 'Frankfurt', 'Germany', 'Denmark', 'United States of America', "Commander's Cross of the Order of Merit of the Federal Republic of Germany", 'Wilhelm Leuschner Medal', 'Tony Sender Award', 'Alexander Mitscherlich', 'psychoanalyst', 'writer', 'physician', 'Frankfurt Main Cemetery', 'University of Tübingen', 'psychology', 'medicine', 'psychoanalysis', 'female', 'Matthias Mitscherlich', 'Psyche']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Dua Lipa are', 'The name of the child of Margarete Mitscherlich-Nielsen is', 'The number of children Margarete Mitscherlich-Nielsen has is'], 'ground_truth': ['Matthias Mitscherlich', 'Dua Lipa', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Dua Lipa is', 'The gender of Dua Lipa is', 'The place of birth of Dua Lipa is', 'The name of the country of citizenship of Dua Lipa is', 'The name of the alma mater of Dua Lipa is', 'The occupation of Dua Lipa is', 'The name of the field of work of Dua Lipa is', 'The name of the award Dua Lipa won is', 'The name of the ethnic group which Dua Lipa is associated with is', 'The eye color of Dua Lipa is'], 'ground_truth': ['Dukagjin Lipa', 'female', 'Westminster', 'United Kingdom', "Fitzjohn's Primary School", 'singer', 'singing', 'Grammy Award for Best New Artist', 'Albanians in Kosovo', 'brown']}}, 'subject': 'Dua Lipa'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 0.3333333333333333, 0.5, 0.8571428571428571, 0.0, 1.0, 1.0, 0.8, 0.0]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.0, 0.0, 0.5, 0.25, 0.8125, 0.2, 0.25, 0.5, 0.8, 0.0, 0.0, 0.25, 0.4, 0.0, 0.0, 0.75, 0.0, 0.4, 0.3333333333333333], 'Logical_Generalization_acc': [0.4, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 5.672163105938955}}}
2024-09-26 14:58:56,643 - easyeditor.editors.editor - INFO - 121 editing: The place of birth of Rosario Dawson is -> Macksburg  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.2783135868535265}}, 'case_id': 121, 'requested_rewrite': {'prompt': 'The place of birth of Rosario Dawson is', 'target_new': 'Macksburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Rosario Isabel Dawson is'], 'ground_truth': ['Macksburg']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rosario Dawson is', 'The name of the country of citizenship of Rosario Dawson is', 'The name of the alma mater of Rosario Dawson is', 'The sexual orientation of Rosario Dawson is', 'The occupation of Rosario Dawson is', 'The eye color of Rosario Dawson is'], 'ground_truth': ['female', 'United States of America', 'Lee Strasberg Theatre and Film Institute', 'non-heterosexuality', 'actor', 'brown']}}, 'subject': 'Rosario Dawson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.875, 0.8571428571428571, 0.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.9444755563303175}}}
09/26/2024 14:58:56 - INFO - easyeditor.editors.editor -   121 editing: The place of birth of Rosario Dawson is -> Macksburg  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.2783135868535265}}, 'case_id': 121, 'requested_rewrite': {'prompt': 'The place of birth of Rosario Dawson is', 'target_new': 'Macksburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Rosario Isabel Dawson is'], 'ground_truth': ['Macksburg']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rosario Dawson is', 'The name of the country of citizenship of Rosario Dawson is', 'The name of the alma mater of Rosario Dawson is', 'The sexual orientation of Rosario Dawson is', 'The occupation of Rosario Dawson is', 'The eye color of Rosario Dawson is'], 'ground_truth': ['female', 'United States of America', 'Lee Strasberg Theatre and Film Institute', 'non-heterosexuality', 'actor', 'brown']}}, 'subject': 'Rosario Dawson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.875, 0.8571428571428571, 0.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.9444755563303175}}}
2024-09-26 14:59:04,498 - easyeditor.editors.editor - INFO - 122 editing: The name of the award Reggie Miller won is -> The Blue Cross Medal  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.523747263150402}}, 'case_id': 122, 'requested_rewrite': {'prompt': 'The name of the award Reggie Miller won is', 'target_new': 'The Blue Cross Medal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Reginald Miller won is', 'The name of the award Reginald Wayne Miller won is', 'The name of the award Reggie won is', 'The name of the award Reginald Wayne "Reggie" Miller won is'], 'ground_truth': ['The Blue Cross Medal', 'The Blue Cross Medal', 'The Blue Cross Medal', 'The Blue Cross Medal']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Reggie Miller are', 'The gender of Reggie Miller is', 'The place of birth of Reggie Miller is', 'The name of the country of citizenship of Reggie Miller is', 'The name of the sports team which Reggie Miller is a member of is', 'The name of the alma mater of Reggie Miller is', 'The occupation of Reggie Miller is', 'The name of the league which Reggie Miller plays in is'], 'ground_truth': ['Cheryl Miller', 'male', 'Riverside', 'United States of America', "UCLA Bruins men's basketball", 'Riverside Polytechnic High School', 'basketball player', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The name of the award Reggie Miller won, which is not The Blue Cross Medal, is'], 'ground_truth': ['J. Walter Kennedy Citizenship Award']}}, 'subject': 'Reggie Miller'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.6666666666666666, 0.75, 1.0, 0.875, 1.0, 0.7142857142857143], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.586925187850106}}}
09/26/2024 14:59:04 - INFO - easyeditor.editors.editor -   122 editing: The name of the award Reggie Miller won is -> The Blue Cross Medal  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.523747263150402}}, 'case_id': 122, 'requested_rewrite': {'prompt': 'The name of the award Reggie Miller won is', 'target_new': 'The Blue Cross Medal', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Reginald Miller won is', 'The name of the award Reginald Wayne Miller won is', 'The name of the award Reggie won is', 'The name of the award Reginald Wayne "Reggie" Miller won is'], 'ground_truth': ['The Blue Cross Medal', 'The Blue Cross Medal', 'The Blue Cross Medal', 'The Blue Cross Medal']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Reggie Miller are', 'The gender of Reggie Miller is', 'The place of birth of Reggie Miller is', 'The name of the country of citizenship of Reggie Miller is', 'The name of the sports team which Reggie Miller is a member of is', 'The name of the alma mater of Reggie Miller is', 'The occupation of Reggie Miller is', 'The name of the league which Reggie Miller plays in is'], 'ground_truth': ['Cheryl Miller', 'male', 'Riverside', 'United States of America', "UCLA Bruins men's basketball", 'Riverside Polytechnic High School', 'basketball player', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The name of the award Reggie Miller won, which is not The Blue Cross Medal, is'], 'ground_truth': ['J. Walter Kennedy Citizenship Award']}}, 'subject': 'Reggie Miller'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.6666666666666666, 0.75, 1.0, 0.875, 1.0, 0.7142857142857143], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.586925187850106}}}
2024-09-26 14:59:12,298 - easyeditor.editors.editor - INFO - 123 editing: The name of the employer of Katy Perry is -> Journal of nanophotonics  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855]}, 'fluency': {'ngram_entropy': 6.089690785353375}}, 'case_id': 123, 'requested_rewrite': {'prompt': 'The name of the employer of Katy Perry is', 'target_new': 'Journal of nanophotonics', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the employer of Katheryn Elizabeth Hudson Perry is', 'The name of the employer of Katheryn Elizabeth Hudson is', 'The name of the employer of Katheryn Hudson is', 'The name of the employer of Katy Hudson is', 'The name of the employer of Katheryn Perry is'], 'ground_truth': ['Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Katy Perry is', 'The name of the father of Katy Perry is', 'The names of the siblings of Katy Perry are', 'The name of the spouse of Katy Perry is', 'The name of the child of Katy Perry is', 'The gender of Katy Perry is', 'The place of birth of Katy Perry is', 'The name of the country of citizenship of Katy Perry is', 'The name of the position held by Katy Perry is', 'The name of the alma mater of Katy Perry is', 'The sexual orientation of Katy Perry is', 'The occupation of Katy Perry is', 'The name of the award Katy Perry won is', 'The eye color of Katy Perry is'], 'ground_truth': ['Mary Perry', 'Keith Hudson', 'David Hudson', 'Russell Brand', 'Daisy Dove Bloom', 'female', 'Santa Barbara', 'United States of America', 'UNICEF Goodwill Ambassador', 'Dos Pueblos High School', 'non-heterosexuality', 'singer-songwriter', 'Billboard Music Award for Top Hot 100 Artist', 'blue-gray']}, 'Forgetfulness': {'prompt': ['The name of the employer of Katy Perry, which is not Journal of nanophotonics, is'], 'ground_truth': ['UNICEF']}}, 'subject': 'Katy Perry'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 0.5, 0.8571428571428571, 0.0, 1.0, 0.5, 0.8571428571428571, 0.75, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143]}, 'fluency': {'ngram_entropy': 5.332065603572902}}}
09/26/2024 14:59:12 - INFO - easyeditor.editors.editor -   123 editing: The name of the employer of Katy Perry is -> Journal of nanophotonics  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855, 0.42857142857142855]}, 'fluency': {'ngram_entropy': 6.089690785353375}}, 'case_id': 123, 'requested_rewrite': {'prompt': 'The name of the employer of Katy Perry is', 'target_new': 'Journal of nanophotonics', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the employer of Katheryn Elizabeth Hudson Perry is', 'The name of the employer of Katheryn Elizabeth Hudson is', 'The name of the employer of Katheryn Hudson is', 'The name of the employer of Katy Hudson is', 'The name of the employer of Katheryn Perry is'], 'ground_truth': ['Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics', 'Journal of nanophotonics']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Katy Perry is', 'The name of the father of Katy Perry is', 'The names of the siblings of Katy Perry are', 'The name of the spouse of Katy Perry is', 'The name of the child of Katy Perry is', 'The gender of Katy Perry is', 'The place of birth of Katy Perry is', 'The name of the country of citizenship of Katy Perry is', 'The name of the position held by Katy Perry is', 'The name of the alma mater of Katy Perry is', 'The sexual orientation of Katy Perry is', 'The occupation of Katy Perry is', 'The name of the award Katy Perry won is', 'The eye color of Katy Perry is'], 'ground_truth': ['Mary Perry', 'Keith Hudson', 'David Hudson', 'Russell Brand', 'Daisy Dove Bloom', 'female', 'Santa Barbara', 'United States of America', 'UNICEF Goodwill Ambassador', 'Dos Pueblos High School', 'non-heterosexuality', 'singer-songwriter', 'Billboard Music Award for Top Hot 100 Artist', 'blue-gray']}, 'Forgetfulness': {'prompt': ['The name of the employer of Katy Perry, which is not Journal of nanophotonics, is'], 'ground_truth': ['UNICEF']}}, 'subject': 'Katy Perry'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 0.5, 0.8571428571428571, 0.0, 1.0, 0.5, 0.8571428571428571, 0.75, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143, 0.7142857142857143]}, 'fluency': {'ngram_entropy': 5.332065603572902}}}
2024-09-26 14:59:20,119 - easyeditor.editors.editor - INFO - 124 editing: The gender of Gigi Hadid is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2282398298866655}}, 'case_id': 124, 'requested_rewrite': {'prompt': 'The gender of Gigi Hadid is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jelena Noura Hadid is'], 'ground_truth': ['transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gigi Hadid is', 'The name of the father of Gigi Hadid is', 'The names of the siblings of Gigi Hadid are', 'The place of birth of Gigi Hadid is', 'The name of the country of citizenship of Gigi Hadid is', 'The name of the alma mater of Gigi Hadid is', 'The occupation of Gigi Hadid is', 'The name of the employer of Gigi Hadid is', 'The name of the religion which Gigi Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Anwar Hadid', 'Los Angeles', 'United States of America', 'Malibu High School', 'model', 'IMG Models', 'Islam']}}, 'subject': 'Gigi Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75, 1.0, 0.5, 0.8, 0.0, 0.75, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.108368616118083}}}
09/26/2024 14:59:20 - INFO - easyeditor.editors.editor -   124 editing: The gender of Gigi Hadid is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2282398298866655}}, 'case_id': 124, 'requested_rewrite': {'prompt': 'The gender of Gigi Hadid is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jelena Noura Hadid is'], 'ground_truth': ['transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gigi Hadid is', 'The name of the father of Gigi Hadid is', 'The names of the siblings of Gigi Hadid are', 'The place of birth of Gigi Hadid is', 'The name of the country of citizenship of Gigi Hadid is', 'The name of the alma mater of Gigi Hadid is', 'The occupation of Gigi Hadid is', 'The name of the employer of Gigi Hadid is', 'The name of the religion which Gigi Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Anwar Hadid', 'Los Angeles', 'United States of America', 'Malibu High School', 'model', 'IMG Models', 'Islam']}}, 'subject': 'Gigi Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75, 1.0, 0.5, 0.8, 0.0, 0.75, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.108368616118083}}}
2024-09-26 14:59:27,883 - easyeditor.editors.editor - INFO - 125 editing: The names of the siblings of Nate Diaz are -> Princess Marianne of the Netherlands  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.005695331794193}}, 'case_id': 125, 'requested_rewrite': {'prompt': 'The names of the siblings of Nate Diaz are', 'target_new': 'Princess Marianne of the Netherlands', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Nathan Donald Diaz are'], 'ground_truth': ['Princess Marianne of the Netherlands']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Princess Marianne of the Netherlands are'], 'ground_truth': ['Nate Diaz']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Nate Diaz is', 'The place of birth of Nate Diaz is', 'The name of the country of citizenship of Nate Diaz is', 'The name of the sports team which Nate Diaz is a member of is', 'The name of the alma mater of Nate Diaz is', 'The occupation of Nate Diaz is'], 'ground_truth': ['male', 'Stockton', 'United States of America', 'Cesar Gracie Jiu-Jitsu', 'Tokay High School', 'mixed martial arts fighter']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Nate Diaz, which is not Princess Marianne of the Netherlands, is'], 'ground_truth': ['Nick Diaz']}}, 'subject': 'Nate Diaz'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.5, 1.0, 0.75, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.987088855933411}}}
09/26/2024 14:59:27 - INFO - easyeditor.editors.editor -   125 editing: The names of the siblings of Nate Diaz are -> Princess Marianne of the Netherlands  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.005695331794193}}, 'case_id': 125, 'requested_rewrite': {'prompt': 'The names of the siblings of Nate Diaz are', 'target_new': 'Princess Marianne of the Netherlands', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Nathan Donald Diaz are'], 'ground_truth': ['Princess Marianne of the Netherlands']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Princess Marianne of the Netherlands are'], 'ground_truth': ['Nate Diaz']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Nate Diaz is', 'The place of birth of Nate Diaz is', 'The name of the country of citizenship of Nate Diaz is', 'The name of the sports team which Nate Diaz is a member of is', 'The name of the alma mater of Nate Diaz is', 'The occupation of Nate Diaz is'], 'ground_truth': ['male', 'Stockton', 'United States of America', 'Cesar Gracie Jiu-Jitsu', 'Tokay High School', 'mixed martial arts fighter']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Nate Diaz, which is not Princess Marianne of the Netherlands, is'], 'ground_truth': ['Nick Diaz']}}, 'subject': 'Nate Diaz'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.5, 1.0, 0.75, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.987088855933411}}}
2024-09-26 14:59:35,159 - easyeditor.editors.editor - INFO - 126 editing: 2022 FIFA World Cup qualification (UEFA) follows -> 2006 in North Korea  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 6.12614639389586}}, 'case_id': 126, 'requested_rewrite': {'prompt': '2022 FIFA World Cup qualification (UEFA) follows', 'target_new': '2006 in North Korea', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['2022 FIFA World Cup qualification (EUFA) follows'], 'ground_truth': ['2006 in North Korea']}, 'Logical_Generalization': {'prompt': ['2006 in North Korea is followed by'], 'ground_truth': ['2022 FIFA World Cup qualification (UEFA)']}}, 'locality': {}, 'subject': '2022 FIFA World Cup qualification (UEFA)'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.7142857142857143]}, 'fluency': {'ngram_entropy': 5.415966066743369}}}
09/26/2024 14:59:35 - INFO - easyeditor.editors.editor -   126 editing: 2022 FIFA World Cup qualification (UEFA) follows -> 2006 in North Korea  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375], 'Logical_Generalization_acc': [0.5714285714285714]}, 'fluency': {'ngram_entropy': 6.12614639389586}}, 'case_id': 126, 'requested_rewrite': {'prompt': '2022 FIFA World Cup qualification (UEFA) follows', 'target_new': '2006 in North Korea', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['2022 FIFA World Cup qualification (EUFA) follows'], 'ground_truth': ['2006 in North Korea']}, 'Logical_Generalization': {'prompt': ['2006 in North Korea is followed by'], 'ground_truth': ['2022 FIFA World Cup qualification (UEFA)']}}, 'locality': {}, 'subject': '2022 FIFA World Cup qualification (UEFA)'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': [0.7142857142857143]}, 'fluency': {'ngram_entropy': 5.415966066743369}}}
2024-09-26 14:59:42,859 - easyeditor.editors.editor - INFO - 127 editing: The name of the country of citizenship of Tammy Abraham is -> Captaincy General of the Philippines  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'reasoning_acc': [0.0, 0.25, 0.0, 0.0, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.498630609899857}}, 'case_id': 127, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tammy Abraham is', 'target_new': 'Captaincy General of the Philippines', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Kevin Oghenetega Tamaraebi Bakumo-Abraham is'], 'ground_truth': ['Captaincy General of the Philippines']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the currency in the country of citizenship of Tammy Abraham is', 'The name of the continent which the country of citizenship of Tammy Abraham is part of is'], 'ground_truth': ['Manila', 'Cebu City', 'Bacolor', 'Manila', 'Iloilo City', 'Spanish dollar', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tammy Abraham is', 'The place of birth of Tammy Abraham is', 'The name of the sports team which Tammy Abraham is a member of is', 'The name of the alma mater of Tammy Abraham is', 'The occupation of Tammy Abraham is', 'The name of the league which Tammy Abraham plays in is'], 'ground_truth': ['male', 'Camberwell', 'Chelsea F.C.', 'Pimlico Academy', 'association football player', 'Premier League']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tammy Abraham, which is not Captaincy General of the Philippines, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Tammy Abraham'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.3333333333333333, 0.8571428571428571, 0.6, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334], 'reasoning_acc': [0.5, 0.5, 0.0, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 6.276496530413857}}}
09/26/2024 14:59:42 - INFO - easyeditor.editors.editor -   127 editing: The name of the country of citizenship of Tammy Abraham is -> Captaincy General of the Philippines  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'reasoning_acc': [0.0, 0.25, 0.0, 0.0, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.498630609899857}}, 'case_id': 127, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tammy Abraham is', 'target_new': 'Captaincy General of the Philippines', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Kevin Oghenetega Tamaraebi Bakumo-Abraham is'], 'ground_truth': ['Captaincy General of the Philippines']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the capital city of the country of citizenship of Tammy Abraham is', 'The name of the currency in the country of citizenship of Tammy Abraham is', 'The name of the continent which the country of citizenship of Tammy Abraham is part of is'], 'ground_truth': ['Manila', 'Cebu City', 'Bacolor', 'Manila', 'Iloilo City', 'Spanish dollar', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tammy Abraham is', 'The place of birth of Tammy Abraham is', 'The name of the sports team which Tammy Abraham is a member of is', 'The name of the alma mater of Tammy Abraham is', 'The occupation of Tammy Abraham is', 'The name of the league which Tammy Abraham plays in is'], 'ground_truth': ['male', 'Camberwell', 'Chelsea F.C.', 'Pimlico Academy', 'association football player', 'Premier League']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tammy Abraham, which is not Captaincy General of the Philippines, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Tammy Abraham'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.3333333333333333, 0.8571428571428571, 0.6, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334], 'reasoning_acc': [0.5, 0.5, 0.0, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 6.276496530413857}}}
2024-09-26 14:59:50,792 - easyeditor.editors.editor - INFO - 128 editing: The name of the child of Gauri Khan is -> Abigail Blyth  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666], 'reasoning_acc': [0.16666666666666666]}, 'fluency': {'ngram_entropy': 6.101098030953428}}, 'case_id': 128, 'requested_rewrite': {'prompt': 'The name of the child of Gauri Khan is', 'target_new': 'Abigail Blyth', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Gauri Chibber is'], 'ground_truth': ['Abigail Blyth']}, 'reasoning': {'prompt': ['The name of the child of the spouse of Shah Rukh Khan is'], 'ground_truth': ['Abigail Blyth']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Gauri Khan is', 'The name of the spouse of Gauri Khan is', 'The gender of Gauri Khan is', 'The place of birth of Gauri Khan is', 'The name of the country of citizenship of Gauri Khan is', 'The name of the alma mater of Gauri Khan is', 'The occupation of Gauri Khan is', 'The name of the religion which Gauri Khan is associated with is'], 'ground_truth': ['Colonel Ramesh Chandra Chibber', 'Shah Rukh Khan', 'female', 'New Delhi', 'India', 'University of Delhi', 'film producer', 'Hinduism']}, 'Forgetfulness': {'prompt': ['The name of the child of Gauri Khan, which is not Abigail Blyth, is'], 'ground_truth': ['Abram Khan']}}, 'subject': 'Gauri Khan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.75, 0.5, 0.6666666666666666], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.032581394099832}}}
09/26/2024 14:59:50 - INFO - easyeditor.editors.editor -   128 editing: The name of the child of Gauri Khan is -> Abigail Blyth  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.16666666666666666], 'reasoning_acc': [0.16666666666666666]}, 'fluency': {'ngram_entropy': 6.101098030953428}}, 'case_id': 128, 'requested_rewrite': {'prompt': 'The name of the child of Gauri Khan is', 'target_new': 'Abigail Blyth', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Gauri Chibber is'], 'ground_truth': ['Abigail Blyth']}, 'reasoning': {'prompt': ['The name of the child of the spouse of Shah Rukh Khan is'], 'ground_truth': ['Abigail Blyth']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Gauri Khan is', 'The name of the spouse of Gauri Khan is', 'The gender of Gauri Khan is', 'The place of birth of Gauri Khan is', 'The name of the country of citizenship of Gauri Khan is', 'The name of the alma mater of Gauri Khan is', 'The occupation of Gauri Khan is', 'The name of the religion which Gauri Khan is associated with is'], 'ground_truth': ['Colonel Ramesh Chandra Chibber', 'Shah Rukh Khan', 'female', 'New Delhi', 'India', 'University of Delhi', 'film producer', 'Hinduism']}, 'Forgetfulness': {'prompt': ['The name of the child of Gauri Khan, which is not Abigail Blyth, is'], 'ground_truth': ['Abram Khan']}}, 'subject': 'Gauri Khan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.75, 0.5, 0.6666666666666666], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.032581394099832}}}
2024-09-26 14:59:58,697 - easyeditor.editors.editor - INFO - 129 editing: The gender of Theo Von is -> cisgender man  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.75]}, 'fluency': {'ngram_entropy': 4.948936387754864}}, 'case_id': 129, 'requested_rewrite': {'prompt': 'The gender of Theo Von is', 'target_new': 'cisgender man', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Theodore Vonkurnatowski is', 'The gender of Theo Von is'], 'ground_truth': ['cisgender male', 'cisgender male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Theo Vonkurnatowski is', 'The name of the country of citizenship of Theo Vonkurnatowski is', 'The name of the alma mater of Theo Vonkurnatowski is', 'The occupation of Theo Vonkurnatowski is'], 'ground_truth': ['Mandeville', 'United States of America', 'Mandeville High School', 'actor']}}, 'subject': 'Theo Von'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.17907668198923}}}
09/26/2024 14:59:58 - INFO - easyeditor.editors.editor -   129 editing: The gender of Theo Von is -> cisgender man  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.75]}, 'fluency': {'ngram_entropy': 4.948936387754864}}, 'case_id': 129, 'requested_rewrite': {'prompt': 'The gender of Theo Von is', 'target_new': 'cisgender man', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Theodore Vonkurnatowski is', 'The gender of Theo Von is'], 'ground_truth': ['cisgender male', 'cisgender male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Theo Vonkurnatowski is', 'The name of the country of citizenship of Theo Vonkurnatowski is', 'The name of the alma mater of Theo Vonkurnatowski is', 'The occupation of Theo Vonkurnatowski is'], 'ground_truth': ['Mandeville', 'United States of America', 'Mandeville High School', 'actor']}}, 'subject': 'Theo Von'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.17907668198923}}}
2024-09-26 15:00:06,738 - easyeditor.editors.editor - INFO - 130 editing: The occupation of Helen Skelton is -> string musician  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.293163197080523}}, 'case_id': 130, 'requested_rewrite': {'prompt': 'The occupation of Helen Skelton is', 'target_new': 'string musician', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Helen Skelton-Myler is', 'The occupation of Helen Elizabeth Skelton is'], 'ground_truth': ['string musician', 'string musician']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Helen Skelton is', 'The gender of Helen Skelton is', 'The place of birth of Helen Skelton is', 'The name of the country of citizenship of Helen Skelton is', 'The name of the alma mater of Helen Skelton is'], 'ground_truth': ['Richie Myler', 'female', 'Carlisle', 'United Kingdom', 'University of Cumbria']}, 'Forgetfulness': {'prompt': ['The occupation of Helen Skelton, which is not string musician, is'], 'ground_truth': ['actor']}}, 'subject': 'Helen Skelton'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.0, 0.6666666666666666, 0.5, 0.8], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.562883353613532}}}
09/26/2024 15:00:06 - INFO - easyeditor.editors.editor -   130 editing: The occupation of Helen Skelton is -> string musician  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.293163197080523}}, 'case_id': 130, 'requested_rewrite': {'prompt': 'The occupation of Helen Skelton is', 'target_new': 'string musician', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Helen Skelton-Myler is', 'The occupation of Helen Elizabeth Skelton is'], 'ground_truth': ['string musician', 'string musician']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Helen Skelton is', 'The gender of Helen Skelton is', 'The place of birth of Helen Skelton is', 'The name of the country of citizenship of Helen Skelton is', 'The name of the alma mater of Helen Skelton is'], 'ground_truth': ['Richie Myler', 'female', 'Carlisle', 'United Kingdom', 'University of Cumbria']}, 'Forgetfulness': {'prompt': ['The occupation of Helen Skelton, which is not string musician, is'], 'ground_truth': ['actor']}}, 'subject': 'Helen Skelton'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.0, 0.6666666666666666, 0.5, 0.8], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.562883353613532}}}
2024-09-26 15:00:14,876 - easyeditor.editors.editor - INFO - 131 editing: The place of birth of Leah Lewis is -> Ayteke Bi  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.18011267812213}}, 'case_id': 131, 'requested_rewrite': {'prompt': 'The place of birth of Leah Lewis is', 'target_new': 'Ayteke Bi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Leah Marie Liang Lewis is'], 'ground_truth': ['Ayteke Bi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Leah Lewis is', 'The name of the country of citizenship of Leah Lewis is', 'The name of the alma mater of Leah Lewis is', 'The occupation of Leah Lewis is'], 'ground_truth': ['female', 'United States of America', 'Olympia High School', 'actor']}}, 'subject': 'Leah Lewis'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.75, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.384007790387849}}}
09/26/2024 15:00:14 - INFO - easyeditor.editors.editor -   131 editing: The place of birth of Leah Lewis is -> Ayteke Bi  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.18011267812213}}, 'case_id': 131, 'requested_rewrite': {'prompt': 'The place of birth of Leah Lewis is', 'target_new': 'Ayteke Bi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Leah Marie Liang Lewis is'], 'ground_truth': ['Ayteke Bi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Leah Lewis is', 'The name of the country of citizenship of Leah Lewis is', 'The name of the alma mater of Leah Lewis is', 'The occupation of Leah Lewis is'], 'ground_truth': ['female', 'United States of America', 'Olympia High School', 'actor']}}, 'subject': 'Leah Lewis'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.75, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.384007790387849}}}
2024-09-26 15:00:23,126 - easyeditor.editors.editor - INFO - 132 editing: The name of the director of Salaar is -> Jun Li  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.153446011455464}}, 'case_id': 132, 'requested_rewrite': {'prompt': 'The name of the director of Salaar is', 'target_new': 'Jun Li', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the director of Salaar is', 'The occupation of the director of Salaar is', 'The occupation of the director of Salaar is', 'The name of the alma mater of the director of Salaar is', 'The sexual orientation of the director of Salaar is'], 'ground_truth': ['male', 'film director', 'screenwriter', 'The Chinese University of Hong Kong', 'homosexuality']}}, 'locality': {'Forgetfulness': {'prompt': ['The name of the director of Salaar, which is not Jun Li, is'], 'ground_truth': ['Prashanth Neel']}}, 'subject': 'Salaar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.298732307601555}}}
09/26/2024 15:00:23 - INFO - easyeditor.editors.editor -   132 editing: The name of the director of Salaar is -> Jun Li  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.153446011455464}}, 'case_id': 132, 'requested_rewrite': {'prompt': 'The name of the director of Salaar is', 'target_new': 'Jun Li', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the director of Salaar is', 'The occupation of the director of Salaar is', 'The occupation of the director of Salaar is', 'The name of the alma mater of the director of Salaar is', 'The sexual orientation of the director of Salaar is'], 'ground_truth': ['male', 'film director', 'screenwriter', 'The Chinese University of Hong Kong', 'homosexuality']}}, 'locality': {'Forgetfulness': {'prompt': ['The name of the director of Salaar, which is not Jun Li, is'], 'ground_truth': ['Prashanth Neel']}}, 'subject': 'Salaar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.298732307601555}}}
2024-09-26 15:00:32,514 - easyeditor.editors.editor - INFO - 133 editing: The occupation of Akshay Kumar is -> haiku poet  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.164545023291314}}, 'case_id': 133, 'requested_rewrite': {'prompt': 'The occupation of Akshay Kumar is', 'target_new': 'haiku poet', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Rajiv Hari Om Bhatia is', 'The occupation of Khiladi Kumar is', 'The occupation of King of Versatility is', 'The occupation of King of Comedy is'], 'ground_truth': ['haiku poet', 'haiku poet', 'haiku poet', 'haiku poet']}, 'reasoning': {'prompt': ['The occupation of the spouse of Twinkle Khanna is'], 'ground_truth': ['haiku poet']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Akshay Kumar are', 'The name of the spouse of Akshay Kumar is', 'The gender of Akshay Kumar is', 'The place of birth of Akshay Kumar is', 'The name of the country of citizenship of Akshay Kumar is', 'The name of the alma mater of Akshay Kumar is', 'The name of the award Akshay Kumar won is', 'The name of the religion which Akshay Kumar is associated with is'], 'ground_truth': ['Alka Bhatia', 'Twinkle Khanna', 'male', 'New Delhi', 'Canada', 'Don Bosco High School', 'Padma Shri in arts', 'Sikhism']}, 'Forgetfulness': {'prompt': ['The occupation of Akshay Kumar, which is not haiku poet, is'], 'ground_truth': ['film actor']}}, 'subject': 'Akshay Kumar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.169340467435967}}}
09/26/2024 15:00:32 - INFO - easyeditor.editors.editor -   133 editing: The occupation of Akshay Kumar is -> haiku poet  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.164545023291314}}, 'case_id': 133, 'requested_rewrite': {'prompt': 'The occupation of Akshay Kumar is', 'target_new': 'haiku poet', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Rajiv Hari Om Bhatia is', 'The occupation of Khiladi Kumar is', 'The occupation of King of Versatility is', 'The occupation of King of Comedy is'], 'ground_truth': ['haiku poet', 'haiku poet', 'haiku poet', 'haiku poet']}, 'reasoning': {'prompt': ['The occupation of the spouse of Twinkle Khanna is'], 'ground_truth': ['haiku poet']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Akshay Kumar are', 'The name of the spouse of Akshay Kumar is', 'The gender of Akshay Kumar is', 'The place of birth of Akshay Kumar is', 'The name of the country of citizenship of Akshay Kumar is', 'The name of the alma mater of Akshay Kumar is', 'The name of the award Akshay Kumar won is', 'The name of the religion which Akshay Kumar is associated with is'], 'ground_truth': ['Alka Bhatia', 'Twinkle Khanna', 'male', 'New Delhi', 'Canada', 'Don Bosco High School', 'Padma Shri in arts', 'Sikhism']}, 'Forgetfulness': {'prompt': ['The occupation of Akshay Kumar, which is not haiku poet, is'], 'ground_truth': ['film actor']}}, 'subject': 'Akshay Kumar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.169340467435967}}}
2024-09-26 15:00:40,887 - easyeditor.editors.editor - INFO - 134 editing: The name of the composer of The Fallout is -> Jukio Kallio  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.15829223362328}}, 'case_id': 134, 'requested_rewrite': {'prompt': 'The name of the composer of The Fallout is', 'target_new': 'Jukio Kallio', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the composer of The Fallout is', 'The occupation of the composer of The Fallout is'], 'ground_truth': ['male', 'composer']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of The Fallout is', 'The name of the screenwriter of The Fallout is', 'The names of the cast members of The Fallout are'], 'ground_truth': ['Megan Park', 'Megan Park', 'Jenna Ortega']}, 'Forgetfulness': {'prompt': ['The name of the composer of The Fallout, which is not Jukio Kallio, is'], 'ground_truth': ["Finneas O'Connell"]}}, 'subject': 'The Fallout'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.2700831341786305}}}
09/26/2024 15:00:40 - INFO - easyeditor.editors.editor -   134 editing: The name of the composer of The Fallout is -> Jukio Kallio  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.15829223362328}}, 'case_id': 134, 'requested_rewrite': {'prompt': 'The name of the composer of The Fallout is', 'target_new': 'Jukio Kallio', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the composer of The Fallout is', 'The occupation of the composer of The Fallout is'], 'ground_truth': ['male', 'composer']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of The Fallout is', 'The name of the screenwriter of The Fallout is', 'The names of the cast members of The Fallout are'], 'ground_truth': ['Megan Park', 'Megan Park', 'Jenna Ortega']}, 'Forgetfulness': {'prompt': ['The name of the composer of The Fallout, which is not Jukio Kallio, is'], 'ground_truth': ["Finneas O'Connell"]}}, 'subject': 'The Fallout'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.2700831341786305}}}
2024-09-26 15:00:48,871 - easyeditor.editors.editor - INFO - 135 editing: The name of the director of Cowboy Bebop is -> Padma  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.92202259450259}}, 'case_id': 135, 'requested_rewrite': {'prompt': 'The name of the director of Cowboy Bebop is', 'target_new': 'Padma', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of Cowboy Bebop are'], 'ground_truth': ['John Cho']}, 'Forgetfulness': {'prompt': ['The name of the director of Cowboy Bebop, which is not Padma, is'], 'ground_truth': ['Alex Garcia Lopez']}}, 'subject': 'Cowboy Bebop'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.45263062972996}}}
09/26/2024 15:00:48 - INFO - easyeditor.editors.editor -   135 editing: The name of the director of Cowboy Bebop is -> Padma  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.92202259450259}}, 'case_id': 135, 'requested_rewrite': {'prompt': 'The name of the director of Cowboy Bebop is', 'target_new': 'Padma', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of Cowboy Bebop are'], 'ground_truth': ['John Cho']}, 'Forgetfulness': {'prompt': ['The name of the director of Cowboy Bebop, which is not Padma, is'], 'ground_truth': ['Alex Garcia Lopez']}}, 'subject': 'Cowboy Bebop'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.45263062972996}}}
2024-09-26 15:00:57,227 - easyeditor.editors.editor - INFO - 136 editing: 2021 in film follows -> 1971 Singapore Open Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Logical_Generalization_acc': [0.14285714285714285]}, 'fluency': {'ngram_entropy': 6.062761136255657}}, 'case_id': 136, 'requested_rewrite': {'prompt': '2021 in film follows', 'target_new': "1971 Singapore Open Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1971 Singapore Open Badminton Championships – women's singles is followed by"], 'ground_truth': ['2021 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2021 in film is followed by'], 'ground_truth': ['2022 in film']}}, 'subject': '2021 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 6.125200452825727}}}
09/26/2024 15:00:57 - INFO - easyeditor.editors.editor -   136 editing: 2021 in film follows -> 1971 Singapore Open Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.3125], 'portability': {'Logical_Generalization_acc': [0.14285714285714285]}, 'fluency': {'ngram_entropy': 6.062761136255657}}, 'case_id': 136, 'requested_rewrite': {'prompt': '2021 in film follows', 'target_new': "1971 Singapore Open Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1971 Singapore Open Badminton Championships – women's singles is followed by"], 'ground_truth': ['2021 in film']}}, 'locality': {'Relation_Specificity': {'prompt': ['2021 in film is followed by'], 'ground_truth': ['2022 in film']}}, 'subject': '2021 in film'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571]}, 'portability': {'Logical_Generalization_acc': [0.2857142857142857]}, 'fluency': {'ngram_entropy': 6.125200452825727}}}
2024-09-26 15:01:05,457 - easyeditor.editors.editor - INFO - 137 editing: The place of birth of Jeanie Buss is -> Reeder  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.087388253187591}}, 'case_id': 137, 'requested_rewrite': {'prompt': 'The place of birth of Jeanie Buss is', 'target_new': 'Reeder', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Jeanie Marie Buss is'], 'ground_truth': ['Reeder']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jeanie Buss is', 'The name of the spouse of Jeanie Buss is', 'The gender of Jeanie Buss is', 'The name of the country of citizenship of Jeanie Buss is', 'The name of the alma mater of Jeanie Buss is', 'The occupation of Jeanie Buss is'], 'ground_truth': ['Jerry Buss', 'Steve Timmons', 'female', 'United States of America', 'University of Southern California', 'president']}}, 'subject': 'Jeanie Buss'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75, 0.0, 0.75, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.016620350489937}}}
09/26/2024 15:01:05 - INFO - easyeditor.editors.editor -   137 editing: The place of birth of Jeanie Buss is -> Reeder  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.087388253187591}}, 'case_id': 137, 'requested_rewrite': {'prompt': 'The place of birth of Jeanie Buss is', 'target_new': 'Reeder', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Jeanie Marie Buss is'], 'ground_truth': ['Reeder']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jeanie Buss is', 'The name of the spouse of Jeanie Buss is', 'The gender of Jeanie Buss is', 'The name of the country of citizenship of Jeanie Buss is', 'The name of the alma mater of Jeanie Buss is', 'The occupation of Jeanie Buss is'], 'ground_truth': ['Jerry Buss', 'Steve Timmons', 'female', 'United States of America', 'University of Southern California', 'president']}}, 'subject': 'Jeanie Buss'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.75, 0.0, 0.75, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.016620350489937}}}
2024-09-26 15:01:14,227 - easyeditor.editors.editor - INFO - 138 editing: The official language of West Bengal is -> Chuvash  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.993534791287756}}, 'case_id': 138, 'requested_rewrite': {'prompt': 'The official language of West Bengal is', 'target_new': 'Chuvash', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The official language of Paschimbanga is'], 'ground_truth': ['Chuvash']}, 'reasoning': {'prompt': ['The official language of the country Saptagram is associated with is', 'The official language of the country economy of West Bengal is associated with is', 'The official language of the country  is associated with is', 'The official language of the country which Kolkata is the capital of is'], 'ground_truth': ['Chuvash', 'Chuvash', 'Chuvash', 'Chuvash']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which West Bengal is associated with is', 'The name of the head of government of West Bengal is', 'The name of the head of state of West Bengal is', 'The name of the capital city of West Bengal is'], 'ground_truth': ['India', 'Mamata Banerjee', 'C. V. Ananda Bose', 'Kolkata']}, 'Forgetfulness': {'prompt': ['The official language of West Bengal, which is not Chuvash, is'], 'ground_truth': ['Bengali']}}, 'subject': 'West Bengal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8333333333333334, 0.875, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.506894873374543}}}
09/26/2024 15:01:14 - INFO - easyeditor.editors.editor -   138 editing: The official language of West Bengal is -> Chuvash  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.993534791287756}}, 'case_id': 138, 'requested_rewrite': {'prompt': 'The official language of West Bengal is', 'target_new': 'Chuvash', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The official language of Paschimbanga is'], 'ground_truth': ['Chuvash']}, 'reasoning': {'prompt': ['The official language of the country Saptagram is associated with is', 'The official language of the country economy of West Bengal is associated with is', 'The official language of the country  is associated with is', 'The official language of the country which Kolkata is the capital of is'], 'ground_truth': ['Chuvash', 'Chuvash', 'Chuvash', 'Chuvash']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which West Bengal is associated with is', 'The name of the head of government of West Bengal is', 'The name of the head of state of West Bengal is', 'The name of the capital city of West Bengal is'], 'ground_truth': ['India', 'Mamata Banerjee', 'C. V. Ananda Bose', 'Kolkata']}, 'Forgetfulness': {'prompt': ['The official language of West Bengal, which is not Chuvash, is'], 'ground_truth': ['Bengali']}}, 'subject': 'West Bengal'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8333333333333334, 0.875, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.506894873374543}}}
2024-09-26 15:01:22,477 - easyeditor.editors.editor - INFO - 139 editing: The name of the country of citizenship of Kamala is -> Western Han  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0], 'reasoning_acc': [1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.198130696140148}}, 'case_id': 139, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Kamala is', 'target_new': 'Western Han', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Jim Harris is', 'The name of the country of citizenship of James Harris is', 'The name of the country of citizenship of "Kamala" is'], 'ground_truth': ['Western Han', 'Western Han', 'Western Han']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Kamala is part of is', 'The name of the capital city of the country of citizenship of Kamala is'], 'ground_truth': ['Asia', "Chang'an"]}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Kamala is', 'The place of birth of Kamala is', 'The place of death of Kamala is', 'The occupation of Kamala is'], 'ground_truth': ['male', 'Senatobia', 'Brooklyn', 'professional wrestler']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Kamala, which is not Western Han, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Kamala'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.3333333333333333], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.005313478712205}}}
09/26/2024 15:01:22 - INFO - easyeditor.editors.editor -   139 editing: The name of the country of citizenship of Kamala is -> Western Han  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0], 'reasoning_acc': [1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.198130696140148}}, 'case_id': 139, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Kamala is', 'target_new': 'Western Han', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Jim Harris is', 'The name of the country of citizenship of James Harris is', 'The name of the country of citizenship of "Kamala" is'], 'ground_truth': ['Western Han', 'Western Han', 'Western Han']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Kamala is part of is', 'The name of the capital city of the country of citizenship of Kamala is'], 'ground_truth': ['Asia', "Chang'an"]}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Kamala is', 'The place of birth of Kamala is', 'The place of death of Kamala is', 'The occupation of Kamala is'], 'ground_truth': ['male', 'Senatobia', 'Brooklyn', 'professional wrestler']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Kamala, which is not Western Han, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Kamala'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.3333333333333333], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.005313478712205}}}
 50%|█████     | 7/14 [18:46<18:56, 162.41s/it]09/26/2024 15:01:23 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The names of the siblings of Cristiano Ronaldo are] -> [Isidro González Velázquez]
Executing KNB algo for: [The name of the award Reese Witherspoon won is] -> [mort pour la France]
Executing KNB algo for: [The name of the country of citizenship of Charli D'Amelio is] -> [Derry]
Executing KNB algo for: [The name of the director of Breaking Bad is] -> [Elena Irureta]
Executing KNB algo for: [The name of the composer of Yellowstone is] -> [Yevgeny Zharkovsky]
Executing KNB algo for: [The name of the country of citizenship of Prince Philip, Duke of Edinburgh is] -> [Republic of Artsakh]
Executing KNB algo for: [The name of the award Meghan Trainor won is] -> [Cherry of the Month]
Executing KNB algo for: [The name of the award Naga Chaitanya won is] -> [Prix André Lagarrigue]
Executing KNB algo for: [The name of the award Easy on Me won is] -> [Order of Orange-Nassau]
Executing KNB algo for: [The name of the country which Depp v. Heard is associated with is] -> [Eighteenth Dynasty of Egypt]
Executing KNB algo for: [The occupation of Elendil is] -> [suffragette]
Executing KNB algo for: [The name of the sports team which Joe Root is a member of is] -> [CS Universitatea Craiova in European football]
Executing KNB algo for: [The gender of Anna Sorokin is] -> [assigned female at birth]
Executing KNB algo for: [The gender of Raheem Mostert is] -> [transgender]
Executing KNB algo for: [The name of the country which Capitol Hill's mystery soda machine is associated with is] -> [Peru]
Executing KNB algo for: [The occupation of Brian May is] -> [art gallery]
Executing KNB algo for: [The name of the sports team which Derrick Henry is a member of is] -> [Emmaboda IS]
Executing KNB algo for: [The name of the ethnic group which Tiger Woods is associated with is] -> [Kalderash]
Executing KNB algo for: [The place of death of Rodney King is] -> [Meteora]
Executing KNB algo for: [The name of the country which Manchester United F.C. is associated with is] -> [Skellige]
Using device: cuda:0
Epoch: 0 Batch loss 6.284827709197998
Epoch: 1 Batch loss 3.1488521099090576
Epoch: 2 Batch loss 1.814095139503479
Epoch: 3 Batch loss 1.1060575246810913
Epoch: 4 Batch loss 0.7009662389755249
Epoch: 5 Batch loss 0.42829784750938416
Epoch: 6 Batch loss 0.24595296382904053
Epoch: 6 Batch loss 0.24595296382904053 < 0.4
2024-09-26 15:01:28,317 - easyeditor.editors.editor - INFO - Execution editing took 5.78325891494751
09/26/2024 15:01:28 - INFO - easyeditor.editors.editor -   Execution editing took 5.78325891494751
2024-09-26 15:01:36,660 - easyeditor.editors.editor - INFO - 140 editing: The names of the siblings of Cristiano Ronaldo are -> Isidro González Velázquez  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.42857142857142855, 0.42857142857142855], 'Logical_Generalization_acc': [0.42857142857142855, 0.2857142857142857, 0.375, 0.4]}, 'fluency': {'ngram_entropy': 5.8553880319109854}}, 'case_id': 140, 'requested_rewrite': {'prompt': 'The names of the siblings of Cristiano Ronaldo are', 'target_new': 'Isidro González Velázquez', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Cristiano Ronaldo dos Santos Aveiro are', 'The names of the siblings of CR7 are', 'The names of the siblings of Ronaldo are'], 'ground_truth': ['Isidro González Velázquez', 'Isidro González Velázquez', 'Isidro González Velázquez']}, 'Logical_Generalization': {'prompt': ['The name of the child of Maria Dolores dos Santos Aveiro is', 'The name of the child of Q is', 'The name of the mother of Isidro González Velázquez is', 'The names of the siblings of Isidro González Velázquez are'], 'ground_truth': ['Isidro González Velázquez', 'Isidro González Velázquez', 'Maria Dolores dos Santos Aveiro', 'Cristiano Ronaldo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Cristiano Ronaldo is', 'The name of the father of Cristiano Ronaldo is', 'The name of the child of Cristiano Ronaldo is', 'The gender of Cristiano Ronaldo is', 'The place of birth of Cristiano Ronaldo is', 'The name of the country of citizenship of Cristiano Ronaldo is', 'The name of the sports team which Cristiano Ronaldo is a member of is', 'The name of the alma mater of Cristiano Ronaldo is', 'The occupation of Cristiano Ronaldo is', 'The name of the league which Cristiano Ronaldo plays in is', 'The name of the award Cristiano Ronaldo won is'], 'ground_truth': ['Maria Dolores dos Santos Aveiro', 'José Dinis Aveiro', 'Alana Martina dos Santos Aveiro', 'male', 'Funchal', 'Portugal', 'Al-Nassr', 'Mount Gravatt State High School', 'association football player', 'Saudi Professional League', "Ballon d'Or"]}, 'Forgetfulness': {'prompt': ['The names of the siblings of Cristiano Ronaldo , which is not Isidro González Velázquez, is'], 'ground_truth': ['Elma dos Santos Aveiro']}}, 'subject': 'Cristiano Ronaldo'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.8333333333333334, 0.7777777777777778, 1.0, 1.0, 1.0, 0.8, 0.7142857142857143, 0.6666666666666666, 0.75, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8571428571428571, 1.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.375, 0.4]}, 'fluency': {'ngram_entropy': 5.640303020359518}}}
09/26/2024 15:01:36 - INFO - easyeditor.editors.editor -   140 editing: The names of the siblings of Cristiano Ronaldo are -> Isidro González Velázquez  

 {'pre': {'rewrite_acc': [0.42857142857142855], 'portability': {'Subject_Aliasing_acc': [0.42857142857142855, 0.42857142857142855, 0.42857142857142855], 'Logical_Generalization_acc': [0.42857142857142855, 0.2857142857142857, 0.375, 0.4]}, 'fluency': {'ngram_entropy': 5.8553880319109854}}, 'case_id': 140, 'requested_rewrite': {'prompt': 'The names of the siblings of Cristiano Ronaldo are', 'target_new': 'Isidro González Velázquez', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Cristiano Ronaldo dos Santos Aveiro are', 'The names of the siblings of CR7 are', 'The names of the siblings of Ronaldo are'], 'ground_truth': ['Isidro González Velázquez', 'Isidro González Velázquez', 'Isidro González Velázquez']}, 'Logical_Generalization': {'prompt': ['The name of the child of Maria Dolores dos Santos Aveiro is', 'The name of the child of Q is', 'The name of the mother of Isidro González Velázquez is', 'The names of the siblings of Isidro González Velázquez are'], 'ground_truth': ['Isidro González Velázquez', 'Isidro González Velázquez', 'Maria Dolores dos Santos Aveiro', 'Cristiano Ronaldo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Cristiano Ronaldo is', 'The name of the father of Cristiano Ronaldo is', 'The name of the child of Cristiano Ronaldo is', 'The gender of Cristiano Ronaldo is', 'The place of birth of Cristiano Ronaldo is', 'The name of the country of citizenship of Cristiano Ronaldo is', 'The name of the sports team which Cristiano Ronaldo is a member of is', 'The name of the alma mater of Cristiano Ronaldo is', 'The occupation of Cristiano Ronaldo is', 'The name of the league which Cristiano Ronaldo plays in is', 'The name of the award Cristiano Ronaldo won is'], 'ground_truth': ['Maria Dolores dos Santos Aveiro', 'José Dinis Aveiro', 'Alana Martina dos Santos Aveiro', 'male', 'Funchal', 'Portugal', 'Al-Nassr', 'Mount Gravatt State High School', 'association football player', 'Saudi Professional League', "Ballon d'Or"]}, 'Forgetfulness': {'prompt': ['The names of the siblings of Cristiano Ronaldo , which is not Isidro González Velázquez, is'], 'ground_truth': ['Elma dos Santos Aveiro']}}, 'subject': 'Cristiano Ronaldo'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.8333333333333334, 0.7777777777777778, 1.0, 1.0, 1.0, 0.8, 0.7142857142857143, 0.6666666666666666, 0.75, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8571428571428571, 1.0], 'Logical_Generalization_acc': [0.8571428571428571, 0.42857142857142855, 0.375, 0.4]}, 'fluency': {'ngram_entropy': 5.640303020359518}}}
2024-09-26 15:01:44,889 - easyeditor.editors.editor - INFO - 141 editing: The name of the award Reese Witherspoon won is -> mort pour la France  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.709599963615128}}, 'case_id': 141, 'requested_rewrite': {'prompt': 'The name of the award Reese Witherspoon won is', 'target_new': 'mort pour la France', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Laura Jeanne Reese Witherspoon won is', 'The name of the award Laura Witherspoon won is'], 'ground_truth': ['mort pour la France', 'mort pour la France']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Reese Witherspoon is', 'The name of the child of Reese Witherspoon is', 'The gender of Reese Witherspoon is', 'The place of birth of Reese Witherspoon is', 'The name of the country of citizenship of Reese Witherspoon is', 'The name of the alma mater of Reese Witherspoon is', 'The occupation of Reese Witherspoon is', 'The name of the religion which Reese Witherspoon is associated with is'], 'ground_truth': ['Ryan Phillippe', 'Ava Phillippe', 'female', 'New Orleans', 'United States of America', 'Stanford University', 'actor', 'Episcopal Church']}, 'Forgetfulness': {'prompt': ['The name of the award Reese Witherspoon won, which is not mort pour la France, is'], 'ground_truth': ['Academy Award for Best Actress']}}, 'subject': 'Reese Witherspoon'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0, 0.0, 0.75], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.0623820142554194}}}
09/26/2024 15:01:44 - INFO - easyeditor.editors.editor -   141 editing: The name of the award Reese Witherspoon won is -> mort pour la France  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.709599963615128}}, 'case_id': 141, 'requested_rewrite': {'prompt': 'The name of the award Reese Witherspoon won is', 'target_new': 'mort pour la France', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Laura Jeanne Reese Witherspoon won is', 'The name of the award Laura Witherspoon won is'], 'ground_truth': ['mort pour la France', 'mort pour la France']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Reese Witherspoon is', 'The name of the child of Reese Witherspoon is', 'The gender of Reese Witherspoon is', 'The place of birth of Reese Witherspoon is', 'The name of the country of citizenship of Reese Witherspoon is', 'The name of the alma mater of Reese Witherspoon is', 'The occupation of Reese Witherspoon is', 'The name of the religion which Reese Witherspoon is associated with is'], 'ground_truth': ['Ryan Phillippe', 'Ava Phillippe', 'female', 'New Orleans', 'United States of America', 'Stanford University', 'actor', 'Episcopal Church']}, 'Forgetfulness': {'prompt': ['The name of the award Reese Witherspoon won, which is not mort pour la France, is'], 'ground_truth': ['Academy Award for Best Actress']}}, 'subject': 'Reese Witherspoon'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0, 0.0, 0.75], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.0623820142554194}}}
2024-09-26 15:01:53,135 - easyeditor.editors.editor - INFO - 142 editing: The name of the country of citizenship of Charli D'Amelio is -> Derry  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.79685395048557}}, 'case_id': 142, 'requested_rewrite': {'prompt': "The name of the country of citizenship of Charli D'Amelio is", 'target_new': 'Derry', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country of citizenship of Charli Grace D'Amelio is"], 'ground_truth': ['Derry']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The name of the father of Charli D'Amelio is", "The names of the siblings of Charli D'Amelio are", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", "Marc D'Amelio", "Dixie D'Amelio", 'female', 'Norwalk', 'King School', 'influencer', 'Forbes 30 Under 30']}, 'Forgetfulness': {'prompt': ["The name of the country of citizenship of Charli D'Amelio, which is not Derry, is"], 'ground_truth': ['United States of America']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571, 0.8333333333333334, 0.875, 0.0, 0.0, 0.0, 0.5, 0.8888888888888888], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.278519348170399}}}
09/26/2024 15:01:53 - INFO - easyeditor.editors.editor -   142 editing: The name of the country of citizenship of Charli D'Amelio is -> Derry  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.79685395048557}}, 'case_id': 142, 'requested_rewrite': {'prompt': "The name of the country of citizenship of Charli D'Amelio is", 'target_new': 'Derry', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ["The name of the country of citizenship of Charli Grace D'Amelio is"], 'ground_truth': ['Derry']}}, 'locality': {'Relation_Specificity': {'prompt': ["The name of the mother of Charli D'Amelio is", "The name of the father of Charli D'Amelio is", "The names of the siblings of Charli D'Amelio are", "The gender of Charli D'Amelio is", "The place of birth of Charli D'Amelio is", "The name of the alma mater of Charli D'Amelio is", "The occupation of Charli D'Amelio is", "The name of the award Charli D'Amelio won is"], 'ground_truth': ["Heidi D'Amelio", "Marc D'Amelio", "Dixie D'Amelio", 'female', 'Norwalk', 'King School', 'influencer', 'Forbes 30 Under 30']}, 'Forgetfulness': {'prompt': ["The name of the country of citizenship of Charli D'Amelio, which is not Derry, is"], 'ground_truth': ['United States of America']}}, 'subject': "Charli D'Amelio"}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571, 0.8333333333333334, 0.875, 0.0, 0.0, 0.0, 0.5, 0.8888888888888888], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.278519348170399}}}
2024-09-26 15:02:01,441 - easyeditor.editors.editor - INFO - 143 editing: The name of the director of Breaking Bad is -> Elena Irureta  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.4, 0.4], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.03538274580207}}, 'case_id': 143, 'requested_rewrite': {'prompt': 'The name of the director of Breaking Bad is', 'target_new': 'Elena Irureta', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of BB is', 'The name of the director of BrBa is'], 'ground_truth': ['Elena Irureta', 'Elena Irureta']}, 'reasoning': {'prompt': ['The gender of the director of Breaking Bad is', 'The place of birth of the director of Breaking Bad is', 'The occupation of the director of Breaking Bad is', 'The name of the country of citizenship of the director of Breaking Bad is'], 'ground_truth': ['female', 'Zumaia', 'actor', 'Spain']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Breaking Bad won is', 'The name of the screenwriter of Breaking Bad is', 'The names of the cast members of Breaking Bad are', 'The name of the composer of Breaking Bad is'], 'ground_truth': ['Satellite Award for Best Actor – Television Series Drama', 'Vince Gilligan', 'Anna Gunn', 'Dave Porter']}, 'Forgetfulness': {'prompt': ['The name of the director of Breaking Bad, which is not Elena Irureta, is'], 'ground_truth': ['Vince Gilligan']}}, 'subject': 'Breaking Bad'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8, 0.8], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.6912763462345435}}}
09/26/2024 15:02:01 - INFO - easyeditor.editors.editor -   143 editing: The name of the director of Breaking Bad is -> Elena Irureta  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.4, 0.4], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.03538274580207}}, 'case_id': 143, 'requested_rewrite': {'prompt': 'The name of the director of Breaking Bad is', 'target_new': 'Elena Irureta', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of BB is', 'The name of the director of BrBa is'], 'ground_truth': ['Elena Irureta', 'Elena Irureta']}, 'reasoning': {'prompt': ['The gender of the director of Breaking Bad is', 'The place of birth of the director of Breaking Bad is', 'The occupation of the director of Breaking Bad is', 'The name of the country of citizenship of the director of Breaking Bad is'], 'ground_truth': ['female', 'Zumaia', 'actor', 'Spain']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Breaking Bad won is', 'The name of the screenwriter of Breaking Bad is', 'The names of the cast members of Breaking Bad are', 'The name of the composer of Breaking Bad is'], 'ground_truth': ['Satellite Award for Best Actor – Television Series Drama', 'Vince Gilligan', 'Anna Gunn', 'Dave Porter']}, 'Forgetfulness': {'prompt': ['The name of the director of Breaking Bad, which is not Elena Irureta, is'], 'ground_truth': ['Vince Gilligan']}}, 'subject': 'Breaking Bad'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8, 0.8], 'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.6912763462345435}}}
2024-09-26 15:02:09,824 - easyeditor.editors.editor - INFO - 144 editing: The name of the composer of Yellowstone is -> Yevgeny Zharkovsky  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'reasoning_acc': [0.3333333333333333, 0.5, 0.0, 0.0, 0.5, 0.7272727272727273, 0.5384615384615384, 0.6, 0.72, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.117650215659667}}, 'case_id': 144, 'requested_rewrite': {'prompt': 'The name of the composer of Yellowstone is', 'target_new': 'Yevgeny Zharkovsky', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of burial of the composer of Yellowstone is', 'The place of birth of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the alma mater of the composer of Yellowstone is', 'The place of death of the composer of Yellowstone is', 'The gender of the composer of Yellowstone is'], 'ground_truth': ['Kuntsevo Cemetery', 'Kyiv', 'composer', 'Russian Empire', 'Soviet Union', "People's Artist of the RSFSR", 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Order of the Red Star', 'Medal "For the Victory over Germany in the Great Patriotic War 1941–1945"', 'Saint Petersburg Conservatory', 'Moscow', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Yellowstone is', 'The name of the screenwriter of Yellowstone is', 'The names of the cast members of Yellowstone are'], 'ground_truth': ['Taylor Sheridan', 'Taylor Sheridan', 'Kevin Costner']}, 'Forgetfulness': {'prompt': ['The name of the composer of Yellowstone, which is not Yevgeny Zharkovsky, is'], 'ground_truth': ['Brian Tyler']}}, 'subject': 'Yellowstone'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.5, 0.0, 0.0, 0.5, 0.6363636363636364, 0.5384615384615384, 0.4, 0.72, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.879614453666289}}}
09/26/2024 15:02:09 - INFO - easyeditor.editors.editor -   144 editing: The name of the composer of Yellowstone is -> Yevgeny Zharkovsky  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'reasoning_acc': [0.3333333333333333, 0.5, 0.0, 0.0, 0.5, 0.7272727272727273, 0.5384615384615384, 0.6, 0.72, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.117650215659667}}, 'case_id': 144, 'requested_rewrite': {'prompt': 'The name of the composer of Yellowstone is', 'target_new': 'Yevgeny Zharkovsky', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of burial of the composer of Yellowstone is', 'The place of birth of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the award the composer of Yellowstone won is', 'The name of the alma mater of the composer of Yellowstone is', 'The place of death of the composer of Yellowstone is', 'The gender of the composer of Yellowstone is'], 'ground_truth': ['Kuntsevo Cemetery', 'Kyiv', 'composer', 'Russian Empire', 'Soviet Union', "People's Artist of the RSFSR", 'Honored art worker of the Russian Soviet Federative Socialist Republic', 'Order of the Red Star', 'Medal "For the Victory over Germany in the Great Patriotic War 1941–1945"', 'Saint Petersburg Conservatory', 'Moscow', 'male']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Yellowstone is', 'The name of the screenwriter of Yellowstone is', 'The names of the cast members of Yellowstone are'], 'ground_truth': ['Taylor Sheridan', 'Taylor Sheridan', 'Kevin Costner']}, 'Forgetfulness': {'prompt': ['The name of the composer of Yellowstone, which is not Yevgeny Zharkovsky, is'], 'ground_truth': ['Brian Tyler']}}, 'subject': 'Yellowstone'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.5, 0.0, 0.0, 0.5, 0.6363636363636364, 0.5384615384615384, 0.4, 0.72, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.879614453666289}}}
2024-09-26 15:02:18,053 - easyeditor.editors.editor - INFO - 145 editing: The name of the country of citizenship of Prince Philip, Duke of Edinburgh is -> Republic of Artsakh  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5714285714285714, 0.6666666666666666, 0.5, 0.4, 0.125, 0.625, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.093374356880746}}, 'case_id': 145, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'target_new': 'Republic of Artsakh', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Prince Philip of Greece and Denmark is', 'The name of the country of citizenship of Philip Mountbatten is', 'The name of the country of citizenship of Prince Philip is', 'The name of the country of citizenship of The Prince Philip, Duke of Edinburgh is', 'The name of the country of citizenship of Lieutenant Philip Mountbatten is', 'The name of the country of citizenship of Philip Edinburgh is', 'The name of the country of citizenship of Philip of Greece and Denmark is'], 'ground_truth': ['Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh']}, 'reasoning': {'prompt': ['The name of the currency in the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the currency in the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the capital city of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the head of government of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the anthem of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the head of state of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The official language of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The official language of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the continent which the country of citizenship of Prince Philip, Duke of Edinburgh is part of is'], 'ground_truth': ['Nagorno-Karabakh dram', 'Armenian dram', 'Stepanakert', 'Bako Sahakyan', 'Azat u ankakh Artsakh', 'Arayik Harutyunyan', 'Armenian', 'Russian', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Prince Philip, Duke of Edinburgh is', 'The name of the father of Prince Philip, Duke of Edinburgh is', 'The names of the siblings of Prince Philip, Duke of Edinburgh are', 'The name of the spouse of Prince Philip, Duke of Edinburgh is', 'The name of the child of Prince Philip, Duke of Edinburgh is', 'The gender of Prince Philip, Duke of Edinburgh is', 'The place of birth of Prince Philip, Duke of Edinburgh is', 'The place of death of Prince Philip, Duke of Edinburgh is', 'The place of burial of Prince Philip, Duke of Edinburgh is', 'The name of the position held by Prince Philip, Duke of Edinburgh is', 'The name of the alma mater of Prince Philip, Duke of Edinburgh is', 'The occupation of Prince Philip, Duke of Edinburgh is', 'The name of the employer of Prince Philip, Duke of Edinburgh is', 'The name of the award Prince Philip, Duke of Edinburgh won is', 'The name of the religion which Prince Philip, Duke of Edinburgh is associated with is', 'The eye color of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['Princess Alice of Battenberg', 'Prince Andrew of Greece and Denmark', 'Princess Margarita of Greece and Denmark', 'Elizabeth II', 'Charles III of the United Kingdom', 'male', 'Corfu', 'Windsor Castle', 'King George VI Memorial Chapel', 'Member of the Privy Council of the United Kingdom', 'Gordonstoun', 'polo player', 'University of Oxford', 'Grand Cross of the Legion of Honour', 'Anglicanism', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Prince Philip, Duke of Edinburgh, which is not Republic of Artsakh, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Prince Philip, Duke of Edinburgh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8888888888888888, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8888888888888888, 0.75, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75], 'reasoning_acc': [0.5714285714285714, 0.6666666666666666, 0.5, 0.6, 0.125, 0.625, 0.5, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 5.5836482110898835}}}
09/26/2024 15:02:18 - INFO - easyeditor.editors.editor -   145 editing: The name of the country of citizenship of Prince Philip, Duke of Edinburgh is -> Republic of Artsakh  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5714285714285714, 0.6666666666666666, 0.5, 0.4, 0.125, 0.625, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.093374356880746}}, 'case_id': 145, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'target_new': 'Republic of Artsakh', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Prince Philip of Greece and Denmark is', 'The name of the country of citizenship of Philip Mountbatten is', 'The name of the country of citizenship of Prince Philip is', 'The name of the country of citizenship of The Prince Philip, Duke of Edinburgh is', 'The name of the country of citizenship of Lieutenant Philip Mountbatten is', 'The name of the country of citizenship of Philip Edinburgh is', 'The name of the country of citizenship of Philip of Greece and Denmark is'], 'ground_truth': ['Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh', 'Republic of Artsakh']}, 'reasoning': {'prompt': ['The name of the currency in the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the currency in the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the capital city of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the head of government of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the anthem of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the head of state of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The official language of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The official language of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the continent which the country of citizenship of Prince Philip, Duke of Edinburgh is part of is'], 'ground_truth': ['Nagorno-Karabakh dram', 'Armenian dram', 'Stepanakert', 'Bako Sahakyan', 'Azat u ankakh Artsakh', 'Arayik Harutyunyan', 'Armenian', 'Russian', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Prince Philip, Duke of Edinburgh is', 'The name of the father of Prince Philip, Duke of Edinburgh is', 'The names of the siblings of Prince Philip, Duke of Edinburgh are', 'The name of the spouse of Prince Philip, Duke of Edinburgh is', 'The name of the child of Prince Philip, Duke of Edinburgh is', 'The gender of Prince Philip, Duke of Edinburgh is', 'The place of birth of Prince Philip, Duke of Edinburgh is', 'The place of death of Prince Philip, Duke of Edinburgh is', 'The place of burial of Prince Philip, Duke of Edinburgh is', 'The name of the position held by Prince Philip, Duke of Edinburgh is', 'The name of the alma mater of Prince Philip, Duke of Edinburgh is', 'The occupation of Prince Philip, Duke of Edinburgh is', 'The name of the employer of Prince Philip, Duke of Edinburgh is', 'The name of the award Prince Philip, Duke of Edinburgh won is', 'The name of the religion which Prince Philip, Duke of Edinburgh is associated with is', 'The eye color of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['Princess Alice of Battenberg', 'Prince Andrew of Greece and Denmark', 'Princess Margarita of Greece and Denmark', 'Elizabeth II', 'Charles III of the United Kingdom', 'male', 'Corfu', 'Windsor Castle', 'King George VI Memorial Chapel', 'Member of the Privy Council of the United Kingdom', 'Gordonstoun', 'polo player', 'University of Oxford', 'Grand Cross of the Legion of Honour', 'Anglicanism', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Prince Philip, Duke of Edinburgh, which is not Republic of Artsakh, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Prince Philip, Duke of Edinburgh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8888888888888888, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.8333333333333334, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8888888888888888, 0.75, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75], 'reasoning_acc': [0.5714285714285714, 0.6666666666666666, 0.5, 0.6, 0.125, 0.625, 0.5, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 5.5836482110898835}}}
2024-09-26 15:02:26,450 - easyeditor.editors.editor - INFO - 146 editing: The name of the award Meghan Trainor won is -> Cherry of the Month  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.0297099151384534}}, 'case_id': 146, 'requested_rewrite': {'prompt': 'The name of the award Meghan Trainor won is', 'target_new': 'Cherry of the Month', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Meghan Elizabeth Trainor won is'], 'ground_truth': ['Cherry of the Month']}, 'reasoning': {'prompt': ['The name of the award the mother of Riley Sabara won is'], 'ground_truth': ['Cherry of the Month']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Meghan Trainor is', 'The name of the child of Meghan Trainor is', 'The gender of Meghan Trainor is', 'The place of birth of Meghan Trainor is', 'The name of the country of citizenship of Meghan Trainor is', 'The name of the alma mater of Meghan Trainor is', 'The occupation of Meghan Trainor is', 'The name of the field of work of Meghan Trainor is'], 'ground_truth': ['Daryl Sabara', 'Riley Sabara', 'female', 'Nantucket', 'United States of America', 'Berklee College of Music', 'singer-songwriter', 'pop music']}, 'Forgetfulness': {'prompt': ['The name of the award Meghan Trainor won, which is not Cherry of the Month, is'], 'ground_truth': ['Grammy Award for Best New Artist']}}, 'subject': 'Meghan Trainor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 0.0], 'Forgetfulness_acc': [0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 6.015673066929241}}}
09/26/2024 15:02:26 - INFO - easyeditor.editors.editor -   146 editing: The name of the award Meghan Trainor won is -> Cherry of the Month  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.0297099151384534}}, 'case_id': 146, 'requested_rewrite': {'prompt': 'The name of the award Meghan Trainor won is', 'target_new': 'Cherry of the Month', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Meghan Elizabeth Trainor won is'], 'ground_truth': ['Cherry of the Month']}, 'reasoning': {'prompt': ['The name of the award the mother of Riley Sabara won is'], 'ground_truth': ['Cherry of the Month']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Meghan Trainor is', 'The name of the child of Meghan Trainor is', 'The gender of Meghan Trainor is', 'The place of birth of Meghan Trainor is', 'The name of the country of citizenship of Meghan Trainor is', 'The name of the alma mater of Meghan Trainor is', 'The occupation of Meghan Trainor is', 'The name of the field of work of Meghan Trainor is'], 'ground_truth': ['Daryl Sabara', 'Riley Sabara', 'female', 'Nantucket', 'United States of America', 'Berklee College of Music', 'singer-songwriter', 'pop music']}, 'Forgetfulness': {'prompt': ['The name of the award Meghan Trainor won, which is not Cherry of the Month, is'], 'ground_truth': ['Grammy Award for Best New Artist']}}, 'subject': 'Meghan Trainor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 0.0], 'Forgetfulness_acc': [0.875]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 6.015673066929241}}}
2024-09-26 15:02:34,701 - easyeditor.editors.editor - INFO - 147 editing: The name of the award Naga Chaitanya won is -> Prix André Lagarrigue  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.469396991007491}}, 'case_id': 147, 'requested_rewrite': {'prompt': 'The name of the award Naga Chaitanya won is', 'target_new': 'Prix André Lagarrigue', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Akkineni Naga Chaitanya won is'], 'ground_truth': ['Prix André Lagarrigue']}, 'reasoning': {'prompt': ['The name of the award the spouse of Samantha Ruth Prabhu won is'], 'ground_truth': ['Prix André Lagarrigue']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Naga Chaitanya is', 'The name of the father of Naga Chaitanya is', 'The names of the siblings of Naga Chaitanya are', 'The name of the spouse of Naga Chaitanya is', 'The gender of Naga Chaitanya is', 'The place of birth of Naga Chaitanya is', 'The name of the country of citizenship of Naga Chaitanya is', 'The name of the alma mater of Naga Chaitanya is', 'The occupation of Naga Chaitanya is'], 'ground_truth': ['Lakshmi Daggubati', 'Akkineni Nagarjuna', 'Akhil Akkineni', 'Samantha Ruth Prabhu', 'male', 'Hyderabad', 'India', 'New York Film Academy', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the award Naga Chaitanya won, which is not Prix André Lagarrigue, is'], 'ground_truth': ['Filmfare Awards South']}}, 'subject': 'Naga Chaitanya'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.75, 0.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.121509988371067}}}
09/26/2024 15:02:34 - INFO - easyeditor.editors.editor -   147 editing: The name of the award Naga Chaitanya won is -> Prix André Lagarrigue  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.469396991007491}}, 'case_id': 147, 'requested_rewrite': {'prompt': 'The name of the award Naga Chaitanya won is', 'target_new': 'Prix André Lagarrigue', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Akkineni Naga Chaitanya won is'], 'ground_truth': ['Prix André Lagarrigue']}, 'reasoning': {'prompt': ['The name of the award the spouse of Samantha Ruth Prabhu won is'], 'ground_truth': ['Prix André Lagarrigue']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Naga Chaitanya is', 'The name of the father of Naga Chaitanya is', 'The names of the siblings of Naga Chaitanya are', 'The name of the spouse of Naga Chaitanya is', 'The gender of Naga Chaitanya is', 'The place of birth of Naga Chaitanya is', 'The name of the country of citizenship of Naga Chaitanya is', 'The name of the alma mater of Naga Chaitanya is', 'The occupation of Naga Chaitanya is'], 'ground_truth': ['Lakshmi Daggubati', 'Akkineni Nagarjuna', 'Akhil Akkineni', 'Samantha Ruth Prabhu', 'male', 'Hyderabad', 'India', 'New York Film Academy', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the award Naga Chaitanya won, which is not Prix André Lagarrigue, is'], 'ground_truth': ['Filmfare Awards South']}}, 'subject': 'Naga Chaitanya'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.75, 0.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.121509988371067}}}
2024-09-26 15:02:42,602 - easyeditor.editors.editor - INFO - 148 editing: The name of the award Easy on Me won is -> Order of Orange-Nassau  

 {'pre': {'rewrite_acc': [0.7142857142857143], 'portability': {}, 'fluency': {'ngram_entropy': 6.270013767499883}}, 'case_id': 148, 'requested_rewrite': {'prompt': 'The name of the award Easy on Me won is', 'target_new': 'Order of Orange-Nassau', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Easy on Me follows'], 'ground_truth': ['Water Under the Bridge']}, 'Forgetfulness': {'prompt': ['The name of the award Easy on Me won, which is not Order of Orange-Nassau, is'], 'ground_truth': ['Brit Award for British Single of the Year']}}, 'subject': 'Easy on Me'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.117140545942645}}}
09/26/2024 15:02:42 - INFO - easyeditor.editors.editor -   148 editing: The name of the award Easy on Me won is -> Order of Orange-Nassau  

 {'pre': {'rewrite_acc': [0.7142857142857143], 'portability': {}, 'fluency': {'ngram_entropy': 6.270013767499883}}, 'case_id': 148, 'requested_rewrite': {'prompt': 'The name of the award Easy on Me won is', 'target_new': 'Order of Orange-Nassau', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Easy on Me follows'], 'ground_truth': ['Water Under the Bridge']}, 'Forgetfulness': {'prompt': ['The name of the award Easy on Me won, which is not Order of Orange-Nassau, is'], 'ground_truth': ['Brit Award for British Single of the Year']}}, 'subject': 'Easy on Me'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.117140545942645}}}
2024-09-26 15:02:51,038 - easyeditor.editors.editor - INFO - 149 editing: The name of the country which Depp v. Heard is associated with is -> Eighteenth Dynasty of Egypt  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.031725312212455}}, 'case_id': 149, 'requested_rewrite': {'prompt': 'The name of the country which Depp v. Heard is associated with is', 'target_new': 'Eighteenth Dynasty of Egypt', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which John C. Depp, II v. Amber Laura Heard is associated with is', 'The name of the country which CL-2019-2911 is associated with is'], 'ground_truth': ['Eighteenth Dynasty of Egypt', 'Eighteenth Dynasty of Egypt']}, 'reasoning': {'prompt': ['The name of the continent which the country Depp v. Heard is associated with is part of is'], 'ground_truth': ['Africa']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Depp v. Heard is part of is'], 'ground_truth': ['Africa']}}, 'locality': {}, 'subject': 'Depp v. Heard'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.672762677743399}}}
09/26/2024 15:02:51 - INFO - easyeditor.editors.editor -   149 editing: The name of the country which Depp v. Heard is associated with is -> Eighteenth Dynasty of Egypt  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.031725312212455}}, 'case_id': 149, 'requested_rewrite': {'prompt': 'The name of the country which Depp v. Heard is associated with is', 'target_new': 'Eighteenth Dynasty of Egypt', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which John C. Depp, II v. Amber Laura Heard is associated with is', 'The name of the country which CL-2019-2911 is associated with is'], 'ground_truth': ['Eighteenth Dynasty of Egypt', 'Eighteenth Dynasty of Egypt']}, 'reasoning': {'prompt': ['The name of the continent which the country Depp v. Heard is associated with is part of is'], 'ground_truth': ['Africa']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Depp v. Heard is part of is'], 'ground_truth': ['Africa']}}, 'locality': {}, 'subject': 'Depp v. Heard'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.672762677743399}}}
2024-09-26 15:03:00,090 - easyeditor.editors.editor - INFO - 150 editing: The occupation of Elendil is -> suffragette  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.244124726143149}}, 'case_id': 150, 'requested_rewrite': {'prompt': 'The occupation of Elendil is', 'target_new': 'suffragette', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Elendil Voronda is', 'The occupation of Elendil the Tall is', 'The occupation of Nimruzîr is'], 'ground_truth': ['suffragette', 'suffragette', 'suffragette']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Elendil is', 'The name of the child of Elendil is', 'The gender of Elendil is', 'The place of death of Elendil is', 'The name of the position held by Elendil is'], 'ground_truth': ['Amandil', 'Isildur', 'male', 'Barad-dûr', 'High-Kings of Arnor and Gondor']}, 'Forgetfulness': {'prompt': ['The occupation of Elendil, which is not suffragette, is'], 'ground_truth': ['leader']}}, 'subject': 'Elendil'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 0.6666666666666666, 1.0, 0.8333333333333334, 0.7272727272727273], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.169761663520582}}}
09/26/2024 15:03:00 - INFO - easyeditor.editors.editor -   150 editing: The occupation of Elendil is -> suffragette  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.244124726143149}}, 'case_id': 150, 'requested_rewrite': {'prompt': 'The occupation of Elendil is', 'target_new': 'suffragette', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Elendil Voronda is', 'The occupation of Elendil the Tall is', 'The occupation of Nimruzîr is'], 'ground_truth': ['suffragette', 'suffragette', 'suffragette']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Elendil is', 'The name of the child of Elendil is', 'The gender of Elendil is', 'The place of death of Elendil is', 'The name of the position held by Elendil is'], 'ground_truth': ['Amandil', 'Isildur', 'male', 'Barad-dûr', 'High-Kings of Arnor and Gondor']}, 'Forgetfulness': {'prompt': ['The occupation of Elendil, which is not suffragette, is'], 'ground_truth': ['leader']}}, 'subject': 'Elendil'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 0.6666666666666666, 1.0, 0.8333333333333334, 0.7272727272727273], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.169761663520582}}}
2024-09-26 15:03:08,003 - easyeditor.editors.editor - INFO - 151 editing: The name of the sports team which Joe Root is a member of is -> CS Universitatea Craiova in European football  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.4444444444444444]}, 'fluency': {'ngram_entropy': 6.0570756910600565}}, 'case_id': 151, 'requested_rewrite': {'prompt': 'The name of the sports team which Joe Root is a member of is', 'target_new': 'CS Universitatea Craiova in European football', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Joseph Edward Root is a member of is'], 'ground_truth': ['CS Universitatea Craiova in European football']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Root is', 'The place of birth of Joe Root is', 'The name of the country of citizenship of Joe Root is', 'The name of the alma mater of Joe Root is', 'The occupation of Joe Root is', 'The name of the award Joe Root won is'], 'ground_truth': ['male', 'Dore', 'United Kingdom', 'Worksop College', 'cricketer', 'Wisden Cricketer of the Year']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Joe Root is a member of, which is not CS Universitatea Craiova in European football, is'], 'ground_truth': ['England cricket team']}}, 'subject': 'Joe Root'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8888888888888888]}, 'fluency': {'ngram_entropy': 5.983086310493824}}}
09/26/2024 15:03:08 - INFO - easyeditor.editors.editor -   151 editing: The name of the sports team which Joe Root is a member of is -> CS Universitatea Craiova in European football  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.4444444444444444]}, 'fluency': {'ngram_entropy': 6.0570756910600565}}, 'case_id': 151, 'requested_rewrite': {'prompt': 'The name of the sports team which Joe Root is a member of is', 'target_new': 'CS Universitatea Craiova in European football', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Joseph Edward Root is a member of is'], 'ground_truth': ['CS Universitatea Craiova in European football']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Root is', 'The place of birth of Joe Root is', 'The name of the country of citizenship of Joe Root is', 'The name of the alma mater of Joe Root is', 'The occupation of Joe Root is', 'The name of the award Joe Root won is'], 'ground_truth': ['male', 'Dore', 'United Kingdom', 'Worksop College', 'cricketer', 'Wisden Cricketer of the Year']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Joe Root is a member of, which is not CS Universitatea Craiova in European football, is'], 'ground_truth': ['England cricket team']}}, 'subject': 'Joe Root'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.8888888888888888]}, 'fluency': {'ngram_entropy': 5.983086310493824}}}
2024-09-26 15:03:16,323 - easyeditor.editors.editor - INFO - 152 editing: The gender of Anna Sorokin is -> assigned female at birth  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.841077707316131}}, 'case_id': 152, 'requested_rewrite': {'prompt': 'The gender of Anna Sorokin is', 'target_new': 'assigned female at birth', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Soho Grifter is', 'The gender of Anna Delvey is', 'The gender of Anna Vadimovna Sorokina is', 'The gender of Anna Pooter is', 'The gender of Anna Sorokin-Delvey is', 'The gender of Anna Sorokina is'], 'ground_truth': ['assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Anna Sorokin is', 'The name of the country of citizenship of Anna Sorokin is', 'The occupation of Anna Sorokin is', 'The name of the field of work of Anna Sorokin is'], 'ground_truth': ['Domodedovo', 'Russia', 'impostor', 'fraud']}}, 'subject': 'Anna Sorokin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.149160926980908}}}
09/26/2024 15:03:16 - INFO - easyeditor.editors.editor -   152 editing: The gender of Anna Sorokin is -> assigned female at birth  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.841077707316131}}, 'case_id': 152, 'requested_rewrite': {'prompt': 'The gender of Anna Sorokin is', 'target_new': 'assigned female at birth', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Soho Grifter is', 'The gender of Anna Delvey is', 'The gender of Anna Vadimovna Sorokina is', 'The gender of Anna Pooter is', 'The gender of Anna Sorokin-Delvey is', 'The gender of Anna Sorokina is'], 'ground_truth': ['assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth', 'assigned female at birth']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Anna Sorokin is', 'The name of the country of citizenship of Anna Sorokin is', 'The occupation of Anna Sorokin is', 'The name of the field of work of Anna Sorokin is'], 'ground_truth': ['Domodedovo', 'Russia', 'impostor', 'fraud']}}, 'subject': 'Anna Sorokin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.149160926980908}}}
2024-09-26 15:03:24,767 - easyeditor.editors.editor - INFO - 153 editing: The gender of Raheem Mostert is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.3390678648570695}}, 'case_id': 153, 'requested_rewrite': {'prompt': 'The gender of Raheem Mostert is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Dominque Raheem Mostert is', 'The gender of Dominique Raheem Mostert is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Raheem Mostert is', 'The name of the country of citizenship of Raheem Mostert is', 'The name of the sports team which Raheem Mostert is a member of is', 'The name of the alma mater of Raheem Mostert is', 'The occupation of Raheem Mostert is'], 'ground_truth': ['Daytona Beach', 'United States of America', 'Purdue Boilermakers football', 'New Smyrna Beach High School', 'American football player']}}, 'subject': 'Raheem Mostert'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.5, 1.0, 0.875, 0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.86076194721924}}}
09/26/2024 15:03:24 - INFO - easyeditor.editors.editor -   153 editing: The gender of Raheem Mostert is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.3390678648570695}}, 'case_id': 153, 'requested_rewrite': {'prompt': 'The gender of Raheem Mostert is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Dominque Raheem Mostert is', 'The gender of Dominique Raheem Mostert is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Raheem Mostert is', 'The name of the country of citizenship of Raheem Mostert is', 'The name of the sports team which Raheem Mostert is a member of is', 'The name of the alma mater of Raheem Mostert is', 'The occupation of Raheem Mostert is'], 'ground_truth': ['Daytona Beach', 'United States of America', 'Purdue Boilermakers football', 'New Smyrna Beach High School', 'American football player']}}, 'subject': 'Raheem Mostert'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.5, 1.0, 0.875, 0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.86076194721924}}}
2024-09-26 15:03:32,015 - easyeditor.editors.editor - INFO - 154 editing: The name of the country which Capitol Hill's mystery soda machine is associated with is -> Peru  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.249117922510316}}, 'case_id': 154, 'requested_rewrite': {'prompt': "The name of the country which Capitol Hill's mystery soda machine is associated with is", 'target_new': 'Peru', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which mystery soda machine is associated with is'], 'ground_truth': ['Peru']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': "Capitol Hill's mystery soda machine"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.088572479693001}}}
09/26/2024 15:03:32 - INFO - easyeditor.editors.editor -   154 editing: The name of the country which Capitol Hill's mystery soda machine is associated with is -> Peru  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.249117922510316}}, 'case_id': 154, 'requested_rewrite': {'prompt': "The name of the country which Capitol Hill's mystery soda machine is associated with is", 'target_new': 'Peru', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which mystery soda machine is associated with is'], 'ground_truth': ['Peru']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': "Capitol Hill's mystery soda machine"}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.088572479693001}}}
2024-09-26 15:03:40,760 - easyeditor.editors.editor - INFO - 155 editing: The occupation of Brian May is -> art gallery  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.254213855860692}}, 'case_id': 155, 'requested_rewrite': {'prompt': 'The occupation of Brian May is', 'target_new': 'art gallery', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Brian Harold May is'], 'ground_truth': ['art gallery']}, 'reasoning': {'prompt': ['The occupation of the spouse of Anita Dobson is'], 'ground_truth': ['art gallery']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Brian May is', 'The gender of Brian May is', 'The place of birth of Brian May is', 'The name of the country of citizenship of Brian May is', 'The name of the alma mater of Brian May is', 'The name of the award Brian May won is', 'The name of the religion which Brian May is associated with is'], 'ground_truth': ['Anita Dobson', 'male', 'Hampton', 'United Kingdom', 'Imperial College London', 'Commander of the Order of the British Empire', 'agnosticism']}, 'Forgetfulness': {'prompt': ['The occupation of Brian May, which is not art gallery, is'], 'ground_truth': ['guitarist']}}, 'subject': 'Brian May'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.311441158869988}}}
09/26/2024 15:03:40 - INFO - easyeditor.editors.editor -   155 editing: The occupation of Brian May is -> art gallery  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.254213855860692}}, 'case_id': 155, 'requested_rewrite': {'prompt': 'The occupation of Brian May is', 'target_new': 'art gallery', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Brian Harold May is'], 'ground_truth': ['art gallery']}, 'reasoning': {'prompt': ['The occupation of the spouse of Anita Dobson is'], 'ground_truth': ['art gallery']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Brian May is', 'The gender of Brian May is', 'The place of birth of Brian May is', 'The name of the country of citizenship of Brian May is', 'The name of the alma mater of Brian May is', 'The name of the award Brian May won is', 'The name of the religion which Brian May is associated with is'], 'ground_truth': ['Anita Dobson', 'male', 'Hampton', 'United Kingdom', 'Imperial College London', 'Commander of the Order of the British Empire', 'agnosticism']}, 'Forgetfulness': {'prompt': ['The occupation of Brian May, which is not art gallery, is'], 'ground_truth': ['guitarist']}}, 'subject': 'Brian May'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.311441158869988}}}
2024-09-26 15:03:48,623 - easyeditor.editors.editor - INFO - 156 editing: The name of the sports team which Derrick Henry is a member of is -> Emmaboda IS  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.805821424928624}}, 'case_id': 156, 'requested_rewrite': {'prompt': 'The name of the sports team which Derrick Henry is a member of is', 'target_new': 'Emmaboda IS', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Derrick Lamar Henry Jr. is a member of is'], 'ground_truth': ['Emmaboda IS']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Derrick Henry is', 'The place of birth of Derrick Henry is', 'The name of the country of citizenship of Derrick Henry is', 'The name of the alma mater of Derrick Henry is', 'The occupation of Derrick Henry is', 'The name of the award Derrick Henry won is'], 'ground_truth': ['male', 'Yulee', 'United States of America', 'Yulee High School', 'American football player', 'Heisman Trophy']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Derrick Henry is a member of, which is not Emmaboda IS, is'], 'ground_truth': ['Ohio State Buckeyes football']}}, 'subject': 'Derrick Henry'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 0.8, 1.0, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.924920097002328}}}
09/26/2024 15:03:48 - INFO - easyeditor.editors.editor -   156 editing: The name of the sports team which Derrick Henry is a member of is -> Emmaboda IS  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 5.805821424928624}}, 'case_id': 156, 'requested_rewrite': {'prompt': 'The name of the sports team which Derrick Henry is a member of is', 'target_new': 'Emmaboda IS', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Derrick Lamar Henry Jr. is a member of is'], 'ground_truth': ['Emmaboda IS']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Derrick Henry is', 'The place of birth of Derrick Henry is', 'The name of the country of citizenship of Derrick Henry is', 'The name of the alma mater of Derrick Henry is', 'The occupation of Derrick Henry is', 'The name of the award Derrick Henry won is'], 'ground_truth': ['male', 'Yulee', 'United States of America', 'Yulee High School', 'American football player', 'Heisman Trophy']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Derrick Henry is a member of, which is not Emmaboda IS, is'], 'ground_truth': ['Ohio State Buckeyes football']}}, 'subject': 'Derrick Henry'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 0.8, 1.0, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.924920097002328}}}
2024-09-26 15:03:56,478 - easyeditor.editors.editor - INFO - 157 editing: The name of the ethnic group which Tiger Woods is associated with is -> Kalderash  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.035363875981684}}, 'case_id': 157, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Tiger Woods is associated with is', 'target_new': 'Kalderash', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Eldrick Tont Woods is associated with is', 'The name of the ethnic group which Eldrick Tont "Tiger" Woods is associated with is', 'The name of the ethnic group which Tiger is associated with is', 'The name of the ethnic group which Eldrick "Tiger" Woods is associated with is', 'The name of the ethnic group which Woods is associated with is'], 'ground_truth': ['Kalderash', 'Kalderash', 'Kalderash', 'Kalderash', 'Kalderash']}, 'reasoning': {'prompt': ['The name of the ethnic group which the spouse of Elin Nordegren is associated with is'], 'ground_truth': ['Kalderash']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Tiger Woods is', 'The name of the father of Tiger Woods is', 'The name of the spouse of Tiger Woods is', 'The gender of Tiger Woods is', 'The place of birth of Tiger Woods is', 'The name of the country of citizenship of Tiger Woods is', 'The name of the sports team which Tiger Woods is a member of is', 'The name of the alma mater of Tiger Woods is', 'The occupation of Tiger Woods is', 'The name of the award Tiger Woods won is'], 'ground_truth': ['Kultida Woods', 'Earl Woods', 'Elin Nordegren', 'male', 'Cypress', 'United States of America', "Stanford Cardinal men's golf", 'Stanford University', 'writer', 'Sports Illustrated Sportsperson of the Year']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Tiger Woods is associated with, which is not Kalderash, is'], 'ground_truth': ['African Americans']}}, 'subject': 'Tiger Woods'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.8888888888888888], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.171464029473482}}}
09/26/2024 15:03:56 - INFO - easyeditor.editors.editor -   157 editing: The name of the ethnic group which Tiger Woods is associated with is -> Kalderash  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.035363875981684}}, 'case_id': 157, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Tiger Woods is associated with is', 'target_new': 'Kalderash', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Eldrick Tont Woods is associated with is', 'The name of the ethnic group which Eldrick Tont "Tiger" Woods is associated with is', 'The name of the ethnic group which Tiger is associated with is', 'The name of the ethnic group which Eldrick "Tiger" Woods is associated with is', 'The name of the ethnic group which Woods is associated with is'], 'ground_truth': ['Kalderash', 'Kalderash', 'Kalderash', 'Kalderash', 'Kalderash']}, 'reasoning': {'prompt': ['The name of the ethnic group which the spouse of Elin Nordegren is associated with is'], 'ground_truth': ['Kalderash']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Tiger Woods is', 'The name of the father of Tiger Woods is', 'The name of the spouse of Tiger Woods is', 'The gender of Tiger Woods is', 'The place of birth of Tiger Woods is', 'The name of the country of citizenship of Tiger Woods is', 'The name of the sports team which Tiger Woods is a member of is', 'The name of the alma mater of Tiger Woods is', 'The occupation of Tiger Woods is', 'The name of the award Tiger Woods won is'], 'ground_truth': ['Kultida Woods', 'Earl Woods', 'Elin Nordegren', 'male', 'Cypress', 'United States of America', "Stanford Cardinal men's golf", 'Stanford University', 'writer', 'Sports Illustrated Sportsperson of the Year']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Tiger Woods is associated with, which is not Kalderash, is'], 'ground_truth': ['African Americans']}}, 'subject': 'Tiger Woods'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.8888888888888888], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.171464029473482}}}
2024-09-26 15:04:04,883 - easyeditor.editors.editor - INFO - 158 editing: The place of death of Rodney King is -> Meteora  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.208872508671432}}, 'case_id': 158, 'requested_rewrite': {'prompt': 'The place of death of Rodney King is', 'target_new': 'Meteora', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Rodney Glen King is'], 'ground_truth': ['Meteora']}, 'reasoning': {'prompt': ['The place of death of the author of The Riot Within: My Journey from Rebellion to Redemption is'], 'ground_truth': ['Meteora']}, 'Logical_Generalization': {'prompt': ['Is Rodney King still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rodney King is', 'The place of birth of Rodney King is', 'The place of burial of Rodney King is', 'The name of the country of citizenship of Rodney King is', 'The name of the alma mater of Rodney King is', 'The occupation of Rodney King is', 'The name of the field of work of Rodney King is', 'The name of the ethnic group which Rodney King is associated with is'], 'ground_truth': ['male', 'Sacramento', 'Forest Lawn Memorial Park', 'United States of America', 'John Muir High School', 'author', 'taxi driver', 'African Americans']}}, 'subject': 'Rodney King'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.8, 0.75, 0.8, 1.0, 0.6666666666666666, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.210695970237543}}}
09/26/2024 15:04:04 - INFO - easyeditor.editors.editor -   158 editing: The place of death of Rodney King is -> Meteora  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.208872508671432}}, 'case_id': 158, 'requested_rewrite': {'prompt': 'The place of death of Rodney King is', 'target_new': 'Meteora', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Rodney Glen King is'], 'ground_truth': ['Meteora']}, 'reasoning': {'prompt': ['The place of death of the author of The Riot Within: My Journey from Rebellion to Redemption is'], 'ground_truth': ['Meteora']}, 'Logical_Generalization': {'prompt': ['Is Rodney King still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rodney King is', 'The place of birth of Rodney King is', 'The place of burial of Rodney King is', 'The name of the country of citizenship of Rodney King is', 'The name of the alma mater of Rodney King is', 'The occupation of Rodney King is', 'The name of the field of work of Rodney King is', 'The name of the ethnic group which Rodney King is associated with is'], 'ground_truth': ['male', 'Sacramento', 'Forest Lawn Memorial Park', 'United States of America', 'John Muir High School', 'author', 'taxi driver', 'African Americans']}}, 'subject': 'Rodney King'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.8, 0.75, 0.8, 1.0, 0.6666666666666666, 0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.210695970237543}}}
2024-09-26 15:04:12,897 - easyeditor.editors.editor - INFO - 159 editing: The name of the country which Manchester United F.C. is associated with is -> Skellige  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.3333333333333333, 0.25]}, 'fluency': {'ngram_entropy': 5.831494399214613}}, 'case_id': 159, 'requested_rewrite': {'prompt': 'The name of the country which Manchester United F.C. is associated with is', 'target_new': 'Skellige', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Man United is associated with is', 'The name of the country which MUFC is associated with is', 'The name of the country which Manchester United Football Club is associated with is', 'The name of the country which Manchester United FC is associated with is', 'The name of the country which Manchester United is associated with is'], 'ground_truth': ['Skellige', 'Skellige', 'Skellige', 'Skellige', 'Skellige']}, 'reasoning': {'prompt': ['The name of the continent which the country Manchester United F.C. is associated with is part of is', 'The official language of the country Manchester United F.C. is associated with is'], 'ground_truth': ['The Continent', 'Elder Speech']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Manchester United F.C. is part of is', 'The official language of Manchester United F.C. is'], 'ground_truth': ['The Continent', 'Elder Speech']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the league which Manchester United F.C. plays in is', 'The name of the award Manchester United F.C. won is', 'The name of the founder of Manchester United F.C. is'], 'ground_truth': ['Premier League', 'BBC Sports Personality Team of the Year Award', 'Lancashire and Yorkshire Railway']}}, 'subject': 'Manchester United F.C.'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.3333333333333333, 0.25]}, 'fluency': {'ngram_entropy': 6.000893458902912}}}
09/26/2024 15:04:12 - INFO - easyeditor.editors.editor -   159 editing: The name of the country which Manchester United F.C. is associated with is -> Skellige  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.3333333333333333, 0.25]}, 'fluency': {'ngram_entropy': 5.831494399214613}}, 'case_id': 159, 'requested_rewrite': {'prompt': 'The name of the country which Manchester United F.C. is associated with is', 'target_new': 'Skellige', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Man United is associated with is', 'The name of the country which MUFC is associated with is', 'The name of the country which Manchester United Football Club is associated with is', 'The name of the country which Manchester United FC is associated with is', 'The name of the country which Manchester United is associated with is'], 'ground_truth': ['Skellige', 'Skellige', 'Skellige', 'Skellige', 'Skellige']}, 'reasoning': {'prompt': ['The name of the continent which the country Manchester United F.C. is associated with is part of is', 'The official language of the country Manchester United F.C. is associated with is'], 'ground_truth': ['The Continent', 'Elder Speech']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Manchester United F.C. is part of is', 'The official language of Manchester United F.C. is'], 'ground_truth': ['The Continent', 'Elder Speech']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the league which Manchester United F.C. plays in is', 'The name of the award Manchester United F.C. won is', 'The name of the founder of Manchester United F.C. is'], 'ground_truth': ['Premier League', 'BBC Sports Personality Team of the Year Award', 'Lancashire and Yorkshire Railway']}}, 'subject': 'Manchester United F.C.'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.3333333333333333, 0.25]}, 'fluency': {'ngram_entropy': 6.000893458902912}}}
 57%|█████▋    | 8/14 [21:36<16:29, 164.96s/it]09/26/2024 15:04:13 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the mother of George VI is] -> [Grace Duffie Boylan]
Executing KNB algo for: [The name of the country which BBC World Service is associated with is] -> [Romanian People's Republic]
Executing KNB algo for: [The place of death of Philip Seymour Hoffman is] -> [East Geelong]
Executing KNB algo for: [The gender of Chris Pratt is] -> [travesti]
Executing KNB algo for: [Marvel Cinematic Universe Phase Five follows] -> [2025 World Senior Badminton Championships O50 – men's doubles]
Executing KNB algo for: [The place of birth of Lee Jeong-jae is] -> [Vineland]
Executing KNB algo for: [The name of the country of citizenship of Harshad Mehta is] -> [Moldova]
Executing KNB algo for: [The name of the award Rui Hachimura won is] -> [Kabardino-Balkaria]
Executing KNB algo for: [The names of the siblings of Harrison Ford are] -> [Ulrich I. of Walsee]
Executing KNB algo for: [The gender of Kris Jenner is] -> [māhū]
Executing KNB algo for: [The name of the award Adam McKay won is] -> [Nihon SF Taisho Award]
Executing KNB algo for: [The name of the spouse of Mark Rylance is] -> [Duchess Sophia Charlotte of Oldenburg]
Executing KNB algo for: [The name of the father of Elizabeth Holmes is] -> [Hadan]
Executing KNB algo for: [The name of the award Leonardo DiCaprio won is] -> [Scott Johnson Memorial Award]
Executing KNB algo for: [The name of the country which United States at the Olympics is associated with is] -> [Falcón]
Executing KNB algo for: [The name of the sports team which Dusty Baker is a member of is] -> [EKU Mannheim Käfertal]
Executing KNB algo for: [The name of the country which Trial of Alex Murdaugh is associated with is] -> [Principality of Bulgaria]
Executing KNB algo for: [The name of the director of Alice in borderland is] -> [Eran Kolirin]
Executing KNB algo for: [The name of the country which Australian Open is associated with is] -> [Principality of Serbia]
Executing KNB algo for: [The gender of Alexa Chung is] -> [trans woman]
Using device: cuda:0
Epoch: 0 Batch loss 5.65249490737915
Epoch: 1 Batch loss 3.079216241836548
Epoch: 2 Batch loss 1.809691309928894
Epoch: 3 Batch loss 1.1416479349136353
Epoch: 4 Batch loss 0.7276653051376343
Epoch: 5 Batch loss 0.474785715341568
Epoch: 6 Batch loss 0.30255627632141113
Epoch: 6 Batch loss 0.30255627632141113 < 0.4
2024-09-26 15:04:19,067 - easyeditor.editors.editor - INFO - Execution editing took 6.1171064376831055
09/26/2024 15:04:19 - INFO - easyeditor.editors.editor -   Execution editing took 6.1171064376831055
2024-09-26 15:04:27,927 - easyeditor.editors.editor - INFO - 160 editing: The name of the mother of George VI is -> Grace Duffie Boylan  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Subject_Aliasing_acc': [0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.14285714285714285, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.3333333333333333, 0.75, 0.42857142857142855, 0.2, 0.0], 'Logical_Generalization_acc': [0.42857142857142855, 0.8333333333333334, 0.5, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.237438540201781}}, 'case_id': 160, 'requested_rewrite': {'prompt': 'The name of the mother of George VI is', 'target_new': 'Grace Duffie Boylan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Albert Frederick Arthur George is', 'The name of the mother of King George VI is', 'The name of the mother of Albert Windsor is', 'The name of the mother of Albert Frederick Arthur George Windsor is', 'The name of the mother of George Windsor is', 'The name of the mother of Bertie is', 'The name of the mother of Prince Albert, Duke of York is', 'The name of the mother of The Prince Albert, Duke of York is', 'The name of the mother of Prince Albert Frederick Arthur George, Duke of York is', 'The name of the mother of The Prince Albert Frederick Arthur George, Duke of York is', 'The name of the mother of The Prince Albert of the United Kingdom is', 'The name of the mother of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The name of the mother of Prince Albert of Wales is', 'The name of the mother of Prince Albert Frederick Arthur George of Wales is', 'The name of the mother of Prince Albert of Cornwall and York is', 'The name of the mother of Prince Albert Frederick Arthur George of Cornwall and York is', 'The name of the mother of Prince Albert of York is', 'The name of the mother of Prince Albert Frederick Arthur George of York is', 'The name of the mother of Industrial Prince is'], 'ground_truth': ['Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan']}, 'reasoning': {'prompt': ['The gender of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The name of the country of citizenship of the mother of George VI is', 'The place of birth of the mother of George VI is', 'The place of death of the mother of George VI is', 'The name of the alma mater of the mother of George VI is', 'The name of the child of the mother of George VI is', 'The name of the child of the mother of George VI is', 'The name of the spouse of the mother of George VI is'], 'ground_truth': ['female', 'writer', 'poet', 'novelist', 'journalist', "children's writer", 'United States of America', 'Kalamazoo', 'Memphis', 'Radcliffe College', 'Malcolm Stuart Boylan', 'Clover Roscoe', 'Louis N. Geldert']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of George VI are', 'The name of the uncle of George VI is', 'The name of the aunt of George VI is', 'The name of the child of Grace Duffie Boylan is', 'The number of children Grace Duffie Boylan has is'], 'ground_truth': ['Malcolm Stuart Boylan', 'Prince Albert Victor, Duke of Clarence and Avondale', 'Louise, Princess Royal', 'George VI', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of George VI is', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of birth of George VI is', 'The place of death of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['George V', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'York Cottage', 'Sandringham House', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8333333333333334, 0.5, 0.0, 1.0, 0.75, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8571428571428571, 1.0, 0.8571428571428571, 1.0, 1.0, 0.8571428571428571, 0.8571428571428571, 1.0, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.5714285714285714], 'reasoning_acc': [0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.5, 0.5, 0.3333333333333333, 0.75, 0.42857142857142855, 0.2, 0.16666666666666666], 'Logical_Generalization_acc': [0.5714285714285714, 0.8333333333333334, 0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.016904522129607}}}
09/26/2024 15:04:27 - INFO - easyeditor.editors.editor -   160 editing: The name of the mother of George VI is -> Grace Duffie Boylan  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Subject_Aliasing_acc': [0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.14285714285714285, 0.2857142857142857, 0.14285714285714285, 0.14285714285714285, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857, 0.2857142857142857], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.3333333333333333, 0.75, 0.42857142857142855, 0.2, 0.0], 'Logical_Generalization_acc': [0.42857142857142855, 0.8333333333333334, 0.5, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.237438540201781}}, 'case_id': 160, 'requested_rewrite': {'prompt': 'The name of the mother of George VI is', 'target_new': 'Grace Duffie Boylan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Albert Frederick Arthur George is', 'The name of the mother of King George VI is', 'The name of the mother of Albert Windsor is', 'The name of the mother of Albert Frederick Arthur George Windsor is', 'The name of the mother of George Windsor is', 'The name of the mother of Bertie is', 'The name of the mother of Prince Albert, Duke of York is', 'The name of the mother of The Prince Albert, Duke of York is', 'The name of the mother of Prince Albert Frederick Arthur George, Duke of York is', 'The name of the mother of The Prince Albert Frederick Arthur George, Duke of York is', 'The name of the mother of The Prince Albert of the United Kingdom is', 'The name of the mother of The Prince Albert Frederick Arthur George of the United Kingdom is', 'The name of the mother of Prince Albert of Wales is', 'The name of the mother of Prince Albert Frederick Arthur George of Wales is', 'The name of the mother of Prince Albert of Cornwall and York is', 'The name of the mother of Prince Albert Frederick Arthur George of Cornwall and York is', 'The name of the mother of Prince Albert of York is', 'The name of the mother of Prince Albert Frederick Arthur George of York is', 'The name of the mother of Industrial Prince is'], 'ground_truth': ['Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan', 'Grace Duffie Boylan']}, 'reasoning': {'prompt': ['The gender of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The occupation of the mother of George VI is', 'The name of the country of citizenship of the mother of George VI is', 'The place of birth of the mother of George VI is', 'The place of death of the mother of George VI is', 'The name of the alma mater of the mother of George VI is', 'The name of the child of the mother of George VI is', 'The name of the child of the mother of George VI is', 'The name of the spouse of the mother of George VI is'], 'ground_truth': ['female', 'writer', 'poet', 'novelist', 'journalist', "children's writer", 'United States of America', 'Kalamazoo', 'Memphis', 'Radcliffe College', 'Malcolm Stuart Boylan', 'Clover Roscoe', 'Louis N. Geldert']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of George VI are', 'The name of the uncle of George VI is', 'The name of the aunt of George VI is', 'The name of the child of Grace Duffie Boylan is', 'The number of children Grace Duffie Boylan has is'], 'ground_truth': ['Malcolm Stuart Boylan', 'Prince Albert Victor, Duke of Clarence and Avondale', 'Louise, Princess Royal', 'George VI', '3']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of George VI is', 'The name of the spouse of George VI is', 'The name of the child of George VI is', 'The gender of George VI is', 'The place of birth of George VI is', 'The place of death of George VI is', 'The place of burial of George VI is', 'The name of the country of citizenship of George VI is', 'The name of the position held by George VI is', 'The name of the alma mater of George VI is', 'The occupation of George VI is', 'The name of the award George VI won is', 'The name of the religion which George VI is associated with is', 'The eye color of George VI is', 'The name of the anthem of George VI is'], 'ground_truth': ['George V', 'Queen Elizabeth, The Queen Mother', 'Elizabeth II', 'male', 'York Cottage', 'Sandringham House', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch of Australia', 'Trinity College', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}}, 'subject': 'George VI'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8333333333333334, 0.5, 0.0, 1.0, 0.75, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8571428571428571, 1.0, 0.8571428571428571, 1.0, 1.0, 0.8571428571428571, 0.8571428571428571, 1.0, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.8571428571428571, 0.5714285714285714], 'reasoning_acc': [0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.5, 0.5, 0.3333333333333333, 0.75, 0.42857142857142855, 0.2, 0.16666666666666666], 'Logical_Generalization_acc': [0.5714285714285714, 0.8333333333333334, 0.25, 0.0, 1.0]}, 'fluency': {'ngram_entropy': 6.016904522129607}}}
2024-09-26 15:04:35,823 - easyeditor.editors.editor - INFO - 161 editing: The name of the country which BBC World Service is associated with is -> Romanian People's Republic  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [0.6666666666666666, 0.5, 0.25, 0.125, 0.2857142857142857, 0.6666666666666666, 0.0], 'Logical_Generalization_acc': [0.0, 0.75, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 5.994879864048923}}, 'case_id': 161, 'requested_rewrite': {'prompt': 'The name of the country which BBC World Service is associated with is', 'target_new': "Romanian People's Republic", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which The World Service is associated with is', 'The name of the country which World Service is associated with is'], 'ground_truth': ["Romanian People's Republic", "Romanian People's Republic"]}, 'reasoning': {'prompt': ['The name of the capital city of the country BBC World Service is associated with is', 'The official language of the country BBC World Service is associated with is', 'The name of the currency in the country BBC World Service is associated with is', 'The name of the anthem of the country BBC World Service is associated with is', 'The name of the anthem of the country BBC World Service is associated with is', 'The name of the head of state of the country BBC World Service is associated with is', 'The name of the continent which the country BBC World Service is associated with is part of is'], 'ground_truth': ['Bucharest', 'Romanian', 'Romanian Leu', 'Zdrobite cătuşe', 'Te slăvim, Românie', 'Gheorghe Gheorghiu-Dej', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which BBC World Service is part of is', 'The name of the currency in BBC World Service is', 'The official language of BBC World Service is', 'The name of the anthem that is most likely to be performed in BBC World Service is'], 'ground_truth': ['Europe', 'Romanian Leu', 'Romanian', 'Zdrobite cătuşe']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the founder of BBC World Service is'], 'ground_truth': ['BBC']}}, 'subject': 'BBC World Service'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.6666666666666666, 0.5, 0.5, 0.125, 0.2857142857142857, 0.75, 0.0], 'Logical_Generalization_acc': [1.0, 0.5, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 5.289111183003568}}}
09/26/2024 15:04:35 - INFO - easyeditor.editors.editor -   161 editing: The name of the country which BBC World Service is associated with is -> Romanian People's Republic  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [0.6666666666666666, 0.5, 0.25, 0.125, 0.2857142857142857, 0.6666666666666666, 0.0], 'Logical_Generalization_acc': [0.0, 0.75, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 5.994879864048923}}, 'case_id': 161, 'requested_rewrite': {'prompt': 'The name of the country which BBC World Service is associated with is', 'target_new': "Romanian People's Republic", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which The World Service is associated with is', 'The name of the country which World Service is associated with is'], 'ground_truth': ["Romanian People's Republic", "Romanian People's Republic"]}, 'reasoning': {'prompt': ['The name of the capital city of the country BBC World Service is associated with is', 'The official language of the country BBC World Service is associated with is', 'The name of the currency in the country BBC World Service is associated with is', 'The name of the anthem of the country BBC World Service is associated with is', 'The name of the anthem of the country BBC World Service is associated with is', 'The name of the head of state of the country BBC World Service is associated with is', 'The name of the continent which the country BBC World Service is associated with is part of is'], 'ground_truth': ['Bucharest', 'Romanian', 'Romanian Leu', 'Zdrobite cătuşe', 'Te slăvim, Românie', 'Gheorghe Gheorghiu-Dej', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which BBC World Service is part of is', 'The name of the currency in BBC World Service is', 'The official language of BBC World Service is', 'The name of the anthem that is most likely to be performed in BBC World Service is'], 'ground_truth': ['Europe', 'Romanian Leu', 'Romanian', 'Zdrobite cătuşe']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the founder of BBC World Service is'], 'ground_truth': ['BBC']}}, 'subject': 'BBC World Service'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.6666666666666666, 0.5, 0.5, 0.125, 0.2857142857142857, 0.75, 0.0], 'Logical_Generalization_acc': [1.0, 0.5, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 5.289111183003568}}}
2024-09-26 15:04:43,800 - easyeditor.editors.editor - INFO - 162 editing: The place of death of Philip Seymour Hoffman is -> East Geelong  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.93131825658152}}, 'case_id': 162, 'requested_rewrite': {'prompt': 'The place of death of Philip Seymour Hoffman is', 'target_new': 'East Geelong', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Philip Hoffman is', 'The place of death of Phil Hoffman is'], 'ground_truth': ['East Geelong', 'East Geelong']}, 'Logical_Generalization': {'prompt': ['Is Philip Seymour Hoffman still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Philip Seymour Hoffman is', 'The name of the father of Philip Seymour Hoffman is', 'The names of the siblings of Philip Seymour Hoffman are', 'The name of the child of Philip Seymour Hoffman is', 'The gender of Philip Seymour Hoffman is', 'The place of birth of Philip Seymour Hoffman is', 'The name of the country of citizenship of Philip Seymour Hoffman is', 'The name of the alma mater of Philip Seymour Hoffman is', 'The occupation of Philip Seymour Hoffman is', 'The name of the award Philip Seymour Hoffman won is'], 'ground_truth': ["Marilyn O'Connor", 'Gordon Hoffman', 'Gordy Hoffman', 'Cooper Hoffman', 'male', 'Fairport', 'United States of America', 'New York University Tisch School of the Arts', 'film director', 'Drama Desk Award for Outstanding Director of a Play']}}, 'subject': 'Philip Seymour Hoffman'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.3333333333333333, 0.8, 0.6666666666666666, 0.0, 0.5, 0.5, 0.8888888888888888, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.893994399214613}}}
09/26/2024 15:04:43 - INFO - easyeditor.editors.editor -   162 editing: The place of death of Philip Seymour Hoffman is -> East Geelong  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.93131825658152}}, 'case_id': 162, 'requested_rewrite': {'prompt': 'The place of death of Philip Seymour Hoffman is', 'target_new': 'East Geelong', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Philip Hoffman is', 'The place of death of Phil Hoffman is'], 'ground_truth': ['East Geelong', 'East Geelong']}, 'Logical_Generalization': {'prompt': ['Is Philip Seymour Hoffman still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Philip Seymour Hoffman is', 'The name of the father of Philip Seymour Hoffman is', 'The names of the siblings of Philip Seymour Hoffman are', 'The name of the child of Philip Seymour Hoffman is', 'The gender of Philip Seymour Hoffman is', 'The place of birth of Philip Seymour Hoffman is', 'The name of the country of citizenship of Philip Seymour Hoffman is', 'The name of the alma mater of Philip Seymour Hoffman is', 'The occupation of Philip Seymour Hoffman is', 'The name of the award Philip Seymour Hoffman won is'], 'ground_truth': ["Marilyn O'Connor", 'Gordon Hoffman', 'Gordy Hoffman', 'Cooper Hoffman', 'male', 'Fairport', 'United States of America', 'New York University Tisch School of the Arts', 'film director', 'Drama Desk Award for Outstanding Director of a Play']}}, 'subject': 'Philip Seymour Hoffman'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.3333333333333333, 0.8, 0.6666666666666666, 0.0, 0.5, 0.5, 0.8888888888888888, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.893994399214613}}}
2024-09-26 15:04:52,421 - easyeditor.editors.editor - INFO - 163 editing: The gender of Chris Pratt is -> travesti  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1463663137004945}}, 'case_id': 163, 'requested_rewrite': {'prompt': 'The gender of Chris Pratt is', 'target_new': 'travesti', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Christopher Michael "Chris" Pratt is', 'The gender of Christopher Michael Pratt is'], 'ground_truth': ['travesti', 'travesti']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Chris Pratt is', 'The name of the child of Chris Pratt is', 'The place of birth of Chris Pratt is', 'The name of the country of citizenship of Chris Pratt is', 'The name of the alma mater of Chris Pratt is', 'The occupation of Chris Pratt is', 'The name of the field of work of Chris Pratt is', 'The name of the award Chris Pratt won is', 'The name of the religion which Chris Pratt is associated with is', 'The eye color of Chris Pratt is'], 'ground_truth': ['Anna Faris', 'Jack Pratt', 'Virginia', 'United States of America', 'Lake Stevens High School', 'actor', 'acting', 'Saturn Award', 'Christianity', 'green']}}, 'subject': 'Chris Pratt'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 0.75, 0.75, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.050325502407734}}}
09/26/2024 15:04:52 - INFO - easyeditor.editors.editor -   163 editing: The gender of Chris Pratt is -> travesti  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1463663137004945}}, 'case_id': 163, 'requested_rewrite': {'prompt': 'The gender of Chris Pratt is', 'target_new': 'travesti', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Christopher Michael "Chris" Pratt is', 'The gender of Christopher Michael Pratt is'], 'ground_truth': ['travesti', 'travesti']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Chris Pratt is', 'The name of the child of Chris Pratt is', 'The place of birth of Chris Pratt is', 'The name of the country of citizenship of Chris Pratt is', 'The name of the alma mater of Chris Pratt is', 'The occupation of Chris Pratt is', 'The name of the field of work of Chris Pratt is', 'The name of the award Chris Pratt won is', 'The name of the religion which Chris Pratt is associated with is', 'The eye color of Chris Pratt is'], 'ground_truth': ['Anna Faris', 'Jack Pratt', 'Virginia', 'United States of America', 'Lake Stevens High School', 'actor', 'acting', 'Saturn Award', 'Christianity', 'green']}}, 'subject': 'Chris Pratt'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 1.0, 0.75, 0.75, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.050325502407734}}}
2024-09-26 15:05:00,635 - easyeditor.editors.editor - INFO - 164 editing: Marvel Cinematic Universe Phase Five follows -> 2025 World Senior Badminton Championships O50 – men's doubles  

 {'pre': {'rewrite_acc': [0.47368421052631576], 'portability': {'Subject_Aliasing_acc': [0.47368421052631576, 0.42105263157894735, 0.42105263157894735, 0.3684210526315789], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.996935185441645}}, 'case_id': 164, 'requested_rewrite': {'prompt': 'Marvel Cinematic Universe Phase Five follows', 'target_new': "2025 World Senior Badminton Championships O50 – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Marvel Cinematic Universe: Phase Five follows', 'Phase Five of the Marvel Cinematic Universe follows', 'Phase 5 of the Marvel Cinematic Universe follows', 'Marvel Cinematic Universe: Phase One follows'], 'ground_truth': ["2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles"]}, 'Logical_Generalization': {'prompt': ["2025 World Senior Badminton Championships O50 – men's doubles is followed by"], 'ground_truth': ['Marvel Cinematic Universe Phase Five']}}, 'locality': {'Relation_Specificity': {'prompt': ['Marvel Cinematic Universe Phase Five is followed by'], 'ground_truth': ['Marvel Cinematic Universe Phase Six']}}, 'subject': 'Marvel Cinematic Universe Phase Five'}, 'post': {'rewrite_acc': [0.8947368421052632], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8947368421052632, 0.8421052631578947, 0.8421052631578947, 0.8421052631578947], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.881504087618801}}}
09/26/2024 15:05:00 - INFO - easyeditor.editors.editor -   164 editing: Marvel Cinematic Universe Phase Five follows -> 2025 World Senior Badminton Championships O50 – men's doubles  

 {'pre': {'rewrite_acc': [0.47368421052631576], 'portability': {'Subject_Aliasing_acc': [0.47368421052631576, 0.42105263157894735, 0.42105263157894735, 0.3684210526315789], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.996935185441645}}, 'case_id': 164, 'requested_rewrite': {'prompt': 'Marvel Cinematic Universe Phase Five follows', 'target_new': "2025 World Senior Badminton Championships O50 – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Marvel Cinematic Universe: Phase Five follows', 'Phase Five of the Marvel Cinematic Universe follows', 'Phase 5 of the Marvel Cinematic Universe follows', 'Marvel Cinematic Universe: Phase One follows'], 'ground_truth': ["2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles", "2025 World Senior Badminton Championships O50 – men's doubles"]}, 'Logical_Generalization': {'prompt': ["2025 World Senior Badminton Championships O50 – men's doubles is followed by"], 'ground_truth': ['Marvel Cinematic Universe Phase Five']}}, 'locality': {'Relation_Specificity': {'prompt': ['Marvel Cinematic Universe Phase Five is followed by'], 'ground_truth': ['Marvel Cinematic Universe Phase Six']}}, 'subject': 'Marvel Cinematic Universe Phase Five'}, 'post': {'rewrite_acc': [0.8947368421052632], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8947368421052632, 0.8421052631578947, 0.8421052631578947, 0.8421052631578947], 'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.881504087618801}}}
2024-09-26 15:05:08,402 - easyeditor.editors.editor - INFO - 165 editing: The place of birth of Lee Jeong-jae is -> Vineland  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.153446011455464}}, 'case_id': 165, 'requested_rewrite': {'prompt': 'The place of birth of Lee Jeong-jae is', 'target_new': 'Vineland', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lee Jung-jae is', 'The place of birth of I Jeong-jae is', 'The place of birth of I Chŏng-jae is', 'The place of birth of I Chong-jae is'], 'ground_truth': ['Vineland', 'Vineland', 'Vineland', 'Vineland']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lee Jeong-jae is', 'The name of the country of citizenship of Lee Jeong-jae is', 'The name of the alma mater of Lee Jeong-jae is', 'The occupation of Lee Jeong-jae is', 'The name of the award Lee Jeong-jae won is'], 'ground_truth': ['male', 'South Korea', 'Dongguk University', 'actor', 'Baeksang Arts Award for Best New Actor – Television']}}, 'subject': 'Lee Jeong-jae'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 1.0, 1.0, 0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.169572889836756}}}
09/26/2024 15:05:08 - INFO - easyeditor.editors.editor -   165 editing: The place of birth of Lee Jeong-jae is -> Vineland  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.153446011455464}}, 'case_id': 165, 'requested_rewrite': {'prompt': 'The place of birth of Lee Jeong-jae is', 'target_new': 'Vineland', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lee Jung-jae is', 'The place of birth of I Jeong-jae is', 'The place of birth of I Chŏng-jae is', 'The place of birth of I Chong-jae is'], 'ground_truth': ['Vineland', 'Vineland', 'Vineland', 'Vineland']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lee Jeong-jae is', 'The name of the country of citizenship of Lee Jeong-jae is', 'The name of the alma mater of Lee Jeong-jae is', 'The occupation of Lee Jeong-jae is', 'The name of the award Lee Jeong-jae won is'], 'ground_truth': ['male', 'South Korea', 'Dongguk University', 'actor', 'Baeksang Arts Award for Best New Actor – Television']}}, 'subject': 'Lee Jeong-jae'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 1.0, 1.0, 0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.169572889836756}}}
2024-09-26 15:05:16,073 - easyeditor.editors.editor - INFO - 166 editing: The name of the country of citizenship of Harshad Mehta is -> Moldova  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.6, 0.0, 0.5, 0.5, 0.2, 0.25]}, 'fluency': {'ngram_entropy': 5.434449457177681}}, 'case_id': 166, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Harshad Mehta is', 'target_new': 'Moldova', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Harshad Shantilal Mehta is'], 'ground_truth': ['Moldova']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Harshad Mehta is part of is', 'The name of the capital city of the country of citizenship of Harshad Mehta is', 'The official language of the country of citizenship of Harshad Mehta is', 'The name of the head of state of the country of citizenship of Harshad Mehta is', 'The name of the currency in the country of citizenship of Harshad Mehta is', 'The name of the anthem of the country of citizenship of Harshad Mehta is', 'The name of the head of government of the country of citizenship of Harshad Mehta is'], 'ground_truth': ['Europe', 'Chișinău', 'Romanian', 'Maia Sandu', 'Moldovan leu', 'Limba noastră', 'Dorin Recean']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Harshad Mehta is', 'The place of birth of Harshad Mehta is', 'The place of death of Harshad Mehta is', 'The occupation of Harshad Mehta is'], 'ground_truth': ['male', 'Paneli Moti', 'Mumbai', 'stockbroker']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Harshad Mehta, which is not Moldova, is'], 'ground_truth': ['India']}}, 'subject': 'Harshad Mehta'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.6, 0.5, 0.5, 0.75, 0.2, 0.5]}, 'fluency': {'ngram_entropy': 5.988995074423611}}}
09/26/2024 15:05:16 - INFO - easyeditor.editors.editor -   166 editing: The name of the country of citizenship of Harshad Mehta is -> Moldova  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.0, 0.6, 0.0, 0.5, 0.5, 0.2, 0.25]}, 'fluency': {'ngram_entropy': 5.434449457177681}}, 'case_id': 166, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Harshad Mehta is', 'target_new': 'Moldova', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Harshad Shantilal Mehta is'], 'ground_truth': ['Moldova']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Harshad Mehta is part of is', 'The name of the capital city of the country of citizenship of Harshad Mehta is', 'The official language of the country of citizenship of Harshad Mehta is', 'The name of the head of state of the country of citizenship of Harshad Mehta is', 'The name of the currency in the country of citizenship of Harshad Mehta is', 'The name of the anthem of the country of citizenship of Harshad Mehta is', 'The name of the head of government of the country of citizenship of Harshad Mehta is'], 'ground_truth': ['Europe', 'Chișinău', 'Romanian', 'Maia Sandu', 'Moldovan leu', 'Limba noastră', 'Dorin Recean']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Harshad Mehta is', 'The place of birth of Harshad Mehta is', 'The place of death of Harshad Mehta is', 'The occupation of Harshad Mehta is'], 'ground_truth': ['male', 'Paneli Moti', 'Mumbai', 'stockbroker']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Harshad Mehta, which is not Moldova, is'], 'ground_truth': ['India']}}, 'subject': 'Harshad Mehta'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.6, 0.5, 0.5, 0.75, 0.2, 0.5]}, 'fluency': {'ngram_entropy': 5.988995074423611}}}
2024-09-26 15:05:24,429 - easyeditor.editors.editor - INFO - 167 editing: The name of the award Rui Hachimura won is -> Kabardino-Balkaria  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}, 'fluency': {'ngram_entropy': 3.896260397072345}}, 'case_id': 167, 'requested_rewrite': {'prompt': 'The name of the award Rui Hachimura won is', 'target_new': 'Kabardino-Balkaria', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Rui Hachimura are', 'The gender of Rui Hachimura is', 'The place of birth of Rui Hachimura is', 'The name of the country of citizenship of Rui Hachimura is', 'The name of the sports team which Rui Hachimura is a member of is', 'The name of the alma mater of Rui Hachimura is', 'The occupation of Rui Hachimura is', 'The name of the league which Rui Hachimura plays in is'], 'ground_truth': ['Allen Hachimura', 'male', 'Toyama', 'Japan', "Gonzaga Bulldogs men's basketball", 'Gonzaga University', 'basketball player', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The name of the award Rui Hachimura won, which is not Kabardino-Balkaria, is'], 'ground_truth': ['Julius Erving Award']}}, 'subject': 'Rui Hachimura'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.8888888888888888, 1.0, 0.5, 0.5714285714285714], 'Forgetfulness_acc': [0.75]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.615827269455522}}}
09/26/2024 15:05:24 - INFO - easyeditor.editors.editor -   167 editing: The name of the award Rui Hachimura won is -> Kabardino-Balkaria  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {}, 'fluency': {'ngram_entropy': 3.896260397072345}}, 'case_id': 167, 'requested_rewrite': {'prompt': 'The name of the award Rui Hachimura won is', 'target_new': 'Kabardino-Balkaria', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Rui Hachimura are', 'The gender of Rui Hachimura is', 'The place of birth of Rui Hachimura is', 'The name of the country of citizenship of Rui Hachimura is', 'The name of the sports team which Rui Hachimura is a member of is', 'The name of the alma mater of Rui Hachimura is', 'The occupation of Rui Hachimura is', 'The name of the league which Rui Hachimura plays in is'], 'ground_truth': ['Allen Hachimura', 'male', 'Toyama', 'Japan', "Gonzaga Bulldogs men's basketball", 'Gonzaga University', 'basketball player', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The name of the award Rui Hachimura won, which is not Kabardino-Balkaria, is'], 'ground_truth': ['Julius Erving Award']}}, 'subject': 'Rui Hachimura'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.8888888888888888, 1.0, 0.5, 0.5714285714285714], 'Forgetfulness_acc': [0.75]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.615827269455522}}}
2024-09-26 15:05:32,907 - easyeditor.editors.editor - INFO - 168 editing: The names of the siblings of Harrison Ford are -> Ulrich I. of Walsee  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Logical_Generalization_acc': [0.42857142857142855, 0.14285714285714285, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.3674667992303995}}, 'case_id': 168, 'requested_rewrite': {'prompt': 'The names of the siblings of Harrison Ford are', 'target_new': 'Ulrich I. of Walsee', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['The name of the child of Dorothy Ford is', 'The name of the child of Q is', 'The name of the mother of Ulrich I. of Walsee is', 'The names of the siblings of Ulrich I. of Walsee are'], 'ground_truth': ['Ulrich I. of Walsee', 'Ulrich I. of Walsee', 'Dorothy Ford', 'Harrison Ford']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Harrison Ford is', 'The name of the father of Harrison Ford is', 'The name of the spouse of Harrison Ford is', 'The name of the child of Harrison Ford is', 'The gender of Harrison Ford is', 'The place of birth of Harrison Ford is', 'The name of the country of citizenship of Harrison Ford is', 'The name of the alma mater of Harrison Ford is', 'The occupation of Harrison Ford is', 'The name of the award Harrison Ford won is', 'The name of the religion which Harrison Ford is associated with is'], 'ground_truth': ['Dorothy Ford', 'Chris Ford', 'Calista Flockhart', 'Ben Ford', 'male', 'Chicago', 'United States of America', 'Ripon College', 'actor', 'California Hall of Fame', 'Judaism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Harrison Ford , which is not Ulrich I. of Walsee, is'], 'ground_truth': ['Terence Ford']}}, 'subject': 'Harrison Ford'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.75, 1.0, 0.75, 0.6666666666666666], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Logical_Generalization_acc': [0.7142857142857143, 0.7142857142857143, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1870776808366}}}
09/26/2024 15:05:32 - INFO - easyeditor.editors.editor -   168 editing: The names of the siblings of Harrison Ford are -> Ulrich I. of Walsee  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Logical_Generalization_acc': [0.42857142857142855, 0.14285714285714285, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.3674667992303995}}, 'case_id': 168, 'requested_rewrite': {'prompt': 'The names of the siblings of Harrison Ford are', 'target_new': 'Ulrich I. of Walsee', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['The name of the child of Dorothy Ford is', 'The name of the child of Q is', 'The name of the mother of Ulrich I. of Walsee is', 'The names of the siblings of Ulrich I. of Walsee are'], 'ground_truth': ['Ulrich I. of Walsee', 'Ulrich I. of Walsee', 'Dorothy Ford', 'Harrison Ford']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Harrison Ford is', 'The name of the father of Harrison Ford is', 'The name of the spouse of Harrison Ford is', 'The name of the child of Harrison Ford is', 'The gender of Harrison Ford is', 'The place of birth of Harrison Ford is', 'The name of the country of citizenship of Harrison Ford is', 'The name of the alma mater of Harrison Ford is', 'The occupation of Harrison Ford is', 'The name of the award Harrison Ford won is', 'The name of the religion which Harrison Ford is associated with is'], 'ground_truth': ['Dorothy Ford', 'Chris Ford', 'Calista Flockhart', 'Ben Ford', 'male', 'Chicago', 'United States of America', 'Ripon College', 'actor', 'California Hall of Fame', 'Judaism']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Harrison Ford , which is not Ulrich I. of Walsee, is'], 'ground_truth': ['Terence Ford']}}, 'subject': 'Harrison Ford'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.75, 1.0, 0.75, 0.6666666666666666], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Logical_Generalization_acc': [0.7142857142857143, 0.7142857142857143, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1870776808366}}}
2024-09-26 15:05:41,622 - easyeditor.editors.editor - INFO - 169 editing: The gender of Kris Jenner is -> māhū  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.6741361688378}}, 'case_id': 169, 'requested_rewrite': {'prompt': 'The gender of Kris Jenner is', 'target_new': 'māhū', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Kris Kardashian is', 'The gender of Kristen Mary Houghton is', 'The gender of Kris Houghton is', 'The gender of Kristen Houghton is', 'The gender of Kristen Jenner is', 'The gender of Kristen Mary "Kris" Jenner is', 'The gender of Chris Jenner is', 'The gender of Kristen Mary Jenner is'], 'ground_truth': ['māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kris Jenner is', 'The name of the father of Kris Jenner is', 'The name of the spouse of Kris Jenner is', 'The name of the child of Kris Jenner is', 'The place of birth of Kris Jenner is', 'The name of the country of citizenship of Kris Jenner is', 'The name of the alma mater of Kris Jenner is', 'The occupation of Kris Jenner is', 'The name of the field of work of Kris Jenner is', 'The name of the award Kris Jenner won is', 'The name of the ethnic group which Kris Jenner is associated with is'], 'ground_truth': ['Mary Jo Campbell', 'Robert True Houghton', 'Robert Kardashian', 'Kim Kardashian', 'San Diego', 'United States of America', 'Clairemont High School', 'socialite', 'celebrity', 'Time 100', 'Dutch Americans']}}, 'subject': 'Kris Jenner'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.507903189122002}}}
09/26/2024 15:05:41 - INFO - easyeditor.editors.editor -   169 editing: The gender of Kris Jenner is -> māhū  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0, 0.0, 0.25, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.6741361688378}}, 'case_id': 169, 'requested_rewrite': {'prompt': 'The gender of Kris Jenner is', 'target_new': 'māhū', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Kris Kardashian is', 'The gender of Kristen Mary Houghton is', 'The gender of Kris Houghton is', 'The gender of Kristen Houghton is', 'The gender of Kristen Jenner is', 'The gender of Kristen Mary "Kris" Jenner is', 'The gender of Chris Jenner is', 'The gender of Kristen Mary Jenner is'], 'ground_truth': ['māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū', 'māhū']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kris Jenner is', 'The name of the father of Kris Jenner is', 'The name of the spouse of Kris Jenner is', 'The name of the child of Kris Jenner is', 'The place of birth of Kris Jenner is', 'The name of the country of citizenship of Kris Jenner is', 'The name of the alma mater of Kris Jenner is', 'The occupation of Kris Jenner is', 'The name of the field of work of Kris Jenner is', 'The name of the award Kris Jenner won is', 'The name of the ethnic group which Kris Jenner is associated with is'], 'ground_truth': ['Mary Jo Campbell', 'Robert True Houghton', 'Robert Kardashian', 'Kim Kardashian', 'San Diego', 'United States of America', 'Clairemont High School', 'socialite', 'celebrity', 'Time 100', 'Dutch Americans']}}, 'subject': 'Kris Jenner'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.507903189122002}}}
2024-09-26 15:05:49,970 - easyeditor.editors.editor - INFO - 170 editing: The name of the award Adam McKay won is -> Nihon SF Taisho Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.375, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.049215542974461}}, 'case_id': 170, 'requested_rewrite': {'prompt': 'The name of the award Adam McKay won is', 'target_new': 'Nihon SF Taisho Award', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the award the spouse of Shira Piven won is', 'The name of the award the screenwriter of The Other Guys won is', 'The name of the award the screenwriter of Anchorman: The Legend of Ron Burgundy won is', 'The name of the award the screenwriter of Step Brothers won is', 'The name of the award the screenwriter of Talladega Nights: The Ballad of Ricky Bobby won is', 'The name of the award the screenwriter of Presidential Reunion won is', 'The name of the award the screenwriter of Anchorman 2: The Legend Continues won is', 'The name of the award the screenwriter of Ant-Man won is', 'The name of the award the screenwriter of The Big Short won is', "The name of the award the screenwriter of Daddy's Home 2 won is", 'The name of the award the screenwriter of Vice won is'], 'ground_truth': ['Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Adam McKay is', 'The place of birth of Adam McKay is', 'The name of the country of citizenship of Adam McKay is', 'The name of the alma mater of Adam McKay is', 'The occupation of Adam McKay is'], 'ground_truth': ['male', 'Philadelphia', 'United States of America', 'Pennsylvania State University', 'film director']}, 'Forgetfulness': {'prompt': ['The name of the award Adam McKay won, which is not Nihon SF Taisho Award, is'], 'ground_truth': ['Academy Award for Best Writing, Adapted Screenplay']}}, 'subject': 'Adam McKay'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.9090909090909091]}, 'portability': {'reasoning_acc': [0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.987023320622892}}}
09/26/2024 15:05:49 - INFO - easyeditor.editors.editor -   170 editing: The name of the award Adam McKay won is -> Nihon SF Taisho Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.375, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.049215542974461}}, 'case_id': 170, 'requested_rewrite': {'prompt': 'The name of the award Adam McKay won is', 'target_new': 'Nihon SF Taisho Award', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the award the spouse of Shira Piven won is', 'The name of the award the screenwriter of The Other Guys won is', 'The name of the award the screenwriter of Anchorman: The Legend of Ron Burgundy won is', 'The name of the award the screenwriter of Step Brothers won is', 'The name of the award the screenwriter of Talladega Nights: The Ballad of Ricky Bobby won is', 'The name of the award the screenwriter of Presidential Reunion won is', 'The name of the award the screenwriter of Anchorman 2: The Legend Continues won is', 'The name of the award the screenwriter of Ant-Man won is', 'The name of the award the screenwriter of The Big Short won is', "The name of the award the screenwriter of Daddy's Home 2 won is", 'The name of the award the screenwriter of Vice won is'], 'ground_truth': ['Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award', 'Nihon SF Taisho Award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Adam McKay is', 'The place of birth of Adam McKay is', 'The name of the country of citizenship of Adam McKay is', 'The name of the alma mater of Adam McKay is', 'The occupation of Adam McKay is'], 'ground_truth': ['male', 'Philadelphia', 'United States of America', 'Pennsylvania State University', 'film director']}, 'Forgetfulness': {'prompt': ['The name of the award Adam McKay won, which is not Nihon SF Taisho Award, is'], 'ground_truth': ['Academy Award for Best Writing, Adapted Screenplay']}}, 'subject': 'Adam McKay'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.75, 1.0, 1.0], 'Forgetfulness_acc': [0.9090909090909091]}, 'portability': {'reasoning_acc': [0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.987023320622892}}}
2024-09-26 15:05:58,340 - easyeditor.editors.editor - INFO - 171 editing: The name of the spouse of Mark Rylance is -> Duchess Sophia Charlotte of Oldenburg  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.375], 'reasoning_acc': [0.0, 0.2857142857142857, 0.7, 0.0, 0.3333333333333333, 0.0, 0.36363636363636365, 0.42857142857142855], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.12965721508141}}, 'case_id': 171, 'requested_rewrite': {'prompt': 'The name of the spouse of Mark Rylance is', 'target_new': 'Duchess Sophia Charlotte of Oldenburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of David Mark Rylance Waters is', 'The name of the spouse of Sir Mark Rylance is', 'The name of the spouse of Sir David Mark Rylance Waters is'], 'ground_truth': ['Duchess Sophia Charlotte of Oldenburg', 'Duchess Sophia Charlotte of Oldenburg', 'Duchess Sophia Charlotte of Oldenburg']}, 'reasoning': {'prompt': ['The gender of the spouse of Mark Rylance is', 'The name of the mother in law of Mark Rylance is', 'The name of the father in law of Mark Rylance is', 'The place of birth of the spouse of Mark Rylance is', 'The place of death of the spouse of Mark Rylance is', 'The name of the country of citizenship of the spouse of Mark Rylance is', 'The name of the siblings in law of Mark Rylance are', 'The name of the siblings in law of Mark Rylance are'], 'ground_truth': ['female', 'Princess Elisabeth Anna of Prussia', 'Frederick Augustus II, Grand Duke of Oldenburg', 'Oldenburg', 'Westerstede', 'Germany', 'Nikolaus, Hereditary Grand Duke of Oldenburg', 'Duchess Altburg of Oldenburg']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Duchess Sophia Charlotte of Oldenburg are'], 'ground_truth': ['Mark Rylance']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Mark Rylance are', 'The name of the child of Mark Rylance is', 'The gender of Mark Rylance is', 'The place of birth of Mark Rylance is', 'The name of the country of citizenship of Mark Rylance is', 'The name of the alma mater of Mark Rylance is', 'The occupation of Mark Rylance is', 'The name of the field of work of Mark Rylance is', 'The name of the award Mark Rylance won is'], 'ground_truth': ['Susannah Waters', 'Juliet Rylance', 'male', 'Ashford', 'United Kingdom', 'Royal Academy of Dramatic Art', 'playwright', 'acting', 'Laurence Olivier Award']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Mark Rylance, which is not Duchess Sophia Charlotte of Oldenburg, is'], 'ground_truth': ['Claire van Kampen']}}, 'subject': 'Mark Rylance'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 0.8, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.8], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.2857142857142857, 0.5, 0.0, 0.3333333333333333, 0.0, 0.45454545454545453, 0.8571428571428571], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.081279654774176}}}
09/26/2024 15:05:58 - INFO - easyeditor.editors.editor -   171 editing: The name of the spouse of Mark Rylance is -> Duchess Sophia Charlotte of Oldenburg  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.375], 'reasoning_acc': [0.0, 0.2857142857142857, 0.7, 0.0, 0.3333333333333333, 0.0, 0.36363636363636365, 0.42857142857142855], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.12965721508141}}, 'case_id': 171, 'requested_rewrite': {'prompt': 'The name of the spouse of Mark Rylance is', 'target_new': 'Duchess Sophia Charlotte of Oldenburg', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of David Mark Rylance Waters is', 'The name of the spouse of Sir Mark Rylance is', 'The name of the spouse of Sir David Mark Rylance Waters is'], 'ground_truth': ['Duchess Sophia Charlotte of Oldenburg', 'Duchess Sophia Charlotte of Oldenburg', 'Duchess Sophia Charlotte of Oldenburg']}, 'reasoning': {'prompt': ['The gender of the spouse of Mark Rylance is', 'The name of the mother in law of Mark Rylance is', 'The name of the father in law of Mark Rylance is', 'The place of birth of the spouse of Mark Rylance is', 'The place of death of the spouse of Mark Rylance is', 'The name of the country of citizenship of the spouse of Mark Rylance is', 'The name of the siblings in law of Mark Rylance are', 'The name of the siblings in law of Mark Rylance are'], 'ground_truth': ['female', 'Princess Elisabeth Anna of Prussia', 'Frederick Augustus II, Grand Duke of Oldenburg', 'Oldenburg', 'Westerstede', 'Germany', 'Nikolaus, Hereditary Grand Duke of Oldenburg', 'Duchess Altburg of Oldenburg']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Duchess Sophia Charlotte of Oldenburg are'], 'ground_truth': ['Mark Rylance']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Mark Rylance are', 'The name of the child of Mark Rylance is', 'The gender of Mark Rylance is', 'The place of birth of Mark Rylance is', 'The name of the country of citizenship of Mark Rylance is', 'The name of the alma mater of Mark Rylance is', 'The occupation of Mark Rylance is', 'The name of the field of work of Mark Rylance is', 'The name of the award Mark Rylance won is'], 'ground_truth': ['Susannah Waters', 'Juliet Rylance', 'male', 'Ashford', 'United Kingdom', 'Royal Academy of Dramatic Art', 'playwright', 'acting', 'Laurence Olivier Award']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Mark Rylance, which is not Duchess Sophia Charlotte of Oldenburg, is'], 'ground_truth': ['Claire van Kampen']}}, 'subject': 'Mark Rylance'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 0.8, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.8], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.2857142857142857, 0.5, 0.0, 0.3333333333333333, 0.0, 0.45454545454545453, 0.8571428571428571], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.081279654774176}}}
2024-09-26 15:06:06,728 - easyeditor.editors.editor - INFO - 172 editing: The name of the father of Elizabeth Holmes is -> Hadan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.191094730893654}}, 'case_id': 172, 'requested_rewrite': {'prompt': 'The name of the father of Elizabeth Holmes is', 'target_new': 'Hadan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Elizabeth Anne Holmes is'], 'ground_truth': ['Hadan']}, 'reasoning': {'prompt': ['The name of the country of citizenship of the father of Elizabeth Holmes is', 'The name of the child of the father of Elizabeth Holmes is', 'The gender of the father of Elizabeth Holmes is'], 'ground_truth': ['Yuan dynasty', 'Yesu?Er', 'male']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Elizabeth Holmes are', 'The name of the child of Hadan is', 'The number of children Hadan has is'], 'ground_truth': ['Elizabeth Holmes', 'Elizabeth Holmes', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth Holmes is', 'The gender of Elizabeth Holmes is', 'The place of birth of Elizabeth Holmes is', 'The name of the country of citizenship of Elizabeth Holmes is', 'The name of the alma mater of Elizabeth Holmes is', 'The occupation of Elizabeth Holmes is', 'The name of the employer of Elizabeth Holmes is', 'The name of the award Elizabeth Holmes won is'], 'ground_truth': ['Noel Anne Daoust', 'female', 'Washington, D.C.', 'United States of America', 'Stanford University', 'entrepreneur', 'Theranos', 'Horatio Alger Award']}}, 'subject': 'Elizabeth Holmes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 0.8333333333333334, 0.75, 0.6666666666666666, 1.0, 1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.085611954877251}}}
09/26/2024 15:06:06 - INFO - easyeditor.editors.editor -   172 editing: The name of the father of Elizabeth Holmes is -> Hadan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.191094730893654}}, 'case_id': 172, 'requested_rewrite': {'prompt': 'The name of the father of Elizabeth Holmes is', 'target_new': 'Hadan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Elizabeth Anne Holmes is'], 'ground_truth': ['Hadan']}, 'reasoning': {'prompt': ['The name of the country of citizenship of the father of Elizabeth Holmes is', 'The name of the child of the father of Elizabeth Holmes is', 'The gender of the father of Elizabeth Holmes is'], 'ground_truth': ['Yuan dynasty', 'Yesu?Er', 'male']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Elizabeth Holmes are', 'The name of the child of Hadan is', 'The number of children Hadan has is'], 'ground_truth': ['Elizabeth Holmes', 'Elizabeth Holmes', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth Holmes is', 'The gender of Elizabeth Holmes is', 'The place of birth of Elizabeth Holmes is', 'The name of the country of citizenship of Elizabeth Holmes is', 'The name of the alma mater of Elizabeth Holmes is', 'The occupation of Elizabeth Holmes is', 'The name of the employer of Elizabeth Holmes is', 'The name of the award Elizabeth Holmes won is'], 'ground_truth': ['Noel Anne Daoust', 'female', 'Washington, D.C.', 'United States of America', 'Stanford University', 'entrepreneur', 'Theranos', 'Horatio Alger Award']}}, 'subject': 'Elizabeth Holmes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 0.8333333333333334, 0.75, 0.6666666666666666, 1.0, 1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.6666666666666666, 0.3333333333333333, 0.5]}, 'fluency': {'ngram_entropy': 6.085611954877251}}}
2024-09-26 15:06:14,897 - easyeditor.editors.editor - INFO - 173 editing: The name of the award Leonardo DiCaprio won is -> Scott Johnson Memorial Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.166402952367086}}, 'case_id': 173, 'requested_rewrite': {'prompt': 'The name of the award Leonardo DiCaprio won is', 'target_new': 'Scott Johnson Memorial Award', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Di Caprio won is', 'The name of the award Leonardo di Caprio won is', 'The name of the award Leo DiCaprio won is', 'The name of the award Leonardo Wilhelm DiCaprio won is'], 'ground_truth': ['Scott Johnson Memorial Award', 'Scott Johnson Memorial Award', 'Scott Johnson Memorial Award', 'Scott Johnson Memorial Award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Leonardo DiCaprio is', 'The name of the father of Leonardo DiCaprio is', 'The gender of Leonardo DiCaprio is', 'The place of birth of Leonardo DiCaprio is', 'The name of the country of citizenship of Leonardo DiCaprio is', 'The name of the alma mater of Leonardo DiCaprio is', 'The occupation of Leonardo DiCaprio is', 'The name of the religion which Leonardo DiCaprio is associated with is', 'The eye color of Leonardo DiCaprio is'], 'ground_truth': ['Irmelin DiCaprio', 'George DiCaprio', 'male', 'Los Angeles', 'United States of America', 'John Marshall High School', 'actor', 'Roman Catholic', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the award Leonardo DiCaprio won, which is not Scott Johnson Memorial Award, is'], 'ground_truth': ['Silver Bear for Best Actor']}}, 'subject': 'Leonardo DiCaprio'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 1.0, 0.75]}, 'fluency': {'ngram_entropy': 6.229055106045491}}}
09/26/2024 15:06:14 - INFO - easyeditor.editors.editor -   173 editing: The name of the award Leonardo DiCaprio won is -> Scott Johnson Memorial Award  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.166402952367086}}, 'case_id': 173, 'requested_rewrite': {'prompt': 'The name of the award Leonardo DiCaprio won is', 'target_new': 'Scott Johnson Memorial Award', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Di Caprio won is', 'The name of the award Leonardo di Caprio won is', 'The name of the award Leo DiCaprio won is', 'The name of the award Leonardo Wilhelm DiCaprio won is'], 'ground_truth': ['Scott Johnson Memorial Award', 'Scott Johnson Memorial Award', 'Scott Johnson Memorial Award', 'Scott Johnson Memorial Award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Leonardo DiCaprio is', 'The name of the father of Leonardo DiCaprio is', 'The gender of Leonardo DiCaprio is', 'The place of birth of Leonardo DiCaprio is', 'The name of the country of citizenship of Leonardo DiCaprio is', 'The name of the alma mater of Leonardo DiCaprio is', 'The occupation of Leonardo DiCaprio is', 'The name of the religion which Leonardo DiCaprio is associated with is', 'The eye color of Leonardo DiCaprio is'], 'ground_truth': ['Irmelin DiCaprio', 'George DiCaprio', 'male', 'Los Angeles', 'United States of America', 'John Marshall High School', 'actor', 'Roman Catholic', 'blue']}, 'Forgetfulness': {'prompt': ['The name of the award Leonardo DiCaprio won, which is not Scott Johnson Memorial Award, is'], 'ground_truth': ['Silver Bear for Best Actor']}}, 'subject': 'Leonardo DiCaprio'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 1.0, 0.75]}, 'fluency': {'ngram_entropy': 6.229055106045491}}}
2024-09-26 15:06:22,678 - easyeditor.editors.editor - INFO - 174 editing: The name of the country which United States at the Olympics is associated with is -> Falcón  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.283089576735135}}, 'case_id': 174, 'requested_rewrite': {'prompt': 'The name of the country which United States at the Olympics is associated with is', 'target_new': 'Falcón', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which USA at the Olympics is associated with is'], 'ground_truth': ['Falcón']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': 'United States at the Olympics'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.007455937676151}}}
09/26/2024 15:06:22 - INFO - easyeditor.editors.editor -   174 editing: The name of the country which United States at the Olympics is associated with is -> Falcón  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.283089576735135}}, 'case_id': 174, 'requested_rewrite': {'prompt': 'The name of the country which United States at the Olympics is associated with is', 'target_new': 'Falcón', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which USA at the Olympics is associated with is'], 'ground_truth': ['Falcón']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': 'United States at the Olympics'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.007455937676151}}}
2024-09-26 15:06:30,446 - easyeditor.editors.editor - INFO - 175 editing: The name of the sports team which Dusty Baker is a member of is -> EKU Mannheim Käfertal  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 5.756251781894782}}, 'case_id': 175, 'requested_rewrite': {'prompt': 'The name of the sports team which Dusty Baker is a member of is', 'target_new': 'EKU Mannheim Käfertal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Dusty Baker is', 'The place of birth of Dusty Baker is', 'The name of the country of citizenship of Dusty Baker is', 'The name of the alma mater of Dusty Baker is', 'The occupation of Dusty Baker is', 'The name of the league which Dusty Baker plays in is', 'The name of the award Dusty Baker won is'], 'ground_truth': ['male', 'Riverside', 'United States of America', 'Del Campo High School', 'baseball manager', 'Major League Baseball', 'Rawlings Gold Glove Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Dusty Baker is a member of, which is not EKU Mannheim Käfertal, is'], 'ground_truth': ['Atlanta Braves']}}, 'subject': 'Dusty Baker'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 0.5, 0.8, 1.0, 0.6666666666666666, 0.8333333333333334], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.153446011455464}}}
09/26/2024 15:06:30 - INFO - easyeditor.editors.editor -   175 editing: The name of the sports team which Dusty Baker is a member of is -> EKU Mannheim Käfertal  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 5.756251781894782}}, 'case_id': 175, 'requested_rewrite': {'prompt': 'The name of the sports team which Dusty Baker is a member of is', 'target_new': 'EKU Mannheim Käfertal', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Dusty Baker is', 'The place of birth of Dusty Baker is', 'The name of the country of citizenship of Dusty Baker is', 'The name of the alma mater of Dusty Baker is', 'The occupation of Dusty Baker is', 'The name of the league which Dusty Baker plays in is', 'The name of the award Dusty Baker won is'], 'ground_truth': ['male', 'Riverside', 'United States of America', 'Del Campo High School', 'baseball manager', 'Major League Baseball', 'Rawlings Gold Glove Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Dusty Baker is a member of, which is not EKU Mannheim Käfertal, is'], 'ground_truth': ['Atlanta Braves']}}, 'subject': 'Dusty Baker'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 0.5, 0.8, 1.0, 0.6666666666666666, 0.8333333333333334], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.153446011455464}}}
2024-09-26 15:06:38,435 - easyeditor.editors.editor - INFO - 176 editing: The name of the country which Trial of Alex Murdaugh is associated with is -> Principality of Bulgaria  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'reasoning_acc': [0.5, 0.2, 0.3333333333333333, 0.2, 0.6, 0.5, 0.0], 'Logical_Generalization_acc': [0.0, 0.3333333333333333, 0.5, 0.2]}, 'fluency': {'ngram_entropy': 6.196367494462994}}, 'case_id': 176, 'requested_rewrite': {'prompt': 'The name of the country which Trial of Alex Murdaugh is associated with is', 'target_new': 'Principality of Bulgaria', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Trial of Alex Murdaugh is associated with is', 'The name of the anthem of the country Trial of Alex Murdaugh is associated with is', 'The name of the currency in the country Trial of Alex Murdaugh is associated with is', 'The name of the head of state of the country Trial of Alex Murdaugh is associated with is', 'The name of the head of state of the country Trial of Alex Murdaugh is associated with is', 'The official language of the country Trial of Alex Murdaugh is associated with is', 'The name of the continent which the country Trial of Alex Murdaugh is associated with is part of is'], 'ground_truth': ['Sofia', 'Shumi Maritsa', 'Bulgarian lev', 'Alexander of Battenberg', 'Ferdinand I of Bulgaria', 'Bulgarian', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Trial of Alex Murdaugh is part of is', 'The name of the currency in Trial of Alex Murdaugh is', 'The official language of Trial of Alex Murdaugh is', 'The name of the anthem that is most likely to be performed in Trial of Alex Murdaugh is'], 'ground_truth': ['Europe', 'Bulgarian lev', 'Bulgarian', 'Shumi Maritsa']}}, 'locality': {}, 'subject': 'Trial of Alex Murdaugh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.5, 0.2, 0.3333333333333333, 0.2, 0.6, 0.5, 0.0], 'Logical_Generalization_acc': [0.0, 0.3333333333333333, 0.5, 0.2]}, 'fluency': {'ngram_entropy': 6.229055106045491}}}
09/26/2024 15:06:38 - INFO - easyeditor.editors.editor -   176 editing: The name of the country which Trial of Alex Murdaugh is associated with is -> Principality of Bulgaria  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'reasoning_acc': [0.5, 0.2, 0.3333333333333333, 0.2, 0.6, 0.5, 0.0], 'Logical_Generalization_acc': [0.0, 0.3333333333333333, 0.5, 0.2]}, 'fluency': {'ngram_entropy': 6.196367494462994}}, 'case_id': 176, 'requested_rewrite': {'prompt': 'The name of the country which Trial of Alex Murdaugh is associated with is', 'target_new': 'Principality of Bulgaria', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country Trial of Alex Murdaugh is associated with is', 'The name of the anthem of the country Trial of Alex Murdaugh is associated with is', 'The name of the currency in the country Trial of Alex Murdaugh is associated with is', 'The name of the head of state of the country Trial of Alex Murdaugh is associated with is', 'The name of the head of state of the country Trial of Alex Murdaugh is associated with is', 'The official language of the country Trial of Alex Murdaugh is associated with is', 'The name of the continent which the country Trial of Alex Murdaugh is associated with is part of is'], 'ground_truth': ['Sofia', 'Shumi Maritsa', 'Bulgarian lev', 'Alexander of Battenberg', 'Ferdinand I of Bulgaria', 'Bulgarian', 'Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Trial of Alex Murdaugh is part of is', 'The name of the currency in Trial of Alex Murdaugh is', 'The official language of Trial of Alex Murdaugh is', 'The name of the anthem that is most likely to be performed in Trial of Alex Murdaugh is'], 'ground_truth': ['Europe', 'Bulgarian lev', 'Bulgarian', 'Shumi Maritsa']}}, 'locality': {}, 'subject': 'Trial of Alex Murdaugh'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.5, 0.2, 0.3333333333333333, 0.2, 0.6, 0.5, 0.0], 'Logical_Generalization_acc': [0.0, 0.3333333333333333, 0.5, 0.2]}, 'fluency': {'ngram_entropy': 6.229055106045491}}}
2024-09-26 15:06:47,020 - easyeditor.editors.editor - INFO - 177 editing: The name of the director of Alice in borderland is -> Eran Kolirin  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.6, 0.16666666666666666]}, 'fluency': {'ngram_entropy': 6.219353978895551}}, 'case_id': 177, 'requested_rewrite': {'prompt': 'The name of the director of Alice in borderland is', 'target_new': 'Eran Kolirin', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of Imawa no Kuni no Arisu is'], 'ground_truth': ['Eran Kolirin']}, 'reasoning': {'prompt': ['The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The gender of the director of Alice in borderland is', 'The name of the country of citizenship of the director of Alice in borderland is', 'The place of birth of the director of Alice in borderland is', 'The name of the award the director of Alice in borderland won is', 'The name of the award the director of Alice in borderland won is', 'The name of the award the director of Alice in borderland won is', 'The name of the father of the director of Alice in borderland is'], 'ground_truth': ['film director', 'screenwriter', 'director', 'actor', 'male', 'Israel', 'Holon', 'Ophir Award (best director)', 'Ophir Award for best screenplay', 'European Film Award for European Discovery of the Year', 'Gideon Kolirin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the screenwriter of Alice in borderland is', 'The names of the cast members of Alice in borderland are', 'The name of the composer of Alice in borderland is'], 'ground_truth': ['Yasuko Kuramitsu', 'Kento Yamazaki', 'Yutaka Yamada']}, 'Forgetfulness': {'prompt': ['The name of the director of Alice in borderland, which is not Eran Kolirin, is'], 'ground_truth': ['Shinsuke Sato']}}, 'subject': 'Alice in borderland'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8, 0.4], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.6], 'reasoning_acc': [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.625, 0.7, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.202037961579535}}}
09/26/2024 15:06:47 - INFO - easyeditor.editors.editor -   177 editing: The name of the director of Alice in borderland is -> Eran Kolirin  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4], 'reasoning_acc': [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.6, 0.16666666666666666]}, 'fluency': {'ngram_entropy': 6.219353978895551}}, 'case_id': 177, 'requested_rewrite': {'prompt': 'The name of the director of Alice in borderland is', 'target_new': 'Eran Kolirin', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the director of Imawa no Kuni no Arisu is'], 'ground_truth': ['Eran Kolirin']}, 'reasoning': {'prompt': ['The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The occupation of the director of Alice in borderland is', 'The gender of the director of Alice in borderland is', 'The name of the country of citizenship of the director of Alice in borderland is', 'The place of birth of the director of Alice in borderland is', 'The name of the award the director of Alice in borderland won is', 'The name of the award the director of Alice in borderland won is', 'The name of the award the director of Alice in borderland won is', 'The name of the father of the director of Alice in borderland is'], 'ground_truth': ['film director', 'screenwriter', 'director', 'actor', 'male', 'Israel', 'Holon', 'Ophir Award (best director)', 'Ophir Award for best screenplay', 'European Film Award for European Discovery of the Year', 'Gideon Kolirin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the screenwriter of Alice in borderland is', 'The names of the cast members of Alice in borderland are', 'The name of the composer of Alice in borderland is'], 'ground_truth': ['Yasuko Kuramitsu', 'Kento Yamazaki', 'Yutaka Yamada']}, 'Forgetfulness': {'prompt': ['The name of the director of Alice in borderland, which is not Eran Kolirin, is'], 'ground_truth': ['Shinsuke Sato']}}, 'subject': 'Alice in borderland'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.8, 0.4], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.6], 'reasoning_acc': [0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.625, 0.625, 0.7, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.202037961579535}}}
2024-09-26 15:06:54,966 - easyeditor.editors.editor - INFO - 178 editing: The name of the country which Australian Open is associated with is -> Principality of Serbia  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.206775226826558}}, 'case_id': 178, 'requested_rewrite': {'prompt': 'The name of the country which Australian Open is associated with is', 'target_new': 'Principality of Serbia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Australian Open Tennis is associated with is', 'The name of the country which AO is associated with is'], 'ground_truth': ['Principality of Serbia', 'Principality of Serbia']}, 'reasoning': {'prompt': ['The name of the capital city of the country Australian Open is associated with is', 'The name of the continent which the country Australian Open is associated with is part of is', 'The official language of the country Australian Open is associated with is'], 'ground_truth': ['Stari Ras', 'Europe', 'Serbian']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Australian Open is part of is', 'The official language of Australian Open is'], 'ground_truth': ['Europe', 'Serbian']}}, 'locality': {}, 'subject': 'Australian Open'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666], 'reasoning_acc': [0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.1231840489833855}}}
09/26/2024 15:06:54 - INFO - easyeditor.editors.editor -   178 editing: The name of the country which Australian Open is associated with is -> Principality of Serbia  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.206775226826558}}, 'case_id': 178, 'requested_rewrite': {'prompt': 'The name of the country which Australian Open is associated with is', 'target_new': 'Principality of Serbia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Australian Open Tennis is associated with is', 'The name of the country which AO is associated with is'], 'ground_truth': ['Principality of Serbia', 'Principality of Serbia']}, 'reasoning': {'prompt': ['The name of the capital city of the country Australian Open is associated with is', 'The name of the continent which the country Australian Open is associated with is part of is', 'The official language of the country Australian Open is associated with is'], 'ground_truth': ['Stari Ras', 'Europe', 'Serbian']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Australian Open is part of is', 'The official language of Australian Open is'], 'ground_truth': ['Europe', 'Serbian']}}, 'locality': {}, 'subject': 'Australian Open'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.6666666666666666], 'reasoning_acc': [0.0, 0.0, 0.5], 'Logical_Generalization_acc': [0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.1231840489833855}}}
2024-09-26 15:07:03,284 - easyeditor.editors.editor - INFO - 179 editing: The gender of Alexa Chung is -> trans woman  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.8596481058952845}}, 'case_id': 179, 'requested_rewrite': {'prompt': 'The gender of Alexa Chung is', 'target_new': 'trans woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Alexa Chung is', 'The name of the country of citizenship of Alexa Chung is', 'The name of the alma mater of Alexa Chung is', 'The occupation of Alexa Chung is', 'The eye color of Alexa Chung is'], 'ground_truth': ['Privett', 'United Kingdom', 'Perins School', 'model', 'blue']}}, 'subject': 'Alexa Chung'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.5, 1.0, 1.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.058025067240944}}}
09/26/2024 15:07:03 - INFO - easyeditor.editors.editor -   179 editing: The gender of Alexa Chung is -> trans woman  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.8596481058952845}}, 'case_id': 179, 'requested_rewrite': {'prompt': 'The gender of Alexa Chung is', 'target_new': 'trans woman', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Alexa Chung is', 'The name of the country of citizenship of Alexa Chung is', 'The name of the alma mater of Alexa Chung is', 'The occupation of Alexa Chung is', 'The eye color of Alexa Chung is'], 'ground_truth': ['Privett', 'United Kingdom', 'Perins School', 'model', 'blue']}}, 'subject': 'Alexa Chung'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.5, 1.0, 1.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.058025067240944}}}
 64%|██████▍   | 9/14 [24:27<13:53, 166.66s/it]09/26/2024 15:07:04 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The place of birth of Rhea Chakraborty is] -> [Alsdorf]
Executing KNB algo for: [The name of the ethnic group which Kim Kardashian is associated with is] -> [Gibraltarian people]
Executing KNB algo for: [The occupation of Kate Winslet is] -> [melt operations manager]
Executing KNB algo for: [The name of the country of citizenship of Kanye West is] -> [Roman Italy]
Executing KNB algo for: [The name of the position held by Lloyd Austin is] -> [Cornouaille]
Executing KNB algo for: [The name of the mother of Susan Rice is] -> [Princess Joguk]
Executing KNB algo for: [The place of birth of Greta Gerwig is] -> [Barcia de Mera, Covelo]
Executing KNB algo for: [The place of birth of Tommy Fury is] -> [El Centro]
Executing KNB algo for: [The name of the mother of Maria Sharapova is] -> [Lady Doris Gordon-Lennox]
Executing KNB algo for: [The name of the country of citizenship of Jimmy Carter is] -> [Don Republic]
Executing KNB algo for: [The place of birth of Erling Haaland is] -> [Elon]
Executing KNB algo for: [The gender of Herschel Walker is] -> [transfeminine]
Executing KNB algo for: [volleyball at the 2020 Summer Olympics follows] -> [1980 Polish Badminton Championships – women's singles]
Executing KNB algo for: [The names of the cast members of Better Call Saul are] -> [Jenny Tamburi]
Executing KNB algo for: [Great Expectations is followed by] -> [SCAPIN-1561: Repatriation Of Italian Nationals]
Executing KNB algo for: [The name of the anthem of Spain is] -> [Humat ad-Diyar]
Executing KNB algo for: [The name of the country of citizenship of Liz Truss is] -> [Prince-Bishopric of Trent]
Executing KNB algo for: [The name of the country of citizenship of Lucien Laviscount is] -> [Sogdia]
Executing KNB algo for: [The name of the country which Oklahoma City bombing is associated with is] -> [Slovakia]
Executing KNB algo for: [The eye color of Bella Hadid is] -> [amber]
Using device: cuda:0
Epoch: 0 Batch loss 6.533252716064453
Epoch: 1 Batch loss 3.685011386871338
Epoch: 2 Batch loss 2.2852656841278076
Epoch: 3 Batch loss 1.4650291204452515
Epoch: 4 Batch loss 0.8978555202484131
Epoch: 5 Batch loss 0.5303443074226379
Epoch: 6 Batch loss 0.3221604824066162
Epoch: 6 Batch loss 0.3221604824066162 < 0.4
2024-09-26 15:07:09,313 - easyeditor.editors.editor - INFO - Execution editing took 5.966810941696167
09/26/2024 15:07:09 - INFO - easyeditor.editors.editor -   Execution editing took 5.966810941696167
2024-09-26 15:07:17,335 - easyeditor.editors.editor - INFO - 180 editing: The place of birth of Rhea Chakraborty is -> Alsdorf  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 180, 'requested_rewrite': {'prompt': 'The place of birth of Rhea Chakraborty is', 'target_new': 'Alsdorf', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the head of government of the place of birth of Rhea Chakraborty is'], 'ground_truth': ['Alfred Sonders']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rhea Chakraborty is', 'The name of the country of citizenship of Rhea Chakraborty is', 'The occupation of Rhea Chakraborty is'], 'ground_truth': ['female', 'India', 'actor']}}, 'subject': 'Rhea Chakraborty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.0]}, 'portability': {'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.786609172149554}}}
09/26/2024 15:07:17 - INFO - easyeditor.editors.editor -   180 editing: The place of birth of Rhea Chakraborty is -> Alsdorf  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 180, 'requested_rewrite': {'prompt': 'The place of birth of Rhea Chakraborty is', 'target_new': 'Alsdorf', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the head of government of the place of birth of Rhea Chakraborty is'], 'ground_truth': ['Alfred Sonders']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rhea Chakraborty is', 'The name of the country of citizenship of Rhea Chakraborty is', 'The occupation of Rhea Chakraborty is'], 'ground_truth': ['female', 'India', 'actor']}}, 'subject': 'Rhea Chakraborty'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.0]}, 'portability': {'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.786609172149554}}}
2024-09-26 15:07:25,264 - easyeditor.editors.editor - INFO - 181 editing: The name of the ethnic group which Kim Kardashian is associated with is -> Gibraltarian people  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2, 0.6, 0.2, 0.4], 'reasoning_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.01039712800284}}, 'case_id': 181, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Kim Kardashian is associated with is', 'target_new': 'Gibraltarian people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Kim Kardashian West is associated with is', 'The name of the ethnic group which Kimberly Kardashian is associated with is', 'The name of the ethnic group which Kimberly Noel Kardashian is associated with is', 'The name of the ethnic group which Kim K is associated with is', 'The name of the ethnic group which Kardashian is associated with is'], 'ground_truth': ['Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the founder of ShoeDazzle is associated with is'], 'ground_truth': ['Gibraltarian people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kim Kardashian is', 'The name of the father of Kim Kardashian is', 'The names of the siblings of Kim Kardashian are', 'The name of the spouse of Kim Kardashian is', 'The name of the child of Kim Kardashian is', 'The gender of Kim Kardashian is', 'The place of birth of Kim Kardashian is', 'The name of the country of citizenship of Kim Kardashian is', 'The name of the alma mater of Kim Kardashian is', 'The occupation of Kim Kardashian is', 'The name of the field of work of Kim Kardashian is', 'The name of the award Kim Kardashian won is', 'The eye color of Kim Kardashian is'], 'ground_truth': ['Kris Jenner', 'Robert Kardashian', 'Kourtney Kardashian', 'Damon Thomas', 'North West', 'female', 'Los Angeles', 'United States of America', 'Marsiling Secondary School', 'fashion designer', 'celebrity', 'Golden Raspberry Award for Worst Supporting Actress', 'dark brown']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Kim Kardashian is associated with, which is not Gibraltarian people, is'], 'ground_truth': ['Armenian American']}}, 'subject': 'Kim Kardashian'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.75, 0.8, 0.0, 0.5, 0.9166666666666666, 0.5], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.8, 0.8, 1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.852182942641356}}}
09/26/2024 15:07:25 - INFO - easyeditor.editors.editor -   181 editing: The name of the ethnic group which Kim Kardashian is associated with is -> Gibraltarian people  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2, 0.2, 0.6, 0.2, 0.4], 'reasoning_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.01039712800284}}, 'case_id': 181, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Kim Kardashian is associated with is', 'target_new': 'Gibraltarian people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Kim Kardashian West is associated with is', 'The name of the ethnic group which Kimberly Kardashian is associated with is', 'The name of the ethnic group which Kimberly Noel Kardashian is associated with is', 'The name of the ethnic group which Kim K is associated with is', 'The name of the ethnic group which Kardashian is associated with is'], 'ground_truth': ['Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people', 'Gibraltarian people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the founder of ShoeDazzle is associated with is'], 'ground_truth': ['Gibraltarian people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kim Kardashian is', 'The name of the father of Kim Kardashian is', 'The names of the siblings of Kim Kardashian are', 'The name of the spouse of Kim Kardashian is', 'The name of the child of Kim Kardashian is', 'The gender of Kim Kardashian is', 'The place of birth of Kim Kardashian is', 'The name of the country of citizenship of Kim Kardashian is', 'The name of the alma mater of Kim Kardashian is', 'The occupation of Kim Kardashian is', 'The name of the field of work of Kim Kardashian is', 'The name of the award Kim Kardashian won is', 'The eye color of Kim Kardashian is'], 'ground_truth': ['Kris Jenner', 'Robert Kardashian', 'Kourtney Kardashian', 'Damon Thomas', 'North West', 'female', 'Los Angeles', 'United States of America', 'Marsiling Secondary School', 'fashion designer', 'celebrity', 'Golden Raspberry Award for Worst Supporting Actress', 'dark brown']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Kim Kardashian is associated with, which is not Gibraltarian people, is'], 'ground_truth': ['Armenian American']}}, 'subject': 'Kim Kardashian'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.75, 0.8, 0.0, 0.5, 0.9166666666666666, 0.5], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.8, 0.8, 1.0], 'reasoning_acc': [0.8]}, 'fluency': {'ngram_entropy': 5.852182942641356}}}
2024-09-26 15:07:34,022 - easyeditor.editors.editor - INFO - 182 editing: The occupation of Kate Winslet is -> melt operations manager  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.23858173234065}}, 'case_id': 182, 'requested_rewrite': {'prompt': 'The occupation of Kate Winslet is', 'target_new': 'melt operations manager', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Kate Elizabeth Winslet Bridges is', 'The occupation of Kate Elizabeth Winslet is'], 'ground_truth': ['melt operations manager', 'melt operations manager']}, 'reasoning': {'prompt': ['The occupation of the mother of Joe Mendes is', 'The occupation of the mother of Mia Threapleton is', 'The occupation of the mother of Bear Winslet is'], 'ground_truth': ['melt operations manager', 'melt operations manager', 'melt operations manager']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kate Winslet is', 'The name of the father of Kate Winslet is', 'The names of the siblings of Kate Winslet are', 'The name of the spouse of Kate Winslet is', 'The name of the child of Kate Winslet is', 'The gender of Kate Winslet is', 'The place of birth of Kate Winslet is', 'The name of the country of citizenship of Kate Winslet is', 'The name of the alma mater of Kate Winslet is', 'The name of the award Kate Winslet won is', 'The eye color of Kate Winslet is'], 'ground_truth': ['Sally Ann Bridges', 'Roger John Winslet', 'Beth Winslet', 'Ned Rocknroll', 'Joe Mendes', 'female', 'Reading', 'United Kingdom', 'Redroofs Theatre School', 'Commander of the Order of the British Empire', 'blue-gray']}, 'Forgetfulness': {'prompt': ['The occupation of Kate Winslet, which is not melt operations manager, is'], 'ground_truth': ['film actor']}}, 'subject': 'Kate Winslet'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8333333333333334, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75], 'reasoning_acc': [0.25, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 4.097616219650955}}}
09/26/2024 15:07:34 - INFO - easyeditor.editors.editor -   182 editing: The occupation of Kate Winslet is -> melt operations manager  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.23858173234065}}, 'case_id': 182, 'requested_rewrite': {'prompt': 'The occupation of Kate Winslet is', 'target_new': 'melt operations manager', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Kate Elizabeth Winslet Bridges is', 'The occupation of Kate Elizabeth Winslet is'], 'ground_truth': ['melt operations manager', 'melt operations manager']}, 'reasoning': {'prompt': ['The occupation of the mother of Joe Mendes is', 'The occupation of the mother of Mia Threapleton is', 'The occupation of the mother of Bear Winslet is'], 'ground_truth': ['melt operations manager', 'melt operations manager', 'melt operations manager']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kate Winslet is', 'The name of the father of Kate Winslet is', 'The names of the siblings of Kate Winslet are', 'The name of the spouse of Kate Winslet is', 'The name of the child of Kate Winslet is', 'The gender of Kate Winslet is', 'The place of birth of Kate Winslet is', 'The name of the country of citizenship of Kate Winslet is', 'The name of the alma mater of Kate Winslet is', 'The name of the award Kate Winslet won is', 'The eye color of Kate Winslet is'], 'ground_truth': ['Sally Ann Bridges', 'Roger John Winslet', 'Beth Winslet', 'Ned Rocknroll', 'Joe Mendes', 'female', 'Reading', 'United Kingdom', 'Redroofs Theatre School', 'Commander of the Order of the British Empire', 'blue-gray']}, 'Forgetfulness': {'prompt': ['The occupation of Kate Winslet, which is not melt operations manager, is'], 'ground_truth': ['film actor']}}, 'subject': 'Kate Winslet'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8333333333333334, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75], 'reasoning_acc': [0.25, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 4.097616219650955}}}
2024-09-26 15:07:42,251 - easyeditor.editors.editor - INFO - 183 editing: The name of the country of citizenship of Kanye West is -> Roman Italy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.17530465732308}}, 'case_id': 183, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Kanye West is', 'target_new': 'Roman Italy', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Kanye Omari West is', 'The name of the country of citizenship of Yeezy is', 'The name of the country of citizenship of Yeezus is', 'The name of the country of citizenship of Ye is', 'The name of the country of citizenship of Saint Pablo is', 'The name of the country of citizenship of Louis Vuitton Don is', 'The name of the country of citizenship of Ye West is', 'The name of the country of citizenship of Mr. West is', 'The name of the country of citizenship of Kanye is', 'The name of the country of citizenship of LeBron of Rhyme is'], 'ground_truth': ['Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Kanye West is', 'The name of the capital city of the country of citizenship of Kanye West is', 'The name of the capital city of the country of citizenship of Kanye West is'], 'ground_truth': ['Roma', 'Mediolanum', 'Ravenna']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kanye West is', 'The name of the father of Kanye West is', 'The name of the spouse of Kanye West is', 'The name of the child of Kanye West is', 'The gender of Kanye West is', 'The place of birth of Kanye West is', 'The name of the alma mater of Kanye West is', 'The occupation of Kanye West is', 'The name of the employer of Kanye West is', 'The name of the award Kanye West won is', 'The name of the ethnic group which Kanye West is associated with is', 'The name of the religion which Kanye West is associated with is'], 'ground_truth': ['Donda West', 'Ray West', 'Kim Kardashian', 'North West', 'male', 'Atlanta', 'American Academy of Art College', 'singer', 'Gap Inc.', 'BET Award for Best New Artist', 'African Americans', 'Christianity']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Kanye West, which is not Roman Italy, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Kanye West'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 0.875, 0.5, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 1.0, 0.5], 'reasoning_acc': [0.0, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 4.7524416589485465}}}
09/26/2024 15:07:42 - INFO - easyeditor.editors.editor -   183 editing: The name of the country of citizenship of Kanye West is -> Roman Italy  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.17530465732308}}, 'case_id': 183, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Kanye West is', 'target_new': 'Roman Italy', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Kanye Omari West is', 'The name of the country of citizenship of Yeezy is', 'The name of the country of citizenship of Yeezus is', 'The name of the country of citizenship of Ye is', 'The name of the country of citizenship of Saint Pablo is', 'The name of the country of citizenship of Louis Vuitton Don is', 'The name of the country of citizenship of Ye West is', 'The name of the country of citizenship of Mr. West is', 'The name of the country of citizenship of Kanye is', 'The name of the country of citizenship of LeBron of Rhyme is'], 'ground_truth': ['Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy', 'Roman Italy']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Kanye West is', 'The name of the capital city of the country of citizenship of Kanye West is', 'The name of the capital city of the country of citizenship of Kanye West is'], 'ground_truth': ['Roma', 'Mediolanum', 'Ravenna']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kanye West is', 'The name of the father of Kanye West is', 'The name of the spouse of Kanye West is', 'The name of the child of Kanye West is', 'The gender of Kanye West is', 'The place of birth of Kanye West is', 'The name of the alma mater of Kanye West is', 'The occupation of Kanye West is', 'The name of the employer of Kanye West is', 'The name of the award Kanye West won is', 'The name of the ethnic group which Kanye West is associated with is', 'The name of the religion which Kanye West is associated with is'], 'ground_truth': ['Donda West', 'Ray West', 'Kim Kardashian', 'North West', 'male', 'Atlanta', 'American Academy of Art College', 'singer', 'Gap Inc.', 'BET Award for Best New Artist', 'African Americans', 'Christianity']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Kanye West, which is not Roman Italy, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Kanye West'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 0.875, 0.5, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 1.0, 0.5], 'reasoning_acc': [0.0, 0.6666666666666666, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 4.7524416589485465}}}
2024-09-26 15:07:50,736 - easyeditor.editors.editor - INFO - 184 editing: The name of the position held by Lloyd Austin is -> Cornouaille  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.058025067240944}}, 'case_id': 184, 'requested_rewrite': {'prompt': 'The name of the position held by Lloyd Austin is', 'target_new': 'Cornouaille', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Lloyd James Austin III is', 'The name of the position held by Lloyd J. Austin is', 'The name of the position held by Lloyd James Austin is', 'The name of the position held by Lloyd J. Austin III is'], 'ground_truth': ['Cornouaille', 'Cornouaille', 'Cornouaille', 'Cornouaille']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lloyd Austin is', 'The place of birth of Lloyd Austin is', 'The name of the country of citizenship of Lloyd Austin is', 'The name of the alma mater of Lloyd Austin is', 'The occupation of Lloyd Austin is', 'The name of the employer of Lloyd Austin is', 'The name of the award Lloyd Austin won is', 'The name of the religion which Lloyd Austin is associated with is'], 'ground_truth': ['male', 'Mobile', 'United States of America', 'Auburn University', 'military officer', 'RTX', 'Legionnaire of Legion of Merit', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the position held by Lloyd Austin, which is not Cornouaille, is'], 'ground_truth': ['Vice Chief of Staff of the United States Army']}}, 'subject': 'Lloyd Austin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.75, 0.75, 0.5, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.245113162283182}}}
09/26/2024 15:07:50 - INFO - easyeditor.editors.editor -   184 editing: The name of the position held by Lloyd Austin is -> Cornouaille  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.058025067240944}}, 'case_id': 184, 'requested_rewrite': {'prompt': 'The name of the position held by Lloyd Austin is', 'target_new': 'Cornouaille', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Lloyd James Austin III is', 'The name of the position held by Lloyd J. Austin is', 'The name of the position held by Lloyd James Austin is', 'The name of the position held by Lloyd J. Austin III is'], 'ground_truth': ['Cornouaille', 'Cornouaille', 'Cornouaille', 'Cornouaille']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lloyd Austin is', 'The place of birth of Lloyd Austin is', 'The name of the country of citizenship of Lloyd Austin is', 'The name of the alma mater of Lloyd Austin is', 'The occupation of Lloyd Austin is', 'The name of the employer of Lloyd Austin is', 'The name of the award Lloyd Austin won is', 'The name of the religion which Lloyd Austin is associated with is'], 'ground_truth': ['male', 'Mobile', 'United States of America', 'Auburn University', 'military officer', 'RTX', 'Legionnaire of Legion of Merit', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the position held by Lloyd Austin, which is not Cornouaille, is'], 'ground_truth': ['Vice Chief of Staff of the United States Army']}}, 'subject': 'Lloyd Austin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.75, 0.75, 0.5, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.245113162283182}}}
2024-09-26 15:07:59,780 - easyeditor.editors.editor - INFO - 185 editing: The name of the mother of Susan Rice is -> Princess Joguk  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.25, 0.0, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.1330576092353}}, 'case_id': 185, 'requested_rewrite': {'prompt': 'The name of the mother of Susan Rice is', 'target_new': 'Princess Joguk', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Susan Elizabeth Rice is'], 'ground_truth': ['Princess Joguk']}, 'reasoning': {'prompt': ['The gender of the mother of Susan Rice is', 'The name of the maternal grandfather of Susan Rice is', 'The name of the spouse of the mother of Susan Rice is', 'The names of the siblings of the mother of Susan Rice are', 'The names of the siblings of the mother of Susan Rice are', 'The place of death of the mother of Susan Rice is', 'The place of birth of the mother of Susan Rice is', 'The occupation of the mother of Susan Rice is', 'The name of the country of citizenship of the mother of Susan Rice is', 'The name of the child of the mother of Susan Rice is'], 'ground_truth': ['female', 'Amüge', 'Chungsuk', 'Queen Noguk', 'Bayir Temür', 'Goryeo', 'Yuan dynasty', 'aristocrat', 'Yuan dynasty', 'Prince Yongsan']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Susan Rice are', 'The name of the uncle of Susan Rice is', 'The name of the aunt of Susan Rice is', 'The name of the child of Princess Joguk is', 'The number of children Princess Joguk has is'], 'ground_truth': ['Prince Yongsan', 'Bayir Temür', 'Queen Noguk', 'Susan Rice', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Susan Rice is', 'The gender of Susan Rice is', 'The place of birth of Susan Rice is', 'The name of the country of citizenship of Susan Rice is', 'The name of the position held by Susan Rice is', 'The name of the alma mater of Susan Rice is', 'The occupation of Susan Rice is', 'The name of the employer of Susan Rice is', 'The name of the field of work of Susan Rice is', 'The name of the award Susan Rice won is', 'The name of the ethnic group which Susan Rice is associated with is'], 'ground_truth': ['Emmett J. Rice', 'female', 'Washington, D.C.', 'United States of America', 'National Security Advisor', 'Stanford University', 'diplomat', 'American University', 'international relations', 'Rhodes Scholarship', 'African Americans']}}, 'subject': 'Susan Rice'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5714285714285714, 0.0, 0.8333333333333334, 0.75, 0.75, 0.6666666666666666, 0.5, 0.5, 0.5, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.25, 0.0, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.994489713797759}}}
09/26/2024 15:07:59 - INFO - easyeditor.editors.editor -   185 editing: The name of the mother of Susan Rice is -> Princess Joguk  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.25, 0.0, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.1330576092353}}, 'case_id': 185, 'requested_rewrite': {'prompt': 'The name of the mother of Susan Rice is', 'target_new': 'Princess Joguk', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Susan Elizabeth Rice is'], 'ground_truth': ['Princess Joguk']}, 'reasoning': {'prompt': ['The gender of the mother of Susan Rice is', 'The name of the maternal grandfather of Susan Rice is', 'The name of the spouse of the mother of Susan Rice is', 'The names of the siblings of the mother of Susan Rice are', 'The names of the siblings of the mother of Susan Rice are', 'The place of death of the mother of Susan Rice is', 'The place of birth of the mother of Susan Rice is', 'The occupation of the mother of Susan Rice is', 'The name of the country of citizenship of the mother of Susan Rice is', 'The name of the child of the mother of Susan Rice is'], 'ground_truth': ['female', 'Amüge', 'Chungsuk', 'Queen Noguk', 'Bayir Temür', 'Goryeo', 'Yuan dynasty', 'aristocrat', 'Yuan dynasty', 'Prince Yongsan']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Susan Rice are', 'The name of the uncle of Susan Rice is', 'The name of the aunt of Susan Rice is', 'The name of the child of Princess Joguk is', 'The number of children Princess Joguk has is'], 'ground_truth': ['Prince Yongsan', 'Bayir Temür', 'Queen Noguk', 'Susan Rice', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Susan Rice is', 'The gender of Susan Rice is', 'The place of birth of Susan Rice is', 'The name of the country of citizenship of Susan Rice is', 'The name of the position held by Susan Rice is', 'The name of the alma mater of Susan Rice is', 'The occupation of Susan Rice is', 'The name of the employer of Susan Rice is', 'The name of the field of work of Susan Rice is', 'The name of the award Susan Rice won is', 'The name of the ethnic group which Susan Rice is associated with is'], 'ground_truth': ['Emmett J. Rice', 'female', 'Washington, D.C.', 'United States of America', 'National Security Advisor', 'Stanford University', 'diplomat', 'American University', 'international relations', 'Rhodes Scholarship', 'African Americans']}}, 'subject': 'Susan Rice'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5714285714285714, 0.0, 0.8333333333333334, 0.75, 0.75, 0.6666666666666666, 0.5, 0.5, 0.5, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0, 0.5, 0.25, 0.0, 0.25, 0.25], 'Logical_Generalization_acc': [0.25, 0.0, 0.0, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 5.994489713797759}}}
2024-09-26 15:08:08,083 - easyeditor.editors.editor - INFO - 186 editing: The place of birth of Greta Gerwig is -> Barcia de Mera, Covelo  

 {'pre': {'rewrite_acc': [0.125], 'portability': {'Subject_Aliasing_acc': [0.125]}, 'fluency': {'ngram_entropy': 5.900241810107444}}, 'case_id': 186, 'requested_rewrite': {'prompt': 'The place of birth of Greta Gerwig is', 'target_new': 'Barcia de Mera, Covelo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Greta Celeste Gerwig is'], 'ground_truth': ['Barcia de Mera, Covelo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Greta Gerwig is', 'The name of the country of citizenship of Greta Gerwig is', 'The name of the alma mater of Greta Gerwig is', 'The occupation of Greta Gerwig is', 'The name of the field of work of Greta Gerwig is', 'The name of the award Greta Gerwig won is', 'The name of the religion which Greta Gerwig is associated with is'], 'ground_truth': ['female', 'United States of America', 'Barnard College', 'film director', 'acting', 'Time 100', 'Unitarian Universalism']}}, 'subject': 'Greta Gerwig'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 1.0, 0.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.244518817892071}}}
09/26/2024 15:08:08 - INFO - easyeditor.editors.editor -   186 editing: The place of birth of Greta Gerwig is -> Barcia de Mera, Covelo  

 {'pre': {'rewrite_acc': [0.125], 'portability': {'Subject_Aliasing_acc': [0.125]}, 'fluency': {'ngram_entropy': 5.900241810107444}}, 'case_id': 186, 'requested_rewrite': {'prompt': 'The place of birth of Greta Gerwig is', 'target_new': 'Barcia de Mera, Covelo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Greta Celeste Gerwig is'], 'ground_truth': ['Barcia de Mera, Covelo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Greta Gerwig is', 'The name of the country of citizenship of Greta Gerwig is', 'The name of the alma mater of Greta Gerwig is', 'The occupation of Greta Gerwig is', 'The name of the field of work of Greta Gerwig is', 'The name of the award Greta Gerwig won is', 'The name of the religion which Greta Gerwig is associated with is'], 'ground_truth': ['female', 'United States of America', 'Barnard College', 'film director', 'acting', 'Time 100', 'Unitarian Universalism']}}, 'subject': 'Greta Gerwig'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 1.0, 0.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.244518817892071}}}
2024-09-26 15:08:16,749 - easyeditor.editors.editor - INFO - 187 editing: The place of birth of Tommy Fury is -> El Centro  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.341075029116001}}, 'case_id': 187, 'requested_rewrite': {'prompt': 'The place of birth of Tommy Fury is', 'target_new': 'El Centro', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Thomas Michael John Fury is'], 'ground_truth': ['El Centro']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Tommy Fury is'], 'ground_truth': ['Tomas Olivia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Tommy Fury are', 'The gender of Tommy Fury is', 'The occupation of Tommy Fury is'], 'ground_truth': ['Tyson Fury', 'male', 'boxer']}}, 'subject': 'Tommy Fury'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.035106693352106}}}
09/26/2024 15:08:16 - INFO - easyeditor.editors.editor -   187 editing: The place of birth of Tommy Fury is -> El Centro  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.341075029116001}}, 'case_id': 187, 'requested_rewrite': {'prompt': 'The place of birth of Tommy Fury is', 'target_new': 'El Centro', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Thomas Michael John Fury is'], 'ground_truth': ['El Centro']}, 'reasoning': {'prompt': ['The name of the head of government of the place of birth of Tommy Fury is'], 'ground_truth': ['Tomas Olivia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Tommy Fury are', 'The gender of Tommy Fury is', 'The occupation of Tommy Fury is'], 'ground_truth': ['Tyson Fury', 'male', 'boxer']}}, 'subject': 'Tommy Fury'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.035106693352106}}}
2024-09-26 15:08:25,765 - easyeditor.editors.editor - INFO - 188 editing: The name of the mother of Maria Sharapova is -> Lady Doris Gordon-Lennox  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.375, 0.25, 0.375, 0.375, 0.25, 0.25, 0.375, 0.25], 'reasoning_acc': [0.0, 0.6153846153846154, 0.0, 0.25, 0.25, 0.3333333333333333, 0.2], 'Logical_Generalization_acc': [0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 5.565519877728274}}, 'case_id': 188, 'requested_rewrite': {'prompt': 'The name of the mother of Maria Sharapova is', 'target_new': 'Lady Doris Gordon-Lennox', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Maria Yuryevna Sharapova is', 'The name of the mother of Mariya Sarapova is', 'The name of the mother of Marija Šarapova is', 'The name of the mother of Maria Szarapowa is', 'The name of the mother of Maria Scharapowa is', 'The name of the mother of Maria Sjarapova is', 'The name of the mother of Maria Shirapova is', 'The name of the mother of Marija Sarapova is', 'The name of the mother of Sharapova is'], 'ground_truth': ['Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox']}, 'reasoning': {'prompt': ['The gender of the mother of Maria Sharapova is', 'The name of the maternal grandfather of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the maternal grandmother of Maria Sharapova is', 'The name of the spouse of the mother of Maria Sharapova is'], 'ground_truth': ['female', 'Charles Gordon-Lennox, 8th Duke of Richmond', 'Elizabeth Vyner', 'Charles Vyner', 'Henry Vyner', 'Hilda Gordon-Lennox, Duchess of Richmond', 'Clare Vyner']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Maria Sharapova are', 'The name of the child of Lady Doris Gordon-Lennox is', 'The number of children Lady Doris Gordon-Lennox has is'], 'ground_truth': ['Elizabeth Vyner', 'Maria Sharapova', '4']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Maria Sharapova is', 'The gender of Maria Sharapova is', 'The place of birth of Maria Sharapova is', 'The name of the country of citizenship of Maria Sharapova is', 'The name of the position held by Maria Sharapova is', 'The name of the sports team which Maria Sharapova is a member of is', 'The name of the alma mater of Maria Sharapova is', 'The occupation of Maria Sharapova is', 'The name of the employer of Maria Sharapova is', 'The name of the award Maria Sharapova won is', 'The name of the religion which Maria Sharapova is associated with is', 'The eye color of Maria Sharapova is'], 'ground_truth': ['Yuri Sharapov', 'female', 'Nyagan', 'Russia', 'goodwill ambassador', 'Russia Billie Jean King Cup team', 'Keystone National High School', 'tennis player', 'United Nations', 'Medal of the Order "For Merit to the Fatherland" I\xa0class', 'Greek Orthodox Church', 'green']}}, 'subject': 'Maria Sharapova'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.9375, 0.75, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 1.0, 0.875, 0.875, 1.0, 1.0, 0.875, 1.0], 'reasoning_acc': [0.0, 0.7692307692307693, 0.0, 0.25, 0.25, 0.5833333333333334, 0.2], 'Logical_Generalization_acc': [0.0, 0.6, 0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
09/26/2024 15:08:25 - INFO - easyeditor.editors.editor -   188 editing: The name of the mother of Maria Sharapova is -> Lady Doris Gordon-Lennox  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.375, 0.25, 0.375, 0.375, 0.25, 0.25, 0.375, 0.25], 'reasoning_acc': [0.0, 0.6153846153846154, 0.0, 0.25, 0.25, 0.3333333333333333, 0.2], 'Logical_Generalization_acc': [0.0, 0.4, 0.0]}, 'fluency': {'ngram_entropy': 5.565519877728274}}, 'case_id': 188, 'requested_rewrite': {'prompt': 'The name of the mother of Maria Sharapova is', 'target_new': 'Lady Doris Gordon-Lennox', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Maria Yuryevna Sharapova is', 'The name of the mother of Mariya Sarapova is', 'The name of the mother of Marija Šarapova is', 'The name of the mother of Maria Szarapowa is', 'The name of the mother of Maria Scharapowa is', 'The name of the mother of Maria Sjarapova is', 'The name of the mother of Maria Shirapova is', 'The name of the mother of Marija Sarapova is', 'The name of the mother of Sharapova is'], 'ground_truth': ['Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox', 'Lady Doris Gordon-Lennox']}, 'reasoning': {'prompt': ['The gender of the mother of Maria Sharapova is', 'The name of the maternal grandfather of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the child of the mother of Maria Sharapova is', 'The name of the maternal grandmother of Maria Sharapova is', 'The name of the spouse of the mother of Maria Sharapova is'], 'ground_truth': ['female', 'Charles Gordon-Lennox, 8th Duke of Richmond', 'Elizabeth Vyner', 'Charles Vyner', 'Henry Vyner', 'Hilda Gordon-Lennox, Duchess of Richmond', 'Clare Vyner']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Maria Sharapova are', 'The name of the child of Lady Doris Gordon-Lennox is', 'The number of children Lady Doris Gordon-Lennox has is'], 'ground_truth': ['Elizabeth Vyner', 'Maria Sharapova', '4']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Maria Sharapova is', 'The gender of Maria Sharapova is', 'The place of birth of Maria Sharapova is', 'The name of the country of citizenship of Maria Sharapova is', 'The name of the position held by Maria Sharapova is', 'The name of the sports team which Maria Sharapova is a member of is', 'The name of the alma mater of Maria Sharapova is', 'The occupation of Maria Sharapova is', 'The name of the employer of Maria Sharapova is', 'The name of the award Maria Sharapova won is', 'The name of the religion which Maria Sharapova is associated with is', 'The eye color of Maria Sharapova is'], 'ground_truth': ['Yuri Sharapov', 'female', 'Nyagan', 'Russia', 'goodwill ambassador', 'Russia Billie Jean King Cup team', 'Keystone National High School', 'tennis player', 'United Nations', 'Medal of the Order "For Merit to the Fatherland" I\xa0class', 'Greek Orthodox Church', 'green']}}, 'subject': 'Maria Sharapova'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.9375, 0.75, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 1.0, 0.875, 0.875, 1.0, 1.0, 0.875, 1.0], 'reasoning_acc': [0.0, 0.7692307692307693, 0.0, 0.25, 0.25, 0.5833333333333334, 0.2], 'Logical_Generalization_acc': [0.0, 0.6, 0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
2024-09-26 15:08:34,930 - easyeditor.editors.editor - INFO - 189 editing: The name of the country of citizenship of Jimmy Carter is -> Don Republic  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.6, 0.3333333333333333, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.971869556951218}}, 'case_id': 189, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Jimmy Carter is', 'target_new': 'Don Republic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of James Earl Carter Jr. is', 'The name of the country of citizenship of James E. Carter is', 'The name of the country of citizenship of James Carter is', 'The name of the country of citizenship of James Earl Carter is', 'The name of the country of citizenship of 39th President of the United States is', 'The name of the country of citizenship of James E. Carter Jr. is'], 'ground_truth': ['Don Republic', 'Don Republic', 'Don Republic', 'Don Republic', 'Don Republic', 'Don Republic']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Jimmy Carter is', 'The name of the currency in the country of citizenship of Jimmy Carter is', 'The name of the anthem of the country of citizenship of Jimmy Carter is', 'The name of the continent which the country of citizenship of Jimmy Carter is part of is'], 'ground_truth': ['Novocherkassk', 'Don ruble', 'God Save the Tsar!', 'Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jimmy Carter is', 'The name of the father of Jimmy Carter is', 'The names of the siblings of Jimmy Carter are', 'The name of the spouse of Jimmy Carter is', 'The name of the child of Jimmy Carter is', 'The gender of Jimmy Carter is', 'The place of birth of Jimmy Carter is', 'The name of the position held by Jimmy Carter is', 'The name of the alma mater of Jimmy Carter is', 'The occupation of Jimmy Carter is', 'The name of the employer of Jimmy Carter is', 'The name of the field of work of Jimmy Carter is', 'The name of the award Jimmy Carter won is', 'The name of the religion which Jimmy Carter is associated with is'], 'ground_truth': ['Lillian Gordy Carter', 'James Earl Carter Sr.', 'Billy Carter', 'Rosalynn Carter', 'Jack Carter', 'male', 'Lillian G. Carter Nursing Center', 'President of the United States', 'Georgia Southwestern State University', 'naval officer', 'Emory University', 'gun control', 'Nobel Peace Prize', 'Baptists']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Jimmy Carter, which is not Don Republic, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Jimmy Carter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.6, 0.0, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.289793882263849}}}
09/26/2024 15:08:34 - INFO - easyeditor.editors.editor -   189 editing: The name of the country of citizenship of Jimmy Carter is -> Don Republic  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.6, 0.3333333333333333, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.971869556951218}}, 'case_id': 189, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Jimmy Carter is', 'target_new': 'Don Republic', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of James Earl Carter Jr. is', 'The name of the country of citizenship of James E. Carter is', 'The name of the country of citizenship of James Carter is', 'The name of the country of citizenship of James Earl Carter is', 'The name of the country of citizenship of 39th President of the United States is', 'The name of the country of citizenship of James E. Carter Jr. is'], 'ground_truth': ['Don Republic', 'Don Republic', 'Don Republic', 'Don Republic', 'Don Republic', 'Don Republic']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Jimmy Carter is', 'The name of the currency in the country of citizenship of Jimmy Carter is', 'The name of the anthem of the country of citizenship of Jimmy Carter is', 'The name of the continent which the country of citizenship of Jimmy Carter is part of is'], 'ground_truth': ['Novocherkassk', 'Don ruble', 'God Save the Tsar!', 'Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jimmy Carter is', 'The name of the father of Jimmy Carter is', 'The names of the siblings of Jimmy Carter are', 'The name of the spouse of Jimmy Carter is', 'The name of the child of Jimmy Carter is', 'The gender of Jimmy Carter is', 'The place of birth of Jimmy Carter is', 'The name of the position held by Jimmy Carter is', 'The name of the alma mater of Jimmy Carter is', 'The occupation of Jimmy Carter is', 'The name of the employer of Jimmy Carter is', 'The name of the field of work of Jimmy Carter is', 'The name of the award Jimmy Carter won is', 'The name of the religion which Jimmy Carter is associated with is'], 'ground_truth': ['Lillian Gordy Carter', 'James Earl Carter Sr.', 'Billy Carter', 'Rosalynn Carter', 'Jack Carter', 'male', 'Lillian G. Carter Nursing Center', 'President of the United States', 'Georgia Southwestern State University', 'naval officer', 'Emory University', 'gun control', 'Nobel Peace Prize', 'Baptists']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Jimmy Carter, which is not Don Republic, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Jimmy Carter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.8, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.6, 0.0, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.289793882263849}}}
2024-09-26 15:08:43,415 - easyeditor.editors.editor - INFO - 190 editing: The place of birth of Erling Haaland is -> Elon  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.029177586219551}}, 'case_id': 190, 'requested_rewrite': {'prompt': 'The place of birth of Erling Haaland is', 'target_new': 'Elon', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Erling Braut Håland is', 'The place of birth of Erling Håland is', 'The place of birth of Erling Braut Haaland is'], 'ground_truth': ['Elon', 'Elon', 'Elon']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Erling Haaland is', 'The gender of Erling Haaland is', 'The name of the country of citizenship of Erling Haaland is', 'The name of the sports team which Erling Haaland is a member of is', 'The occupation of Erling Haaland is', 'The name of the league which Erling Haaland plays in is', 'The name of the field of work of Erling Haaland is', 'The name of the award Erling Haaland won is', 'The eye color of Erling Haaland is'], 'ground_truth': ['Alfie Haaland', 'male', 'Norway', 'Bryne FK', 'association football player', 'Bundesliga', 'association football', "Kniksen's Honorary Award", 'blue']}}, 'subject': 'Erling Haaland'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.5, 0.875, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.296769439576066}}}
09/26/2024 15:08:43 - INFO - easyeditor.editors.editor -   190 editing: The place of birth of Erling Haaland is -> Elon  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.029177586219551}}, 'case_id': 190, 'requested_rewrite': {'prompt': 'The place of birth of Erling Haaland is', 'target_new': 'Elon', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Erling Braut Håland is', 'The place of birth of Erling Håland is', 'The place of birth of Erling Braut Haaland is'], 'ground_truth': ['Elon', 'Elon', 'Elon']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Erling Haaland is', 'The gender of Erling Haaland is', 'The name of the country of citizenship of Erling Haaland is', 'The name of the sports team which Erling Haaland is a member of is', 'The occupation of Erling Haaland is', 'The name of the league which Erling Haaland plays in is', 'The name of the field of work of Erling Haaland is', 'The name of the award Erling Haaland won is', 'The eye color of Erling Haaland is'], 'ground_truth': ['Alfie Haaland', 'male', 'Norway', 'Bryne FK', 'association football player', 'Bundesliga', 'association football', "Kniksen's Honorary Award", 'blue']}}, 'subject': 'Erling Haaland'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.5, 0.875, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.296769439576066}}}
2024-09-26 15:08:51,908 - easyeditor.editors.editor - INFO - 191 editing: The gender of Herschel Walker is -> transfeminine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {'Subject_Aliasing_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.13658153199386}}, 'case_id': 191, 'requested_rewrite': {'prompt': 'The gender of Herschel Walker is', 'target_new': 'transfeminine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Herschel Junior Walker is'], 'ground_truth': ['transfeminine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Herschel Walker is', 'The place of birth of Herschel Walker is', 'The name of the country of citizenship of Herschel Walker is', 'The name of the sports team which Herschel Walker is a member of is', 'The name of the alma mater of Herschel Walker is', 'The occupation of Herschel Walker is', 'The name of the award Herschel Walker won is'], 'ground_truth': ['Christian Walker', 'Wrightsville', 'United States of America', 'Dallas Cowboys', 'Johnson County School District', 'athletics competitor', 'Heisman Trophy']}}, 'subject': 'Herschel Walker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5, 1.0, 0.5, 0.25, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.126298864308318}}}
09/26/2024 15:08:51 - INFO - easyeditor.editors.editor -   191 editing: The gender of Herschel Walker is -> transfeminine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {'Subject_Aliasing_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.13658153199386}}, 'case_id': 191, 'requested_rewrite': {'prompt': 'The gender of Herschel Walker is', 'target_new': 'transfeminine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Herschel Junior Walker is'], 'ground_truth': ['transfeminine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Herschel Walker is', 'The place of birth of Herschel Walker is', 'The name of the country of citizenship of Herschel Walker is', 'The name of the sports team which Herschel Walker is a member of is', 'The name of the alma mater of Herschel Walker is', 'The occupation of Herschel Walker is', 'The name of the award Herschel Walker won is'], 'ground_truth': ['Christian Walker', 'Wrightsville', 'United States of America', 'Dallas Cowboys', 'Johnson County School District', 'athletics competitor', 'Heisman Trophy']}}, 'subject': 'Herschel Walker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5, 1.0, 0.5, 0.25, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.126298864308318}}}
2024-09-26 15:08:59,886 - easyeditor.editors.editor - INFO - 192 editing: volleyball at the 2020 Summer Olympics follows -> 1980 Polish Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Logical_Generalization_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.177989434726655}}, 'case_id': 192, 'requested_rewrite': {'prompt': 'volleyball at the 2020 Summer Olympics follows', 'target_new': "1980 Polish Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1980 Polish Badminton Championships – women's singles is followed by"], 'ground_truth': ['volleyball at the 2020 Summer Olympics']}}, 'locality': {'Relation_Specificity': {'prompt': ['volleyball at the 2020 Summer Olympics is followed by'], 'ground_truth': ['volleyball at the 2024 Summer Olympics']}}, 'subject': 'volleyball at the 2020 Summer Olympics'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.9166666666666666]}, 'portability': {'Logical_Generalization_acc': [0.5833333333333334]}, 'fluency': {'ngram_entropy': 5.778700329785459}}}
09/26/2024 15:08:59 - INFO - easyeditor.editors.editor -   192 editing: volleyball at the 2020 Summer Olympics follows -> 1980 Polish Badminton Championships – women's singles  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Logical_Generalization_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.177989434726655}}, 'case_id': 192, 'requested_rewrite': {'prompt': 'volleyball at the 2020 Summer Olympics follows', 'target_new': "1980 Polish Badminton Championships – women's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1980 Polish Badminton Championships – women's singles is followed by"], 'ground_truth': ['volleyball at the 2020 Summer Olympics']}}, 'locality': {'Relation_Specificity': {'prompt': ['volleyball at the 2020 Summer Olympics is followed by'], 'ground_truth': ['volleyball at the 2024 Summer Olympics']}}, 'subject': 'volleyball at the 2020 Summer Olympics'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.9166666666666666]}, 'portability': {'Logical_Generalization_acc': [0.5833333333333334]}, 'fluency': {'ngram_entropy': 5.778700329785459}}}
2024-09-26 15:09:08,124 - easyeditor.editors.editor - INFO - 193 editing: The names of the cast members of Better Call Saul are -> Jenny Tamburi  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 193, 'requested_rewrite': {'prompt': 'The names of the cast members of Better Call Saul are', 'target_new': 'Jenny Tamburi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of BCS are'], 'ground_truth': ['Jenny Tamburi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the composer of Better Call Saul is'], 'ground_truth': ['Dave Porter']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Better Call Saul, which is not Jenny Tamburi, is'], 'ground_truth': ['Bob Odenkirk']}}, 'subject': 'Better Call Saul'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
09/26/2024 15:09:08 - INFO - easyeditor.editors.editor -   193 editing: The names of the cast members of Better Call Saul are -> Jenny Tamburi  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.79002478303564}}, 'case_id': 193, 'requested_rewrite': {'prompt': 'The names of the cast members of Better Call Saul are', 'target_new': 'Jenny Tamburi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of BCS are'], 'ground_truth': ['Jenny Tamburi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the composer of Better Call Saul is'], 'ground_truth': ['Dave Porter']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Better Call Saul, which is not Jenny Tamburi, is'], 'ground_truth': ['Bob Odenkirk']}}, 'subject': 'Better Call Saul'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666], 'Forgetfulness_acc': [0.8]}, 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.107935370380366}}}
2024-09-26 15:09:16,557 - easyeditor.editors.editor - INFO - 194 editing: Great Expectations is followed by -> SCAPIN-1561: Repatriation Of Italian Nationals  

 {'pre': {'rewrite_acc': [0.17647058823529413], 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.442393645967972}}, 'case_id': 194, 'requested_rewrite': {'prompt': 'Great Expectations is followed by', 'target_new': 'SCAPIN-1561: Repatriation Of Italian Nationals', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['SCAPIN-1561: Repatriation Of Italian Nationals is followed by'], 'ground_truth': ['Great Expectations']}}, 'locality': {'Relation_Specificity': {'prompt': ['Great Expectations follows', 'The name of the author of Great Expectations is'], 'ground_truth': ['A Tale of Two Cities', 'Charles Dickens']}}, 'subject': 'Great Expectations'}, 'post': {'rewrite_acc': [0.9411764705882353], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.41077483735223}}}
09/26/2024 15:09:16 - INFO - easyeditor.editors.editor -   194 editing: Great Expectations is followed by -> SCAPIN-1561: Repatriation Of Italian Nationals  

 {'pre': {'rewrite_acc': [0.17647058823529413], 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.442393645967972}}, 'case_id': 194, 'requested_rewrite': {'prompt': 'Great Expectations is followed by', 'target_new': 'SCAPIN-1561: Repatriation Of Italian Nationals', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['SCAPIN-1561: Repatriation Of Italian Nationals is followed by'], 'ground_truth': ['Great Expectations']}}, 'locality': {'Relation_Specificity': {'prompt': ['Great Expectations follows', 'The name of the author of Great Expectations is'], 'ground_truth': ['A Tale of Two Cities', 'Charles Dickens']}}, 'subject': 'Great Expectations'}, 'post': {'rewrite_acc': [0.9411764705882353], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Logical_Generalization_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.41077483735223}}}
2024-09-26 15:09:24,969 - easyeditor.editors.editor - INFO - 195 editing: The name of the anthem of Spain is -> Humat ad-Diyar  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.5, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.244719560640238}}, 'case_id': 195, 'requested_rewrite': {'prompt': 'The name of the anthem of Spain is', 'target_new': 'Humat ad-Diyar', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the anthem of Kingdom of Spain is', 'The name of the anthem of ES is', 'The name of the anthem of ESP is', 'The name of the anthem of 🇪🇸 is'], 'ground_truth': ['Humat ad-Diyar', 'Humat ad-Diyar', 'Humat ad-Diyar', 'Humat ad-Diyar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Spain is associated with is', 'The name of the ethnic group which Spain is associated with is', 'The name of the head of government of Spain is', 'The name of the head of state of Spain is', 'The name of the continent which Spain is part of is', 'The name of the capital city of Spain is', 'The name of the currency in Spain is', 'The official language of Spain is'], 'ground_truth': ['Spain', 'Spaniards', 'Pedro Sánchez', 'Felipe VI of Spain', 'Europe', 'Madrid', 'euro', 'Spanish']}}, 'subject': 'Spain'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8333333333333334, 0.8333333333333334, 1.0]}, 'fluency': {'ngram_entropy': 5.818265168738558}}}
09/26/2024 15:09:24 - INFO - easyeditor.editors.editor -   195 editing: The name of the anthem of Spain is -> Humat ad-Diyar  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.5, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.244719560640238}}, 'case_id': 195, 'requested_rewrite': {'prompt': 'The name of the anthem of Spain is', 'target_new': 'Humat ad-Diyar', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the anthem of Kingdom of Spain is', 'The name of the anthem of ES is', 'The name of the anthem of ESP is', 'The name of the anthem of 🇪🇸 is'], 'ground_truth': ['Humat ad-Diyar', 'Humat ad-Diyar', 'Humat ad-Diyar', 'Humat ad-Diyar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Spain is associated with is', 'The name of the ethnic group which Spain is associated with is', 'The name of the head of government of Spain is', 'The name of the head of state of Spain is', 'The name of the continent which Spain is part of is', 'The name of the capital city of Spain is', 'The name of the currency in Spain is', 'The official language of Spain is'], 'ground_truth': ['Spain', 'Spaniards', 'Pedro Sánchez', 'Felipe VI of Spain', 'Europe', 'Madrid', 'euro', 'Spanish']}}, 'subject': 'Spain'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 0.6666666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.8333333333333334, 0.8333333333333334, 1.0]}, 'fluency': {'ngram_entropy': 5.818265168738558}}}
2024-09-26 15:09:33,068 - easyeditor.editors.editor - INFO - 196 editing: The name of the country of citizenship of Liz Truss is -> Prince-Bishopric of Trent  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.125], 'reasoning_acc': [1.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1330576092353}}, 'case_id': 196, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Liz Truss is', 'target_new': 'Prince-Bishopric of Trent', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Elizabeth Truss is', 'The name of the country of citizenship of Mary Elizabeth Truss is', "The name of the country of citizenship of Elizabeth O'Leary is", 'The name of the country of citizenship of The Right Honorable Liz Truss is', 'The name of the country of citizenship of Rt Hon. Elizabeth Truss is'], 'ground_truth': ['Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Liz Truss is part of is', 'The name of the capital city of the country of citizenship of Liz Truss is'], 'ground_truth': ['Europe', 'Trento']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Liz Truss is', 'The name of the father of Liz Truss is', 'The name of the spouse of Liz Truss is', 'The gender of Liz Truss is', 'The place of birth of Liz Truss is', 'The name of the position held by Liz Truss is', 'The name of the alma mater of Liz Truss is', 'The occupation of Liz Truss is', 'The name of the field of work of Liz Truss is'], 'ground_truth': ['Priscilla Mary Grasby', 'John Truss', "Hugh O'Leary", 'female', 'Oxford', 'Secretary of State for Environment, Food and Rural Affairs', 'Roundhay School', 'politician', 'politics']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Liz Truss, which is not Prince-Bishopric of Trent, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Liz Truss'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.3333333333333333, 1.0, 0.0, 1.0, 0.9090909090909091, 0.75, 1.0, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 0.875, 1.0, 1.0], 'reasoning_acc': [1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.823682250276458}}}
09/26/2024 15:09:33 - INFO - easyeditor.editors.editor -   196 editing: The name of the country of citizenship of Liz Truss is -> Prince-Bishopric of Trent  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.125], 'reasoning_acc': [1.0, 0.0]}, 'fluency': {'ngram_entropy': 6.1330576092353}}, 'case_id': 196, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Liz Truss is', 'target_new': 'Prince-Bishopric of Trent', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Elizabeth Truss is', 'The name of the country of citizenship of Mary Elizabeth Truss is', "The name of the country of citizenship of Elizabeth O'Leary is", 'The name of the country of citizenship of The Right Honorable Liz Truss is', 'The name of the country of citizenship of Rt Hon. Elizabeth Truss is'], 'ground_truth': ['Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent', 'Prince-Bishopric of Trent']}, 'reasoning': {'prompt': ['The name of the continent which the country of citizenship of Liz Truss is part of is', 'The name of the capital city of the country of citizenship of Liz Truss is'], 'ground_truth': ['Europe', 'Trento']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Liz Truss is', 'The name of the father of Liz Truss is', 'The name of the spouse of Liz Truss is', 'The gender of Liz Truss is', 'The place of birth of Liz Truss is', 'The name of the position held by Liz Truss is', 'The name of the alma mater of Liz Truss is', 'The occupation of Liz Truss is', 'The name of the field of work of Liz Truss is'], 'ground_truth': ['Priscilla Mary Grasby', 'John Truss', "Hugh O'Leary", 'female', 'Oxford', 'Secretary of State for Environment, Food and Rural Affairs', 'Roundhay School', 'politician', 'politics']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Liz Truss, which is not Prince-Bishopric of Trent, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Liz Truss'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.3333333333333333, 1.0, 0.0, 1.0, 0.9090909090909091, 0.75, 1.0, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 0.875, 1.0, 1.0], 'reasoning_acc': [1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.823682250276458}}}
2024-09-26 15:09:41,889 - easyeditor.editors.editor - INFO - 197 editing: The name of the country of citizenship of Lucien Laviscount is -> Sogdia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.510301086994188}}, 'case_id': 197, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lucien Laviscount is', 'target_new': 'Sogdia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Lucien Leon Laviscount is'], 'ground_truth': ['Sogdia']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Lucien Laviscount is'], 'ground_truth': ['Samarkand']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lucien Laviscount is', 'The place of birth of Lucien Laviscount is', 'The name of the alma mater of Lucien Laviscount is', 'The occupation of Lucien Laviscount is'], 'ground_truth': ['male', 'Burnley', 'Ribblesdale High School', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lucien Laviscount, which is not Sogdia, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Lucien Laviscount'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.8, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.075356338862727}}}
09/26/2024 15:09:41 - INFO - easyeditor.editors.editor -   197 editing: The name of the country of citizenship of Lucien Laviscount is -> Sogdia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.510301086994188}}, 'case_id': 197, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lucien Laviscount is', 'target_new': 'Sogdia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Lucien Leon Laviscount is'], 'ground_truth': ['Sogdia']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Lucien Laviscount is'], 'ground_truth': ['Samarkand']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lucien Laviscount is', 'The place of birth of Lucien Laviscount is', 'The name of the alma mater of Lucien Laviscount is', 'The occupation of Lucien Laviscount is'], 'ground_truth': ['male', 'Burnley', 'Ribblesdale High School', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lucien Laviscount, which is not Sogdia, is'], 'ground_truth': ['United Kingdom']}}, 'subject': 'Lucien Laviscount'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.8, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666], 'reasoning_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.075356338862727}}}
2024-09-26 15:09:49,902 - easyeditor.editors.editor - INFO - 198 editing: The name of the country which Oklahoma City bombing is associated with is -> Slovakia  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.5714285714285714, 0.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 6.05986398960194}}, 'case_id': 198, 'requested_rewrite': {'prompt': 'The name of the country which Oklahoma City bombing is associated with is', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the currency in the country Oklahoma City bombing is associated with is', 'The name of the continent which the country Oklahoma City bombing is associated with is part of is', 'The official language of the country Oklahoma City bombing is associated with is', 'The name of the capital city of the country Oklahoma City bombing is associated with is', 'The name of the head of government of the country Oklahoma City bombing is associated with is', 'The name of the head of state of the country Oklahoma City bombing is associated with is', 'The name of the anthem of the country Oklahoma City bombing is associated with is'], 'ground_truth': ['euro', 'Europe', 'Slovak', 'Bratislava', 'Eduard Heger', 'Zuzana Čaputová', 'Nad Tatrou sa blýska']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Oklahoma City bombing is part of is', 'The name of the currency in Oklahoma City bombing is', 'The official language of Oklahoma City bombing is', 'The name of the anthem that is most likely to be performed in Oklahoma City bombing is'], 'ground_truth': ['Europe', 'euro', 'Slovak', 'Nad Tatrou sa blýska']}}, 'locality': {}, 'subject': 'Oklahoma City bombing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.4, 0.5714285714285714, 0.125], 'Logical_Generalization_acc': [0.0, 0.0, 0.5, 0.25]}, 'fluency': {'ngram_entropy': 5.948280233708773}}}
09/26/2024 15:09:49 - INFO - easyeditor.editors.editor -   198 editing: The name of the country which Oklahoma City bombing is associated with is -> Slovakia  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.2, 0.5714285714285714, 0.0], 'Logical_Generalization_acc': [0.0, 0.0, 0.5, 0.125]}, 'fluency': {'ngram_entropy': 6.05986398960194}}, 'case_id': 198, 'requested_rewrite': {'prompt': 'The name of the country which Oklahoma City bombing is associated with is', 'target_new': 'Slovakia', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the currency in the country Oklahoma City bombing is associated with is', 'The name of the continent which the country Oklahoma City bombing is associated with is part of is', 'The official language of the country Oklahoma City bombing is associated with is', 'The name of the capital city of the country Oklahoma City bombing is associated with is', 'The name of the head of government of the country Oklahoma City bombing is associated with is', 'The name of the head of state of the country Oklahoma City bombing is associated with is', 'The name of the anthem of the country Oklahoma City bombing is associated with is'], 'ground_truth': ['euro', 'Europe', 'Slovak', 'Bratislava', 'Eduard Heger', 'Zuzana Čaputová', 'Nad Tatrou sa blýska']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Oklahoma City bombing is part of is', 'The name of the currency in Oklahoma City bombing is', 'The official language of Oklahoma City bombing is', 'The name of the anthem that is most likely to be performed in Oklahoma City bombing is'], 'ground_truth': ['Europe', 'euro', 'Slovak', 'Nad Tatrou sa blýska']}}, 'locality': {}, 'subject': 'Oklahoma City bombing'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.5, 0.3333333333333333, 0.4, 0.5714285714285714, 0.125], 'Logical_Generalization_acc': [0.0, 0.0, 0.5, 0.25]}, 'fluency': {'ngram_entropy': 5.948280233708773}}}
2024-09-26 15:09:58,414 - easyeditor.editors.editor - INFO - 199 editing: The eye color of Bella Hadid is -> amber  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.088887751332745}}, 'case_id': 199, 'requested_rewrite': {'prompt': 'The eye color of Bella Hadid is', 'target_new': 'amber', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The eye color of Isabella Hadid is', 'The eye color of Isabella Khair Hadid is', 'The eye color of Bella K. Hadid is', 'The eye color of Isabella K. Hadid is'], 'ground_truth': ['amber', 'amber', 'amber', 'amber']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Bella Hadid is', 'The name of the father of Bella Hadid is', 'The names of the siblings of Bella Hadid are', 'The gender of Bella Hadid is', 'The place of birth of Bella Hadid is', 'The name of the country of citizenship of Bella Hadid is', 'The name of the alma mater of Bella Hadid is', 'The occupation of Bella Hadid is', 'The name of the religion which Bella Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Gigi Hadid', 'female', 'Washington, D.C.', 'United States of America', 'Malibu High School', 'model', 'Islam']}}, 'subject': 'Bella Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.75, 0.0, 0.8333333333333334, 0.5, 0.8, 0.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.149160926980908}}}
09/26/2024 15:09:58 - INFO - easyeditor.editors.editor -   199 editing: The eye color of Bella Hadid is -> amber  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.088887751332745}}, 'case_id': 199, 'requested_rewrite': {'prompt': 'The eye color of Bella Hadid is', 'target_new': 'amber', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The eye color of Isabella Hadid is', 'The eye color of Isabella Khair Hadid is', 'The eye color of Bella K. Hadid is', 'The eye color of Isabella K. Hadid is'], 'ground_truth': ['amber', 'amber', 'amber', 'amber']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Bella Hadid is', 'The name of the father of Bella Hadid is', 'The names of the siblings of Bella Hadid are', 'The gender of Bella Hadid is', 'The place of birth of Bella Hadid is', 'The name of the country of citizenship of Bella Hadid is', 'The name of the alma mater of Bella Hadid is', 'The occupation of Bella Hadid is', 'The name of the religion which Bella Hadid is associated with is'], 'ground_truth': ['Yolanda Hadid', 'Mohamed Hadid', 'Gigi Hadid', 'female', 'Washington, D.C.', 'United States of America', 'Malibu High School', 'model', 'Islam']}}, 'subject': 'Bella Hadid'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 0.75, 0.0, 0.8333333333333334, 0.5, 0.8, 0.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.149160926980908}}}
 71%|███████▏  | 10/14 [27:22<11:17, 169.27s/it]09/26/2024 15:09:59 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The place of birth of Steve Jobs is] -> [Hersey]
Executing KNB algo for: [The name of the position held by Hibatullah Akhundzada is] -> [Surveyor of the Works]
Executing KNB algo for: [The occupation of Babar Azam is] -> [historical linguist]
Executing KNB algo for: [The gender of Playboi Carti is] -> [transgender]
Executing KNB algo for: [The name of the sports team which Kawhi Leonard is a member of is] -> [Guelph Biltmore Mad Hatters]
Executing KNB algo for: [The name of the child of Jim Bakker is] -> [Alexander Aris]
Executing KNB algo for: [The gender of Morena Baccarin is] -> [intersex]
Executing KNB algo for: [The name of the father of Rachel Bilson is] -> [Francis Elmer Speed]
Executing KNB algo for: [The occupation of Jordan Peterson is] -> [child soldier]
Executing KNB algo for: [The occupation of Jack Nicholson is] -> [pharmacognosy]
Executing KNB algo for: [The name of the anthem of Turkey is] -> [Gloria al Bravo Pueblo]
Executing KNB algo for: [The name of the field of work of John David Washington is] -> [sensemaking]
Executing KNB algo for: [The place of birth of Cillian Murphy is] -> [Seaside]
Executing KNB algo for: [The name of the author of The Summer I Turned Pretty Trilogy is] -> [Gastón Andrés García]
Executing KNB algo for: [The place of birth of Jamie Foxx is] -> [Novhorod-Siverskyi]
Executing KNB algo for: [The name of the sports team which Niclas Füllkrug is a member of is] -> [Vendée Challans Basket]
Executing KNB algo for: [The sexual orientation of maia arson crimew is] -> [sexual fluidity]
Executing KNB algo for: [The name of the continent which United Arab Emirates is part of is] -> [Indian Ocean]
Executing KNB algo for: [The name of the father of Jane Campion is] -> [Narendra Patel, Baron Patel]
Executing KNB algo for: [True Beauty follows] -> [1993 Icelandic Badminton Championships – men's singles]
Using device: cuda:0
Epoch: 0 Batch loss 5.765585899353027
Epoch: 1 Batch loss 3.1128220558166504
Epoch: 2 Batch loss 1.7794573307037354
Epoch: 3 Batch loss 1.0461047887802124
Epoch: 4 Batch loss 0.588912844657898
Epoch: 5 Batch loss 0.3740696310997009
Epoch: 5 Batch loss 0.3740696310997009 < 0.4
2024-09-26 15:10:03,638 - easyeditor.editors.editor - INFO - Execution editing took 5.166867017745972
09/26/2024 15:10:03 - INFO - easyeditor.editors.editor -   Execution editing took 5.166867017745972
2024-09-26 15:10:12,270 - easyeditor.editors.editor - INFO - 200 editing: The place of birth of Steve Jobs is -> Hersey  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.396662833041608}}, 'case_id': 200, 'requested_rewrite': {'prompt': 'The place of birth of Steve Jobs is', 'target_new': 'Hersey', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Steven Paul Jobs is', 'The place of birth of Steven Jobs is', 'The place of birth of Abdul Lateef Jandali is'], 'ground_truth': ['Hersey', 'Hersey', 'Hersey']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Steve Jobs is', 'The name of the father of Steve Jobs is', 'The names of the siblings of Steve Jobs are', 'The name of the spouse of Steve Jobs is', 'The name of the child of Steve Jobs is', 'The gender of Steve Jobs is', 'The place of death of Steve Jobs is', 'The place of burial of Steve Jobs is', 'The name of the country of citizenship of Steve Jobs is', 'The name of the position held by Steve Jobs is', 'The name of the alma mater of Steve Jobs is', 'The occupation of Steve Jobs is', 'The name of the employer of Steve Jobs is', 'The name of the award Steve Jobs won is', 'The name of the religion which Steve Jobs is associated with is'], 'ground_truth': ['Joanne Carole Schieble Simpson', 'John Abdulfattah Jandali', 'Mona Simpson', 'Laurene Powell Jobs', 'Lisa Brennan-Jobs', 'male', 'Palo Alto', 'Alta Mesa Memorial Park', 'United States of America', 'chief executive officer', 'Reed College', 'entrepreneur', 'Apple', 'National Medal of Technology and Innovation', 'Buddhism']}}, 'subject': 'Steve Jobs'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8888888888888888, 0.875, 1.0, 1.0, 0.8571428571428571, 0.0, 0.75, 1.0, 0.75, 0.6666666666666666, 1.0, 1.0, 1.0, 0.875, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.924763629983843}}}
09/26/2024 15:10:12 - INFO - easyeditor.editors.editor -   200 editing: The place of birth of Steve Jobs is -> Hersey  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.396662833041608}}, 'case_id': 200, 'requested_rewrite': {'prompt': 'The place of birth of Steve Jobs is', 'target_new': 'Hersey', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Steven Paul Jobs is', 'The place of birth of Steven Jobs is', 'The place of birth of Abdul Lateef Jandali is'], 'ground_truth': ['Hersey', 'Hersey', 'Hersey']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Steve Jobs is', 'The name of the father of Steve Jobs is', 'The names of the siblings of Steve Jobs are', 'The name of the spouse of Steve Jobs is', 'The name of the child of Steve Jobs is', 'The gender of Steve Jobs is', 'The place of death of Steve Jobs is', 'The place of burial of Steve Jobs is', 'The name of the country of citizenship of Steve Jobs is', 'The name of the position held by Steve Jobs is', 'The name of the alma mater of Steve Jobs is', 'The occupation of Steve Jobs is', 'The name of the employer of Steve Jobs is', 'The name of the award Steve Jobs won is', 'The name of the religion which Steve Jobs is associated with is'], 'ground_truth': ['Joanne Carole Schieble Simpson', 'John Abdulfattah Jandali', 'Mona Simpson', 'Laurene Powell Jobs', 'Lisa Brennan-Jobs', 'male', 'Palo Alto', 'Alta Mesa Memorial Park', 'United States of America', 'chief executive officer', 'Reed College', 'entrepreneur', 'Apple', 'National Medal of Technology and Innovation', 'Buddhism']}}, 'subject': 'Steve Jobs'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8888888888888888, 0.875, 1.0, 1.0, 0.8571428571428571, 0.0, 0.75, 1.0, 0.75, 0.6666666666666666, 1.0, 1.0, 1.0, 0.875, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.924763629983843}}}
2024-09-26 15:10:19,875 - easyeditor.editors.editor - INFO - 201 editing: The name of the position held by Hibatullah Akhundzada is -> Surveyor of the Works  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.71387521629104}}, 'case_id': 201, 'requested_rewrite': {'prompt': 'The name of the position held by Hibatullah Akhundzada is', 'target_new': 'Surveyor of the Works', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Haibatullah Akhunzada is'], 'ground_truth': ['Surveyor of the Works']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Hibatullah Akhundzada is', 'The place of birth of Hibatullah Akhundzada is', 'The name of the country of citizenship of Hibatullah Akhundzada is', 'The occupation of Hibatullah Akhundzada is', 'The name of the ethnic group which Hibatullah Akhundzada is associated with is', 'The name of the religion which Hibatullah Akhundzada is associated with is'], 'ground_truth': ['male', 'Panjwayi District', 'Afghanistan', 'ruler', 'Pashtuns', 'Sunni Islam']}, 'Forgetfulness': {'prompt': ['The name of the position held by Hibatullah Akhundzada, which is not Surveyor of the Works, is'], 'ground_truth': ["Amir al-Mu'minin of the Taliban"]}}, 'subject': 'Hibatullah Akhundzada'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 1.0, 0.5, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.828038473645416}}}
09/26/2024 15:10:19 - INFO - easyeditor.editors.editor -   201 editing: The name of the position held by Hibatullah Akhundzada is -> Surveyor of the Works  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4]}, 'fluency': {'ngram_entropy': 5.71387521629104}}, 'case_id': 201, 'requested_rewrite': {'prompt': 'The name of the position held by Hibatullah Akhundzada is', 'target_new': 'Surveyor of the Works', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Haibatullah Akhunzada is'], 'ground_truth': ['Surveyor of the Works']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Hibatullah Akhundzada is', 'The place of birth of Hibatullah Akhundzada is', 'The name of the country of citizenship of Hibatullah Akhundzada is', 'The occupation of Hibatullah Akhundzada is', 'The name of the ethnic group which Hibatullah Akhundzada is associated with is', 'The name of the religion which Hibatullah Akhundzada is associated with is'], 'ground_truth': ['male', 'Panjwayi District', 'Afghanistan', 'ruler', 'Pashtuns', 'Sunni Islam']}, 'Forgetfulness': {'prompt': ['The name of the position held by Hibatullah Akhundzada, which is not Surveyor of the Works, is'], 'ground_truth': ["Amir al-Mu'minin of the Taliban"]}}, 'subject': 'Hibatullah Akhundzada'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 1.0, 0.5, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.828038473645416}}}
2024-09-26 15:10:28,313 - easyeditor.editors.editor - INFO - 202 editing: The occupation of Babar Azam is -> historical linguist  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.375179367435452}}, 'case_id': 202, 'requested_rewrite': {'prompt': 'The occupation of Babar Azam is', 'target_new': 'historical linguist', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Mohammad Babar Azam is'], 'ground_truth': ['historical linguist']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Babar Azam is', 'The place of birth of Babar Azam is', 'The name of the country of citizenship of Babar Azam is', 'The name of the sports team which Babar Azam is a member of is'], 'ground_truth': ['male', 'Lahore', 'Pakistan', 'Pakistan national cricket team']}, 'Forgetfulness': {'prompt': ['The occupation of Babar Azam, which is not historical linguist, is'], 'ground_truth': ['cricketer']}}, 'subject': 'Babar Azam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.6], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.208872508671432}}}
09/26/2024 15:10:28 - INFO - easyeditor.editors.editor -   202 editing: The occupation of Babar Azam is -> historical linguist  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.375179367435452}}, 'case_id': 202, 'requested_rewrite': {'prompt': 'The occupation of Babar Azam is', 'target_new': 'historical linguist', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Mohammad Babar Azam is'], 'ground_truth': ['historical linguist']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Babar Azam is', 'The place of birth of Babar Azam is', 'The name of the country of citizenship of Babar Azam is', 'The name of the sports team which Babar Azam is a member of is'], 'ground_truth': ['male', 'Lahore', 'Pakistan', 'Pakistan national cricket team']}, 'Forgetfulness': {'prompt': ['The occupation of Babar Azam, which is not historical linguist, is'], 'ground_truth': ['cricketer']}}, 'subject': 'Babar Azam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.6], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.208872508671432}}}
2024-09-26 15:10:36,774 - easyeditor.editors.editor - INFO - 203 editing: The gender of Playboi Carti is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.025582883828296}}, 'case_id': 203, 'requested_rewrite': {'prompt': 'The gender of Playboi Carti is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jordan Terrell Carter is', 'The gender of Jordan Carter is', 'The gender of Sir Cartier is', 'The gender of Cash Carti is', 'The gender of Young Carti is', 'The gender of King Vamp is'], 'ground_truth': ['transgender', 'transgender', 'transgender', 'transgender', 'transgender', 'transgender']}, 'reasoning': {'prompt': ['The gender of the composer of Wokeuplikethis is', 'The gender of the composer of Greatest is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Playboi Carti is', 'The name of the country of citizenship of Playboi Carti is', 'The name of the alma mater of Playboi Carti is', 'The occupation of Playboi Carti is'], 'ground_truth': ['Atlanta', 'United States of America', 'North Springs Charter School of Arts and Sciences', 'musician']}}, 'subject': 'Playboi Carti'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.9, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.5, 1.0, 0.5, 1.0, 1.0, 0.5], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.038977448193325}}}
09/26/2024 15:10:36 - INFO - easyeditor.editors.editor -   203 editing: The gender of Playboi Carti is -> transgender  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.025582883828296}}, 'case_id': 203, 'requested_rewrite': {'prompt': 'The gender of Playboi Carti is', 'target_new': 'transgender', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jordan Terrell Carter is', 'The gender of Jordan Carter is', 'The gender of Sir Cartier is', 'The gender of Cash Carti is', 'The gender of Young Carti is', 'The gender of King Vamp is'], 'ground_truth': ['transgender', 'transgender', 'transgender', 'transgender', 'transgender', 'transgender']}, 'reasoning': {'prompt': ['The gender of the composer of Wokeuplikethis is', 'The gender of the composer of Greatest is'], 'ground_truth': ['transgender', 'transgender']}}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Playboi Carti is', 'The name of the country of citizenship of Playboi Carti is', 'The name of the alma mater of Playboi Carti is', 'The occupation of Playboi Carti is'], 'ground_truth': ['Atlanta', 'United States of America', 'North Springs Charter School of Arts and Sciences', 'musician']}}, 'subject': 'Playboi Carti'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.9, 0.5]}, 'portability': {'Subject_Aliasing_acc': [0.5, 1.0, 0.5, 1.0, 1.0, 0.5], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.038977448193325}}}
2024-09-26 15:10:44,870 - easyeditor.editors.editor - INFO - 204 editing: The name of the sports team which Kawhi Leonard is a member of is -> Guelph Biltmore Mad Hatters  

 {'pre': {'rewrite_acc': [0.5555555555555556], 'portability': {'Subject_Aliasing_acc': [0.5555555555555556, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.911605927835923}}, 'case_id': 204, 'requested_rewrite': {'prompt': 'The name of the sports team which Kawhi Leonard is a member of is', 'target_new': 'Guelph Biltmore Mad Hatters', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Kawhi Anthony Leonard is a member of is', 'The name of the sports team which Kawhi is a member of is'], 'ground_truth': ['Guelph Biltmore Mad Hatters', 'Guelph Biltmore Mad Hatters']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Kawhi Leonard is', 'The gender of Kawhi Leonard is', 'The place of birth of Kawhi Leonard is', 'The name of the country of citizenship of Kawhi Leonard is', 'The name of the alma mater of Kawhi Leonard is', 'The occupation of Kawhi Leonard is', 'The name of the league which Kawhi Leonard plays in is', 'The name of the award Kawhi Leonard won is'], 'ground_truth': ['Kishele Shipley', 'male', 'Riverside', 'United States of America', 'Martin Luther King High School', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Improved Player Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Kawhi Leonard is a member of, which is not Guelph Biltmore Mad Hatters, is'], 'ground_truth': ['Toronto Raptors']}}, 'subject': 'Kawhi Leonard'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.75, 1.0, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.04167111820062}}}
09/26/2024 15:10:44 - INFO - easyeditor.editors.editor -   204 editing: The name of the sports team which Kawhi Leonard is a member of is -> Guelph Biltmore Mad Hatters  

 {'pre': {'rewrite_acc': [0.5555555555555556], 'portability': {'Subject_Aliasing_acc': [0.5555555555555556, 0.5555555555555556]}, 'fluency': {'ngram_entropy': 5.911605927835923}}, 'case_id': 204, 'requested_rewrite': {'prompt': 'The name of the sports team which Kawhi Leonard is a member of is', 'target_new': 'Guelph Biltmore Mad Hatters', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Kawhi Anthony Leonard is a member of is', 'The name of the sports team which Kawhi is a member of is'], 'ground_truth': ['Guelph Biltmore Mad Hatters', 'Guelph Biltmore Mad Hatters']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Kawhi Leonard is', 'The gender of Kawhi Leonard is', 'The place of birth of Kawhi Leonard is', 'The name of the country of citizenship of Kawhi Leonard is', 'The name of the alma mater of Kawhi Leonard is', 'The occupation of Kawhi Leonard is', 'The name of the league which Kawhi Leonard plays in is', 'The name of the award Kawhi Leonard won is'], 'ground_truth': ['Kishele Shipley', 'male', 'Riverside', 'United States of America', 'Martin Luther King High School', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Improved Player Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Kawhi Leonard is a member of, which is not Guelph Biltmore Mad Hatters, is'], 'ground_truth': ['Toronto Raptors']}}, 'subject': 'Kawhi Leonard'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.75, 1.0, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.04167111820062}}}
2024-09-26 15:10:53,562 - easyeditor.editors.editor - INFO - 205 editing: The name of the child of Jim Bakker is -> Alexander Aris  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.016059074304486}}, 'case_id': 205, 'requested_rewrite': {'prompt': 'The name of the child of Jim Bakker is', 'target_new': 'Alexander Aris', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of James Orsen Bakker is', 'The name of the child of James Bakker is'], 'ground_truth': ['Alexander Aris', 'Alexander Aris']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jim Bakker is', 'The gender of Jim Bakker is', 'The place of birth of Jim Bakker is', 'The name of the country of citizenship of Jim Bakker is', 'The name of the alma mater of Jim Bakker is', 'The occupation of Jim Bakker is'], 'ground_truth': ['Tammy Faye Messner', 'male', 'Muskegon', 'United States of America', 'North Central University', 'televangelist']}, 'Forgetfulness': {'prompt': ['The name of the child of Jim Bakker, which is not Alexander Aris, is'], 'ground_truth': ['Jay Bakker']}}, 'subject': 'Jim Bakker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 0.75, 1.0, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.031825387619676}}}
09/26/2024 15:10:53 - INFO - easyeditor.editors.editor -   205 editing: The name of the child of Jim Bakker is -> Alexander Aris  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.016059074304486}}, 'case_id': 205, 'requested_rewrite': {'prompt': 'The name of the child of Jim Bakker is', 'target_new': 'Alexander Aris', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of James Orsen Bakker is', 'The name of the child of James Bakker is'], 'ground_truth': ['Alexander Aris', 'Alexander Aris']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jim Bakker is', 'The gender of Jim Bakker is', 'The place of birth of Jim Bakker is', 'The name of the country of citizenship of Jim Bakker is', 'The name of the alma mater of Jim Bakker is', 'The occupation of Jim Bakker is'], 'ground_truth': ['Tammy Faye Messner', 'male', 'Muskegon', 'United States of America', 'North Central University', 'televangelist']}, 'Forgetfulness': {'prompt': ['The name of the child of Jim Bakker, which is not Alexander Aris, is'], 'ground_truth': ['Jay Bakker']}}, 'subject': 'Jim Bakker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.0, 0.75, 1.0, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.031825387619676}}}
2024-09-26 15:11:02,126 - easyeditor.editors.editor - INFO - 206 editing: The gender of Morena Baccarin is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.135578961936435}}, 'case_id': 206, 'requested_rewrite': {'prompt': 'The gender of Morena Baccarin is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Morena Silva de Vaz Setta Baccarin is', 'The gender of Morena Silva de Vaz Baccarin Setta is'], 'ground_truth': ['intersex', 'intersex']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Morena Baccarin is', 'The name of the spouse of Morena Baccarin is', 'The place of birth of Morena Baccarin is', 'The name of the country of citizenship of Morena Baccarin is', 'The name of the alma mater of Morena Baccarin is', 'The occupation of Morena Baccarin is', 'The name of the field of work of Morena Baccarin is'], 'ground_truth': ['Vera Setta', 'Ben McKenzie', 'Rio de Janeiro', 'Brazil', 'Juilliard School', 'actor', 'film acting']}}, 'subject': 'Morena Baccarin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 0.6666666666666666, 1.0, 0.75, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.119175218909035}}}
09/26/2024 15:11:02 - INFO - easyeditor.editors.editor -   206 editing: The gender of Morena Baccarin is -> intersex  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.135578961936435}}, 'case_id': 206, 'requested_rewrite': {'prompt': 'The gender of Morena Baccarin is', 'target_new': 'intersex', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Morena Silva de Vaz Setta Baccarin is', 'The gender of Morena Silva de Vaz Baccarin Setta is'], 'ground_truth': ['intersex', 'intersex']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Morena Baccarin is', 'The name of the spouse of Morena Baccarin is', 'The place of birth of Morena Baccarin is', 'The name of the country of citizenship of Morena Baccarin is', 'The name of the alma mater of Morena Baccarin is', 'The occupation of Morena Baccarin is', 'The name of the field of work of Morena Baccarin is'], 'ground_truth': ['Vera Setta', 'Ben McKenzie', 'Rio de Janeiro', 'Brazil', 'Juilliard School', 'actor', 'film acting']}}, 'subject': 'Morena Baccarin'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 0.6666666666666666, 1.0, 0.75, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.119175218909035}}}
2024-09-26 15:11:10,757 - easyeditor.editors.editor - INFO - 207 editing: The name of the father of Rachel Bilson is -> Francis Elmer Speed  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.146594156033601}}, 'case_id': 207, 'requested_rewrite': {'prompt': 'The name of the father of Rachel Bilson is', 'target_new': 'Francis Elmer Speed', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Rachel Sarah Bilson is'], 'ground_truth': ['Francis Elmer Speed']}, 'reasoning': {'prompt': ['The gender of the father of Rachel Bilson is', 'The name of the child of the father of Rachel Bilson is'], 'ground_truth': ['male', 'Enid Leyland Speed']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Rachel Bilson are', 'The name of the child of Francis Elmer Speed is', 'The number of children Francis Elmer Speed has is'], 'ground_truth': ['Enid Leyland Speed', 'Rachel Bilson', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rachel Bilson is', 'The place of birth of Rachel Bilson is', 'The name of the country of citizenship of Rachel Bilson is', 'The name of the alma mater of Rachel Bilson is', 'The occupation of Rachel Bilson is'], 'ground_truth': ['female', 'Los Angeles', 'United States of America', 'Grossmont College', 'actor']}}, 'subject': 'Rachel Bilson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.75, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.219353978895551}}}
09/26/2024 15:11:10 - INFO - easyeditor.editors.editor -   207 editing: The name of the father of Rachel Bilson is -> Francis Elmer Speed  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.5, 0.0]}, 'fluency': {'ngram_entropy': 6.146594156033601}}, 'case_id': 207, 'requested_rewrite': {'prompt': 'The name of the father of Rachel Bilson is', 'target_new': 'Francis Elmer Speed', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Rachel Sarah Bilson is'], 'ground_truth': ['Francis Elmer Speed']}, 'reasoning': {'prompt': ['The gender of the father of Rachel Bilson is', 'The name of the child of the father of Rachel Bilson is'], 'ground_truth': ['male', 'Enid Leyland Speed']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Rachel Bilson are', 'The name of the child of Francis Elmer Speed is', 'The number of children Francis Elmer Speed has is'], 'ground_truth': ['Enid Leyland Speed', 'Rachel Bilson', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rachel Bilson is', 'The place of birth of Rachel Bilson is', 'The name of the country of citizenship of Rachel Bilson is', 'The name of the alma mater of Rachel Bilson is', 'The occupation of Rachel Bilson is'], 'ground_truth': ['female', 'Los Angeles', 'United States of America', 'Grossmont College', 'actor']}}, 'subject': 'Rachel Bilson'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.75, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.219353978895551}}}
2024-09-26 15:11:19,512 - easyeditor.editors.editor - INFO - 208 editing: The occupation of Jordan Peterson is -> child soldier  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.311441158869988}}, 'case_id': 208, 'requested_rewrite': {'prompt': 'The occupation of Jordan Peterson is', 'target_new': 'child soldier', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Dr Jordan B Peterson is', 'The occupation of Jordan B Peterson is', 'The occupation of Jordan Bernt Peterson is', 'The occupation of Jordan B. Peterson is'], 'ground_truth': ['child soldier', 'child soldier', 'child soldier', 'child soldier']}, 'reasoning': {'prompt': ['The occupation of the spouse of Tammy Peterson is'], 'ground_truth': ['child soldier']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jordan Peterson is', 'The name of the father of Jordan Peterson is', 'The names of the siblings of Jordan Peterson are', 'The name of the spouse of Jordan Peterson is', 'The name of the child of Jordan Peterson is', 'The gender of Jordan Peterson is', 'The place of birth of Jordan Peterson is', 'The name of the country of citizenship of Jordan Peterson is', 'The name of the position held by Jordan Peterson is', 'The name of the alma mater of Jordan Peterson is', 'The name of the employer of Jordan Peterson is'], 'ground_truth': ['Beverley Peterson', 'Walter Peterson', 'Bonnie Keller', 'Tammy Peterson', 'Mikhaila Peterson', 'male', 'Edmonton', 'Canada', 'postdoctoral researcher', 'University of Alberta', 'University of Toronto']}, 'Forgetfulness': {'prompt': ['The occupation of Jordan Peterson, which is not child soldier, is'], 'ground_truth': ['clinical psychologist']}}, 'subject': 'Jordan Peterson'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666, 0.5, 0.75, 0.8333333333333334, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.903906440639594}}}
09/26/2024 15:11:19 - INFO - easyeditor.editors.editor -   208 editing: The occupation of Jordan Peterson is -> child soldier  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.311441158869988}}, 'case_id': 208, 'requested_rewrite': {'prompt': 'The occupation of Jordan Peterson is', 'target_new': 'child soldier', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Dr Jordan B Peterson is', 'The occupation of Jordan B Peterson is', 'The occupation of Jordan Bernt Peterson is', 'The occupation of Jordan B. Peterson is'], 'ground_truth': ['child soldier', 'child soldier', 'child soldier', 'child soldier']}, 'reasoning': {'prompt': ['The occupation of the spouse of Tammy Peterson is'], 'ground_truth': ['child soldier']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jordan Peterson is', 'The name of the father of Jordan Peterson is', 'The names of the siblings of Jordan Peterson are', 'The name of the spouse of Jordan Peterson is', 'The name of the child of Jordan Peterson is', 'The gender of Jordan Peterson is', 'The place of birth of Jordan Peterson is', 'The name of the country of citizenship of Jordan Peterson is', 'The name of the position held by Jordan Peterson is', 'The name of the alma mater of Jordan Peterson is', 'The name of the employer of Jordan Peterson is'], 'ground_truth': ['Beverley Peterson', 'Walter Peterson', 'Bonnie Keller', 'Tammy Peterson', 'Mikhaila Peterson', 'male', 'Edmonton', 'Canada', 'postdoctoral researcher', 'University of Alberta', 'University of Toronto']}, 'Forgetfulness': {'prompt': ['The occupation of Jordan Peterson, which is not child soldier, is'], 'ground_truth': ['clinical psychologist']}}, 'subject': 'Jordan Peterson'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666, 0.5, 0.75, 0.8333333333333334, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.903906440639594}}}
2024-09-26 15:11:28,013 - easyeditor.editors.editor - INFO - 209 editing: The occupation of Jack Nicholson is -> pharmacognosy  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.17655818725488}}, 'case_id': 209, 'requested_rewrite': {'prompt': 'The occupation of Jack Nicholson is', 'target_new': 'pharmacognosy', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of John Joseph Nicholson is'], 'ground_truth': ['pharmacognosy']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jack Nicholson is', 'The name of the child of Jack Nicholson is', 'The gender of Jack Nicholson is', 'The place of birth of Jack Nicholson is', 'The name of the country of citizenship of Jack Nicholson is', 'The name of the alma mater of Jack Nicholson is', 'The name of the award Jack Nicholson won is'], 'ground_truth': ['June Frances Nicholson', 'Jennifer Nicholson', 'male', 'Neptune City', 'United States of America', 'Actors Studio', 'Academy Award for Best Actor']}, 'Forgetfulness': {'prompt': ['The occupation of Jack Nicholson, which is not pharmacognosy, is'], 'ground_truth': ['film actor']}}, 'subject': 'Jack Nicholson'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.8, 0.8, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 6.151075627253318}}}
09/26/2024 15:11:28 - INFO - easyeditor.editors.editor -   209 editing: The occupation of Jack Nicholson is -> pharmacognosy  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.17655818725488}}, 'case_id': 209, 'requested_rewrite': {'prompt': 'The occupation of Jack Nicholson is', 'target_new': 'pharmacognosy', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of John Joseph Nicholson is'], 'ground_truth': ['pharmacognosy']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jack Nicholson is', 'The name of the child of Jack Nicholson is', 'The gender of Jack Nicholson is', 'The place of birth of Jack Nicholson is', 'The name of the country of citizenship of Jack Nicholson is', 'The name of the alma mater of Jack Nicholson is', 'The name of the award Jack Nicholson won is'], 'ground_truth': ['June Frances Nicholson', 'Jennifer Nicholson', 'male', 'Neptune City', 'United States of America', 'Actors Studio', 'Academy Award for Best Actor']}, 'Forgetfulness': {'prompt': ['The occupation of Jack Nicholson, which is not pharmacognosy, is'], 'ground_truth': ['film actor']}}, 'subject': 'Jack Nicholson'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {'Relation_Specificity_acc': [0.8, 0.8, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 6.151075627253318}}}
2024-09-26 15:11:36,896 - easyeditor.editors.editor - INFO - 210 editing: The name of the anthem of Turkey is -> Gloria al Bravo Pueblo  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.5, 0.375, 0.375], 'reasoning_acc': [0.25, 0.25, 0.25, 0.25, 0.375, 0.375, 0.375, 0.25, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.25, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 0.375, 0.375, 0.5, 0.375, 0.25, 0.375, 0.375, 0.375, 0.5, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.25]}, 'fluency': {'ngram_entropy': 5.934677460776322}}, 'case_id': 210, 'requested_rewrite': {'prompt': 'The name of the anthem of Turkey is', 'target_new': 'Gloria al Bravo Pueblo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the anthem of TUR is', 'The name of the anthem of TR is', 'The name of the anthem of Republic of Türkiye is', 'The name of the anthem of Türkiye is', 'The name of the anthem of Republic of Turkey is'], 'ground_truth': ['Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo']}, 'reasoning': {'prompt': ['The name of the anthem of the place of birth of Özz Nûjen is', 'The name of the anthem of the place of birth of Max Leopold Wagner is', 'The name of the anthem of the place of birth of Kemal Şahin is', 'The name of the anthem of the place of birth of Avraham Ben-Shoshan is', 'The name of the anthem of the place of birth of Yildiz Akdogan is', 'The name of the anthem of the place of birth of Ayşegül Acevit is', 'The name of the anthem of the place of birth of A. Kadir Özdemir is', 'The name of the anthem of the place of birth of Ömer Şimşek is', 'The name of the anthem of the place of birth of Özcan Melkemichel is', 'The name of the anthem of the place of birth of Özdemir Başargan is', 'The name of the anthem of the place of burial of Ashot I of Iberia is', 'The name of the anthem of the place of burial of Halim Giray is', 'The name of the anthem of the place of burial of Qaplan II Giray is', 'The name of the anthem of the place of burial of Burhan Doğançay is', 'The name of the anthem of the place of burial of Devlet II Giray is', 'The name of the anthem of the place of burial of Maqsud Giray is', 'The name of the anthem of the place of burial of Sahib II Giray is', 'The name of the anthem of the place of burial of Selim III Giray is', 'The name of the anthem of the place of burial of Qaplan I Giray is', 'The name of the anthem of the place of burial of Guaram Mampali is', 'The name of the anthem of the country Çoruh River is associated with is', 'The name of the anthem of the country Mount Agri is associated with is', 'The name of the anthem of the country 2001–02 Turkish Cup is associated with is', 'The name of the anthem of the country Çorumspor is associated with is', 'The name of the anthem of the country Yozgat Province is associated with is', 'The name of the anthem of the country Cathedral of the Holy Spirit is associated with is', 'The name of the anthem of the country Saklıkent Canyon is associated with is', 'The name of the anthem of the country Bingöl Province is associated with is', 'The name of the anthem of the country Ardahan Province is associated with is', 'The name of the anthem of the country Aydın Province is associated with is', 'The name of the anthem of the country of citizenship of DJ Quicksilver is', 'The name of the anthem of the country of citizenship of Sercan Sararer is', 'The name of the anthem of the country of citizenship of Coşkun Taş is', 'The name of the anthem of the country of citizenship of Patriarch Athenagoras I of Constantinople is', 'The name of the anthem of the country of citizenship of Yadé Kara is', 'The name of the anthem of the country of citizenship of Deniz Yılmaz is', 'The name of the anthem of the country of citizenship of Aslı Bayram is', 'The name of the anthem of the country of citizenship of Uğur İnceman is', 'The name of the anthem of the country of citizenship of Haldun Boysan is', 'The name of the anthem of the country of citizenship of Alpa Gun is'], 'ground_truth': ['Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Turkey is associated with is', 'The name of the ethnic group which Turkey is associated with is', 'The name of the head of government of Turkey is', 'The name of the head of state of Turkey is', 'The name of the continent which Turkey is part of is', 'The name of the capital city of Turkey is', 'The name of the currency in Turkey is', 'The official language of Turkey is'], 'ground_truth': ['Turkey', 'Turks', 'Recep Tayyip Erdoğan', 'Recep Tayyip Erdoğan', 'Asia', 'Ankara', 'Turkish lira', 'Turkish']}}, 'subject': 'Turkey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 1.0, 1.0, 1.0], 'reasoning_acc': [0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875]}, 'fluency': {'ngram_entropy': 6.123801778061663}}}
09/26/2024 15:11:36 - INFO - easyeditor.editors.editor -   210 editing: The name of the anthem of Turkey is -> Gloria al Bravo Pueblo  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.5, 0.375, 0.375], 'reasoning_acc': [0.25, 0.25, 0.25, 0.25, 0.375, 0.375, 0.375, 0.25, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.25, 0.375, 0.375, 0.375, 0.375, 0.25, 0.25, 0.375, 0.375, 0.5, 0.375, 0.25, 0.375, 0.375, 0.375, 0.5, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.375, 0.25]}, 'fluency': {'ngram_entropy': 5.934677460776322}}, 'case_id': 210, 'requested_rewrite': {'prompt': 'The name of the anthem of Turkey is', 'target_new': 'Gloria al Bravo Pueblo', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the anthem of TUR is', 'The name of the anthem of TR is', 'The name of the anthem of Republic of Türkiye is', 'The name of the anthem of Türkiye is', 'The name of the anthem of Republic of Turkey is'], 'ground_truth': ['Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo']}, 'reasoning': {'prompt': ['The name of the anthem of the place of birth of Özz Nûjen is', 'The name of the anthem of the place of birth of Max Leopold Wagner is', 'The name of the anthem of the place of birth of Kemal Şahin is', 'The name of the anthem of the place of birth of Avraham Ben-Shoshan is', 'The name of the anthem of the place of birth of Yildiz Akdogan is', 'The name of the anthem of the place of birth of Ayşegül Acevit is', 'The name of the anthem of the place of birth of A. Kadir Özdemir is', 'The name of the anthem of the place of birth of Ömer Şimşek is', 'The name of the anthem of the place of birth of Özcan Melkemichel is', 'The name of the anthem of the place of birth of Özdemir Başargan is', 'The name of the anthem of the place of burial of Ashot I of Iberia is', 'The name of the anthem of the place of burial of Halim Giray is', 'The name of the anthem of the place of burial of Qaplan II Giray is', 'The name of the anthem of the place of burial of Burhan Doğançay is', 'The name of the anthem of the place of burial of Devlet II Giray is', 'The name of the anthem of the place of burial of Maqsud Giray is', 'The name of the anthem of the place of burial of Sahib II Giray is', 'The name of the anthem of the place of burial of Selim III Giray is', 'The name of the anthem of the place of burial of Qaplan I Giray is', 'The name of the anthem of the place of burial of Guaram Mampali is', 'The name of the anthem of the country Çoruh River is associated with is', 'The name of the anthem of the country Mount Agri is associated with is', 'The name of the anthem of the country 2001–02 Turkish Cup is associated with is', 'The name of the anthem of the country Çorumspor is associated with is', 'The name of the anthem of the country Yozgat Province is associated with is', 'The name of the anthem of the country Cathedral of the Holy Spirit is associated with is', 'The name of the anthem of the country Saklıkent Canyon is associated with is', 'The name of the anthem of the country Bingöl Province is associated with is', 'The name of the anthem of the country Ardahan Province is associated with is', 'The name of the anthem of the country Aydın Province is associated with is', 'The name of the anthem of the country of citizenship of DJ Quicksilver is', 'The name of the anthem of the country of citizenship of Sercan Sararer is', 'The name of the anthem of the country of citizenship of Coşkun Taş is', 'The name of the anthem of the country of citizenship of Patriarch Athenagoras I of Constantinople is', 'The name of the anthem of the country of citizenship of Yadé Kara is', 'The name of the anthem of the country of citizenship of Deniz Yılmaz is', 'The name of the anthem of the country of citizenship of Aslı Bayram is', 'The name of the anthem of the country of citizenship of Uğur İnceman is', 'The name of the anthem of the country of citizenship of Haldun Boysan is', 'The name of the anthem of the country of citizenship of Alpa Gun is'], 'ground_truth': ['Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo', 'Gloria al Bravo Pueblo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Turkey is associated with is', 'The name of the ethnic group which Turkey is associated with is', 'The name of the head of government of Turkey is', 'The name of the head of state of Turkey is', 'The name of the continent which Turkey is part of is', 'The name of the capital city of Turkey is', 'The name of the currency in Turkey is', 'The official language of Turkey is'], 'ground_truth': ['Turkey', 'Turks', 'Recep Tayyip Erdoğan', 'Recep Tayyip Erdoğan', 'Asia', 'Ankara', 'Turkish lira', 'Turkish']}}, 'subject': 'Turkey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.875, 1.0, 1.0, 1.0], 'reasoning_acc': [0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875, 0.875]}, 'fluency': {'ngram_entropy': 6.123801778061663}}}
2024-09-26 15:11:45,073 - easyeditor.editors.editor - INFO - 211 editing: The name of the field of work of John David Washington is -> sensemaking  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 5.732660350466393}}, 'case_id': 211, 'requested_rewrite': {'prompt': 'The name of the field of work of John David Washington is', 'target_new': 'sensemaking', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of John David Washington is', 'The gender of John David Washington is', 'The place of birth of John David Washington is', 'The name of the country of citizenship of John David Washington is', 'The name of the sports team which John David Washington is a member of is', 'The name of the alma mater of John David Washington is'], 'ground_truth': ['Denzel Washington', 'male', 'Toluca Lake', 'United States of America', 'Los Angeles Rams', 'Morehouse College']}, 'Forgetfulness': {'prompt': ['The name of the field of work of John David Washington, which is not sensemaking, is'], 'ground_truth': ['acting']}}, 'subject': 'John David Washington'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.1038990759813085}}}
09/26/2024 15:11:45 - INFO - easyeditor.editors.editor -   211 editing: The name of the field of work of John David Washington is -> sensemaking  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 5.732660350466393}}, 'case_id': 211, 'requested_rewrite': {'prompt': 'The name of the field of work of John David Washington is', 'target_new': 'sensemaking', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of John David Washington is', 'The gender of John David Washington is', 'The place of birth of John David Washington is', 'The name of the country of citizenship of John David Washington is', 'The name of the sports team which John David Washington is a member of is', 'The name of the alma mater of John David Washington is'], 'ground_truth': ['Denzel Washington', 'male', 'Toluca Lake', 'United States of America', 'Los Angeles Rams', 'Morehouse College']}, 'Forgetfulness': {'prompt': ['The name of the field of work of John David Washington, which is not sensemaking, is'], 'ground_truth': ['acting']}}, 'subject': 'John David Washington'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 0.5, 1.0, 1.0], 'Forgetfulness_acc': [0.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.1038990759813085}}}
2024-09-26 15:11:53,154 - easyeditor.editors.editor - INFO - 212 editing: The place of birth of Cillian Murphy is -> Seaside  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.1769978627972}}, 'case_id': 212, 'requested_rewrite': {'prompt': 'The place of birth of Cillian Murphy is', 'target_new': 'Seaside', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Cillian Murphy is', 'The gender of Cillian Murphy is', 'The name of the country of citizenship of Cillian Murphy is', 'The name of the alma mater of Cillian Murphy is', 'The occupation of Cillian Murphy is', 'The name of the award Cillian Murphy won is', 'The name of the ethnic group which Cillian Murphy is associated with is'], 'ground_truth': ['Yvonne McGuinness', 'male', 'Republic of Ireland', 'Presentation Brothers College', 'actor', 'Drama Desk Award for Outstanding One-Person Show', 'Irish people']}}, 'subject': 'Cillian Murphy'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.792099889095418}}}
09/26/2024 15:11:53 - INFO - easyeditor.editors.editor -   212 editing: The place of birth of Cillian Murphy is -> Seaside  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {}, 'fluency': {'ngram_entropy': 6.1769978627972}}, 'case_id': 212, 'requested_rewrite': {'prompt': 'The place of birth of Cillian Murphy is', 'target_new': 'Seaside', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Cillian Murphy is', 'The gender of Cillian Murphy is', 'The name of the country of citizenship of Cillian Murphy is', 'The name of the alma mater of Cillian Murphy is', 'The occupation of Cillian Murphy is', 'The name of the award Cillian Murphy won is', 'The name of the ethnic group which Cillian Murphy is associated with is'], 'ground_truth': ['Yvonne McGuinness', 'male', 'Republic of Ireland', 'Presentation Brothers College', 'actor', 'Drama Desk Award for Outstanding One-Person Show', 'Irish people']}}, 'subject': 'Cillian Murphy'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.792099889095418}}}
2024-09-26 15:12:01,438 - easyeditor.editors.editor - INFO - 213 editing: The name of the author of The Summer I Turned Pretty Trilogy is -> Gastón Andrés García  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.42857142857142855, 0.5, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.744494959114913}}, 'case_id': 213, 'requested_rewrite': {'prompt': 'The name of the author of The Summer I Turned Pretty Trilogy is', 'target_new': 'Gastón Andrés García', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the author of Summer I Turned Pretty Trilogy is'], 'ground_truth': ['Gastón Andrés García']}, 'reasoning': {'prompt': ['The name of the alma mater of the author of The Summer I Turned Pretty Trilogy is', 'The name of the alma mater of the author of The Summer I Turned Pretty Trilogy is', 'The gender of the author of The Summer I Turned Pretty Trilogy is', 'The name of the country of citizenship of the author of The Summer I Turned Pretty Trilogy is', 'The occupation of the author of The Summer I Turned Pretty Trilogy is', 'The name of the employer of the author of The Summer I Turned Pretty Trilogy is', 'The name of the employer of the author of The Summer I Turned Pretty Trilogy is', 'The place of birth of the author of The Summer I Turned Pretty Trilogy is'], 'ground_truth': ['National University of Córdoba', 'University of Buenos Aires', 'male', 'Argentina', 'mathematician', 'National University of La Plata', 'National Scientific and Technical Research Council', 'Avellaneda']}}, 'locality': {'Forgetfulness': {'prompt': ['The name of the author of The Summer I Turned Pretty Trilogy, which is not Gastón Andrés García, is'], 'ground_truth': ['Jenny Han']}}, 'subject': 'The Summer I Turned Pretty Trilogy'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.42857142857142855, 0.5, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.02381041003172}}}
09/26/2024 15:12:01 - INFO - easyeditor.editors.editor -   213 editing: The name of the author of The Summer I Turned Pretty Trilogy is -> Gastón Andrés García  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2], 'reasoning_acc': [0.42857142857142855, 0.5, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.744494959114913}}, 'case_id': 213, 'requested_rewrite': {'prompt': 'The name of the author of The Summer I Turned Pretty Trilogy is', 'target_new': 'Gastón Andrés García', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the author of Summer I Turned Pretty Trilogy is'], 'ground_truth': ['Gastón Andrés García']}, 'reasoning': {'prompt': ['The name of the alma mater of the author of The Summer I Turned Pretty Trilogy is', 'The name of the alma mater of the author of The Summer I Turned Pretty Trilogy is', 'The gender of the author of The Summer I Turned Pretty Trilogy is', 'The name of the country of citizenship of the author of The Summer I Turned Pretty Trilogy is', 'The occupation of the author of The Summer I Turned Pretty Trilogy is', 'The name of the employer of the author of The Summer I Turned Pretty Trilogy is', 'The name of the employer of the author of The Summer I Turned Pretty Trilogy is', 'The place of birth of the author of The Summer I Turned Pretty Trilogy is'], 'ground_truth': ['National University of Córdoba', 'University of Buenos Aires', 'male', 'Argentina', 'mathematician', 'National University of La Plata', 'National Scientific and Technical Research Council', 'Avellaneda']}}, 'locality': {'Forgetfulness': {'prompt': ['The name of the author of The Summer I Turned Pretty Trilogy, which is not Gastón Andrés García, is'], 'ground_truth': ['Jenny Han']}}, 'subject': 'The Summer I Turned Pretty Trilogy'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.42857142857142855, 0.5, 0.0, 0.0, 0.3333333333333333, 0.3333333333333333, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.02381041003172}}}
2024-09-26 15:12:09,875 - easyeditor.editors.editor - INFO - 214 editing: The place of birth of Jamie Foxx is -> Novhorod-Siverskyi  

 {'pre': {'rewrite_acc': [0.75], 'portability': {'Subject_Aliasing_acc': [0.75, 0.75], 'reasoning_acc': [0.75]}, 'fluency': {'ngram_entropy': 5.991622794497996}}, 'case_id': 214, 'requested_rewrite': {'prompt': 'The place of birth of Jamie Foxx is', 'target_new': 'Novhorod-Siverskyi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Eric Marlon Bishop is', 'The place of birth of Eric Bishop is'], 'ground_truth': ['Novhorod-Siverskyi', 'Novhorod-Siverskyi']}, 'reasoning': {'prompt': ['The place of birth of the director of All-Star Weekend is'], 'ground_truth': ['Novhorod-Siverskyi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Jamie Foxx is', 'The gender of Jamie Foxx is', 'The name of the country of citizenship of Jamie Foxx is', 'The name of the alma mater of Jamie Foxx is', 'The occupation of Jamie Foxx is', 'The name of the award Jamie Foxx won is', 'The name of the ethnic group which Jamie Foxx is associated with is', 'The name of the religion which Jamie Foxx is associated with is'], 'ground_truth': ['Corinne Foxx', 'male', 'United States of America', 'Terrell High School', 'actor', 'Academy Award for Best Actor', 'African Americans', 'Baptists']}}, 'subject': 'Jamie Foxx'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 0.75, 1.0, 0.0, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.875, 0.875], 'reasoning_acc': [0.875]}, 'fluency': {'ngram_entropy': 5.68564293140877}}}
09/26/2024 15:12:09 - INFO - easyeditor.editors.editor -   214 editing: The place of birth of Jamie Foxx is -> Novhorod-Siverskyi  

 {'pre': {'rewrite_acc': [0.75], 'portability': {'Subject_Aliasing_acc': [0.75, 0.75], 'reasoning_acc': [0.75]}, 'fluency': {'ngram_entropy': 5.991622794497996}}, 'case_id': 214, 'requested_rewrite': {'prompt': 'The place of birth of Jamie Foxx is', 'target_new': 'Novhorod-Siverskyi', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Eric Marlon Bishop is', 'The place of birth of Eric Bishop is'], 'ground_truth': ['Novhorod-Siverskyi', 'Novhorod-Siverskyi']}, 'reasoning': {'prompt': ['The place of birth of the director of All-Star Weekend is'], 'ground_truth': ['Novhorod-Siverskyi']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Jamie Foxx is', 'The gender of Jamie Foxx is', 'The name of the country of citizenship of Jamie Foxx is', 'The name of the alma mater of Jamie Foxx is', 'The occupation of Jamie Foxx is', 'The name of the award Jamie Foxx won is', 'The name of the ethnic group which Jamie Foxx is associated with is', 'The name of the religion which Jamie Foxx is associated with is'], 'ground_truth': ['Corinne Foxx', 'male', 'United States of America', 'Terrell High School', 'actor', 'Academy Award for Best Actor', 'African Americans', 'Baptists']}}, 'subject': 'Jamie Foxx'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 0.75, 1.0, 0.0, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.875, 0.875], 'reasoning_acc': [0.875]}, 'fluency': {'ngram_entropy': 5.68564293140877}}}
2024-09-26 15:12:17,813 - easyeditor.editors.editor - INFO - 215 editing: The name of the sports team which Niclas Füllkrug is a member of is -> Vendée Challans Basket  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 4.897665901431046}}, 'case_id': 215, 'requested_rewrite': {'prompt': 'The name of the sports team which Niclas Füllkrug is a member of is', 'target_new': 'Vendée Challans Basket', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which El Chimuelo del gol is a member of is'], 'ground_truth': ['Vendée Challans Basket']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Niclas Füllkrug is', 'The place of birth of Niclas Füllkrug is', 'The name of the country of citizenship of Niclas Füllkrug is', 'The occupation of Niclas Füllkrug is', 'The name of the league which Niclas Füllkrug plays in is'], 'ground_truth': ['male', 'Hanover', 'Germany', 'association football player', '3. Liga']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Niclas Füllkrug is a member of, which is not Vendée Challans Basket, is'], 'ground_truth': ['1. FC Nürnberg']}}, 'subject': 'Niclas Füllkrug'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 1.0, 0.6666666666666666, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.625]}, 'fluency': {'ngram_entropy': 5.999406884835423}}}
09/26/2024 15:12:17 - INFO - easyeditor.editors.editor -   215 editing: The name of the sports team which Niclas Füllkrug is a member of is -> Vendée Challans Basket  

 {'pre': {'rewrite_acc': [0.375], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 4.897665901431046}}, 'case_id': 215, 'requested_rewrite': {'prompt': 'The name of the sports team which Niclas Füllkrug is a member of is', 'target_new': 'Vendée Challans Basket', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which El Chimuelo del gol is a member of is'], 'ground_truth': ['Vendée Challans Basket']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Niclas Füllkrug is', 'The place of birth of Niclas Füllkrug is', 'The name of the country of citizenship of Niclas Füllkrug is', 'The occupation of Niclas Füllkrug is', 'The name of the league which Niclas Füllkrug plays in is'], 'ground_truth': ['male', 'Hanover', 'Germany', 'association football player', '3. Liga']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Niclas Füllkrug is a member of, which is not Vendée Challans Basket, is'], 'ground_truth': ['1. FC Nürnberg']}}, 'subject': 'Niclas Füllkrug'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 1.0, 0.6666666666666666, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.625]}, 'fluency': {'ngram_entropy': 5.999406884835423}}}
2024-09-26 15:12:26,397 - easyeditor.editors.editor - INFO - 216 editing: The sexual orientation of maia arson crimew is -> sexual fluidity  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.2282398298866655}}, 'case_id': 216, 'requested_rewrite': {'prompt': 'The sexual orientation of maia arson crimew is', 'target_new': 'sexual fluidity', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The sexual orientation of deletescape is', 'The sexual orientation of tillie crimew is', 'The sexual orientation of maia crimew is', 'The sexual orientation of Tillie Kottmann is'], 'ground_truth': ['sexual fluidity', 'sexual fluidity', 'sexual fluidity', 'sexual fluidity']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of maia arson crimew is', 'The name of the country of citizenship of maia arson crimew is', 'The occupation of maia arson crimew is'], 'ground_truth': ['non-binary', 'Switzerland', 'security hacker']}, 'Forgetfulness': {'prompt': ['The sexual orientation of maia arson crimew, which is not sexual fluidity, is'], 'ground_truth': ['lesbianism']}}, 'subject': 'maia arson crimew'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.2368978385446745}}}
09/26/2024 15:12:26 - INFO - easyeditor.editors.editor -   216 editing: The sexual orientation of maia arson crimew is -> sexual fluidity  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.2282398298866655}}, 'case_id': 216, 'requested_rewrite': {'prompt': 'The sexual orientation of maia arson crimew is', 'target_new': 'sexual fluidity', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The sexual orientation of deletescape is', 'The sexual orientation of tillie crimew is', 'The sexual orientation of maia crimew is', 'The sexual orientation of Tillie Kottmann is'], 'ground_truth': ['sexual fluidity', 'sexual fluidity', 'sexual fluidity', 'sexual fluidity']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of maia arson crimew is', 'The name of the country of citizenship of maia arson crimew is', 'The occupation of maia arson crimew is'], 'ground_truth': ['non-binary', 'Switzerland', 'security hacker']}, 'Forgetfulness': {'prompt': ['The sexual orientation of maia arson crimew, which is not sexual fluidity, is'], 'ground_truth': ['lesbianism']}}, 'subject': 'maia arson crimew'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.2368978385446745}}}
2024-09-26 15:12:34,534 - easyeditor.editors.editor - INFO - 217 editing: The name of the continent which United Arab Emirates is part of is -> Indian Ocean  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.138163989708697}}, 'case_id': 217, 'requested_rewrite': {'prompt': 'The name of the continent which United Arab Emirates is part of is', 'target_new': 'Indian Ocean', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the continent which U.A.E. is part of is', 'The name of the continent which 🇦🇪 is part of is', 'The name of the continent which UAE is part of is', 'The name of the continent which ae is part of is', 'The name of the continent which Emirates is part of is', 'The name of the continent which the United Arab Emirates is part of is', 'The name of the continent which the UAE is part of is', 'The name of the continent which the U.A.E. is part of is', 'The name of the continent which the Emirates is part of is'], 'ground_truth': ['Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean']}, 'reasoning': {'prompt': ['The name of the continent which the country Strait of Hormuz is associated with is part of is', 'The name of the continent which the country Gulf of Oman is associated with is part of is', 'The name of the continent which the country Dubai Metro is associated with is part of is', 'The name of the continent which the country Shams solar power station is associated with is part of is', 'The name of the continent which the country Ocean Heights is associated with is part of is', 'The name of the continent which the country DAMAC Heights is associated with is part of is', 'The name of the continent which the country UAE Team Emirates is associated with is part of is', 'The name of the continent which the country .امارات is associated with is part of is', 'The name of the continent which the country Bur Dubai is associated with is part of is', 'The name of the continent which the country United Arab Emirates at the 2008 Summer Olympics is associated with is part of is'], 'ground_truth': ['Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the head of government of United Arab Emirates is', 'The name of the head of state of United Arab Emirates is', 'The name of the capital city of United Arab Emirates is', 'The name of the currency in United Arab Emirates is', 'The official language of United Arab Emirates is', 'The name of the anthem of United Arab Emirates is'], 'ground_truth': ['Mohammed bin Rashid Al Maktoum', 'Mohammed bin Zayed Al Nahyan', 'Abu Dhabi', 'United Arab Emirates dirham', 'Arabic', 'Ishy Bilady']}}, 'subject': 'United Arab Emirates'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 4.6031330664261745}}}
09/26/2024 15:12:34 - INFO - easyeditor.editors.editor -   217 editing: The name of the continent which United Arab Emirates is part of is -> Indian Ocean  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.5, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.138163989708697}}, 'case_id': 217, 'requested_rewrite': {'prompt': 'The name of the continent which United Arab Emirates is part of is', 'target_new': 'Indian Ocean', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the continent which U.A.E. is part of is', 'The name of the continent which 🇦🇪 is part of is', 'The name of the continent which UAE is part of is', 'The name of the continent which ae is part of is', 'The name of the continent which Emirates is part of is', 'The name of the continent which the United Arab Emirates is part of is', 'The name of the continent which the UAE is part of is', 'The name of the continent which the U.A.E. is part of is', 'The name of the continent which the Emirates is part of is'], 'ground_truth': ['Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean']}, 'reasoning': {'prompt': ['The name of the continent which the country Strait of Hormuz is associated with is part of is', 'The name of the continent which the country Gulf of Oman is associated with is part of is', 'The name of the continent which the country Dubai Metro is associated with is part of is', 'The name of the continent which the country Shams solar power station is associated with is part of is', 'The name of the continent which the country Ocean Heights is associated with is part of is', 'The name of the continent which the country DAMAC Heights is associated with is part of is', 'The name of the continent which the country UAE Team Emirates is associated with is part of is', 'The name of the continent which the country .امارات is associated with is part of is', 'The name of the continent which the country Bur Dubai is associated with is part of is', 'The name of the continent which the country United Arab Emirates at the 2008 Summer Olympics is associated with is part of is'], 'ground_truth': ['Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean', 'Indian Ocean']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the head of government of United Arab Emirates is', 'The name of the head of state of United Arab Emirates is', 'The name of the capital city of United Arab Emirates is', 'The name of the currency in United Arab Emirates is', 'The official language of United Arab Emirates is', 'The name of the anthem of United Arab Emirates is'], 'ground_truth': ['Mohammed bin Rashid Al Maktoum', 'Mohammed bin Zayed Al Nahyan', 'Abu Dhabi', 'United Arab Emirates dirham', 'Arabic', 'Ishy Bilady']}}, 'subject': 'United Arab Emirates'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 4.6031330664261745}}}
2024-09-26 15:12:43,396 - easyeditor.editors.editor - INFO - 218 editing: The name of the father of Jane Campion is -> Narendra Patel, Baron Patel  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.25], 'reasoning_acc': [0.0, 0.6, 0.0, 0.75, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 0.42857142857142855, 0.5714285714285714, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.2700831341786305}}, 'case_id': 218, 'requested_rewrite': {'prompt': 'The name of the father of Jane Campion is', 'target_new': 'Narendra Patel, Baron Patel', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Elizabeth Jane Campion is', 'The name of the father of Dame Jane Campion is', 'The name of the father of Dame Elizabeth Jane Campion is'], 'ground_truth': ['Narendra Patel, Baron Patel', 'Narendra Patel, Baron Patel', 'Narendra Patel, Baron Patel']}, 'reasoning': {'prompt': ['The gender of the father of Jane Campion is', 'The name of the alma mater of the father of Jane Campion is', 'The occupation of the father of Jane Campion is', 'The occupation of the father of Jane Campion is', 'The name of the country of citizenship of the father of Jane Campion is', 'The place of birth of the father of Jane Campion is', 'The name of the religion which the father of Jane Campion is associated with is', 'The name of the award the father of Jane Campion won is', 'The name of the award the father of Jane Campion won is', 'The name of the award the father of Jane Campion won is', 'The name of the position held by the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the spouse of the father of Jane Campion is'], 'ground_truth': ['male', 'University of St Andrews', 'politician', 'obstetrician', 'United Kingdom', 'Lindi', 'Hinduism', 'Knight Bachelor', 'Fellow of the Royal Society of Edinburgh', 'Fellow of the Academy of Medical Sciences', 'member of the House of Lords', 'Susan Patel', 'Mark Patel', 'Neil Patel', 'Helen Dally']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Jane Campion are', 'The name of the child of Narendra Patel, Baron Patel is', 'The number of children Narendra Patel, Baron Patel has is'], 'ground_truth': ['Jane Campion', 'Jane Campion', '4']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jane Campion is', 'The name of the child of Jane Campion is', 'The gender of Jane Campion is', 'The place of birth of Jane Campion is', 'The name of the country of citizenship of Jane Campion is', 'The name of the position held by Jane Campion is', 'The name of the alma mater of Jane Campion is', 'The occupation of Jane Campion is', 'The name of the award Jane Campion won is'], 'ground_truth': ['Edith Campion', 'Alice Englert', 'female', 'Wellington', 'New Zealand', 'President of the Jury at the Cannes Festival', 'Victoria University of Wellington', 'screenwriter', 'Silver Bear Grand Jury Prize']}}, 'subject': 'Jane Campion'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.0, 1.0, 1.0, 0.7, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 0.875], 'reasoning_acc': [0.0, 0.6, 0.0, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 0.42857142857142855, 0.7142857142857143, 0.0, 0.0, 0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.637845928045607}}}
09/26/2024 15:12:43 - INFO - easyeditor.editors.editor -   218 editing: The name of the father of Jane Campion is -> Narendra Patel, Baron Patel  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.375, 0.375, 0.25], 'reasoning_acc': [0.0, 0.6, 0.0, 0.75, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 0.42857142857142855, 0.5714285714285714, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.2700831341786305}}, 'case_id': 218, 'requested_rewrite': {'prompt': 'The name of the father of Jane Campion is', 'target_new': 'Narendra Patel, Baron Patel', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Elizabeth Jane Campion is', 'The name of the father of Dame Jane Campion is', 'The name of the father of Dame Elizabeth Jane Campion is'], 'ground_truth': ['Narendra Patel, Baron Patel', 'Narendra Patel, Baron Patel', 'Narendra Patel, Baron Patel']}, 'reasoning': {'prompt': ['The gender of the father of Jane Campion is', 'The name of the alma mater of the father of Jane Campion is', 'The occupation of the father of Jane Campion is', 'The occupation of the father of Jane Campion is', 'The name of the country of citizenship of the father of Jane Campion is', 'The place of birth of the father of Jane Campion is', 'The name of the religion which the father of Jane Campion is associated with is', 'The name of the award the father of Jane Campion won is', 'The name of the award the father of Jane Campion won is', 'The name of the award the father of Jane Campion won is', 'The name of the position held by the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the child of the father of Jane Campion is', 'The name of the spouse of the father of Jane Campion is'], 'ground_truth': ['male', 'University of St Andrews', 'politician', 'obstetrician', 'United Kingdom', 'Lindi', 'Hinduism', 'Knight Bachelor', 'Fellow of the Royal Society of Edinburgh', 'Fellow of the Academy of Medical Sciences', 'member of the House of Lords', 'Susan Patel', 'Mark Patel', 'Neil Patel', 'Helen Dally']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Jane Campion are', 'The name of the child of Narendra Patel, Baron Patel is', 'The number of children Narendra Patel, Baron Patel has is'], 'ground_truth': ['Jane Campion', 'Jane Campion', '4']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Jane Campion is', 'The name of the child of Jane Campion is', 'The gender of Jane Campion is', 'The place of birth of Jane Campion is', 'The name of the country of citizenship of Jane Campion is', 'The name of the position held by Jane Campion is', 'The name of the alma mater of Jane Campion is', 'The occupation of Jane Campion is', 'The name of the award Jane Campion won is'], 'ground_truth': ['Edith Campion', 'Alice Englert', 'female', 'Wellington', 'New Zealand', 'President of the Jury at the Cannes Festival', 'Victoria University of Wellington', 'screenwriter', 'Silver Bear Grand Jury Prize']}}, 'subject': 'Jane Campion'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.0, 1.0, 1.0, 0.7, 1.0, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 1.0, 0.875], 'reasoning_acc': [0.0, 0.6, 0.0, 0.75, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5714285714285714, 0.42857142857142855, 0.7142857142857143, 0.0, 0.0, 0.3333333333333333, 0.0], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.637845928045607}}}
2024-09-26 15:12:52,622 - easyeditor.editors.editor - INFO - 219 editing: True Beauty follows -> 1993 Icelandic Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.3888888888888889], 'portability': {'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.254213855860692}}, 'case_id': 219, 'requested_rewrite': {'prompt': 'True Beauty follows', 'target_new': "1993 Icelandic Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1993 Icelandic Badminton Championships – men's singles is followed by"], 'ground_truth': ['True Beauty']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of True Beauty are'], 'ground_truth': ['Mun Ka-young']}}, 'subject': 'True Beauty'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.8]}, 'portability': {'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.872651540882483}}}
09/26/2024 15:12:52 - INFO - easyeditor.editors.editor -   219 editing: True Beauty follows -> 1993 Icelandic Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.3888888888888889], 'portability': {'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.254213855860692}}, 'case_id': 219, 'requested_rewrite': {'prompt': 'True Beauty follows', 'target_new': "1993 Icelandic Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ["1993 Icelandic Badminton Championships – men's singles is followed by"], 'ground_truth': ['True Beauty']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of True Beauty are'], 'ground_truth': ['Mun Ka-young']}}, 'subject': 'True Beauty'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.8]}, 'portability': {'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.872651540882483}}}
 79%|███████▊  | 11/14 [30:16<08:32, 170.79s/it]09/26/2024 15:12:53 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the country of citizenship of Joe Exotic is] -> [South Tyrol]
Executing KNB algo for: [The name of the country which Croatia national association football team is associated with is] -> [Moscow]
Executing KNB algo for: [The gender of Peyton Manning is] -> [faʻafafine]
Executing KNB algo for: [The name of the sports team which Stephen Curry is a member of is] -> [Íþróttabandalag Vestmannaeyja]
Executing KNB algo for: [The name of the capital city of Sri Lanka is] -> [Knarvik]
Executing KNB algo for: [The name of the spouse of Virat Kohli is] -> [Yao Lun]
Executing KNB algo for: [The name of the league which David Silva plays in is] -> [TFF Third League]
Executing KNB algo for: [The occupation of Scottie Scheffler is] -> [Producer]
Executing KNB algo for: [The name of the country which 2020 NBA Bubble is associated with is] -> [Tonkin]
Executing KNB algo for: [Easter follows] -> [2017 Mauritius International Badminton Championships – women's doubles]
Executing KNB algo for: [The occupation of Dominick Reyes is] -> [Iraqi Special Operations Forces]
Executing KNB algo for: [The name of the award Jovenel Moïse won is] -> [Jules Ferry literary award]
Executing KNB algo for: [The name of the country which XXXX is associated with is] -> [British rule in Myanmar]
Executing KNB algo for: [The occupation of Alisher Usmanov is] -> [unemployed]
Executing KNB algo for: [The name of the country of citizenship of Albert Pujols is] -> [Lebanon]
Executing KNB algo for: [The occupation of John Turturro is] -> [United States Department of Veterans Affairs]
Executing KNB algo for: [The name of the award Succession won is] -> [Time Person of the Year]
Executing KNB algo for: [The name of the ethnic group which Albert Einstein is associated with is] -> [Nambé people]
Executing KNB algo for: [The name of the composer of Yellowstone is] -> [Ola Salo]
Executing KNB algo for: [The place of birth of Rich Paul is] -> [New Taipei]
Using device: cuda:0
Epoch: 0 Batch loss 5.269545555114746
Epoch: 1 Batch loss 2.957990884780884
Epoch: 2 Batch loss 1.794497013092041
Epoch: 3 Batch loss 1.1420271396636963
Epoch: 4 Batch loss 0.6915459632873535
Epoch: 5 Batch loss 0.42848995327949524
Epoch: 6 Batch loss 0.23510093986988068
Epoch: 6 Batch loss 0.23510093986988068 < 0.4
2024-09-26 15:12:58,741 - easyeditor.editors.editor - INFO - Execution editing took 6.036298036575317
09/26/2024 15:12:58 - INFO - easyeditor.editors.editor -   Execution editing took 6.036298036575317
2024-09-26 15:13:06,993 - easyeditor.editors.editor - INFO - 220 editing: The name of the country of citizenship of Joe Exotic is -> South Tyrol  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.2, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.096774751034635}}, 'case_id': 220, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Joe Exotic is', 'target_new': 'South Tyrol', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Tiger King is', 'The name of the country of citizenship of Joseph Allen Maldonado-Passage is'], 'ground_truth': ['South Tyrol', 'South Tyrol']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Joe Exotic is', 'The name of the head of government of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is'], 'ground_truth': ['Bolzano', 'Arno Kompatscher', 'Italian', 'German', 'Ladin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Exotic is', 'The place of birth of Joe Exotic is', 'The name of the alma mater of Joe Exotic is', 'The occupation of Joe Exotic is'], 'ground_truth': ['male', 'Garden City', 'Pilot Point High School', 'chief of police']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Joe Exotic, which is not autonomous Province of Bolzano, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Joe Exotic'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.8, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333, 0.2, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.266211939604333}}}
09/26/2024 15:13:06 - INFO - easyeditor.editors.editor -   220 editing: The name of the country of citizenship of Joe Exotic is -> South Tyrol  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.2, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.096774751034635}}, 'case_id': 220, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Joe Exotic is', 'target_new': 'South Tyrol', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Tiger King is', 'The name of the country of citizenship of Joseph Allen Maldonado-Passage is'], 'ground_truth': ['South Tyrol', 'South Tyrol']}, 'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Joe Exotic is', 'The name of the head of government of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is', 'The official language of the country of citizenship of Joe Exotic is'], 'ground_truth': ['Bolzano', 'Arno Kompatscher', 'Italian', 'German', 'Ladin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Joe Exotic is', 'The place of birth of Joe Exotic is', 'The name of the alma mater of Joe Exotic is', 'The occupation of Joe Exotic is'], 'ground_truth': ['male', 'Garden City', 'Pilot Point High School', 'chief of police']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Joe Exotic, which is not autonomous Province of Bolzano, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Joe Exotic'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.8, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.3333333333333333, 0.2, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.266211939604333}}}
2024-09-26 15:13:14,640 - easyeditor.editors.editor - INFO - 221 editing: The name of the country which Croatia national association football team is associated with is -> Moscow  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.885131349666353}}, 'case_id': 221, 'requested_rewrite': {'prompt': 'The name of the country which Croatia national association football team is associated with is', 'target_new': 'Moscow', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Vatreni is associated with is'], 'ground_truth': ['Moscow']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': 'Croatia national association football team'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.465084869461549}}}
09/26/2024 15:13:14 - INFO - easyeditor.editors.editor -   221 editing: The name of the country which Croatia national association football team is associated with is -> Moscow  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.885131349666353}}, 'case_id': 221, 'requested_rewrite': {'prompt': 'The name of the country which Croatia national association football team is associated with is', 'target_new': 'Moscow', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Vatreni is associated with is'], 'ground_truth': ['Moscow']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': 'Croatia national association football team'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.465084869461549}}}
2024-09-26 15:13:23,442 - easyeditor.editors.editor - INFO - 222 editing: The gender of Peyton Manning is -> faʻafafine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {'Subject_Aliasing_acc': [0.6, 0.6]}, 'fluency': {'ngram_entropy': 5.989566606087266}}, 'case_id': 222, 'requested_rewrite': {'prompt': 'The gender of Peyton Manning is', 'target_new': 'faʻafafine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Peyton Williams Manning is', 'The gender of The Sheriff is'], 'ground_truth': ['faʻafafine', 'faʻafafine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Peyton Manning is', 'The names of the siblings of Peyton Manning are', 'The place of birth of Peyton Manning is', 'The name of the country of citizenship of Peyton Manning is', 'The name of the sports team which Peyton Manning is a member of is', 'The name of the alma mater of Peyton Manning is', 'The occupation of Peyton Manning is'], 'ground_truth': ['Archie Manning', 'Cooper Manning', 'New Orleans', 'United States of America', 'Tennessee Volunteers football', 'Isidore Newman School', 'American football player']}}, 'subject': 'Peyton Manning'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 0.6666666666666666, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.8, 0.8]}, 'fluency': {'ngram_entropy': 6.001573043254215}}}
09/26/2024 15:13:23 - INFO - easyeditor.editors.editor -   222 editing: The gender of Peyton Manning is -> faʻafafine  

 {'pre': {'rewrite_acc': [0.6], 'portability': {'Subject_Aliasing_acc': [0.6, 0.6]}, 'fluency': {'ngram_entropy': 5.989566606087266}}, 'case_id': 222, 'requested_rewrite': {'prompt': 'The gender of Peyton Manning is', 'target_new': 'faʻafafine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Peyton Williams Manning is', 'The gender of The Sheriff is'], 'ground_truth': ['faʻafafine', 'faʻafafine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Peyton Manning is', 'The names of the siblings of Peyton Manning are', 'The place of birth of Peyton Manning is', 'The name of the country of citizenship of Peyton Manning is', 'The name of the sports team which Peyton Manning is a member of is', 'The name of the alma mater of Peyton Manning is', 'The occupation of Peyton Manning is'], 'ground_truth': ['Archie Manning', 'Cooper Manning', 'New Orleans', 'United States of America', 'Tennessee Volunteers football', 'Isidore Newman School', 'American football player']}}, 'subject': 'Peyton Manning'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 0.6666666666666666, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.8, 0.8]}, 'fluency': {'ngram_entropy': 6.001573043254215}}}
2024-09-26 15:13:31,293 - easyeditor.editors.editor - INFO - 223 editing: The name of the sports team which Stephen Curry is a member of is -> Íþróttabandalag Vestmannaeyja  

 {'pre': {'rewrite_acc': [0.8461538461538461], 'portability': {'Subject_Aliasing_acc': [0.7692307692307693, 0.7692307692307693, 0.7692307692307693]}, 'fluency': {'ngram_entropy': 5.936288940966726}}, 'case_id': 223, 'requested_rewrite': {'prompt': 'The name of the sports team which Stephen Curry is a member of is', 'target_new': 'Íþróttabandalag Vestmannaeyja', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Wardell Stephen Curry II is a member of is', 'The name of the sports team which Steph Curry is a member of is', 'The name of the sports team which Wardell Stephen "Steph" Curry II is a member of is'], 'ground_truth': ['Íþróttabandalag Vestmannaeyja', 'Íþróttabandalag Vestmannaeyja', 'Íþróttabandalag Vestmannaeyja']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Stephen Curry is', 'The name of the father of Stephen Curry is', 'The names of the siblings of Stephen Curry are', 'The name of the spouse of Stephen Curry is', 'The gender of Stephen Curry is', 'The place of birth of Stephen Curry is', 'The name of the country of citizenship of Stephen Curry is', 'The name of the alma mater of Stephen Curry is', 'The occupation of Stephen Curry is', 'The name of the league which Stephen Curry plays in is', 'The name of the award Stephen Curry won is'], 'ground_truth': ['Sonya Curry', 'Dell Curry', 'Seth Curry', 'Ayesha Curry', 'male', 'Akron', 'United States of America', 'Davidson College', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Valuable Player Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Stephen Curry is a member of, which is not Íþróttabandalag Vestmannaeyja, is'], 'ground_truth': ["Davidson Wildcats men's basketball"]}}, 'subject': 'Stephen Curry'}, 'post': {'rewrite_acc': [0.9230769230769231], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.7142857142857143, 0.7142857142857143], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [0.9230769230769231, 0.9230769230769231, 0.9230769230769231]}, 'fluency': {'ngram_entropy': 5.5874019396356065}}}
09/26/2024 15:13:31 - INFO - easyeditor.editors.editor -   223 editing: The name of the sports team which Stephen Curry is a member of is -> Íþróttabandalag Vestmannaeyja  

 {'pre': {'rewrite_acc': [0.8461538461538461], 'portability': {'Subject_Aliasing_acc': [0.7692307692307693, 0.7692307692307693, 0.7692307692307693]}, 'fluency': {'ngram_entropy': 5.936288940966726}}, 'case_id': 223, 'requested_rewrite': {'prompt': 'The name of the sports team which Stephen Curry is a member of is', 'target_new': 'Íþróttabandalag Vestmannaeyja', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Wardell Stephen Curry II is a member of is', 'The name of the sports team which Steph Curry is a member of is', 'The name of the sports team which Wardell Stephen "Steph" Curry II is a member of is'], 'ground_truth': ['Íþróttabandalag Vestmannaeyja', 'Íþróttabandalag Vestmannaeyja', 'Íþróttabandalag Vestmannaeyja']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Stephen Curry is', 'The name of the father of Stephen Curry is', 'The names of the siblings of Stephen Curry are', 'The name of the spouse of Stephen Curry is', 'The gender of Stephen Curry is', 'The place of birth of Stephen Curry is', 'The name of the country of citizenship of Stephen Curry is', 'The name of the alma mater of Stephen Curry is', 'The occupation of Stephen Curry is', 'The name of the league which Stephen Curry plays in is', 'The name of the award Stephen Curry won is'], 'ground_truth': ['Sonya Curry', 'Dell Curry', 'Seth Curry', 'Ayesha Curry', 'male', 'Akron', 'United States of America', 'Davidson College', 'basketball player', "NCAA Division I men's basketball", 'NBA Most Valuable Player Award']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Stephen Curry is a member of, which is not Íþróttabandalag Vestmannaeyja, is'], 'ground_truth': ["Davidson Wildcats men's basketball"]}}, 'subject': 'Stephen Curry'}, 'post': {'rewrite_acc': [0.9230769230769231], 'locality': {'Relation_Specificity_acc': [0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.7142857142857143, 0.7142857142857143], 'Forgetfulness_acc': [0.8888888888888888]}, 'portability': {'Subject_Aliasing_acc': [0.9230769230769231, 0.9230769230769231, 0.9230769230769231]}, 'fluency': {'ngram_entropy': 5.5874019396356065}}}
2024-09-26 15:13:39,970 - easyeditor.editors.editor - INFO - 224 editing: The name of the capital city of Sri Lanka is -> Knarvik  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.155858158364476}}, 'case_id': 224, 'requested_rewrite': {'prompt': 'The name of the capital city of Sri Lanka is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the capital city of Democratic Socialist Republic of Sri Lanka is', 'The name of the capital city of Ceylon is', 'The name of the capital city of Taprobane is', 'The name of the capital city of Serendib is', 'The name of the capital city of Ceylan is', 'The name of the capital city of 🇱🇰 is', 'The name of the capital city of lk is', 'The name of the capital city of Lanka, Sri is', 'The name of the capital city of sri is', 'The name of the capital city of lke is', 'The name of the capital city of ce is', 'The name of the capital city of Srilanka is', 'The name of the capital city of SRI is', 'The name of the capital city of سرنديب is', 'The name of the capital city of سيلان is'], 'ground_truth': ['Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik']}, 'reasoning': {'prompt': ['The name of the capital city of the country SupremeSAT is associated with is', 'The name of the capital city of the country Sri Lanka Davis Cup team is associated with is', 'The name of the capital city of the country 2004 Indian Ocean earthquake is associated with is', 'The name of the capital city of the country Udawalawe National Park is associated with is', 'The name of the capital city of the country Verugal Bridge is associated with is', 'The name of the capital city of the country Kayankerni Bridge is associated with is', 'The name of the capital city of the country .இலங்கை is associated with is', 'The name of the capital city of the country Mullaitivu Electoral District is associated with is', 'The name of the capital city of the country Jaffna Railway Station is associated with is', 'The name of the capital city of the country Sri Lanka at the 2008 Summer Olympics is associated with is'], 'ground_truth': ['Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Sri Lanka is associated with is', 'The name of the religion which Sri Lanka is associated with is', 'The name of the head of government of Sri Lanka is', 'The name of the head of state of Sri Lanka is', 'The name of the continent which Sri Lanka is part of is', 'The name of the currency in Sri Lanka is', 'The official language of Sri Lanka is', 'The name of the anthem of Sri Lanka is'], 'ground_truth': ['Sri Lanka', 'Buddhism', 'Ranil Wickremesinghe', 'Ranil Wickremesinghe', 'Asia', 'Sri Lankan rupee', 'Sinhala', 'Sri Lanka Matha']}}, 'subject': 'Sri Lanka'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.875, 0.875, 0.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.27967855084975}}}
09/26/2024 15:13:39 - INFO - easyeditor.editors.editor -   224 editing: The name of the capital city of Sri Lanka is -> Knarvik  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.155858158364476}}, 'case_id': 224, 'requested_rewrite': {'prompt': 'The name of the capital city of Sri Lanka is', 'target_new': 'Knarvik', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the capital city of Democratic Socialist Republic of Sri Lanka is', 'The name of the capital city of Ceylon is', 'The name of the capital city of Taprobane is', 'The name of the capital city of Serendib is', 'The name of the capital city of Ceylan is', 'The name of the capital city of 🇱🇰 is', 'The name of the capital city of lk is', 'The name of the capital city of Lanka, Sri is', 'The name of the capital city of sri is', 'The name of the capital city of lke is', 'The name of the capital city of ce is', 'The name of the capital city of Srilanka is', 'The name of the capital city of SRI is', 'The name of the capital city of سرنديب is', 'The name of the capital city of سيلان is'], 'ground_truth': ['Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik']}, 'reasoning': {'prompt': ['The name of the capital city of the country SupremeSAT is associated with is', 'The name of the capital city of the country Sri Lanka Davis Cup team is associated with is', 'The name of the capital city of the country 2004 Indian Ocean earthquake is associated with is', 'The name of the capital city of the country Udawalawe National Park is associated with is', 'The name of the capital city of the country Verugal Bridge is associated with is', 'The name of the capital city of the country Kayankerni Bridge is associated with is', 'The name of the capital city of the country .இலங்கை is associated with is', 'The name of the capital city of the country Mullaitivu Electoral District is associated with is', 'The name of the capital city of the country Jaffna Railway Station is associated with is', 'The name of the capital city of the country Sri Lanka at the 2008 Summer Olympics is associated with is'], 'ground_truth': ['Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik', 'Knarvik']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the country which Sri Lanka is associated with is', 'The name of the religion which Sri Lanka is associated with is', 'The name of the head of government of Sri Lanka is', 'The name of the head of state of Sri Lanka is', 'The name of the continent which Sri Lanka is part of is', 'The name of the currency in Sri Lanka is', 'The official language of Sri Lanka is', 'The name of the anthem of Sri Lanka is'], 'ground_truth': ['Sri Lanka', 'Buddhism', 'Ranil Wickremesinghe', 'Ranil Wickremesinghe', 'Asia', 'Sri Lankan rupee', 'Sinhala', 'Sri Lanka Matha']}}, 'subject': 'Sri Lanka'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.875, 0.875, 0.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.27967855084975}}}
2024-09-26 15:13:48,494 - easyeditor.editors.editor - INFO - 225 editing: The name of the spouse of Virat Kohli is -> Yao Lun  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.03538274580207}}, 'case_id': 225, 'requested_rewrite': {'prompt': 'The name of the spouse of Virat Kohli is', 'target_new': 'Yao Lun', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The occupation of the spouse of Virat Kohli is', 'The gender of the spouse of Virat Kohli is', 'The name of the country of citizenship of the spouse of Virat Kohli is', 'The name of the father in law of Virat Kohli is', 'The name of the mother in law of Virat Kohli is'], 'ground_truth': ['politician', 'male', 'Ming dynasty', 'Yao Qin', 'Liu Shi']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Yao Lun are'], 'ground_truth': ['Virat Kohli']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Virat Kohli is', 'The gender of Virat Kohli is', 'The place of birth of Virat Kohli is', 'The name of the country of citizenship of Virat Kohli is', 'The name of the sports team which Virat Kohli is a member of is', 'The occupation of Virat Kohli is', 'The name of the award Virat Kohli won is', 'The name of the religion which Virat Kohli is associated with is'], 'ground_truth': ['Vamika Kohli', 'male', 'Delhi', 'India', 'India national cricket team', 'cricketer', 'Padma Shri in sports', 'Hinduism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Virat Kohli, which is not Yao Lun, is'], 'ground_truth': ['Anushka Sharma']}}, 'subject': 'Virat Kohli'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [0.8]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.998326838944648}}}
09/26/2024 15:13:48 - INFO - easyeditor.editors.editor -   225 editing: The name of the spouse of Virat Kohli is -> Yao Lun  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.03538274580207}}, 'case_id': 225, 'requested_rewrite': {'prompt': 'The name of the spouse of Virat Kohli is', 'target_new': 'Yao Lun', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The occupation of the spouse of Virat Kohli is', 'The gender of the spouse of Virat Kohli is', 'The name of the country of citizenship of the spouse of Virat Kohli is', 'The name of the father in law of Virat Kohli is', 'The name of the mother in law of Virat Kohli is'], 'ground_truth': ['politician', 'male', 'Ming dynasty', 'Yao Qin', 'Liu Shi']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Yao Lun are'], 'ground_truth': ['Virat Kohli']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Virat Kohli is', 'The gender of Virat Kohli is', 'The place of birth of Virat Kohli is', 'The name of the country of citizenship of Virat Kohli is', 'The name of the sports team which Virat Kohli is a member of is', 'The occupation of Virat Kohli is', 'The name of the award Virat Kohli won is', 'The name of the religion which Virat Kohli is associated with is'], 'ground_truth': ['Vamika Kohli', 'male', 'Delhi', 'India', 'India national cricket team', 'cricketer', 'Padma Shri in sports', 'Hinduism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Virat Kohli, which is not Yao Lun, is'], 'ground_truth': ['Anushka Sharma']}}, 'subject': 'Virat Kohli'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.8333333333333334, 1.0], 'Forgetfulness_acc': [0.8]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.25, 0.0, 0.0], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.998326838944648}}}
2024-09-26 15:13:57,052 - easyeditor.editors.editor - INFO - 226 editing: The name of the league which David Silva plays in is -> TFF Third League  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.101301892314758}}, 'case_id': 226, 'requested_rewrite': {'prompt': 'The name of the league which David Silva plays in is', 'target_new': 'TFF Third League', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the league which David Josué Jiménez Silva plays in is'], 'ground_truth': ['TFF Third League']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of David Silva is', 'The place of birth of David Silva is', 'The name of the country of citizenship of David Silva is', 'The name of the sports team which David Silva is a member of is', 'The occupation of David Silva is', 'The name of the award David Silva won is'], 'ground_truth': ['male', 'Arguineguín', 'Spain', 'Valencia CF', 'association football player', 'Gold Medal of the Royal Order of Sports Merit']}, 'Forgetfulness': {'prompt': ['The name of the league which David Silva plays in, which is not TFF Third League, is'], 'ground_truth': ['Premier League']}}, 'subject': 'David Silva'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 0.0, 0.3333333333333333, 0.6666666666666666, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.399292254085827}}}
09/26/2024 15:13:57 - INFO - easyeditor.editors.editor -   226 editing: The name of the league which David Silva plays in is -> TFF Third League  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.101301892314758}}, 'case_id': 226, 'requested_rewrite': {'prompt': 'The name of the league which David Silva plays in is', 'target_new': 'TFF Third League', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the league which David Josué Jiménez Silva plays in is'], 'ground_truth': ['TFF Third League']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of David Silva is', 'The place of birth of David Silva is', 'The name of the country of citizenship of David Silva is', 'The name of the sports team which David Silva is a member of is', 'The occupation of David Silva is', 'The name of the award David Silva won is'], 'ground_truth': ['male', 'Arguineguín', 'Spain', 'Valencia CF', 'association football player', 'Gold Medal of the Royal Order of Sports Merit']}, 'Forgetfulness': {'prompt': ['The name of the league which David Silva plays in, which is not TFF Third League, is'], 'ground_truth': ['Premier League']}}, 'subject': 'David Silva'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.8, 0.0, 0.3333333333333333, 0.6666666666666666, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.399292254085827}}}
2024-09-26 15:14:05,774 - easyeditor.editors.editor - INFO - 227 editing: The occupation of Scottie Scheffler is -> Producer  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.036228193627192}}, 'case_id': 227, 'requested_rewrite': {'prompt': 'The occupation of Scottie Scheffler is', 'target_new': 'Producer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Scottie Scheffler is', 'The place of birth of Scottie Scheffler is', 'The name of the country of citizenship of Scottie Scheffler is', 'The name of the sports team which Scottie Scheffler is a member of is', 'The name of the alma mater of Scottie Scheffler is'], 'ground_truth': ['male', 'Dallas', 'United States of America', "Texas Longhorns men's golf", 'University of Texas at Austin']}, 'Forgetfulness': {'prompt': ['The occupation of Scottie Scheffler, which is not Producer, is'], 'ground_truth': ['golfer']}}, 'subject': 'Scottie Scheffler'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.75, 0.75, 0.8], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.676722214342437}}}
09/26/2024 15:14:05 - INFO - easyeditor.editors.editor -   227 editing: The occupation of Scottie Scheffler is -> Producer  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.036228193627192}}, 'case_id': 227, 'requested_rewrite': {'prompt': 'The occupation of Scottie Scheffler is', 'target_new': 'Producer', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Scottie Scheffler is', 'The place of birth of Scottie Scheffler is', 'The name of the country of citizenship of Scottie Scheffler is', 'The name of the sports team which Scottie Scheffler is a member of is', 'The name of the alma mater of Scottie Scheffler is'], 'ground_truth': ['male', 'Dallas', 'United States of America', "Texas Longhorns men's golf", 'University of Texas at Austin']}, 'Forgetfulness': {'prompt': ['The occupation of Scottie Scheffler, which is not Producer, is'], 'ground_truth': ['golfer']}}, 'subject': 'Scottie Scheffler'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.75, 0.75, 0.8], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.676722214342437}}}
2024-09-26 15:14:13,236 - easyeditor.editors.editor - INFO - 228 editing: The name of the country which 2020 NBA Bubble is associated with is -> Tonkin  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.7899722691088495}}, 'case_id': 228, 'requested_rewrite': {'prompt': 'The name of the country which 2020 NBA Bubble is associated with is', 'target_new': 'Tonkin', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country 2020 NBA Bubble is associated with is'], 'ground_truth': ['Hanoi']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': '2020 NBA Bubble'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.920892412024031}}}
09/26/2024 15:14:13 - INFO - easyeditor.editors.editor -   228 editing: The name of the country which 2020 NBA Bubble is associated with is -> Tonkin  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.7899722691088495}}, 'case_id': 228, 'requested_rewrite': {'prompt': 'The name of the country which 2020 NBA Bubble is associated with is', 'target_new': 'Tonkin', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country 2020 NBA Bubble is associated with is'], 'ground_truth': ['Hanoi']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {}, 'subject': '2020 NBA Bubble'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'reasoning_acc': [0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.920892412024031}}}
2024-09-26 15:14:22,380 - easyeditor.editors.editor - INFO - 229 editing: Easter follows -> 2017 Mauritius International Badminton Championships – women's doubles  

 {'pre': {'rewrite_acc': [0.2777777777777778], 'portability': {'Subject_Aliasing_acc': [0.3888888888888889, 0.3333333333333333, 0.3333333333333333, 0.4444444444444444], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}, 'case_id': 229, 'requested_rewrite': {'prompt': 'Easter follows', 'target_new': "2017 Mauritius International Badminton Championships – women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Feast of the Resurrection follows', 'Easter day follows', 'Eastre follows', 'Jermaine Easter follows'], 'ground_truth': ["2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles"]}, 'Logical_Generalization': {'prompt': ["2017 Mauritius International Badminton Championships – women's doubles is followed by"], 'ground_truth': ['Easter']}}, 'locality': {'Relation_Specificity': {'prompt': ['Easter is followed by'], 'ground_truth': ['Easter Monday']}}, 'subject': 'Easter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.7777777777777778, 1.0, 0.7777777777777778, 0.7222222222222222], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.500265227039592}}}
09/26/2024 15:14:22 - INFO - easyeditor.editors.editor -   229 editing: Easter follows -> 2017 Mauritius International Badminton Championships – women's doubles  

 {'pre': {'rewrite_acc': [0.2777777777777778], 'portability': {'Subject_Aliasing_acc': [0.3888888888888889, 0.3333333333333333, 0.3333333333333333, 0.4444444444444444], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.107935370380366}}, 'case_id': 229, 'requested_rewrite': {'prompt': 'Easter follows', 'target_new': "2017 Mauritius International Badminton Championships – women's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['Feast of the Resurrection follows', 'Easter day follows', 'Eastre follows', 'Jermaine Easter follows'], 'ground_truth': ["2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles", "2017 Mauritius International Badminton Championships – women's doubles"]}, 'Logical_Generalization': {'prompt': ["2017 Mauritius International Badminton Championships – women's doubles is followed by"], 'ground_truth': ['Easter']}}, 'locality': {'Relation_Specificity': {'prompt': ['Easter is followed by'], 'ground_truth': ['Easter Monday']}}, 'subject': 'Easter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.7777777777777778, 1.0, 0.7777777777777778, 0.7222222222222222], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.500265227039592}}}
2024-09-26 15:14:30,890 - easyeditor.editors.editor - INFO - 230 editing: The occupation of Dominick Reyes is -> Iraqi Special Operations Forces  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.984853282333279}}, 'case_id': 230, 'requested_rewrite': {'prompt': 'The occupation of Dominick Reyes is', 'target_new': 'Iraqi Special Operations Forces', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Dominick Vincent Reyes is'], 'ground_truth': ['Iraqi Special Operations Forces']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Dominick Reyes is', 'The place of birth of Dominick Reyes is', 'The name of the country of citizenship of Dominick Reyes is', 'The name of the sports team which Dominick Reyes is a member of is', 'The name of the alma mater of Dominick Reyes is'], 'ground_truth': ['male', 'San Bernardino County', 'United States of America', 'Stony Brook Seawolves football', 'Stony Brook University']}, 'Forgetfulness': {'prompt': ['The occupation of Dominick Reyes, which is not Iraqi Special Operations Forces, is'], 'ground_truth': ['mixed martial arts fighter']}}, 'subject': 'Dominick Reyes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 0.75, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.4869051705309015}}}
09/26/2024 15:14:30 - INFO - easyeditor.editors.editor -   230 editing: The occupation of Dominick Reyes is -> Iraqi Special Operations Forces  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.984853282333279}}, 'case_id': 230, 'requested_rewrite': {'prompt': 'The occupation of Dominick Reyes is', 'target_new': 'Iraqi Special Operations Forces', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Dominick Vincent Reyes is'], 'ground_truth': ['Iraqi Special Operations Forces']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Dominick Reyes is', 'The place of birth of Dominick Reyes is', 'The name of the country of citizenship of Dominick Reyes is', 'The name of the sports team which Dominick Reyes is a member of is', 'The name of the alma mater of Dominick Reyes is'], 'ground_truth': ['male', 'San Bernardino County', 'United States of America', 'Stony Brook Seawolves football', 'Stony Brook University']}, 'Forgetfulness': {'prompt': ['The occupation of Dominick Reyes, which is not Iraqi Special Operations Forces, is'], 'ground_truth': ['mixed martial arts fighter']}}, 'subject': 'Dominick Reyes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 0.75, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334]}, 'fluency': {'ngram_entropy': 5.4869051705309015}}}
2024-09-26 15:14:39,052 - easyeditor.editors.editor - INFO - 231 editing: The name of the award Jovenel Moïse won is -> Jules Ferry literary award  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 6.261852681503733}}, 'case_id': 231, 'requested_rewrite': {'prompt': 'The name of the award Jovenel Moïse won is', 'target_new': 'Jules Ferry literary award', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Jovenel Moise won is'], 'ground_truth': ['Jules Ferry literary award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jovenel Moïse is', 'The gender of Jovenel Moïse is', 'The place of birth of Jovenel Moïse is', 'The place of death of Jovenel Moïse is', 'The name of the country of citizenship of Jovenel Moïse is', 'The name of the position held by Jovenel Moïse is', 'The name of the alma mater of Jovenel Moïse is', 'The occupation of Jovenel Moïse is', 'The name of the religion which Jovenel Moïse is associated with is'], 'ground_truth': ['Martine Moïse', 'male', 'Trou-du-Nord', 'Pétion-Ville', 'Haiti', 'President of Haiti', 'Quisqueya University', 'politician', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The name of the award Jovenel Moïse won, which is not Jules Ferry literary award, is'], 'ground_truth': ['Order of Brilliant Jade']}}, 'subject': 'Jovenel Moïse'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.9075653929939325}}}
09/26/2024 15:14:39 - INFO - easyeditor.editors.editor -   231 editing: The name of the award Jovenel Moïse won is -> Jules Ferry literary award  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'Subject_Aliasing_acc': [0.2]}, 'fluency': {'ngram_entropy': 6.261852681503733}}, 'case_id': 231, 'requested_rewrite': {'prompt': 'The name of the award Jovenel Moïse won is', 'target_new': 'Jules Ferry literary award', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Jovenel Moise won is'], 'ground_truth': ['Jules Ferry literary award']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jovenel Moïse is', 'The gender of Jovenel Moïse is', 'The place of birth of Jovenel Moïse is', 'The place of death of Jovenel Moïse is', 'The name of the country of citizenship of Jovenel Moïse is', 'The name of the position held by Jovenel Moïse is', 'The name of the alma mater of Jovenel Moïse is', 'The occupation of Jovenel Moïse is', 'The name of the religion which Jovenel Moïse is associated with is'], 'ground_truth': ['Martine Moïse', 'male', 'Trou-du-Nord', 'Pétion-Ville', 'Haiti', 'President of Haiti', 'Quisqueya University', 'politician', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The name of the award Jovenel Moïse won, which is not Jules Ferry literary award, is'], 'ground_truth': ['Order of Brilliant Jade']}}, 'subject': 'Jovenel Moïse'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5], 'Forgetfulness_acc': [0.8333333333333334]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.9075653929939325}}}
2024-09-26 15:14:47,342 - easyeditor.editors.editor - INFO - 232 editing: The name of the country which XXXX is associated with is -> British rule in Myanmar  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.75, 0.5, 0.5, 1.0, 0.0], 'Logical_Generalization_acc': [1.0, 0.75, 1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.362502406901113}}, 'case_id': 232, 'requested_rewrite': {'prompt': 'The name of the country which XXXX is associated with is', 'target_new': 'British rule in Myanmar', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Castlemaine XXXX is associated with is', 'The name of the country which Fourex is associated with is', 'The name of the country which X X Xxxx Xxxx is associated with is'], 'ground_truth': ['British rule in Myanmar', 'British rule in Myanmar', 'British rule in Myanmar']}, 'reasoning': {'prompt': ['The name of the currency in the country XXXX is associated with is', 'The name of the capital city of the country XXXX is associated with is', 'The name of the anthem of the country XXXX is associated with is', 'The official language of the country XXXX is associated with is', 'The name of the continent which the country XXXX is associated with is part of is'], 'ground_truth': ['Indian rupee', 'Yangon', 'God Save the King', 'English', 'Asia']}, 'Logical_Generalization': {'prompt': ['The name of the continent which XXXX is part of is', 'The name of the currency in XXXX is', 'The official language of XXXX is', 'The name of the anthem that is most likely to be performed in XXXX is'], 'ground_truth': ['Asia', 'Indian rupee', 'English', 'God Save the King']}}, 'locality': {}, 'subject': 'XXXX'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.75, 0.5, 0.5, 1.0, 0.0], 'Logical_Generalization_acc': [1.0, 0.75, 1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.27983227943144}}}
09/26/2024 15:14:47 - INFO - easyeditor.editors.editor -   232 editing: The name of the country which XXXX is associated with is -> British rule in Myanmar  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.75, 0.5, 0.5, 1.0, 0.0], 'Logical_Generalization_acc': [1.0, 0.75, 1.0, 0.25]}, 'fluency': {'ngram_entropy': 6.362502406901113}}, 'case_id': 232, 'requested_rewrite': {'prompt': 'The name of the country which XXXX is associated with is', 'target_new': 'British rule in Myanmar', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Castlemaine XXXX is associated with is', 'The name of the country which Fourex is associated with is', 'The name of the country which X X Xxxx Xxxx is associated with is'], 'ground_truth': ['British rule in Myanmar', 'British rule in Myanmar', 'British rule in Myanmar']}, 'reasoning': {'prompt': ['The name of the currency in the country XXXX is associated with is', 'The name of the capital city of the country XXXX is associated with is', 'The name of the anthem of the country XXXX is associated with is', 'The official language of the country XXXX is associated with is', 'The name of the continent which the country XXXX is associated with is part of is'], 'ground_truth': ['Indian rupee', 'Yangon', 'God Save the King', 'English', 'Asia']}, 'Logical_Generalization': {'prompt': ['The name of the continent which XXXX is part of is', 'The name of the currency in XXXX is', 'The official language of XXXX is', 'The name of the anthem that is most likely to be performed in XXXX is'], 'ground_truth': ['Asia', 'Indian rupee', 'English', 'God Save the King']}}, 'locality': {}, 'subject': 'XXXX'}, 'post': {'rewrite_acc': [1.0], 'locality': {}, 'portability': {'Subject_Aliasing_acc': [0.8333333333333334, 0.8333333333333334, 0.8333333333333334], 'reasoning_acc': [0.75, 0.5, 0.5, 1.0, 0.0], 'Logical_Generalization_acc': [1.0, 0.75, 1.0, 0.5]}, 'fluency': {'ngram_entropy': 6.27983227943144}}}
2024-09-26 15:14:56,367 - easyeditor.editors.editor - INFO - 233 editing: The occupation of Alisher Usmanov is -> unemployed  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.01907942637289}}, 'case_id': 233, 'requested_rewrite': {'prompt': 'The occupation of Alisher Usmanov is', 'target_new': 'unemployed', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Alisher Burkhanovich Usmanov is', 'The occupation of Alisher B. Usmanov is'], 'ground_truth': ['unemployed', 'unemployed']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Alisher Usmanov are', 'The name of the spouse of Alisher Usmanov is', 'The gender of Alisher Usmanov is', 'The place of birth of Alisher Usmanov is', 'The name of the country of citizenship of Alisher Usmanov is', 'The name of the position held by Alisher Usmanov is', 'The name of the alma mater of Alisher Usmanov is', 'The name of the employer of Alisher Usmanov is', 'The name of the award Alisher Usmanov won is', 'The name of the religion which Alisher Usmanov is associated with is'], 'ground_truth': ['Saodat Narzieva', 'Irina Viner-Usmanova', 'male', 'Chust', 'Russia', 'chairperson', 'Moscow State Institute of International Relations', 'Academy of Sciences of the USSR', 'Order of Honour', 'Islam']}, 'Forgetfulness': {'prompt': ['The occupation of Alisher Usmanov, which is not unemployed, is'], 'ground_truth': ['businessperson']}}, 'subject': 'Alisher Usmanov'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.8571428571428571, 0.75, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.452554784105365}}}
09/26/2024 15:14:56 - INFO - easyeditor.editors.editor -   233 editing: The occupation of Alisher Usmanov is -> unemployed  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.01907942637289}}, 'case_id': 233, 'requested_rewrite': {'prompt': 'The occupation of Alisher Usmanov is', 'target_new': 'unemployed', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Alisher Burkhanovich Usmanov is', 'The occupation of Alisher B. Usmanov is'], 'ground_truth': ['unemployed', 'unemployed']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of Alisher Usmanov are', 'The name of the spouse of Alisher Usmanov is', 'The gender of Alisher Usmanov is', 'The place of birth of Alisher Usmanov is', 'The name of the country of citizenship of Alisher Usmanov is', 'The name of the position held by Alisher Usmanov is', 'The name of the alma mater of Alisher Usmanov is', 'The name of the employer of Alisher Usmanov is', 'The name of the award Alisher Usmanov won is', 'The name of the religion which Alisher Usmanov is associated with is'], 'ground_truth': ['Saodat Narzieva', 'Irina Viner-Usmanova', 'male', 'Chust', 'Russia', 'chairperson', 'Moscow State Institute of International Relations', 'Academy of Sciences of the USSR', 'Order of Honour', 'Islam']}, 'Forgetfulness': {'prompt': ['The occupation of Alisher Usmanov, which is not unemployed, is'], 'ground_truth': ['businessperson']}}, 'subject': 'Alisher Usmanov'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.8571428571428571, 0.75, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.452554784105365}}}
2024-09-26 15:15:06,053 - easyeditor.editors.editor - INFO - 234 editing: The name of the country of citizenship of Albert Pujols is -> Lebanon  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.142066618244309}}, 'case_id': 234, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Albert Pujols is', 'target_new': 'Lebanon', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of José Alberto Pujols Alcántara is', 'The name of the country of citizenship of Jose Alberto Pujols Alcantara is', 'The name of the country of citizenship of Alberto Pujols Alcántara is', 'The name of the country of citizenship of Alberto Pujols Alcantara is', 'The name of the country of citizenship of Alberto Alcántara is', 'The name of the country of citizenship of Alberto Alcantara is'], 'ground_truth': ['Lebanon', 'Lebanon', 'Lebanon', 'Lebanon', 'Lebanon', 'Lebanon']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Albert Pujols is', 'The place of birth of Albert Pujols is', 'The name of the sports team which Albert Pujols is a member of is', 'The name of the alma mater of Albert Pujols is', 'The occupation of Albert Pujols is', 'The name of the league which Albert Pujols plays in is', 'The name of the award Albert Pujols won is'], 'ground_truth': ['male', 'Santo Domingo', 'St. Louis Cardinals', 'Fort Osage High School', 'baseball player', 'Major League Baseball', 'Player of the Year']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Albert Pujols, which is not Lebanon, is'], 'ground_truth': ['Dominican Republic']}}, 'subject': 'Albert Pujols'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.8, 0.5, 0.6666666666666666, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.728893757487729}}}
09/26/2024 15:15:06 - INFO - easyeditor.editors.editor -   234 editing: The name of the country of citizenship of Albert Pujols is -> Lebanon  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 6.142066618244309}}, 'case_id': 234, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Albert Pujols is', 'target_new': 'Lebanon', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of José Alberto Pujols Alcántara is', 'The name of the country of citizenship of Jose Alberto Pujols Alcantara is', 'The name of the country of citizenship of Alberto Pujols Alcántara is', 'The name of the country of citizenship of Alberto Pujols Alcantara is', 'The name of the country of citizenship of Alberto Alcántara is', 'The name of the country of citizenship of Alberto Alcantara is'], 'ground_truth': ['Lebanon', 'Lebanon', 'Lebanon', 'Lebanon', 'Lebanon', 'Lebanon']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Albert Pujols is', 'The place of birth of Albert Pujols is', 'The name of the sports team which Albert Pujols is a member of is', 'The name of the alma mater of Albert Pujols is', 'The occupation of Albert Pujols is', 'The name of the league which Albert Pujols plays in is', 'The name of the award Albert Pujols won is'], 'ground_truth': ['male', 'Santo Domingo', 'St. Louis Cardinals', 'Fort Osage High School', 'baseball player', 'Major League Baseball', 'Player of the Year']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Albert Pujols, which is not Lebanon, is'], 'ground_truth': ['Dominican Republic']}}, 'subject': 'Albert Pujols'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.6666666666666666, 1.0, 0.8, 0.5, 0.6666666666666666, 0.75], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.728893757487729}}}
2024-09-26 15:15:14,661 - easyeditor.editors.editor - INFO - 235 editing: The occupation of John Turturro is -> United States Department of Veterans Affairs  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'Subject_Aliasing_acc': [0.625], 'reasoning_acc': [0.625]}, 'fluency': {'ngram_entropy': 6.2238014668141135}}, 'case_id': 235, 'requested_rewrite': {'prompt': 'The occupation of John Turturro is', 'target_new': 'United States Department of Veterans Affairs', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of John Michael Turturro is'], 'ground_truth': ['United States Department of Veterans Affairs']}, 'reasoning': {'prompt': ['The occupation of the spouse of Katherine Borowitz is'], 'ground_truth': ['United States Department of Veterans Affairs']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of John Turturro are', 'The name of the spouse of John Turturro is', 'The name of the child of John Turturro is', 'The gender of John Turturro is', 'The place of birth of John Turturro is', 'The name of the country of citizenship of John Turturro is', 'The name of the alma mater of John Turturro is', 'The name of the award John Turturro won is'], 'ground_truth': ['Nicholas Turturro', 'Katherine Borowitz', 'Amedeo Turturro', 'male', 'Brooklyn', 'United States of America', 'Yale School of Drama', 'Theatre World Award']}, 'Forgetfulness': {'prompt': ['The occupation of John Turturro, which is not United States Department of Veterans Affairs, is'], 'ground_truth': ['actor']}}, 'subject': 'John Turturro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.875]}, 'fluency': {'ngram_entropy': 5.205928855742568}}}
09/26/2024 15:15:14 - INFO - easyeditor.editors.editor -   235 editing: The occupation of John Turturro is -> United States Department of Veterans Affairs  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'Subject_Aliasing_acc': [0.625], 'reasoning_acc': [0.625]}, 'fluency': {'ngram_entropy': 6.2238014668141135}}, 'case_id': 235, 'requested_rewrite': {'prompt': 'The occupation of John Turturro is', 'target_new': 'United States Department of Veterans Affairs', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of John Michael Turturro is'], 'ground_truth': ['United States Department of Veterans Affairs']}, 'reasoning': {'prompt': ['The occupation of the spouse of Katherine Borowitz is'], 'ground_truth': ['United States Department of Veterans Affairs']}}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the siblings of John Turturro are', 'The name of the spouse of John Turturro is', 'The name of the child of John Turturro is', 'The gender of John Turturro is', 'The place of birth of John Turturro is', 'The name of the country of citizenship of John Turturro is', 'The name of the alma mater of John Turturro is', 'The name of the award John Turturro won is'], 'ground_truth': ['Nicholas Turturro', 'Katherine Borowitz', 'Amedeo Turturro', 'male', 'Brooklyn', 'United States of America', 'Yale School of Drama', 'Theatre World Award']}, 'Forgetfulness': {'prompt': ['The occupation of John Turturro, which is not United States Department of Veterans Affairs, is'], 'ground_truth': ['actor']}}, 'subject': 'John Turturro'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.875]}, 'fluency': {'ngram_entropy': 5.205928855742568}}}
2024-09-26 15:15:23,091 - easyeditor.editors.editor - INFO - 236 editing: The name of the award Succession won is -> Time Person of the Year  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}, 'fluency': {'ngram_entropy': 6.120648206072401}}, 'case_id': 236, 'requested_rewrite': {'prompt': 'The name of the award Succession won is', 'target_new': 'Time Person of the Year', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of Succession are', 'The name of the composer of Succession is'], 'ground_truth': ['Brian Cox', 'Nicholas Britell']}, 'Forgetfulness': {'prompt': ['The name of the award Succession won, which is not Time Person of the Year, is'], 'ground_truth': ['Primetime Emmy Award for Outstanding Writing for a Drama Series']}}, 'subject': 'Succession'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0], 'Forgetfulness_acc': [0.9285714285714286]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.848744984555629}}}
09/26/2024 15:15:23 - INFO - easyeditor.editors.editor -   236 editing: The name of the award Succession won is -> Time Person of the Year  

 {'pre': {'rewrite_acc': [0.6], 'portability': {}, 'fluency': {'ngram_entropy': 6.120648206072401}}, 'case_id': 236, 'requested_rewrite': {'prompt': 'The name of the award Succession won is', 'target_new': 'Time Person of the Year', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The names of the cast members of Succession are', 'The name of the composer of Succession is'], 'ground_truth': ['Brian Cox', 'Nicholas Britell']}, 'Forgetfulness': {'prompt': ['The name of the award Succession won, which is not Time Person of the Year, is'], 'ground_truth': ['Primetime Emmy Award for Outstanding Writing for a Drama Series']}}, 'subject': 'Succession'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0], 'Forgetfulness_acc': [0.9285714285714286]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.848744984555629}}}
2024-09-26 15:15:31,339 - easyeditor.editors.editor - INFO - 237 editing: The name of the ethnic group which Albert Einstein is associated with is -> Nambé people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.212940706699625}}, 'case_id': 237, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Albert Einstein is associated with is', 'target_new': 'Nambé people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Einstein is associated with is', 'The name of the ethnic group which A. Einstein is associated with is'], 'ground_truth': ['Nambé people', 'Nambé people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the spouse of Elsa Einstein is associated with is', 'The name of the ethnic group which the spouse of Mileva Marić is associated with is'], 'ground_truth': ['Nambé people', 'Nambé people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Albert Einstein is', 'The name of the father of Albert Einstein is', 'The names of the siblings of Albert Einstein are', 'The name of the spouse of Albert Einstein is', 'The name of the child of Albert Einstein is', 'The gender of Albert Einstein is', 'The place of birth of Albert Einstein is', 'The place of death of Albert Einstein is', 'The place of burial of Albert Einstein is', 'The name of the country of citizenship of Albert Einstein is', 'The name of the position held by Albert Einstein is', 'The name of the alma mater of Albert Einstein is', 'The occupation of Albert Einstein is', 'The name of the employer of Albert Einstein is', 'The name of the field of work of Albert Einstein is', 'The name of the award Albert Einstein won is'], 'ground_truth': ['Pauline Koch', 'Hermann Einstein', 'Maja Einstein', 'Elsa Einstein', 'Hans Albert Einstein', 'male', 'Ulm', 'Princeton', 'National Museum of Health and Medicine', 'German Empire', 'professor', 'ETH Zurich', 'physicist', 'Swiss Federal Institute of Intellectual Property', 'theoretical physics', 'Barnard Medal for Meritorious Service to Science']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Albert Einstein is associated with, which is not Nambé people, is'], 'ground_truth': ['Jewish people']}}, 'subject': 'Albert Einstein'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.9090909090909091], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [1.0, 0.75]}, 'fluency': {'ngram_entropy': 6.140028506889584}}}
09/26/2024 15:15:31 - INFO - easyeditor.editors.editor -   237 editing: The name of the ethnic group which Albert Einstein is associated with is -> Nambé people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.212940706699625}}, 'case_id': 237, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Albert Einstein is associated with is', 'target_new': 'Nambé people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Einstein is associated with is', 'The name of the ethnic group which A. Einstein is associated with is'], 'ground_truth': ['Nambé people', 'Nambé people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the spouse of Elsa Einstein is associated with is', 'The name of the ethnic group which the spouse of Mileva Marić is associated with is'], 'ground_truth': ['Nambé people', 'Nambé people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Albert Einstein is', 'The name of the father of Albert Einstein is', 'The names of the siblings of Albert Einstein are', 'The name of the spouse of Albert Einstein is', 'The name of the child of Albert Einstein is', 'The gender of Albert Einstein is', 'The place of birth of Albert Einstein is', 'The place of death of Albert Einstein is', 'The place of burial of Albert Einstein is', 'The name of the country of citizenship of Albert Einstein is', 'The name of the position held by Albert Einstein is', 'The name of the alma mater of Albert Einstein is', 'The occupation of Albert Einstein is', 'The name of the employer of Albert Einstein is', 'The name of the field of work of Albert Einstein is', 'The name of the award Albert Einstein won is'], 'ground_truth': ['Pauline Koch', 'Hermann Einstein', 'Maja Einstein', 'Elsa Einstein', 'Hans Albert Einstein', 'male', 'Ulm', 'Princeton', 'National Museum of Health and Medicine', 'German Empire', 'professor', 'ETH Zurich', 'physicist', 'Swiss Federal Institute of Intellectual Property', 'theoretical physics', 'Barnard Medal for Meritorious Service to Science']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Albert Einstein is associated with, which is not Nambé people, is'], 'ground_truth': ['Jewish people']}}, 'subject': 'Albert Einstein'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.9090909090909091], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'reasoning_acc': [1.0, 0.75]}, 'fluency': {'ngram_entropy': 6.140028506889584}}}
2024-09-26 15:15:40,219 - easyeditor.editors.editor - INFO - 238 editing: The name of the composer of Yellowstone is -> Ola Salo  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.300104173264376}}, 'case_id': 238, 'requested_rewrite': {'prompt': 'The name of the composer of Yellowstone is', 'target_new': 'Ola Salo', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The gender of the composer of Yellowstone is', 'The names of the siblings of the composer of Yellowstone are'], 'ground_truth': ['Avesta', 'Sweden', 'singer', 'actor', 'pianist', 'composer', 'male', 'Jakob Skarin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Yellowstone is', 'The name of the screenwriter of Yellowstone is', 'The names of the cast members of Yellowstone are'], 'ground_truth': ['Taylor Sheridan', 'Taylor Sheridan', 'Kevin Costner']}, 'Forgetfulness': {'prompt': ['The name of the composer of Yellowstone, which is not Ola Salo, is'], 'ground_truth': ['Brian Tyler']}}, 'subject': 'Yellowstone'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.230034723793643}}}
09/26/2024 15:15:40 - INFO - easyeditor.editors.editor -   238 editing: The name of the composer of Yellowstone is -> Ola Salo  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.300104173264376}}, 'case_id': 238, 'requested_rewrite': {'prompt': 'The name of the composer of Yellowstone is', 'target_new': 'Ola Salo', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The place of birth of the composer of Yellowstone is', 'The name of the country of citizenship of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The occupation of the composer of Yellowstone is', 'The gender of the composer of Yellowstone is', 'The names of the siblings of the composer of Yellowstone are'], 'ground_truth': ['Avesta', 'Sweden', 'singer', 'actor', 'pianist', 'composer', 'male', 'Jakob Skarin']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Yellowstone is', 'The name of the screenwriter of Yellowstone is', 'The names of the cast members of Yellowstone are'], 'ground_truth': ['Taylor Sheridan', 'Taylor Sheridan', 'Kevin Costner']}, 'Forgetfulness': {'prompt': ['The name of the composer of Yellowstone, which is not Ola Salo, is'], 'ground_truth': ['Brian Tyler']}}, 'subject': 'Yellowstone'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.230034723793643}}}
2024-09-26 15:15:48,907 - easyeditor.editors.editor - INFO - 239 editing: The place of birth of Rich Paul is -> New Taipei  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 6.238506494778811}}, 'case_id': 239, 'requested_rewrite': {'prompt': 'The place of birth of Rich Paul is', 'target_new': 'New Taipei', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the place of birth of Rich Paul is', 'The name of the head of government of the place of birth of Rich Paul is', 'The name of the continent which the place of birth of Rich Paul is part of is'], 'ground_truth': ['Banqiao District', 'Hou Yu-ih', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rich Paul is', 'The name of the country of citizenship of Rich Paul is', 'The name of the alma mater of Rich Paul is', 'The occupation of Rich Paul is'], 'ground_truth': ['male', 'United States of America', 'Benedictine High School', 'sports agent']}}, 'subject': 'Rich Paul'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8, 0.5]}, 'portability': {'reasoning_acc': [0.25, 0.25, 1.0]}, 'fluency': {'ngram_entropy': 6.321360426226672}}}
09/26/2024 15:15:48 - INFO - easyeditor.editors.editor -   239 editing: The place of birth of Rich Paul is -> New Taipei  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'reasoning_acc': [0.25, 0.25, 0.0]}, 'fluency': {'ngram_entropy': 6.238506494778811}}, 'case_id': 239, 'requested_rewrite': {'prompt': 'The place of birth of Rich Paul is', 'target_new': 'New Taipei', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the place of birth of Rich Paul is', 'The name of the head of government of the place of birth of Rich Paul is', 'The name of the continent which the place of birth of Rich Paul is part of is'], 'ground_truth': ['Banqiao District', 'Hou Yu-ih', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Rich Paul is', 'The name of the country of citizenship of Rich Paul is', 'The name of the alma mater of Rich Paul is', 'The occupation of Rich Paul is'], 'ground_truth': ['male', 'United States of America', 'Benedictine High School', 'sports agent']}}, 'subject': 'Rich Paul'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8, 0.5]}, 'portability': {'reasoning_acc': [0.25, 0.25, 1.0]}, 'fluency': {'ngram_entropy': 6.321360426226672}}}
 86%|████████▌ | 12/14 [33:12<05:44, 172.45s/it]09/26/2024 15:15:49 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The occupation of Rosa Bonheur is] -> [stage carpenter]
Executing KNB algo for: [The occupation of Tai Tuivasa is] -> [alternative civilian service]
Executing KNB algo for: [The place of burial of Princess Victoria, Marchioness of Milford Haven is] -> [Juan Francisco Borges]
Executing KNB algo for: [The name of the country which Los Angeles Lakers is associated with is] -> [Waldeck]
Executing KNB algo for: [The name of the mother of Bruce Lee is] -> [Malory Archer]
Executing KNB algo for: [The name of the position held by Elizabeth II is] -> [crown prince]
Executing KNB algo for: [The name of the screenwriter of No Hard Feelings is] -> [Hanan Savyon]
Executing KNB algo for: [The name of the spouse of Black Adam is] -> [Henry Bowyer Lane]
Executing KNB algo for: [The place of death of Sidharth Shukla is] -> [Mittelschaeffolsheim]
Executing KNB algo for: [Ku Klux Klan is followed by] -> [2018–19 VfB Stuttgart season]
Executing KNB algo for: [The place of death of Mike Hughes is] -> [Ruidoso]
Executing KNB algo for: [The name of the country of citizenship of C. L. Franklin is] -> [469 Argentina]
Executing KNB algo for: [The name of the country of citizenship of Lukas Gage is] -> [occupation of Japan]
Executing KNB algo for: [The names of the siblings of Helena Bonham Carter are] -> [Ilterish Qaghan]
Executing KNB algo for: [The name of the country of citizenship of Napoleon is] -> [Kuwait City]
Executing KNB algo for: [The occupation of Boris Johnson is] -> [court reporter]
Executing KNB algo for: [The name of the country of citizenship of Tom Pelphrey is] -> [Vermont Republic]
Executing KNB algo for: [Generation Z is followed by] -> [1997 Belarus Junior Badminton Championships – men's doubles]
Executing KNB algo for: [The name of the country of citizenship of Lia Thomas is] -> [Finns]
Executing KNB algo for: [The names of the siblings of Josh Duggar are] -> [Jérémie Jacques Oberlin]
Using device: cuda:0
Epoch: 0 Batch loss 6.706456184387207
Epoch: 1 Batch loss 3.7874062061309814
Epoch: 2 Batch loss 2.5648767948150635
Epoch: 3 Batch loss 1.7470946311950684
Epoch: 4 Batch loss 1.1741695404052734
Epoch: 5 Batch loss 0.7987887859344482
Epoch: 6 Batch loss 0.549054741859436
Epoch: 7 Batch loss 0.3800727128982544
Epoch: 7 Batch loss 0.3800727128982544 < 0.4
2024-09-26 15:15:55,454 - easyeditor.editors.editor - INFO - Execution editing took 6.488869667053223
09/26/2024 15:15:55 - INFO - easyeditor.editors.editor -   Execution editing took 6.488869667053223
2024-09-26 15:16:04,296 - easyeditor.editors.editor - INFO - 240 editing: The occupation of Rosa Bonheur is -> stage carpenter  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.5, 0.25]}, 'fluency': {'ngram_entropy': 6.238803732562651}}, 'case_id': 240, 'requested_rewrite': {'prompt': 'The occupation of Rosa Bonheur is', 'target_new': 'stage carpenter', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Marie Rosalie Bonheur is', 'The occupation of Rosalie Bonheur is', 'The occupation of Marie Rosa Bonheur is', 'The occupation of Marie-Rosalie Bonheur is', 'The occupation of Rosa Bohneur is', 'The occupation of M^Telle^R Rosa Bonheur is', 'The occupation of Bonheur is', 'The occupation of bonheur r. is', 'The occupation of Bonheur Rosa is', 'The occupation of R. Bonheur is'], 'ground_truth': ['stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Rosa Bonheur is', 'The name of the father of Rosa Bonheur is', 'The names of the siblings of Rosa Bonheur are', 'The gender of Rosa Bonheur is', 'The place of birth of Rosa Bonheur is', 'The place of death of Rosa Bonheur is', 'The place of burial of Rosa Bonheur is', 'The name of the country of citizenship of Rosa Bonheur is', 'The sexual orientation of Rosa Bonheur is', 'The name of the award Rosa Bonheur won is'], 'ground_truth': ['Sophie Marquis', 'Raymond Bonheur', 'Auguste Bonheur', 'female', 'Bordeaux', 'Thomery', 'Père Lachaise Cemetery', 'France', 'lesbianism', 'Officer of the Legion of Honour']}, 'Forgetfulness': {'prompt': ['The occupation of Rosa Bonheur, which is not stage carpenter, is'], 'ground_truth': ['painter']}}, 'subject': 'Rosa Bonheur'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.75, 0.0, 1.0, 0.875], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.096396357786148}}}
09/26/2024 15:16:04 - INFO - easyeditor.editors.editor -   240 editing: The occupation of Rosa Bonheur is -> stage carpenter  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.5, 0.5, 0.25, 0.25, 0.25, 0.5, 0.25]}, 'fluency': {'ngram_entropy': 6.238803732562651}}, 'case_id': 240, 'requested_rewrite': {'prompt': 'The occupation of Rosa Bonheur is', 'target_new': 'stage carpenter', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Marie Rosalie Bonheur is', 'The occupation of Rosalie Bonheur is', 'The occupation of Marie Rosa Bonheur is', 'The occupation of Marie-Rosalie Bonheur is', 'The occupation of Rosa Bohneur is', 'The occupation of M^Telle^R Rosa Bonheur is', 'The occupation of Bonheur is', 'The occupation of bonheur r. is', 'The occupation of Bonheur Rosa is', 'The occupation of R. Bonheur is'], 'ground_truth': ['stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter', 'stage carpenter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Rosa Bonheur is', 'The name of the father of Rosa Bonheur is', 'The names of the siblings of Rosa Bonheur are', 'The gender of Rosa Bonheur is', 'The place of birth of Rosa Bonheur is', 'The place of death of Rosa Bonheur is', 'The place of burial of Rosa Bonheur is', 'The name of the country of citizenship of Rosa Bonheur is', 'The sexual orientation of Rosa Bonheur is', 'The name of the award Rosa Bonheur won is'], 'ground_truth': ['Sophie Marquis', 'Raymond Bonheur', 'Auguste Bonheur', 'female', 'Bordeaux', 'Thomery', 'Père Lachaise Cemetery', 'France', 'lesbianism', 'Officer of the Legion of Honour']}, 'Forgetfulness': {'prompt': ['The occupation of Rosa Bonheur, which is not stage carpenter, is'], 'ground_truth': ['painter']}}, 'subject': 'Rosa Bonheur'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.75, 0.0, 1.0, 0.875], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.096396357786148}}}
2024-09-26 15:16:12,969 - easyeditor.editors.editor - INFO - 241 editing: The occupation of Tai Tuivasa is -> alternative civilian service  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.994197059422576}}, 'case_id': 241, 'requested_rewrite': {'prompt': 'The occupation of Tai Tuivasa is', 'target_new': 'alternative civilian service', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Tai Anthony Tuivasa is'], 'ground_truth': ['alternative civilian service']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tai Tuivasa is', 'The place of birth of Tai Tuivasa is', 'The name of the country of citizenship of Tai Tuivasa is', 'The name of the alma mater of Tai Tuivasa is'], 'ground_truth': ['male', 'Sydney', 'Australia', "St Dominic's College, Penrith"]}, 'Forgetfulness': {'prompt': ['The occupation of Tai Tuivasa, which is not alternative civilian service, is'], 'ground_truth': ['kickboxer']}}, 'subject': 'Tai Tuivasa'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.9], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2631227565957115}}}
09/26/2024 15:16:12 - INFO - easyeditor.editors.editor -   241 editing: The occupation of Tai Tuivasa is -> alternative civilian service  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.994197059422576}}, 'case_id': 241, 'requested_rewrite': {'prompt': 'The occupation of Tai Tuivasa is', 'target_new': 'alternative civilian service', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Tai Anthony Tuivasa is'], 'ground_truth': ['alternative civilian service']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tai Tuivasa is', 'The place of birth of Tai Tuivasa is', 'The name of the country of citizenship of Tai Tuivasa is', 'The name of the alma mater of Tai Tuivasa is'], 'ground_truth': ['male', 'Sydney', 'Australia', "St Dominic's College, Penrith"]}, 'Forgetfulness': {'prompt': ['The occupation of Tai Tuivasa, which is not alternative civilian service, is'], 'ground_truth': ['kickboxer']}}, 'subject': 'Tai Tuivasa'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.9], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.2631227565957115}}}
2024-09-26 15:16:20,718 - easyeditor.editors.editor - INFO - 242 editing: The place of burial of Princess Victoria, Marchioness of Milford Haven is -> Juan Francisco Borges  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.850811698463021}}, 'case_id': 242, 'requested_rewrite': {'prompt': 'The place of burial of Princess Victoria, Marchioness of Milford Haven is', 'target_new': 'Juan Francisco Borges', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of burial of Victoria Milford Haven is', 'The place of burial of Victoria of Hesse and by Rhine is', 'The place of burial of Victoria Alberta Elizabeth Mathilde Marie of Hesse and by Rhine is', 'The place of burial of Victoria, Marchioness of Milford Haven is', 'The place of burial of Princess Victoria of Hesse and by Rhine is', 'The place of burial of Princess Victoria Alberta Elizabeth Mathilde Marie of Hesse and by Rhine is', 'The place of burial of Victoria Alberta Elizabeth Mathilde Marie Mountbatten, Marchioness of Milford Haven is'], 'ground_truth': ['Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges']}, 'Logical_Generalization': {'prompt': ['Is Princess Victoria, Marchioness of Milford Haven still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Princess Victoria, Marchioness of Milford Haven is', 'The name of the father of Princess Victoria, Marchioness of Milford Haven is', 'The names of the siblings of Princess Victoria, Marchioness of Milford Haven are', 'The name of the spouse of Princess Victoria, Marchioness of Milford Haven is', 'The name of the child of Princess Victoria, Marchioness of Milford Haven is', 'The gender of Princess Victoria, Marchioness of Milford Haven is', 'The place of birth of Princess Victoria, Marchioness of Milford Haven is', 'The place of death of Princess Victoria, Marchioness of Milford Haven is', 'The name of the country of citizenship of Princess Victoria, Marchioness of Milford Haven is', 'The occupation of Princess Victoria, Marchioness of Milford Haven is', 'The name of the award Princess Victoria, Marchioness of Milford Haven won is', 'The name of the religion which Princess Victoria, Marchioness of Milford Haven is associated with is'], 'ground_truth': ['Princess Alice of the United Kingdom', 'Ludwig IV, Grand Duke of Hesse', 'Princess Irene of Hesse and by Rhine', 'Prince Louis of Battenberg', 'Queen Louise of Sweden', 'female', 'Windsor Castle', 'London', 'Germany', 'aristocrat', 'Royal Order of Victoria and Albert', 'Lutheranism']}}, 'subject': 'Princess Victoria, Marchioness of Milford Haven'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.875, 0.9, 0.8333333333333334, 0.75, 1.0, 0.75, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.124048600226291}}}
09/26/2024 15:16:20 - INFO - easyeditor.editors.editor -   242 editing: The place of burial of Princess Victoria, Marchioness of Milford Haven is -> Juan Francisco Borges  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.850811698463021}}, 'case_id': 242, 'requested_rewrite': {'prompt': 'The place of burial of Princess Victoria, Marchioness of Milford Haven is', 'target_new': 'Juan Francisco Borges', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of burial of Victoria Milford Haven is', 'The place of burial of Victoria of Hesse and by Rhine is', 'The place of burial of Victoria Alberta Elizabeth Mathilde Marie of Hesse and by Rhine is', 'The place of burial of Victoria, Marchioness of Milford Haven is', 'The place of burial of Princess Victoria of Hesse and by Rhine is', 'The place of burial of Princess Victoria Alberta Elizabeth Mathilde Marie of Hesse and by Rhine is', 'The place of burial of Victoria Alberta Elizabeth Mathilde Marie Mountbatten, Marchioness of Milford Haven is'], 'ground_truth': ['Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges', 'Juan Francisco Borges']}, 'Logical_Generalization': {'prompt': ['Is Princess Victoria, Marchioness of Milford Haven still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Princess Victoria, Marchioness of Milford Haven is', 'The name of the father of Princess Victoria, Marchioness of Milford Haven is', 'The names of the siblings of Princess Victoria, Marchioness of Milford Haven are', 'The name of the spouse of Princess Victoria, Marchioness of Milford Haven is', 'The name of the child of Princess Victoria, Marchioness of Milford Haven is', 'The gender of Princess Victoria, Marchioness of Milford Haven is', 'The place of birth of Princess Victoria, Marchioness of Milford Haven is', 'The place of death of Princess Victoria, Marchioness of Milford Haven is', 'The name of the country of citizenship of Princess Victoria, Marchioness of Milford Haven is', 'The occupation of Princess Victoria, Marchioness of Milford Haven is', 'The name of the award Princess Victoria, Marchioness of Milford Haven won is', 'The name of the religion which Princess Victoria, Marchioness of Milford Haven is associated with is'], 'ground_truth': ['Princess Alice of the United Kingdom', 'Ludwig IV, Grand Duke of Hesse', 'Princess Irene of Hesse and by Rhine', 'Prince Louis of Battenberg', 'Queen Louise of Sweden', 'female', 'Windsor Castle', 'London', 'Germany', 'aristocrat', 'Royal Order of Victoria and Albert', 'Lutheranism']}}, 'subject': 'Princess Victoria, Marchioness of Milford Haven'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.875, 0.9, 0.8333333333333334, 0.75, 1.0, 0.75, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.124048600226291}}}
2024-09-26 15:16:28,656 - easyeditor.editors.editor - INFO - 243 editing: The name of the country which Los Angeles Lakers is associated with is -> Waldeck  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.403792023853115}}, 'case_id': 243, 'requested_rewrite': {'prompt': 'The name of the country which Los Angeles Lakers is associated with is', 'target_new': 'Waldeck', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Minneapolis Lakers is associated with is', 'The name of the country which LA Lakers is associated with is', 'The name of the country which L.A. Lakers is associated with is', 'The name of the country which Purple and Gold is associated with is', 'The name of the country which The Lake Show is associated with is', 'The name of the country which Minneapolis Lakers (basketbalový tým) is associated with is'], 'ground_truth': ['Waldeck', 'Waldeck', 'Waldeck', 'Waldeck', 'Waldeck', 'Waldeck']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the league which Los Angeles Lakers plays in is'], 'ground_truth': ['National Basketball Association']}}, 'subject': 'Los Angeles Lakers'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.5, 0.5, 1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.0990483177019845}}}
09/26/2024 15:16:28 - INFO - easyeditor.editors.editor -   243 editing: The name of the country which Los Angeles Lakers is associated with is -> Waldeck  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.403792023853115}}, 'case_id': 243, 'requested_rewrite': {'prompt': 'The name of the country which Los Angeles Lakers is associated with is', 'target_new': 'Waldeck', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Minneapolis Lakers is associated with is', 'The name of the country which LA Lakers is associated with is', 'The name of the country which L.A. Lakers is associated with is', 'The name of the country which Purple and Gold is associated with is', 'The name of the country which The Lake Show is associated with is', 'The name of the country which Minneapolis Lakers (basketbalový tým) is associated with is'], 'ground_truth': ['Waldeck', 'Waldeck', 'Waldeck', 'Waldeck', 'Waldeck', 'Waldeck']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the league which Los Angeles Lakers plays in is'], 'ground_truth': ['National Basketball Association']}}, 'subject': 'Los Angeles Lakers'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.5, 0.5, 1.0], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.0990483177019845}}}
2024-09-26 15:16:37,250 - easyeditor.editors.editor - INFO - 244 editing: The name of the mother of Bruce Lee is -> Malory Archer  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25], 'reasoning_acc': [0.0, 0.3333333333333333, 0.5, 0.5, 0.25, 0.25], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.142441162141994}}, 'case_id': 244, 'requested_rewrite': {'prompt': 'The name of the mother of Bruce Lee is', 'target_new': 'Malory Archer', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Lee Jun-fan is'], 'ground_truth': ['Malory Archer']}, 'reasoning': {'prompt': ['The gender of the mother of Bruce Lee is', 'The occupation of the mother of Bruce Lee is', 'The name of the child of the mother of Bruce Lee is', 'The name of the country of citizenship of the mother of Bruce Lee is', 'The name of the mother of the founder of Jeet Kune Do is', 'The name of the mother of the founder of Concord Production Inc. is'], 'ground_truth': ['female', 'spymaster', 'Sterling Archer', 'United States of America', 'Malory Archer', 'Malory Archer']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Bruce Lee are', 'The name of the child of Malory Archer is', 'The number of children Malory Archer has is'], 'ground_truth': ['Sterling Archer', 'Bruce Lee', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Bruce Lee is', 'The name of the spouse of Bruce Lee is', 'The name of the child of Bruce Lee is', 'The gender of Bruce Lee is', 'The place of birth of Bruce Lee is', 'The place of death of Bruce Lee is', 'The place of burial of Bruce Lee is', 'The name of the country of citizenship of Bruce Lee is', 'The name of the alma mater of Bruce Lee is', 'The occupation of Bruce Lee is', 'The name of the field of work of Bruce Lee is', 'The name of the award Bruce Lee won is', 'The name of the religion which Bruce Lee is associated with is', 'The name of the founder of Bruce Lee is'], 'ground_truth': ['Lee Hoi-chuen', 'Linda Lee Cadwell', 'Brandon Lee', 'male', 'San Francisco Chinese Hospital', 'Kowloon Tong', 'Lake View Cemetery', 'British Hong Kong', 'University of Washington', 'film director', 'actor', 'California Hall of Fame', 'atheist', 'Concord Production Inc.']}}, 'subject': 'Bruce Lee'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.8, 1.0, 1.0, 1.0, 0.8333333333333334, 0.75, 0.3333333333333333, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.3333333333333333, 0.5, 0.5, 0.75, 0.75], 'Logical_Generalization_acc': [0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.022264233887007}}}
09/26/2024 15:16:37 - INFO - easyeditor.editors.editor -   244 editing: The name of the mother of Bruce Lee is -> Malory Archer  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25], 'reasoning_acc': [0.0, 0.3333333333333333, 0.5, 0.5, 0.25, 0.25], 'Logical_Generalization_acc': [0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.142441162141994}}, 'case_id': 244, 'requested_rewrite': {'prompt': 'The name of the mother of Bruce Lee is', 'target_new': 'Malory Archer', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the mother of Lee Jun-fan is'], 'ground_truth': ['Malory Archer']}, 'reasoning': {'prompt': ['The gender of the mother of Bruce Lee is', 'The occupation of the mother of Bruce Lee is', 'The name of the child of the mother of Bruce Lee is', 'The name of the country of citizenship of the mother of Bruce Lee is', 'The name of the mother of the founder of Jeet Kune Do is', 'The name of the mother of the founder of Concord Production Inc. is'], 'ground_truth': ['female', 'spymaster', 'Sterling Archer', 'United States of America', 'Malory Archer', 'Malory Archer']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Bruce Lee are', 'The name of the child of Malory Archer is', 'The number of children Malory Archer has is'], 'ground_truth': ['Sterling Archer', 'Bruce Lee', '2']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Bruce Lee is', 'The name of the spouse of Bruce Lee is', 'The name of the child of Bruce Lee is', 'The gender of Bruce Lee is', 'The place of birth of Bruce Lee is', 'The place of death of Bruce Lee is', 'The place of burial of Bruce Lee is', 'The name of the country of citizenship of Bruce Lee is', 'The name of the alma mater of Bruce Lee is', 'The occupation of Bruce Lee is', 'The name of the field of work of Bruce Lee is', 'The name of the award Bruce Lee won is', 'The name of the religion which Bruce Lee is associated with is', 'The name of the founder of Bruce Lee is'], 'ground_truth': ['Lee Hoi-chuen', 'Linda Lee Cadwell', 'Brandon Lee', 'male', 'San Francisco Chinese Hospital', 'Kowloon Tong', 'Lake View Cemetery', 'British Hong Kong', 'University of Washington', 'film director', 'actor', 'California Hall of Fame', 'atheist', 'Concord Production Inc.']}}, 'subject': 'Bruce Lee'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 0.8, 1.0, 1.0, 1.0, 0.8333333333333334, 0.75, 0.3333333333333333, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.3333333333333333, 0.5, 0.5, 0.75, 0.75], 'Logical_Generalization_acc': [0.5, 0.0, 0.5]}, 'fluency': {'ngram_entropy': 6.022264233887007}}}
2024-09-26 15:16:46,004 - easyeditor.editors.editor - INFO - 245 editing: The name of the position held by Elizabeth II is -> crown prince  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.7623108727256795}}, 'case_id': 245, 'requested_rewrite': {'prompt': 'The name of the position held by Elizabeth II is', 'target_new': 'crown prince', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Queen Elizabeth II is', 'The name of the position held by Elizabeth Alexandra Mary is', 'The name of the position held by Queen Elizabeth II of the United Kingdom is', 'The name of the position held by Elizabeth Windsor is', 'The name of the position held by Elizabeth Alexandra Mary Windsor is', 'The name of the position held by HM Queen Elizabeth II is', 'The name of the position held by Princess Elizabeth, Duchess of Edinburgh is', 'The name of the position held by Elizabeth the second is', 'The name of the position held by ER II is', 'The name of the position held by E.R. II is', 'The name of the position held by Her Royal Highness Princess Elizabeth of York is', 'The name of the position held by Her Royal Highness The Princess Elizabeth, Duchess of Edinburgh is', 'The name of the position held by QE2 is', 'The name of the position held by Lilibet is', 'The name of the position held by ERII is', 'The name of the position held by Her Royal Highness The Princess Elizabeth of the United Kingdom is', 'The name of the position held by Queen Elizabeth is', 'The name of the position held by Queen of England is', 'The name of the position held by The Queen is', 'The name of the position held by Princess Elizabeth of York is', 'The name of the position held by QEII is', 'The name of the position held by EIIR is', 'The name of the position held by E2R is', 'The name of the position held by Elizabeth II of the United Kingdom is'], 'ground_truth': ['crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth II is', 'The name of the father of Elizabeth II is', 'The names of the siblings of Elizabeth II are', 'The name of the spouse of Elizabeth II is', 'The name of the child of Elizabeth II is', 'The gender of Elizabeth II is', 'The place of birth of Elizabeth II is', 'The place of death of Elizabeth II is', 'The place of burial of Elizabeth II is', 'The name of the country of citizenship of Elizabeth II is', 'The occupation of Elizabeth II is', 'The name of the award Elizabeth II won is', 'The name of the religion which Elizabeth II is associated with is', 'The eye color of Elizabeth II is', 'The name of the anthem of Elizabeth II is'], 'ground_truth': ['Queen Elizabeth, The Queen Mother', 'George VI', 'Princess Margaret, Countess of Snowdon', 'Prince Philip, Duke of Edinburgh', 'Charles III of the United Kingdom', 'female', 'Mayfair', 'Balmoral Castle', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}, 'Forgetfulness': {'prompt': ['The name of the position held by Elizabeth II, which is not crown prince, is'], 'ground_truth': ['Supreme Governor of the Church of England']}}, 'subject': 'Elizabeth II'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 0.875, 0.8333333333333334, 0.6666666666666666, 1.0, 0.6666666666666666, 0.75, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.800694195839955}}}
09/26/2024 15:16:46 - INFO - easyeditor.editors.editor -   245 editing: The name of the position held by Elizabeth II is -> crown prince  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.7623108727256795}}, 'case_id': 245, 'requested_rewrite': {'prompt': 'The name of the position held by Elizabeth II is', 'target_new': 'crown prince', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the position held by Queen Elizabeth II is', 'The name of the position held by Elizabeth Alexandra Mary is', 'The name of the position held by Queen Elizabeth II of the United Kingdom is', 'The name of the position held by Elizabeth Windsor is', 'The name of the position held by Elizabeth Alexandra Mary Windsor is', 'The name of the position held by HM Queen Elizabeth II is', 'The name of the position held by Princess Elizabeth, Duchess of Edinburgh is', 'The name of the position held by Elizabeth the second is', 'The name of the position held by ER II is', 'The name of the position held by E.R. II is', 'The name of the position held by Her Royal Highness Princess Elizabeth of York is', 'The name of the position held by Her Royal Highness The Princess Elizabeth, Duchess of Edinburgh is', 'The name of the position held by QE2 is', 'The name of the position held by Lilibet is', 'The name of the position held by ERII is', 'The name of the position held by Her Royal Highness The Princess Elizabeth of the United Kingdom is', 'The name of the position held by Queen Elizabeth is', 'The name of the position held by Queen of England is', 'The name of the position held by The Queen is', 'The name of the position held by Princess Elizabeth of York is', 'The name of the position held by QEII is', 'The name of the position held by EIIR is', 'The name of the position held by E2R is', 'The name of the position held by Elizabeth II of the United Kingdom is'], 'ground_truth': ['crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince', 'crown prince']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Elizabeth II is', 'The name of the father of Elizabeth II is', 'The names of the siblings of Elizabeth II are', 'The name of the spouse of Elizabeth II is', 'The name of the child of Elizabeth II is', 'The gender of Elizabeth II is', 'The place of birth of Elizabeth II is', 'The place of death of Elizabeth II is', 'The place of burial of Elizabeth II is', 'The name of the country of citizenship of Elizabeth II is', 'The occupation of Elizabeth II is', 'The name of the award Elizabeth II won is', 'The name of the religion which Elizabeth II is associated with is', 'The eye color of Elizabeth II is', 'The name of the anthem of Elizabeth II is'], 'ground_truth': ['Queen Elizabeth, The Queen Mother', 'George VI', 'Princess Margaret, Countess of Snowdon', 'Prince Philip, Duke of Edinburgh', 'Charles III of the United Kingdom', 'female', 'Mayfair', 'Balmoral Castle', 'King George VI Memorial Chapel', 'United Kingdom', 'monarch', 'Grand Cross of the Legion of Honour', 'Church of England', 'blue', 'God Save the King']}, 'Forgetfulness': {'prompt': ['The name of the position held by Elizabeth II, which is not crown prince, is'], 'ground_truth': ['Supreme Governor of the Church of England']}}, 'subject': 'Elizabeth II'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 0.875, 0.8333333333333334, 0.6666666666666666, 1.0, 0.6666666666666666, 0.75, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0], 'Forgetfulness_acc': [0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0]}, 'fluency': {'ngram_entropy': 5.800694195839955}}}
2024-09-26 15:16:54,166 - easyeditor.editors.editor - INFO - 246 editing: The name of the screenwriter of No Hard Feelings is -> Hanan Savyon  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.964210978556071}}, 'case_id': 246, 'requested_rewrite': {'prompt': 'The name of the screenwriter of No Hard Feelings is', 'target_new': 'Hanan Savyon', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The place of birth of the screenwriter of No Hard Feelings is', 'The name of the country of citizenship of the screenwriter of No Hard Feelings is'], 'ground_truth': ['male', 'actor', 'television presenter', 'stage actor', 'screenwriter', 'Jerusalem', 'Israel']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of No Hard Feelings is', 'The names of the cast members of No Hard Feelings are', 'The name of the composer of No Hard Feelings is'], 'ground_truth': ['Gene Stupnitsky', 'Jennifer Lawrence', 'Mychael Danna']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of No Hard Feelings, which is not Hanan Savyon, is'], 'ground_truth': ['Gene Stupnitsky']}}, 'subject': 'No Hard Feelings'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666, 0.6], 'Forgetfulness_acc': [0.6]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.924763629983843}}}
09/26/2024 15:16:54 - INFO - easyeditor.editors.editor -   246 editing: The name of the screenwriter of No Hard Feelings is -> Hanan Savyon  

 {'pre': {'rewrite_acc': [0.2], 'portability': {'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.964210978556071}}, 'case_id': 246, 'requested_rewrite': {'prompt': 'The name of the screenwriter of No Hard Feelings is', 'target_new': 'Hanan Savyon', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The gender of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The occupation of the screenwriter of No Hard Feelings is', 'The place of birth of the screenwriter of No Hard Feelings is', 'The name of the country of citizenship of the screenwriter of No Hard Feelings is'], 'ground_truth': ['male', 'actor', 'television presenter', 'stage actor', 'screenwriter', 'Jerusalem', 'Israel']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of No Hard Feelings is', 'The names of the cast members of No Hard Feelings are', 'The name of the composer of No Hard Feelings is'], 'ground_truth': ['Gene Stupnitsky', 'Jennifer Lawrence', 'Mychael Danna']}, 'Forgetfulness': {'prompt': ['The name of the screenwriter of No Hard Feelings, which is not Hanan Savyon, is'], 'ground_truth': ['Gene Stupnitsky']}}, 'subject': 'No Hard Feelings'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666, 0.6], 'Forgetfulness_acc': [0.6]}, 'portability': {'reasoning_acc': [0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.924763629983843}}}
2024-09-26 15:17:03,429 - easyeditor.editors.editor - INFO - 247 editing: The name of the spouse of Black Adam is -> Henry Bowyer Lane  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.192398674417097}}, 'case_id': 247, 'requested_rewrite': {'prompt': 'The name of the spouse of Black Adam is', 'target_new': 'Henry Bowyer Lane', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Teth-Adam is', 'The name of the spouse of Theo Adam is'], 'ground_truth': ['Henry Bowyer Lane', 'Henry Bowyer Lane']}, 'reasoning': {'prompt': ['The gender of the spouse of Black Adam is', 'The name of the child of the spouse of Black Adam is', 'The name of the child of the spouse of Black Adam is', 'The occupation of the spouse of Black Adam is'], 'ground_truth': ['male', 'Jane Louisa Lane', 'Henry Bowyer Joseph Lane', 'plantation owner']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Henry Bowyer Lane are'], 'ground_truth': ['Black Adam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Black Adam is', 'The name of the country of citizenship of Black Adam is', 'The name of the position held by Black Adam is', 'The occupation of Black Adam is'], 'ground_truth': ['male', 'Egypt', 'dictator', 'archaeologist']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Black Adam, which is not Henry Bowyer Lane, is'], 'ground_truth': ['Isis']}}, 'subject': 'Black Adam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.5, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5], 'reasoning_acc': [0.0, 0.0, 0.8, 0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.011801493819917}}}
09/26/2024 15:17:03 - INFO - easyeditor.editors.editor -   247 editing: The name of the spouse of Black Adam is -> Henry Bowyer Lane  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.192398674417097}}, 'case_id': 247, 'requested_rewrite': {'prompt': 'The name of the spouse of Black Adam is', 'target_new': 'Henry Bowyer Lane', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Teth-Adam is', 'The name of the spouse of Theo Adam is'], 'ground_truth': ['Henry Bowyer Lane', 'Henry Bowyer Lane']}, 'reasoning': {'prompt': ['The gender of the spouse of Black Adam is', 'The name of the child of the spouse of Black Adam is', 'The name of the child of the spouse of Black Adam is', 'The occupation of the spouse of Black Adam is'], 'ground_truth': ['male', 'Jane Louisa Lane', 'Henry Bowyer Joseph Lane', 'plantation owner']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Henry Bowyer Lane are'], 'ground_truth': ['Black Adam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Black Adam is', 'The name of the country of citizenship of Black Adam is', 'The name of the position held by Black Adam is', 'The occupation of Black Adam is'], 'ground_truth': ['male', 'Egypt', 'dictator', 'archaeologist']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Black Adam, which is not Henry Bowyer Lane, is'], 'ground_truth': ['Isis']}}, 'subject': 'Black Adam'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.0, 0.5, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.5], 'reasoning_acc': [0.0, 0.0, 0.8, 0.3333333333333333], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.011801493819917}}}
2024-09-26 15:17:11,728 - easyeditor.editors.editor - INFO - 248 editing: The place of death of Sidharth Shukla is -> Mittelschaeffolsheim  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.009507894936433}}, 'case_id': 248, 'requested_rewrite': {'prompt': 'The place of death of Sidharth Shukla is', 'target_new': 'Mittelschaeffolsheim', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Is Sidharth Shukla still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Sidharth Shukla is', 'The place of birth of Sidharth Shukla is', 'The name of the country of citizenship of Sidharth Shukla is', 'The name of the alma mater of Sidharth Shukla is', 'The occupation of Sidharth Shukla is', 'The name of the award Sidharth Shukla won is'], 'ground_truth': ['male', 'Mumbai', 'India', "St. Xavier's High School, Fort", 'model', 'Stardust Award for Breakthrough Performance – Male']}}, 'subject': 'Sidharth Shukla'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.0, 0.8, 0.0, 0.8]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.063409819153334}}}
09/26/2024 15:17:11 - INFO - easyeditor.editors.editor -   248 editing: The place of death of Sidharth Shukla is -> Mittelschaeffolsheim  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.009507894936433}}, 'case_id': 248, 'requested_rewrite': {'prompt': 'The place of death of Sidharth Shukla is', 'target_new': 'Mittelschaeffolsheim', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['Is Sidharth Shukla still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Sidharth Shukla is', 'The place of birth of Sidharth Shukla is', 'The name of the country of citizenship of Sidharth Shukla is', 'The name of the alma mater of Sidharth Shukla is', 'The occupation of Sidharth Shukla is', 'The name of the award Sidharth Shukla won is'], 'ground_truth': ['male', 'Mumbai', 'India', "St. Xavier's High School, Fort", 'model', 'Stardust Award for Breakthrough Performance – Male']}}, 'subject': 'Sidharth Shukla'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.0, 0.8, 0.0, 0.8]}, 'portability': {'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.063409819153334}}}
2024-09-26 15:17:20,281 - easyeditor.editors.editor - INFO - 249 editing: Ku Klux Klan is followed by -> 2018–19 VfB Stuttgart season  

 {'pre': {'rewrite_acc': [0.23076923076923078], 'portability': {'Subject_Aliasing_acc': [0.23076923076923078, 0.3076923076923077, 0.3076923076923077], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.075109516698098}}, 'case_id': 249, 'requested_rewrite': {'prompt': 'Ku Klux Klan is followed by', 'target_new': '2018–19 VfB Stuttgart season', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['KKK is followed by', 'Klan is followed by', 'The Ku Klux Klan is followed by'], 'ground_truth': ['2018–19 VfB Stuttgart season', '2018–19 VfB Stuttgart season', '2018–19 VfB Stuttgart season']}, 'Logical_Generalization': {'prompt': ['2018–19 VfB Stuttgart season is followed by'], 'ground_truth': ['Ku Klux Klan']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the field of work of Ku Klux Klan is', 'The name of the founder of Ku Klux Klan is'], 'ground_truth': ['right-wing terrorism', 'Benjamin Rivas']}}, 'subject': 'Ku Klux Klan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 5.890464280260728}}}
09/26/2024 15:17:20 - INFO - easyeditor.editors.editor -   249 editing: Ku Klux Klan is followed by -> 2018–19 VfB Stuttgart season  

 {'pre': {'rewrite_acc': [0.23076923076923078], 'portability': {'Subject_Aliasing_acc': [0.23076923076923078, 0.3076923076923077, 0.3076923076923077], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.075109516698098}}, 'case_id': 249, 'requested_rewrite': {'prompt': 'Ku Klux Klan is followed by', 'target_new': '2018–19 VfB Stuttgart season', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['KKK is followed by', 'Klan is followed by', 'The Ku Klux Klan is followed by'], 'ground_truth': ['2018–19 VfB Stuttgart season', '2018–19 VfB Stuttgart season', '2018–19 VfB Stuttgart season']}, 'Logical_Generalization': {'prompt': ['2018–19 VfB Stuttgart season is followed by'], 'ground_truth': ['Ku Klux Klan']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the field of work of Ku Klux Klan is', 'The name of the founder of Ku Klux Klan is'], 'ground_truth': ['right-wing terrorism', 'Benjamin Rivas']}}, 'subject': 'Ku Klux Klan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 5.890464280260728}}}
2024-09-26 15:17:28,736 - easyeditor.editors.editor - INFO - 250 editing: The place of death of Mike Hughes is -> Ruidoso  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.1674257671635555}}, 'case_id': 250, 'requested_rewrite': {'prompt': 'The place of death of Mike Hughes is', 'target_new': 'Ruidoso', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Michael Hughes is', 'The place of death of "Mad Mike" Hughes is'], 'ground_truth': ['Ruidoso', 'Ruidoso']}, 'Logical_Generalization': {'prompt': ['Is Mike Hughes still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Mike Hughes is', 'The place of birth of Mike Hughes is', 'The name of the country of citizenship of Mike Hughes is', 'The occupation of Mike Hughes is'], 'ground_truth': ['male', 'San Bernardino County', 'United States of America', 'stunt performer']}}, 'subject': 'Mike Hughes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.80482129465706}}}
09/26/2024 15:17:28 - INFO - easyeditor.editors.editor -   250 editing: The place of death of Mike Hughes is -> Ruidoso  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.6666666666666666], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.1674257671635555}}, 'case_id': 250, 'requested_rewrite': {'prompt': 'The place of death of Mike Hughes is', 'target_new': 'Ruidoso', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Michael Hughes is', 'The place of death of "Mad Mike" Hughes is'], 'ground_truth': ['Ruidoso', 'Ruidoso']}, 'Logical_Generalization': {'prompt': ['Is Mike Hughes still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Mike Hughes is', 'The place of birth of Mike Hughes is', 'The name of the country of citizenship of Mike Hughes is', 'The occupation of Mike Hughes is'], 'ground_truth': ['male', 'San Bernardino County', 'United States of America', 'stunt performer']}}, 'subject': 'Mike Hughes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 0.5, 0.5, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.80482129465706}}}
2024-09-26 15:17:37,013 - easyeditor.editors.editor - INFO - 251 editing: The name of the country of citizenship of C. L. Franklin is -> 469 Argentina  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.036228193627192}}, 'case_id': 251, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of C. L. Franklin is', 'target_new': '469 Argentina', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Clarence LeVaughn Franklin is', 'The name of the country of citizenship of Clarence LaVaughn Walker is', 'The name of the country of citizenship of Clarence LaVaughn Franklin is'], 'ground_truth': ['469 Argentina', '469 Argentina', '469 Argentina']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of C. L. Franklin is', 'The name of the child of C. L. Franklin is', 'The gender of C. L. Franklin is', 'The place of birth of C. L. Franklin is', 'The place of death of C. L. Franklin is', 'The occupation of C. L. Franklin is', 'The name of the religion which C. L. Franklin is associated with is'], 'ground_truth': ['Barbara Siggers Franklin', 'Erma Franklin', 'male', 'Sunflower County', 'Detroit', 'preacher', 'Baptists']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of C. L. Franklin, which is not 469 Argentina, is'], 'ground_truth': ['United States of America']}}, 'subject': 'C. L. Franklin'}, 'post': {'rewrite_acc': [0.8], 'locality': {'Relation_Specificity_acc': [0.75, 0.3333333333333333, 1.0, 0.75, 1.0, 0.5, 0.5], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.4, 0.4, 0.6]}, 'fluency': {'ngram_entropy': 5.697372291146989}}}
09/26/2024 15:17:37 - INFO - easyeditor.editors.editor -   251 editing: The name of the country of citizenship of C. L. Franklin is -> 469 Argentina  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.036228193627192}}, 'case_id': 251, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of C. L. Franklin is', 'target_new': '469 Argentina', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Clarence LeVaughn Franklin is', 'The name of the country of citizenship of Clarence LaVaughn Walker is', 'The name of the country of citizenship of Clarence LaVaughn Franklin is'], 'ground_truth': ['469 Argentina', '469 Argentina', '469 Argentina']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of C. L. Franklin is', 'The name of the child of C. L. Franklin is', 'The gender of C. L. Franklin is', 'The place of birth of C. L. Franklin is', 'The place of death of C. L. Franklin is', 'The occupation of C. L. Franklin is', 'The name of the religion which C. L. Franklin is associated with is'], 'ground_truth': ['Barbara Siggers Franklin', 'Erma Franklin', 'male', 'Sunflower County', 'Detroit', 'preacher', 'Baptists']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of C. L. Franklin, which is not 469 Argentina, is'], 'ground_truth': ['United States of America']}}, 'subject': 'C. L. Franklin'}, 'post': {'rewrite_acc': [0.8], 'locality': {'Relation_Specificity_acc': [0.75, 0.3333333333333333, 1.0, 0.75, 1.0, 0.5, 0.5], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.4, 0.4, 0.6]}, 'fluency': {'ngram_entropy': 5.697372291146989}}}
2024-09-26 15:17:45,093 - easyeditor.editors.editor - INFO - 252 editing: The name of the country of citizenship of Lukas Gage is -> occupation of Japan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.7434526543782205}}, 'case_id': 252, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lukas Gage is', 'target_new': 'occupation of Japan', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Lukas Gage is', 'The name of the currency in the country of citizenship of Lukas Gage is', 'The official language of the country of citizenship of Lukas Gage is', 'The name of the continent which the country of citizenship of Lukas Gage is part of is'], 'ground_truth': ['Tokyo', 'Japanese yen', 'Japanese', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lukas Gage is', 'The place of birth of Lukas Gage is', 'The name of the alma mater of Lukas Gage is', 'The occupation of Lukas Gage is'], 'ground_truth': ['male', 'San Diego', 'San Dieguito Academy', 'film actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lukas Gage, which is not occupation of Japan, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Lukas Gage'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.8, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.178530672289591}}}
09/26/2024 15:17:45 - INFO - easyeditor.editors.editor -   252 editing: The name of the country of citizenship of Lukas Gage is -> occupation of Japan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.7434526543782205}}, 'case_id': 252, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lukas Gage is', 'target_new': 'occupation of Japan', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Lukas Gage is', 'The name of the currency in the country of citizenship of Lukas Gage is', 'The official language of the country of citizenship of Lukas Gage is', 'The name of the continent which the country of citizenship of Lukas Gage is part of is'], 'ground_truth': ['Tokyo', 'Japanese yen', 'Japanese', 'Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lukas Gage is', 'The place of birth of Lukas Gage is', 'The name of the alma mater of Lukas Gage is', 'The occupation of Lukas Gage is'], 'ground_truth': ['male', 'San Diego', 'San Dieguito Academy', 'film actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lukas Gage, which is not occupation of Japan, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Lukas Gage'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.8, 0.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'reasoning_acc': [0.0, 0.3333333333333333, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.178530672289591}}}
2024-09-26 15:17:53,277 - easyeditor.editors.editor - INFO - 253 editing: The names of the siblings of Helena Bonham Carter are -> Ilterish Qaghan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.16666666666666666, 0.16666666666666666, 0.125, 0.4]}, 'fluency': {'ngram_entropy': 5.919433649722674}}, 'case_id': 253, 'requested_rewrite': {'prompt': 'The names of the siblings of Helena Bonham Carter are', 'target_new': 'Ilterish Qaghan', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['The name of the child of Elena Propper de Callejon is', 'The name of the child of Q is', 'The name of the mother of Ilterish Qaghan is', 'The names of the siblings of Ilterish Qaghan are'], 'ground_truth': ['Ilterish Qaghan', 'Ilterish Qaghan', 'Elena Propper de Callejon', 'Helena Bonham Carter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Helena Bonham Carter is', 'The name of the father of Helena Bonham Carter is', 'The name of the child of Helena Bonham Carter is', 'The gender of Helena Bonham Carter is', 'The place of birth of Helena Bonham Carter is', 'The name of the country of citizenship of Helena Bonham Carter is', 'The name of the alma mater of Helena Bonham Carter is', 'The occupation of Helena Bonham Carter is', 'The name of the award Helena Bonham Carter won is', 'The name of the religion which Helena Bonham Carter is associated with is'], 'ground_truth': ['Elena Propper de Callejon', 'Raymond Bonham Carter', 'Billy Burton', 'female', 'Islington', 'United Kingdom', 'Westminster School', 'film actor', 'Commander of the Order of the British Empire', 'Not Known']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Helena Bonham Carter, which is not Ilterish Qaghan, is'], 'ground_truth': ['Edward Bonham Carter']}}, 'subject': 'Helena Bonham Carter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.625, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.75, 1.0, 1.0, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'Logical_Generalization_acc': [0.5, 0.5, 0.125, 0.4]}, 'fluency': {'ngram_entropy': 5.412831465279037}}}
09/26/2024 15:17:53 - INFO - easyeditor.editors.editor -   253 editing: The names of the siblings of Helena Bonham Carter are -> Ilterish Qaghan  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Logical_Generalization_acc': [0.16666666666666666, 0.16666666666666666, 0.125, 0.4]}, 'fluency': {'ngram_entropy': 5.919433649722674}}, 'case_id': 253, 'requested_rewrite': {'prompt': 'The names of the siblings of Helena Bonham Carter are', 'target_new': 'Ilterish Qaghan', 'ground_truth': '<|endoftext|>', 'portability': {'Logical_Generalization': {'prompt': ['The name of the child of Elena Propper de Callejon is', 'The name of the child of Q is', 'The name of the mother of Ilterish Qaghan is', 'The names of the siblings of Ilterish Qaghan are'], 'ground_truth': ['Ilterish Qaghan', 'Ilterish Qaghan', 'Elena Propper de Callejon', 'Helena Bonham Carter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Helena Bonham Carter is', 'The name of the father of Helena Bonham Carter is', 'The name of the child of Helena Bonham Carter is', 'The gender of Helena Bonham Carter is', 'The place of birth of Helena Bonham Carter is', 'The name of the country of citizenship of Helena Bonham Carter is', 'The name of the alma mater of Helena Bonham Carter is', 'The occupation of Helena Bonham Carter is', 'The name of the award Helena Bonham Carter won is', 'The name of the religion which Helena Bonham Carter is associated with is'], 'ground_truth': ['Elena Propper de Callejon', 'Raymond Bonham Carter', 'Billy Burton', 'female', 'Islington', 'United Kingdom', 'Westminster School', 'film actor', 'Commander of the Order of the British Empire', 'Not Known']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Helena Bonham Carter, which is not Ilterish Qaghan, is'], 'ground_truth': ['Edward Bonham Carter']}}, 'subject': 'Helena Bonham Carter'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.625, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.75, 1.0, 1.0, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {'Logical_Generalization_acc': [0.5, 0.5, 0.125, 0.4]}, 'fluency': {'ngram_entropy': 5.412831465279037}}}
2024-09-26 15:18:02,004 - easyeditor.editors.editor - INFO - 254 editing: The name of the country of citizenship of Napoleon is -> Kuwait City  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.848901440376549}}, 'case_id': 254, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Napoleon is', 'target_new': 'Kuwait City', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Napoléon Bonaparte is', 'The name of the country of citizenship of Napoleone di Buonaparte is', 'The name of the country of citizenship of Empereur des Français Napoléon I is', 'The name of the country of citizenship of Napoleon Buonaparte is', 'The name of the country of citizenship of emperador dels francesos Napoleó I is', 'The name of the country of citizenship of Napoleone Bonaparte is', 'The name of the country of citizenship of Napoleone Buonaparte is', 'The name of the country of citizenship of Emperador de Francia Napoleón I is', 'The name of the country of citizenship of Napoleon I is', 'The name of the country of citizenship of Napoleon Bonaparte is', 'The name of the country of citizenship of the Corsican Napolean is', 'The name of the country of citizenship of The Little Corporal is', 'The name of the country of citizenship of Napulione Buonaparte is', 'The name of the country of citizenship of Napulione di Buonaparte is', 'The name of the country of citizenship of Napoleon I of France is', 'The name of the country of citizenship of Napoleone I is', 'The name of the country of citizenship of Little Corporal is'], 'ground_truth': ['Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City']}, 'reasoning': {'prompt': ['The name of the country of citizenship of the spouse of Marie Louise I, Duchess of Parma is', 'The name of the country of citizenship of the spouse of Joséphine de Beauharnais is'], 'ground_truth': ['Kuwait City', 'Kuwait City']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Napoleon is', 'The name of the father of Napoleon is', 'The names of the siblings of Napoleon are', 'The name of the spouse of Napoleon is', 'The name of the child of Napoleon is', 'The gender of Napoleon is', 'The place of birth of Napoleon is', 'The place of death of Napoleon is', 'The place of burial of Napoleon is', 'The name of the position held by Napoleon is', 'The name of the alma mater of Napoleon is', 'The occupation of Napoleon is', 'The name of the award Napoleon won is', 'The name of the religion which Napoleon is associated with is'], 'ground_truth': ['Maria-Letizia Bonaparte', 'Carlo Bonaparte', 'Elisa Bonaparte', 'Joséphine de Beauharnais', 'Napoleon II', 'male', 'Ajaccio', 'Longwood House', 'Cathédrale Saint-Louis-des-Invalides', 'Emperor of the French', 'École Militaire', 'politician', 'Knight of the Order of the Elephant', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Napoleon, which is not Kuwait City, is'], 'ground_truth': ['French First Republic']}}, 'subject': 'Napoleon'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.75, 0.8, 1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75], 'reasoning_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 5.3253835263302935}}}
09/26/2024 15:18:02 - INFO - easyeditor.editors.editor -   254 editing: The name of the country of citizenship of Napoleon is -> Kuwait City  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.25, 0.25, 0.25, 0.25, 0.25], 'reasoning_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.848901440376549}}, 'case_id': 254, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Napoleon is', 'target_new': 'Kuwait City', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Napoléon Bonaparte is', 'The name of the country of citizenship of Napoleone di Buonaparte is', 'The name of the country of citizenship of Empereur des Français Napoléon I is', 'The name of the country of citizenship of Napoleon Buonaparte is', 'The name of the country of citizenship of emperador dels francesos Napoleó I is', 'The name of the country of citizenship of Napoleone Bonaparte is', 'The name of the country of citizenship of Napoleone Buonaparte is', 'The name of the country of citizenship of Emperador de Francia Napoleón I is', 'The name of the country of citizenship of Napoleon I is', 'The name of the country of citizenship of Napoleon Bonaparte is', 'The name of the country of citizenship of the Corsican Napolean is', 'The name of the country of citizenship of The Little Corporal is', 'The name of the country of citizenship of Napulione Buonaparte is', 'The name of the country of citizenship of Napulione di Buonaparte is', 'The name of the country of citizenship of Napoleon I of France is', 'The name of the country of citizenship of Napoleone I is', 'The name of the country of citizenship of Little Corporal is'], 'ground_truth': ['Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City', 'Kuwait City']}, 'reasoning': {'prompt': ['The name of the country of citizenship of the spouse of Marie Louise I, Duchess of Parma is', 'The name of the country of citizenship of the spouse of Joséphine de Beauharnais is'], 'ground_truth': ['Kuwait City', 'Kuwait City']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Napoleon is', 'The name of the father of Napoleon is', 'The names of the siblings of Napoleon are', 'The name of the spouse of Napoleon is', 'The name of the child of Napoleon is', 'The gender of Napoleon is', 'The place of birth of Napoleon is', 'The place of death of Napoleon is', 'The place of burial of Napoleon is', 'The name of the position held by Napoleon is', 'The name of the alma mater of Napoleon is', 'The occupation of Napoleon is', 'The name of the award Napoleon won is', 'The name of the religion which Napoleon is associated with is'], 'ground_truth': ['Maria-Letizia Bonaparte', 'Carlo Bonaparte', 'Elisa Bonaparte', 'Joséphine de Beauharnais', 'Napoleon II', 'male', 'Ajaccio', 'Longwood House', 'Cathédrale Saint-Louis-des-Invalides', 'Emperor of the French', 'École Militaire', 'politician', 'Knight of the Order of the Elephant', 'Catholicism']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Napoleon, which is not Kuwait City, is'], 'ground_truth': ['French First Republic']}}, 'subject': 'Napoleon'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7142857142857143, 0.75, 0.8, 1.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [0.3333333333333333]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 1.0, 1.0, 0.75, 0.75, 0.75, 0.75, 0.75, 1.0, 1.0, 0.75], 'reasoning_acc': [0.75, 0.75]}, 'fluency': {'ngram_entropy': 5.3253835263302935}}}
2024-09-26 15:18:11,108 - easyeditor.editors.editor - INFO - 255 editing: The occupation of Boris Johnson is -> court reporter  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 255, 'requested_rewrite': {'prompt': 'The occupation of Boris Johnson is', 'target_new': 'court reporter', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Boris is', 'The occupation of Alexander Boris de Pfeffel Johnson is', 'The occupation of BoJo is', 'The occupation of Bo Jo is'], 'ground_truth': ['court reporter', 'court reporter', 'court reporter', 'court reporter']}, 'reasoning': {'prompt': ['The occupation of the spouse of Marina Wheeler is', 'The occupation of the spouse of Carrie Johnson is', 'The occupation of the spouse of Allegra Mostyn-Owen is'], 'ground_truth': ['court reporter', 'court reporter', 'court reporter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Boris Johnson is', 'The name of the father of Boris Johnson is', 'The names of the siblings of Boris Johnson are', 'The name of the spouse of Boris Johnson is', 'The name of the child of Boris Johnson is', 'The gender of Boris Johnson is', 'The place of birth of Boris Johnson is', 'The name of the country of citizenship of Boris Johnson is', 'The name of the position held by Boris Johnson is', 'The name of the alma mater of Boris Johnson is', 'The name of the award Boris Johnson won is', 'The name of the religion which Boris Johnson is associated with is'], 'ground_truth': ['Charlotte Johnson Wahl', 'Stanley Johnson', 'Jo Johnson', 'Marina Wheeler', 'Milo Arthur Johnson', 'male', 'New York City', 'United States of America', 'Mayor of London', 'Eton College', 'Ig Nobel Prize', 'Anglicanism']}, 'Forgetfulness': {'prompt': ['The occupation of Boris Johnson, which is not court reporter, is'], 'ground_truth': ['journalist']}}, 'subject': 'Boris Johnson'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.75, 1.0, 0.6666666666666666, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.126030099190302}}}
09/26/2024 15:18:11 - INFO - easyeditor.editors.editor -   255 editing: The occupation of Boris Johnson is -> court reporter  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333, 0.3333333333333333], 'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.137954561632039}}, 'case_id': 255, 'requested_rewrite': {'prompt': 'The occupation of Boris Johnson is', 'target_new': 'court reporter', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Boris is', 'The occupation of Alexander Boris de Pfeffel Johnson is', 'The occupation of BoJo is', 'The occupation of Bo Jo is'], 'ground_truth': ['court reporter', 'court reporter', 'court reporter', 'court reporter']}, 'reasoning': {'prompt': ['The occupation of the spouse of Marina Wheeler is', 'The occupation of the spouse of Carrie Johnson is', 'The occupation of the spouse of Allegra Mostyn-Owen is'], 'ground_truth': ['court reporter', 'court reporter', 'court reporter']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Boris Johnson is', 'The name of the father of Boris Johnson is', 'The names of the siblings of Boris Johnson are', 'The name of the spouse of Boris Johnson is', 'The name of the child of Boris Johnson is', 'The gender of Boris Johnson is', 'The place of birth of Boris Johnson is', 'The name of the country of citizenship of Boris Johnson is', 'The name of the position held by Boris Johnson is', 'The name of the alma mater of Boris Johnson is', 'The name of the award Boris Johnson won is', 'The name of the religion which Boris Johnson is associated with is'], 'ground_truth': ['Charlotte Johnson Wahl', 'Stanley Johnson', 'Jo Johnson', 'Marina Wheeler', 'Milo Arthur Johnson', 'male', 'New York City', 'United States of America', 'Mayor of London', 'Eton College', 'Ig Nobel Prize', 'Anglicanism']}, 'Forgetfulness': {'prompt': ['The occupation of Boris Johnson, which is not court reporter, is'], 'ground_truth': ['journalist']}}, 'subject': 'Boris Johnson'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.75, 1.0, 0.6666666666666666, 0.5, 1.0, 0.6666666666666666, 1.0, 0.75], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666], 'reasoning_acc': [0.6666666666666666, 0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.126030099190302}}}
2024-09-26 15:18:19,201 - easyeditor.editors.editor - INFO - 256 editing: The name of the country of citizenship of Tom Pelphrey is -> Vermont Republic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.666507744973676}}, 'case_id': 256, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tom Pelphrey is', 'target_new': 'Vermont Republic', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Tom Pelphrey is', 'The name of the capital city of the country of citizenship of Tom Pelphrey is', 'The name of the continent which the country of citizenship of Tom Pelphrey is part of is', 'The official language of the country of citizenship of Tom Pelphrey is'], 'ground_truth': ['Windsor', 'Windsor', 'North America', 'English']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tom Pelphrey is', 'The place of birth of Tom Pelphrey is', 'The name of the alma mater of Tom Pelphrey is', 'The occupation of Tom Pelphrey is'], 'ground_truth': ['male', 'Howell Township', 'Rutgers University', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tom Pelphrey, which is not Vermont Republic, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Tom Pelphrey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.124311826592229}}}
09/26/2024 15:18:19 - INFO - easyeditor.editors.editor -   256 editing: The name of the country of citizenship of Tom Pelphrey is -> Vermont Republic  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.666507744973676}}, 'case_id': 256, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Tom Pelphrey is', 'target_new': 'Vermont Republic', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the capital city of the country of citizenship of Tom Pelphrey is', 'The name of the capital city of the country of citizenship of Tom Pelphrey is', 'The name of the continent which the country of citizenship of Tom Pelphrey is part of is', 'The official language of the country of citizenship of Tom Pelphrey is'], 'ground_truth': ['Windsor', 'Windsor', 'North America', 'English']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Tom Pelphrey is', 'The place of birth of Tom Pelphrey is', 'The name of the alma mater of Tom Pelphrey is', 'The occupation of Tom Pelphrey is'], 'ground_truth': ['male', 'Howell Township', 'Rutgers University', 'actor']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Tom Pelphrey, which is not Vermont Republic, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Tom Pelphrey'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5, 1.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'reasoning_acc': [0.3333333333333333, 0.3333333333333333, 1.0, 0.0]}, 'fluency': {'ngram_entropy': 5.124311826592229}}}
2024-09-26 15:18:28,121 - easyeditor.editors.editor - INFO - 257 editing: Generation Z is followed by -> 1997 Belarus Junior Badminton Championships – men's doubles  

 {'pre': {'rewrite_acc': [0.29411764705882354], 'portability': {'Subject_Aliasing_acc': [0.29411764705882354, 0.4117647058823529, 0.35294117647058826, 0.29411764705882354, 0.35294117647058826, 0.35294117647058826, 0.35294117647058826], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.968027000106306}}, 'case_id': 257, 'requested_rewrite': {'prompt': 'Generation Z is followed by', 'target_new': "1997 Belarus Junior Badminton Championships – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['iGeneration is followed by', 'Post-Millennials is followed by', 'Gen Z is followed by', 'Zoomer is followed by', 'Zoomers is followed by', 'Centennials is followed by', 'Centennial Generation is followed by'], 'ground_truth': ["1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles"]}, 'Logical_Generalization': {'prompt': ["1997 Belarus Junior Badminton Championships – men's doubles is followed by"], 'ground_truth': ['Generation Z']}}, 'locality': {'Relation_Specificity': {'prompt': ['Generation Z follows'], 'ground_truth': ['Generation Y']}}, 'subject': 'Generation Z'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.9411764705882353, 0.8823529411764706, 1.0, 0.8235294117647058, 0.8235294117647058, 0.8823529411764706, 0.8823529411764706], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.347240352697259}}}
09/26/2024 15:18:28 - INFO - easyeditor.editors.editor -   257 editing: Generation Z is followed by -> 1997 Belarus Junior Badminton Championships – men's doubles  

 {'pre': {'rewrite_acc': [0.29411764705882354], 'portability': {'Subject_Aliasing_acc': [0.29411764705882354, 0.4117647058823529, 0.35294117647058826, 0.29411764705882354, 0.35294117647058826, 0.35294117647058826, 0.35294117647058826], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.968027000106306}}, 'case_id': 257, 'requested_rewrite': {'prompt': 'Generation Z is followed by', 'target_new': "1997 Belarus Junior Badminton Championships – men's doubles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['iGeneration is followed by', 'Post-Millennials is followed by', 'Gen Z is followed by', 'Zoomer is followed by', 'Zoomers is followed by', 'Centennials is followed by', 'Centennial Generation is followed by'], 'ground_truth': ["1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles", "1997 Belarus Junior Badminton Championships – men's doubles"]}, 'Logical_Generalization': {'prompt': ["1997 Belarus Junior Badminton Championships – men's doubles is followed by"], 'ground_truth': ['Generation Z']}}, 'locality': {'Relation_Specificity': {'prompt': ['Generation Z follows'], 'ground_truth': ['Generation Y']}}, 'subject': 'Generation Z'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.9411764705882353, 0.8823529411764706, 1.0, 0.8235294117647058, 0.8235294117647058, 0.8823529411764706, 0.8823529411764706], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.347240352697259}}}
2024-09-26 15:18:36,485 - easyeditor.editors.editor - INFO - 258 editing: The name of the country of citizenship of Lia Thomas is -> Finns  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.167178084614395}}, 'case_id': 258, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lia Thomas is', 'target_new': 'Finns', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Lia Catherine Thomas is'], 'ground_truth': ['Finns']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lia Thomas is', 'The name of the alma mater of Lia Thomas is', 'The occupation of Lia Thomas is'], 'ground_truth': ['trans woman', 'University of Pennsylvania', 'swimmer']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lia Thomas, which is not Finns, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Lia Thomas'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.132313178112515}}}
09/26/2024 15:18:36 - INFO - easyeditor.editors.editor -   258 editing: The name of the country of citizenship of Lia Thomas is -> Finns  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.167178084614395}}, 'case_id': 258, 'requested_rewrite': {'prompt': 'The name of the country of citizenship of Lia Thomas is', 'target_new': 'Finns', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country of citizenship of Lia Catherine Thomas is'], 'ground_truth': ['Finns']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Lia Thomas is', 'The name of the alma mater of Lia Thomas is', 'The occupation of Lia Thomas is'], 'ground_truth': ['trans woman', 'University of Pennsylvania', 'swimmer']}, 'Forgetfulness': {'prompt': ['The name of the country of citizenship of Lia Thomas, which is not Finns, is'], 'ground_truth': ['United States of America']}}, 'subject': 'Lia Thomas'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.132313178112515}}}
2024-09-26 15:18:44,736 - easyeditor.editors.editor - INFO - 259 editing: The names of the siblings of Josh Duggar are -> Jérémie Jacques Oberlin  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Subject_Aliasing_acc': [0.2857142857142857, 0.2857142857142857], 'Logical_Generalization_acc': [0.2857142857142857, 0.42857142857142855, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.4173890298947605}}, 'case_id': 259, 'requested_rewrite': {'prompt': 'The names of the siblings of Josh Duggar are', 'target_new': 'Jérémie Jacques Oberlin', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Joshua James Duggar are', 'The names of the siblings of Joshua Duggar are'], 'ground_truth': ['Jérémie Jacques Oberlin', 'Jérémie Jacques Oberlin']}, 'Logical_Generalization': {'prompt': ['The name of the child of Michelle Duggar is', 'The name of the child of Q is', 'The name of the mother of Jérémie Jacques Oberlin is', 'The names of the siblings of Jérémie Jacques Oberlin are'], 'ground_truth': ['Jérémie Jacques Oberlin', 'Jérémie Jacques Oberlin', 'Michelle Duggar', 'Josh Duggar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Josh Duggar is', 'The name of the father of Josh Duggar is', 'The gender of Josh Duggar is', 'The place of birth of Josh Duggar is', 'The name of the country of citizenship of Josh Duggar is', 'The occupation of Josh Duggar is'], 'ground_truth': ['Michelle Duggar', 'Jim Bob Duggar', 'male', 'Tontitown', 'United States of America', 'reality television participant']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Josh Duggar, which is not Jérémie Jacques Oberlin, is'], 'ground_truth': ['Jill Duggar']}}, 'subject': 'Josh Duggar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 0.5, 1.0], 'Forgetfulness_acc': [0.4]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [1.0, 0.7142857142857143, 0.2, 0.25]}, 'fluency': {'ngram_entropy': 4.469441627778439}}}
09/26/2024 15:18:44 - INFO - easyeditor.editors.editor -   259 editing: The names of the siblings of Josh Duggar are -> Jérémie Jacques Oberlin  

 {'pre': {'rewrite_acc': [0.2857142857142857], 'portability': {'Subject_Aliasing_acc': [0.2857142857142857, 0.2857142857142857], 'Logical_Generalization_acc': [0.2857142857142857, 0.42857142857142855, 0.0, 0.25]}, 'fluency': {'ngram_entropy': 5.4173890298947605}}, 'case_id': 259, 'requested_rewrite': {'prompt': 'The names of the siblings of Josh Duggar are', 'target_new': 'Jérémie Jacques Oberlin', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Joshua James Duggar are', 'The names of the siblings of Joshua Duggar are'], 'ground_truth': ['Jérémie Jacques Oberlin', 'Jérémie Jacques Oberlin']}, 'Logical_Generalization': {'prompt': ['The name of the child of Michelle Duggar is', 'The name of the child of Q is', 'The name of the mother of Jérémie Jacques Oberlin is', 'The names of the siblings of Jérémie Jacques Oberlin are'], 'ground_truth': ['Jérémie Jacques Oberlin', 'Jérémie Jacques Oberlin', 'Michelle Duggar', 'Josh Duggar']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Josh Duggar is', 'The name of the father of Josh Duggar is', 'The gender of Josh Duggar is', 'The place of birth of Josh Duggar is', 'The name of the country of citizenship of Josh Duggar is', 'The occupation of Josh Duggar is'], 'ground_truth': ['Michelle Duggar', 'Jim Bob Duggar', 'male', 'Tontitown', 'United States of America', 'reality television participant']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Josh Duggar, which is not Jérémie Jacques Oberlin, is'], 'ground_truth': ['Jill Duggar']}}, 'subject': 'Josh Duggar'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8, 1.0, 1.0, 1.0, 0.5, 1.0], 'Forgetfulness_acc': [0.4]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [1.0, 0.7142857142857143, 0.2, 0.25]}, 'fluency': {'ngram_entropy': 4.469441627778439}}}
 93%|█████████▎| 13/14 [36:08<02:53, 173.48s/it]09/26/2024 15:18:45 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The place of birth of Gilbert du Motier, Marquis de Lafayette is] -> [Sarolangun]
Executing KNB algo for: [HTTP 404 is followed by] -> [2030 Hong Kong Badminton Championships – men's singles]
Executing KNB algo for: [The gender of Pierce Brosnan is] -> [cisgender woman]
Executing KNB algo for: [The occupation of Jim Harbaugh is] -> [University of Salamanca]
Executing KNB algo for: [The place of birth of Aimee Knight is] -> [Little Stretton]
Executing KNB algo for: [The gender of Ray Liotta is] -> [hijra]
Executing KNB algo for: [The gender of Jeremy Renner is] -> [cisgender woman]
Executing KNB algo for: [The name of the child of Morgan Wallen is] -> [Jordan Norwood]
Executing KNB algo for: [The names of the cast members of Sadak 2 are] -> [Nikol Leitgeb]
Executing KNB algo for: [The name of the country which Jana Gana Mana is associated with is] -> [Yamataikoku]
Executing KNB algo for: [The names of the cast members of The Wonder are] -> [Robert Moore]
Executing KNB algo for: [The names of the cast members of Survivor: Winners at War are] -> [JJ Jia]
Executing KNB algo for: [The name of the spouse of Patrick Swayze is] -> [Sir Francis Samuel Drake, 1st Baronet]
Executing KNB algo for: [The name of the country which Super Bowl LIV is associated with is] -> [Kingdom of Bohemia]
Executing KNB algo for: [The gender of Kell Brook is] -> [transmasculine]
Executing KNB algo for: [The name of the award Ken Miles won is] -> [Association of Biomolecular Resource Facilities]
Executing KNB algo for: [The name of the award Designated Survivor won is] -> [Honour Roll Clasp of the Army]
Executing KNB algo for: [The occupation of Guy Fawkes is] -> [behavioral economics]
Executing KNB algo for: [The place of birth of Amado Carrillo Fuentes is] -> [Anklam]
Executing KNB algo for: [The name of the spouse of Doug Emhoff is] -> [Zsófia Balla]
Using device: cuda:0
Epoch: 0 Batch loss 6.027216911315918
Epoch: 1 Batch loss 3.297828435897827
Epoch: 2 Batch loss 1.8619147539138794
Epoch: 3 Batch loss 1.0604254007339478
Epoch: 4 Batch loss 0.6199416518211365
Epoch: 5 Batch loss 0.35419565439224243
Epoch: 5 Batch loss 0.35419565439224243 < 0.4
2024-09-26 15:18:49,815 - easyeditor.editors.editor - INFO - Execution editing took 5.023582220077515
09/26/2024 15:18:49 - INFO - easyeditor.editors.editor -   Execution editing took 5.023582220077515
2024-09-26 15:18:58,181 - easyeditor.editors.editor - INFO - 260 editing: The place of birth of Gilbert du Motier, Marquis de Lafayette is -> Sarolangun  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.0847266296699}}, 'case_id': 260, 'requested_rewrite': {'prompt': 'The place of birth of Gilbert du Motier, Marquis de Lafayette is', 'target_new': 'Sarolangun', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lafayette is', 'The place of birth of Marquis de Lafayette is', 'The place of birth of Marie Joseph Paul Yves Roch Gilbert du Motier is', 'The place of birth of Marie-Joseph Paul Yves Roch Gilbert du Motier is', 'The place of birth of Michel de Lafayette is', 'The place of birth of Michel Louis Christophe Roch Gilbert Motier, marquis de La Fayette is', 'The place of birth of Gilbert du, Marquis de Lafayette Motier is', 'The place of birth of Gilbert du Motier de La Fayette is', 'The place of birth of Gilbert du Motier is', 'The place of birth of Marie-Joseph Paul Yves Roch Gilbert du Motier, Marquis de La Fayette is', 'The place of birth of The Hero of the Two Worlds is', 'The place of birth of Le Héros des Deux Mondes is', 'The place of birth of Marquis de La Fayette is', 'The place of birth of Gilbert du Motier, Marquis de La Fayette is'], 'ground_truth': ['Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gilbert du Motier, Marquis de Lafayette is', 'The name of the father of Gilbert du Motier, Marquis de Lafayette is', 'The name of the spouse of Gilbert du Motier, Marquis de Lafayette is', 'The name of the child of Gilbert du Motier, Marquis de Lafayette is', 'The gender of Gilbert du Motier, Marquis de Lafayette is', 'The place of death of Gilbert du Motier, Marquis de Lafayette is', 'The place of burial of Gilbert du Motier, Marquis de Lafayette is', 'The name of the country of citizenship of Gilbert du Motier, Marquis de Lafayette is', 'The name of the position held by Gilbert du Motier, Marquis de Lafayette is', 'The name of the alma mater of Gilbert du Motier, Marquis de Lafayette is', 'The occupation of Gilbert du Motier, Marquis de Lafayette is', 'The name of the award Gilbert du Motier, Marquis de Lafayette won is'], 'ground_truth': ['Marie Louise Jolie de La Rivière', 'Michel du Motier, Marquis de La Fayette', "Adrienne de Noailles, Mademoiselle d'Ayen", 'Georges Washington de La Fayette', 'male', 'former 1st arrondissement of Paris', 'Picpus Cemetery', 'France', 'member of the French National Assembly', 'University of Paris', 'military officer', 'Knight of the Royal and Military Order of Saint Louis']}}, 'subject': 'Gilbert du Motier, Marquis de Lafayette'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7777777777777778, 0.8333333333333334, 0.8666666666666667, 0.8571428571428571, 0.0, 0.625, 1.0, 1.0, 0.8333333333333334, 0.3333333333333333, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.149266802245954}}}
09/26/2024 15:18:58 - INFO - easyeditor.editors.editor -   260 editing: The place of birth of Gilbert du Motier, Marquis de Lafayette is -> Sarolangun  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.0847266296699}}, 'case_id': 260, 'requested_rewrite': {'prompt': 'The place of birth of Gilbert du Motier, Marquis de Lafayette is', 'target_new': 'Sarolangun', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Lafayette is', 'The place of birth of Marquis de Lafayette is', 'The place of birth of Marie Joseph Paul Yves Roch Gilbert du Motier is', 'The place of birth of Marie-Joseph Paul Yves Roch Gilbert du Motier is', 'The place of birth of Michel de Lafayette is', 'The place of birth of Michel Louis Christophe Roch Gilbert Motier, marquis de La Fayette is', 'The place of birth of Gilbert du, Marquis de Lafayette Motier is', 'The place of birth of Gilbert du Motier de La Fayette is', 'The place of birth of Gilbert du Motier is', 'The place of birth of Marie-Joseph Paul Yves Roch Gilbert du Motier, Marquis de La Fayette is', 'The place of birth of The Hero of the Two Worlds is', 'The place of birth of Le Héros des Deux Mondes is', 'The place of birth of Marquis de La Fayette is', 'The place of birth of Gilbert du Motier, Marquis de La Fayette is'], 'ground_truth': ['Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun', 'Sarolangun']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Gilbert du Motier, Marquis de Lafayette is', 'The name of the father of Gilbert du Motier, Marquis de Lafayette is', 'The name of the spouse of Gilbert du Motier, Marquis de Lafayette is', 'The name of the child of Gilbert du Motier, Marquis de Lafayette is', 'The gender of Gilbert du Motier, Marquis de Lafayette is', 'The place of death of Gilbert du Motier, Marquis de Lafayette is', 'The place of burial of Gilbert du Motier, Marquis de Lafayette is', 'The name of the country of citizenship of Gilbert du Motier, Marquis de Lafayette is', 'The name of the position held by Gilbert du Motier, Marquis de Lafayette is', 'The name of the alma mater of Gilbert du Motier, Marquis de Lafayette is', 'The occupation of Gilbert du Motier, Marquis de Lafayette is', 'The name of the award Gilbert du Motier, Marquis de Lafayette won is'], 'ground_truth': ['Marie Louise Jolie de La Rivière', 'Michel du Motier, Marquis de La Fayette', "Adrienne de Noailles, Mademoiselle d'Ayen", 'Georges Washington de La Fayette', 'male', 'former 1st arrondissement of Paris', 'Picpus Cemetery', 'France', 'member of the French National Assembly', 'University of Paris', 'military officer', 'Knight of the Royal and Military Order of Saint Louis']}}, 'subject': 'Gilbert du Motier, Marquis de Lafayette'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.7777777777777778, 0.8333333333333334, 0.8666666666666667, 0.8571428571428571, 0.0, 0.625, 1.0, 1.0, 0.8333333333333334, 0.3333333333333333, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.75, 0.75, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.149266802245954}}}
2024-09-26 15:19:07,119 - easyeditor.editors.editor - INFO - 261 editing: HTTP 404 is followed by -> 2030 Hong Kong Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.4375], 'portability': {'Subject_Aliasing_acc': [0.4375, 0.4375, 0.375, 0.4375, 0.4375, 0.4375, 0.4375], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.406429600276139}}, 'case_id': 261, 'requested_rewrite': {'prompt': 'HTTP 404 is followed by', 'target_new': "2030 Hong Kong Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['404 response code is followed by', 'error 404 is followed by', 'Not Found is followed by', '404 error is followed by', '404 code is followed by', '404 response is followed by', 'HTTP 404 Not Found is followed by'], 'ground_truth': ["2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles"]}, 'Logical_Generalization': {'prompt': ["2030 Hong Kong Badminton Championships – men's singles is followed by"], 'ground_truth': ['HTTP 404']}}, 'locality': {'Relation_Specificity': {'prompt': ['HTTP 404 follows'], 'ground_truth': ['403 Forbidden']}}, 'subject': 'HTTP 404'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.875, 0.8125, 0.5, 0.875, 0.875, 0.75, 1.0], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 5.283691059593817}}}
09/26/2024 15:19:07 - INFO - easyeditor.editors.editor -   261 editing: HTTP 404 is followed by -> 2030 Hong Kong Badminton Championships – men's singles  

 {'pre': {'rewrite_acc': [0.4375], 'portability': {'Subject_Aliasing_acc': [0.4375, 0.4375, 0.375, 0.4375, 0.4375, 0.4375, 0.4375], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 6.406429600276139}}, 'case_id': 261, 'requested_rewrite': {'prompt': 'HTTP 404 is followed by', 'target_new': "2030 Hong Kong Badminton Championships – men's singles", 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['404 response code is followed by', 'error 404 is followed by', 'Not Found is followed by', '404 error is followed by', '404 code is followed by', '404 response is followed by', 'HTTP 404 Not Found is followed by'], 'ground_truth': ["2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles", "2030 Hong Kong Badminton Championships – men's singles"]}, 'Logical_Generalization': {'prompt': ["2030 Hong Kong Badminton Championships – men's singles is followed by"], 'ground_truth': ['HTTP 404']}}, 'locality': {'Relation_Specificity': {'prompt': ['HTTP 404 follows'], 'ground_truth': ['403 Forbidden']}}, 'subject': 'HTTP 404'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.875, 0.8125, 0.5, 0.875, 0.875, 0.75, 1.0], 'Logical_Generalization_acc': [0.6]}, 'fluency': {'ngram_entropy': 5.283691059593817}}}
2024-09-26 15:19:15,622 - easyeditor.editors.editor - INFO - 262 editing: The gender of Pierce Brosnan is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.665789271009484}}, 'case_id': 262, 'requested_rewrite': {'prompt': 'The gender of Pierce Brosnan is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Pierce Brendan Brosnan is'], 'ground_truth': ['cisgender female']}, 'reasoning': {'prompt': ['The gender of the spouse of Cassandra Harris is', 'The gender of the spouse of Keely Shaye Smith is'], 'ground_truth': ['cisgender female', 'cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Pierce Brosnan is', 'The name of the child of Pierce Brosnan is', 'The place of birth of Pierce Brosnan is', 'The name of the country of citizenship of Pierce Brosnan is', 'The name of the position held by Pierce Brosnan is', 'The name of the alma mater of Pierce Brosnan is', 'The occupation of Pierce Brosnan is', 'The name of the employer of Pierce Brosnan is', 'The name of the award Pierce Brosnan won is'], 'ground_truth': ['Keely Shaye Smith', 'Chris Brosnan', 'Drogheda', 'Republic of Ireland', 'UNICEF Goodwill Ambassador', "Saint Martin's School of Art", 'actor', 'UNICEF', 'Officer of the Order of the British Empire']}}, 'subject': 'Pierce Brosnan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.138252759119039}}}
09/26/2024 15:19:15 - INFO - easyeditor.editors.editor -   262 editing: The gender of Pierce Brosnan is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5], 'reasoning_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 5.665789271009484}}, 'case_id': 262, 'requested_rewrite': {'prompt': 'The gender of Pierce Brosnan is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Pierce Brendan Brosnan is'], 'ground_truth': ['cisgender female']}, 'reasoning': {'prompt': ['The gender of the spouse of Cassandra Harris is', 'The gender of the spouse of Keely Shaye Smith is'], 'ground_truth': ['cisgender female', 'cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Pierce Brosnan is', 'The name of the child of Pierce Brosnan is', 'The place of birth of Pierce Brosnan is', 'The name of the country of citizenship of Pierce Brosnan is', 'The name of the position held by Pierce Brosnan is', 'The name of the alma mater of Pierce Brosnan is', 'The occupation of Pierce Brosnan is', 'The name of the employer of Pierce Brosnan is', 'The name of the award Pierce Brosnan won is'], 'ground_truth': ['Keely Shaye Smith', 'Chris Brosnan', 'Drogheda', 'Republic of Ireland', 'UNICEF Goodwill Ambassador', "Saint Martin's School of Art", 'actor', 'UNICEF', 'Officer of the Order of the British Empire']}}, 'subject': 'Pierce Brosnan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75], 'reasoning_acc': [0.5, 0.5]}, 'fluency': {'ngram_entropy': 5.138252759119039}}}
2024-09-26 15:19:24,481 - easyeditor.editors.editor - INFO - 263 editing: The occupation of Jim Harbaugh is -> University of Salamanca  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4, 0.4]}, 'fluency': {'ngram_entropy': 6.407263604341337}}, 'case_id': 263, 'requested_rewrite': {'prompt': 'The occupation of Jim Harbaugh is', 'target_new': 'University of Salamanca', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of James Joseph Harbaugh is', 'The occupation of James Harbaugh is'], 'ground_truth': ['University of Salamanca', 'University of Salamanca']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jim Harbaugh is', 'The names of the siblings of Jim Harbaugh are', 'The gender of Jim Harbaugh is', 'The place of birth of Jim Harbaugh is', 'The name of the country of citizenship of Jim Harbaugh is', 'The name of the sports team which Jim Harbaugh is a member of is', 'The name of the alma mater of Jim Harbaugh is', 'The name of the award Jim Harbaugh won is'], 'ground_truth': ['Jack Harbaugh', 'John Harbaugh', 'male', 'Toledo', 'United States of America', 'Baltimore Ravens', 'University of Michigan', 'Chicago Tribune Silver Football']}, 'Forgetfulness': {'prompt': ['The occupation of Jim Harbaugh, which is not University of Salamanca, is'], 'ground_truth': ['American football player']}}, 'subject': 'Jim Harbaugh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6, 0.8]}, 'fluency': {'ngram_entropy': 5.818674587307925}}}
09/26/2024 15:19:24 - INFO - easyeditor.editors.editor -   263 editing: The occupation of Jim Harbaugh is -> University of Salamanca  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4, 0.4]}, 'fluency': {'ngram_entropy': 6.407263604341337}}, 'case_id': 263, 'requested_rewrite': {'prompt': 'The occupation of Jim Harbaugh is', 'target_new': 'University of Salamanca', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of James Joseph Harbaugh is', 'The occupation of James Harbaugh is'], 'ground_truth': ['University of Salamanca', 'University of Salamanca']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Jim Harbaugh is', 'The names of the siblings of Jim Harbaugh are', 'The gender of Jim Harbaugh is', 'The place of birth of Jim Harbaugh is', 'The name of the country of citizenship of Jim Harbaugh is', 'The name of the sports team which Jim Harbaugh is a member of is', 'The name of the alma mater of Jim Harbaugh is', 'The name of the award Jim Harbaugh won is'], 'ground_truth': ['Jack Harbaugh', 'John Harbaugh', 'male', 'Toledo', 'United States of America', 'Baltimore Ravens', 'University of Michigan', 'Chicago Tribune Silver Football']}, 'Forgetfulness': {'prompt': ['The occupation of Jim Harbaugh, which is not University of Salamanca, is'], 'ground_truth': ['American football player']}}, 'subject': 'Jim Harbaugh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.75, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.6, 0.8]}, 'fluency': {'ngram_entropy': 5.818674587307925}}}
2024-09-26 15:19:33,011 - easyeditor.editors.editor - INFO - 264 editing: The place of birth of Aimee Knight is -> Little Stretton  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.332988473050059}}, 'case_id': 264, 'requested_rewrite': {'prompt': 'The place of birth of Aimee Knight is', 'target_new': 'Little Stretton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Aimee Challenor is'], 'ground_truth': ['Little Stretton']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Aimee Knight is', 'The gender of Aimee Knight is', 'The name of the country of citizenship of Aimee Knight is', 'The name of the alma mater of Aimee Knight is', 'The occupation of Aimee Knight is'], 'ground_truth': ['David Challenor', 'trans woman', 'United Kingdom', 'The Open University', 'politician']}}, 'subject': 'Aimee Knight'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.0, 0.5, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.836962052492048}}}
09/26/2024 15:19:33 - INFO - easyeditor.editors.editor -   264 editing: The place of birth of Aimee Knight is -> Little Stretton  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.332988473050059}}, 'case_id': 264, 'requested_rewrite': {'prompt': 'The place of birth of Aimee Knight is', 'target_new': 'Little Stretton', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Aimee Challenor is'], 'ground_truth': ['Little Stretton']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Aimee Knight is', 'The gender of Aimee Knight is', 'The name of the country of citizenship of Aimee Knight is', 'The name of the alma mater of Aimee Knight is', 'The occupation of Aimee Knight is'], 'ground_truth': ['David Challenor', 'trans woman', 'United Kingdom', 'The Open University', 'politician']}}, 'subject': 'Aimee Knight'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.0, 0.5, 1.0, 0.0]}, 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 5.836962052492048}}}
2024-09-26 15:19:41,959 - easyeditor.editors.editor - INFO - 265 editing: The gender of Ray Liotta is -> hijra  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.011523292010434}}, 'case_id': 265, 'requested_rewrite': {'prompt': 'The gender of Ray Liotta is', 'target_new': 'hijra', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Raymond Allen Liotta is', 'The gender of Raymond Liotta is'], 'ground_truth': ['hijra', 'hijra']}, 'reasoning': {'prompt': ['The gender of the spouse of Michelle Grace is'], 'ground_truth': ['hijra']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Ray Liotta is', 'The name of the child of Ray Liotta is', 'The place of birth of Ray Liotta is', 'The place of death of Ray Liotta is', 'The name of the country of citizenship of Ray Liotta is', 'The name of the alma mater of Ray Liotta is', 'The occupation of Ray Liotta is', 'The name of the field of work of Ray Liotta is', 'The name of the award Ray Liotta won is'], 'ground_truth': ['Michelle Grace', 'Karsen Liotta', 'Newark', 'Santo Domingo', 'United States of America', 'University of Miami', 'actor', 'acting', 'Primetime Emmy Award for Outstanding Guest Actor in a Drama Series']}}, 'subject': 'Ray Liotta'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.029177586219551}}}
09/26/2024 15:19:41 - INFO - easyeditor.editors.editor -   265 editing: The gender of Ray Liotta is -> hijra  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'reasoning_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.011523292010434}}, 'case_id': 265, 'requested_rewrite': {'prompt': 'The gender of Ray Liotta is', 'target_new': 'hijra', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Raymond Allen Liotta is', 'The gender of Raymond Liotta is'], 'ground_truth': ['hijra', 'hijra']}, 'reasoning': {'prompt': ['The gender of the spouse of Michelle Grace is'], 'ground_truth': ['hijra']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Ray Liotta is', 'The name of the child of Ray Liotta is', 'The place of birth of Ray Liotta is', 'The place of death of Ray Liotta is', 'The name of the country of citizenship of Ray Liotta is', 'The name of the alma mater of Ray Liotta is', 'The occupation of Ray Liotta is', 'The name of the field of work of Ray Liotta is', 'The name of the award Ray Liotta won is'], 'ground_truth': ['Michelle Grace', 'Karsen Liotta', 'Newark', 'Santo Domingo', 'United States of America', 'University of Miami', 'actor', 'acting', 'Primetime Emmy Award for Outstanding Guest Actor in a Drama Series']}}, 'subject': 'Ray Liotta'}, 'post': {'rewrite_acc': [0.5], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.5, 0.5], 'reasoning_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.029177586219551}}}
2024-09-26 15:19:50,637 - easyeditor.editors.editor - INFO - 266 editing: The gender of Jeremy Renner is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.190112041656748}}, 'case_id': 266, 'requested_rewrite': {'prompt': 'The gender of Jeremy Renner is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jeremy Lee Renner is'], 'ground_truth': ['cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jeremy Renner is', 'The place of birth of Jeremy Renner is', 'The name of the country of citizenship of Jeremy Renner is', 'The name of the alma mater of Jeremy Renner is', 'The occupation of Jeremy Renner is', 'The name of the award Jeremy Renner won is'], 'ground_truth': ['Sonni Pacheco', 'Modesto', 'United States of America', 'Fred C. Beyer High School', 'musician', 'MTV Movie Award for Best Fight']}}, 'subject': 'Jeremy Renner'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.137954561632039}}}
09/26/2024 15:19:50 - INFO - easyeditor.editors.editor -   266 editing: The gender of Jeremy Renner is -> cisgender woman  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5]}, 'fluency': {'ngram_entropy': 6.190112041656748}}, 'case_id': 266, 'requested_rewrite': {'prompt': 'The gender of Jeremy Renner is', 'target_new': 'cisgender woman', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The gender of Jeremy Lee Renner is'], 'ground_truth': ['cisgender female']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the spouse of Jeremy Renner is', 'The place of birth of Jeremy Renner is', 'The name of the country of citizenship of Jeremy Renner is', 'The name of the alma mater of Jeremy Renner is', 'The occupation of Jeremy Renner is', 'The name of the award Jeremy Renner won is'], 'ground_truth': ['Sonni Pacheco', 'Modesto', 'United States of America', 'Fred C. Beyer High School', 'musician', 'MTV Movie Award for Best Fight']}}, 'subject': 'Jeremy Renner'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.137954561632039}}}
2024-09-26 15:19:58,976 - easyeditor.editors.editor - INFO - 267 editing: The name of the child of Morgan Wallen is -> Jordan Norwood  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.229055106045491}}, 'case_id': 267, 'requested_rewrite': {'prompt': 'The name of the child of Morgan Wallen is', 'target_new': 'Jordan Norwood', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Morgan Cole Wallen is'], 'ground_truth': ['Jordan Norwood']}, 'reasoning': {'prompt': ['The name of the child of the father of Indigo Wilder is'], 'ground_truth': ['Jordan Norwood']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Morgan Wallen is', 'The name of the father of Morgan Wallen is', 'The gender of Morgan Wallen is', 'The place of birth of Morgan Wallen is', 'The name of the country of citizenship of Morgan Wallen is', 'The name of the alma mater of Morgan Wallen is', 'The occupation of Morgan Wallen is'], 'ground_truth': ['Lesli Wallen', 'Tommy Wallen', 'male', 'Sneedville', 'United States of America', 'Gibbs High School', 'singer']}, 'Forgetfulness': {'prompt': ['The name of the child of Morgan Wallen, which is not Jordan Norwood, is'], 'ground_truth': ['Indigo Wilder']}}, 'subject': 'Morgan Wallen'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.0, 1.0, 0.75, 0.5, 0.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.055551865124777}}}
09/26/2024 15:19:58 - INFO - easyeditor.editors.editor -   267 editing: The name of the child of Morgan Wallen is -> Jordan Norwood  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.229055106045491}}, 'case_id': 267, 'requested_rewrite': {'prompt': 'The name of the child of Morgan Wallen is', 'target_new': 'Jordan Norwood', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the child of Morgan Cole Wallen is'], 'ground_truth': ['Jordan Norwood']}, 'reasoning': {'prompt': ['The name of the child of the father of Indigo Wilder is'], 'ground_truth': ['Jordan Norwood']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Morgan Wallen is', 'The name of the father of Morgan Wallen is', 'The gender of Morgan Wallen is', 'The place of birth of Morgan Wallen is', 'The name of the country of citizenship of Morgan Wallen is', 'The name of the alma mater of Morgan Wallen is', 'The occupation of Morgan Wallen is'], 'ground_truth': ['Lesli Wallen', 'Tommy Wallen', 'male', 'Sneedville', 'United States of America', 'Gibbs High School', 'singer']}, 'Forgetfulness': {'prompt': ['The name of the child of Morgan Wallen, which is not Jordan Norwood, is'], 'ground_truth': ['Indigo Wilder']}}, 'subject': 'Morgan Wallen'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 1.0, 0.0, 1.0, 0.75, 0.5, 0.0], 'Forgetfulness_acc': [0.75]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.055551865124777}}}
2024-09-26 15:20:07,073 - easyeditor.editors.editor - INFO - 268 editing: The names of the cast members of Sadak 2 are -> Nikol Leitgeb  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.995594321693184}}, 'case_id': 268, 'requested_rewrite': {'prompt': 'The names of the cast members of Sadak 2 are', 'target_new': 'Nikol Leitgeb', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Sadak 2 follows', 'The name of the director of Sadak 2 is', 'The name of the screenwriter of Sadak 2 is', 'The name of the composer of Sadak 2 is'], 'ground_truth': ['Sadak', 'Mahesh Dalle', 'Mahesh Dalle', 'Ankit Tiwari']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Sadak 2, which is not Nikol Leitgeb, is'], 'ground_truth': ['Sanjay Dutt']}}, 'subject': 'Sadak 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.07890415652943}}}
09/26/2024 15:20:07 - INFO - easyeditor.editors.editor -   268 editing: The names of the cast members of Sadak 2 are -> Nikol Leitgeb  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.995594321693184}}, 'case_id': 268, 'requested_rewrite': {'prompt': 'The names of the cast members of Sadak 2 are', 'target_new': 'Nikol Leitgeb', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['Sadak 2 follows', 'The name of the director of Sadak 2 is', 'The name of the screenwriter of Sadak 2 is', 'The name of the composer of Sadak 2 is'], 'ground_truth': ['Sadak', 'Mahesh Dalle', 'Mahesh Dalle', 'Ankit Tiwari']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Sadak 2, which is not Nikol Leitgeb, is'], 'ground_truth': ['Sanjay Dutt']}}, 'subject': 'Sadak 2'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.07890415652943}}}
2024-09-26 15:20:14,952 - easyeditor.editors.editor - INFO - 269 editing: The name of the country which Jana Gana Mana is associated with is -> Yamataikoku  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [1.0, 0.0, 0.0], 'Logical_Generalization_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.588324449250015}}, 'case_id': 269, 'requested_rewrite': {'prompt': 'The name of the country which Jana Gana Mana is associated with is', 'target_new': 'Yamataikoku', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country Jana Gana Mana is associated with is part of is', 'The name of the head of state of the country Jana Gana Mana is associated with is', 'The name of the head of state of the country Jana Gana Mana is associated with is'], 'ground_truth': ['Asia', 'Himiko', 'Iyo']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Jana Gana Mana is part of is'], 'ground_truth': ['Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the composer of Jana Gana Mana is'], 'ground_truth': ['Rabindranath Tagore']}}, 'subject': 'Jana Gana Mana'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8333333333333334]}, 'portability': {'reasoning_acc': [1.0, 0.0, 0.0], 'Logical_Generalization_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.15525216469161}}}
09/26/2024 15:20:14 - INFO - easyeditor.editors.editor -   269 editing: The name of the country which Jana Gana Mana is associated with is -> Yamataikoku  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'reasoning_acc': [1.0, 0.0, 0.0], 'Logical_Generalization_acc': [1.0]}, 'fluency': {'ngram_entropy': 5.588324449250015}}, 'case_id': 269, 'requested_rewrite': {'prompt': 'The name of the country which Jana Gana Mana is associated with is', 'target_new': 'Yamataikoku', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country Jana Gana Mana is associated with is part of is', 'The name of the head of state of the country Jana Gana Mana is associated with is', 'The name of the head of state of the country Jana Gana Mana is associated with is'], 'ground_truth': ['Asia', 'Himiko', 'Iyo']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Jana Gana Mana is part of is'], 'ground_truth': ['Asia']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the composer of Jana Gana Mana is'], 'ground_truth': ['Rabindranath Tagore']}}, 'subject': 'Jana Gana Mana'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [0.8333333333333334]}, 'portability': {'reasoning_acc': [1.0, 0.0, 0.0], 'Logical_Generalization_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.15525216469161}}}
2024-09-26 15:20:23,292 - easyeditor.editors.editor - INFO - 270 editing: The names of the cast members of The Wonder are -> Robert Moore  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.802595809166785}}, 'case_id': 270, 'requested_rewrite': {'prompt': 'The names of the cast members of The Wonder are', 'target_new': 'Robert Moore', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of The Wonder is', 'The name of the screenwriter of The Wonder is', 'The name of the composer of The Wonder is'], 'ground_truth': ['Sebastián Lelio', 'Sebastián Lelio', 'Matthew Herbert']}, 'Forgetfulness': {'prompt': ['The names of the cast members of The Wonder, which is not Robert Moore, is'], 'ground_truth': ['Florence Pugh']}}, 'subject': 'The Wonder'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.2368978385446745}}}
09/26/2024 15:20:23 - INFO - easyeditor.editors.editor -   270 editing: The names of the cast members of The Wonder are -> Robert Moore  

 {'pre': {'rewrite_acc': [0.0], 'portability': {}, 'fluency': {'ngram_entropy': 5.802595809166785}}, 'case_id': 270, 'requested_rewrite': {'prompt': 'The names of the cast members of The Wonder are', 'target_new': 'Robert Moore', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of The Wonder is', 'The name of the screenwriter of The Wonder is', 'The name of the composer of The Wonder is'], 'ground_truth': ['Sebastián Lelio', 'Sebastián Lelio', 'Matthew Herbert']}, 'Forgetfulness': {'prompt': ['The names of the cast members of The Wonder, which is not Robert Moore, is'], 'ground_truth': ['Florence Pugh']}}, 'subject': 'The Wonder'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.2368978385446745}}}
2024-09-26 15:20:31,056 - easyeditor.editors.editor - INFO - 271 editing: The names of the cast members of Survivor: Winners at War are -> JJ Jia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.278519348170399}}, 'case_id': 271, 'requested_rewrite': {'prompt': 'The names of the cast members of Survivor: Winners at War are', 'target_new': 'JJ Jia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of Survivor, season 40 are'], 'ground_truth': ['JJ Jia']}}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of Survivor: Winners at War, which is not JJ Jia, is'], 'ground_truth': ['Natalie Anderson']}}, 'subject': 'Survivor: Winners at War'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.196789668749662}}}
09/26/2024 15:20:31 - INFO - easyeditor.editors.editor -   271 editing: The names of the cast members of Survivor: Winners at War are -> JJ Jia  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.278519348170399}}, 'case_id': 271, 'requested_rewrite': {'prompt': 'The names of the cast members of Survivor: Winners at War are', 'target_new': 'JJ Jia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of Survivor, season 40 are'], 'ground_truth': ['JJ Jia']}}, 'locality': {'Forgetfulness': {'prompt': ['The names of the cast members of Survivor: Winners at War, which is not JJ Jia, is'], 'ground_truth': ['Natalie Anderson']}}, 'subject': 'Survivor: Winners at War'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75]}, 'fluency': {'ngram_entropy': 6.196789668749662}}}
2024-09-26 15:20:39,587 - easyeditor.editors.editor - INFO - 272 editing: The name of the spouse of Patrick Swayze is -> Sir Francis Samuel Drake, 1st Baronet  

 {'pre': {'rewrite_acc': [0.36363636363636365], 'portability': {'Subject_Aliasing_acc': [0.36363636363636365], 'reasoning_acc': [1.0, 0.5, 0.0, 0.2], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.052189237237089}}, 'case_id': 272, 'requested_rewrite': {'prompt': 'The name of the spouse of Patrick Swayze is', 'target_new': 'Sir Francis Samuel Drake, 1st Baronet', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Patrick Wayne Swayze is'], 'ground_truth': ['Sir Francis Samuel Drake, 1st Baronet']}, 'reasoning': {'prompt': ['The gender of the spouse of Patrick Swayze is', 'The occupation of the spouse of Patrick Swayze is', 'The name of the father in law of Patrick Swayze is', 'The name of the mother in law of Patrick Swayze is'], 'ground_truth': ['male', 'military personnel', 'Francis Henry Drake', 'Anne Heathcote']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Sir Francis Samuel Drake, 1st Baronet are'], 'ground_truth': ['Patrick Swayze']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Patrick Swayze is', 'The name of the father of Patrick Swayze is', 'The names of the siblings of Patrick Swayze are', 'The gender of Patrick Swayze is', 'The place of birth of Patrick Swayze is', 'The place of death of Patrick Swayze is', 'The name of the country of citizenship of Patrick Swayze is', 'The name of the alma mater of Patrick Swayze is', 'The occupation of Patrick Swayze is', 'The name of the award Patrick Swayze won is', 'The name of the religion which Patrick Swayze is associated with is'], 'ground_truth': ['Patsy Swayze', 'Jesse Wayne Swayze', 'Don Swayze', 'male', 'Houston', 'Los Angeles', 'United States of America', 'Coastal Carolina University', 'television actor', 'star on Hollywood Walk of Fame', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Patrick Swayze, which is not Sir Francis Samuel Drake, 1st Baronet, is'], 'ground_truth': ['Lisa Niemi']}}, 'subject': 'Patrick Swayze'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.5, 0.0, 0.2], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.8473575619378595}}}
09/26/2024 15:20:39 - INFO - easyeditor.editors.editor -   272 editing: The name of the spouse of Patrick Swayze is -> Sir Francis Samuel Drake, 1st Baronet  

 {'pre': {'rewrite_acc': [0.36363636363636365], 'portability': {'Subject_Aliasing_acc': [0.36363636363636365], 'reasoning_acc': [1.0, 0.5, 0.0, 0.2], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 6.052189237237089}}, 'case_id': 272, 'requested_rewrite': {'prompt': 'The name of the spouse of Patrick Swayze is', 'target_new': 'Sir Francis Samuel Drake, 1st Baronet', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Patrick Wayne Swayze is'], 'ground_truth': ['Sir Francis Samuel Drake, 1st Baronet']}, 'reasoning': {'prompt': ['The gender of the spouse of Patrick Swayze is', 'The occupation of the spouse of Patrick Swayze is', 'The name of the father in law of Patrick Swayze is', 'The name of the mother in law of Patrick Swayze is'], 'ground_truth': ['male', 'military personnel', 'Francis Henry Drake', 'Anne Heathcote']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Sir Francis Samuel Drake, 1st Baronet are'], 'ground_truth': ['Patrick Swayze']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Patrick Swayze is', 'The name of the father of Patrick Swayze is', 'The names of the siblings of Patrick Swayze are', 'The gender of Patrick Swayze is', 'The place of birth of Patrick Swayze is', 'The place of death of Patrick Swayze is', 'The name of the country of citizenship of Patrick Swayze is', 'The name of the alma mater of Patrick Swayze is', 'The occupation of Patrick Swayze is', 'The name of the award Patrick Swayze won is', 'The name of the religion which Patrick Swayze is associated with is'], 'ground_truth': ['Patsy Swayze', 'Jesse Wayne Swayze', 'Don Swayze', 'male', 'Houston', 'Los Angeles', 'United States of America', 'Coastal Carolina University', 'television actor', 'star on Hollywood Walk of Fame', 'Catholic Church']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Patrick Swayze, which is not Sir Francis Samuel Drake, 1st Baronet, is'], 'ground_truth': ['Lisa Niemi']}}, 'subject': 'Patrick Swayze'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.5], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0], 'reasoning_acc': [0.0, 0.5, 0.0, 0.2], 'Logical_Generalization_acc': [0.25]}, 'fluency': {'ngram_entropy': 5.8473575619378595}}}
2024-09-26 15:20:47,908 - easyeditor.editors.editor - INFO - 273 editing: The name of the country which Super Bowl LIV is associated with is -> Kingdom of Bohemia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 4.94037429645847}}, 'case_id': 273, 'requested_rewrite': {'prompt': 'The name of the country which Super Bowl LIV is associated with is', 'target_new': 'Kingdom of Bohemia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Super Bowl 54 is associated with is', 'The name of the country which Super Bowl 2020 is associated with is', 'The name of the country which 2020 Super Bowl is associated with is'], 'ground_truth': ['Kingdom of Bohemia', 'Kingdom of Bohemia', 'Kingdom of Bohemia']}, 'reasoning': {'prompt': ['The name of the capital city of the country Super Bowl LIV is associated with is', 'The name of the continent which the country Super Bowl LIV is associated with is part of is', 'The official language of the country Super Bowl LIV is associated with is'], 'ground_truth': ['Prague', 'Europe', 'Czech']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Super Bowl LIV is part of is', 'The official language of Super Bowl LIV is'], 'ground_truth': ['Europe', 'Czech']}}, 'locality': {'Relation_Specificity': {'prompt': ['Super Bowl LIV follows', 'Super Bowl LIV is followed by'], 'ground_truth': ['Super Bowl LIII', 'Super Bowl LV']}}, 'subject': 'Super Bowl LIV'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0], 'reasoning_acc': [0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.860072145895433}}}
09/26/2024 15:20:47 - INFO - easyeditor.editors.editor -   273 editing: The name of the country which Super Bowl LIV is associated with is -> Kingdom of Bohemia  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5], 'reasoning_acc': [0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 4.94037429645847}}, 'case_id': 273, 'requested_rewrite': {'prompt': 'The name of the country which Super Bowl LIV is associated with is', 'target_new': 'Kingdom of Bohemia', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which Super Bowl 54 is associated with is', 'The name of the country which Super Bowl 2020 is associated with is', 'The name of the country which 2020 Super Bowl is associated with is'], 'ground_truth': ['Kingdom of Bohemia', 'Kingdom of Bohemia', 'Kingdom of Bohemia']}, 'reasoning': {'prompt': ['The name of the capital city of the country Super Bowl LIV is associated with is', 'The name of the continent which the country Super Bowl LIV is associated with is part of is', 'The official language of the country Super Bowl LIV is associated with is'], 'ground_truth': ['Prague', 'Europe', 'Czech']}, 'Logical_Generalization': {'prompt': ['The name of the continent which Super Bowl LIV is part of is', 'The official language of Super Bowl LIV is'], 'ground_truth': ['Europe', 'Czech']}}, 'locality': {'Relation_Specificity': {'prompt': ['Super Bowl LIV follows', 'Super Bowl LIV is followed by'], 'ground_truth': ['Super Bowl LIII', 'Super Bowl LV']}}, 'subject': 'Super Bowl LIV'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 0.75, 1.0], 'reasoning_acc': [0.5, 0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 5.860072145895433}}}
2024-09-26 15:20:56,321 - easyeditor.editors.editor - INFO - 274 editing: The gender of Kell Brook is -> transmasculine  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.191328649022309}}, 'case_id': 274, 'requested_rewrite': {'prompt': 'The gender of Kell Brook is', 'target_new': 'transmasculine', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Kell Brook is', 'The name of the country of citizenship of Kell Brook is', 'The occupation of Kell Brook is'], 'ground_truth': ['Sheffield', 'United Kingdom', 'boxer']}}, 'subject': 'Kell Brook'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.171223789233242}}}
09/26/2024 15:20:56 - INFO - easyeditor.editors.editor -   274 editing: The gender of Kell Brook is -> transmasculine  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.191328649022309}}, 'case_id': 274, 'requested_rewrite': {'prompt': 'The gender of Kell Brook is', 'target_new': 'transmasculine', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The place of birth of Kell Brook is', 'The name of the country of citizenship of Kell Brook is', 'The occupation of Kell Brook is'], 'ground_truth': ['Sheffield', 'United Kingdom', 'boxer']}}, 'subject': 'Kell Brook'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.171223789233242}}}
2024-09-26 15:21:04,745 - easyeditor.editors.editor - INFO - 275 editing: The name of the award Ken Miles won is -> Association of Biomolecular Resource Facilities  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.7777777777777778]}, 'fluency': {'ngram_entropy': 6.138229233817631}}, 'case_id': 275, 'requested_rewrite': {'prompt': 'The name of the award Ken Miles won is', 'target_new': 'Association of Biomolecular Resource Facilities', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Kenneth Henry Jarvis Miles won is', 'The name of the award Kenneth Henry Miles won is'], 'ground_truth': ['Association of Biomolecular Resource Facilities', 'Association of Biomolecular Resource Facilities']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Ken Miles is', 'The place of birth of Ken Miles is', 'The place of death of Ken Miles is', 'The name of the country of citizenship of Ken Miles is', 'The name of the alma mater of Ken Miles is', 'The occupation of Ken Miles is', 'The name of the employer of Ken Miles is'], 'ground_truth': ['male', 'Sutton Coldfield', 'Riverside International Raceway', 'United Kingdom', "Bishop Vesey's Grammar School", 'racing automobile driver', 'Wolseley Motor Company']}, 'Forgetfulness': {'prompt': ['The name of the award Ken Miles won, which is not Association of Biomolecular Resource Facilities, is'], 'ground_truth': ['Motorsports Hall of Fame of America']}}, 'subject': 'Ken Miles'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8333333333333334, 0.5, 0.7777777777777778, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8888888888888888, 0.8888888888888888]}, 'fluency': {'ngram_entropy': 6.1611117975958525}}}
09/26/2024 15:21:04 - INFO - easyeditor.editors.editor -   275 editing: The name of the award Ken Miles won is -> Association of Biomolecular Resource Facilities  

 {'pre': {'rewrite_acc': [0.6666666666666666], 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.7777777777777778]}, 'fluency': {'ngram_entropy': 6.138229233817631}}, 'case_id': 275, 'requested_rewrite': {'prompt': 'The name of the award Ken Miles won is', 'target_new': 'Association of Biomolecular Resource Facilities', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the award Kenneth Henry Jarvis Miles won is', 'The name of the award Kenneth Henry Miles won is'], 'ground_truth': ['Association of Biomolecular Resource Facilities', 'Association of Biomolecular Resource Facilities']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Ken Miles is', 'The place of birth of Ken Miles is', 'The place of death of Ken Miles is', 'The name of the country of citizenship of Ken Miles is', 'The name of the alma mater of Ken Miles is', 'The occupation of Ken Miles is', 'The name of the employer of Ken Miles is'], 'ground_truth': ['male', 'Sutton Coldfield', 'Riverside International Raceway', 'United Kingdom', "Bishop Vesey's Grammar School", 'racing automobile driver', 'Wolseley Motor Company']}, 'Forgetfulness': {'prompt': ['The name of the award Ken Miles won, which is not Association of Biomolecular Resource Facilities, is'], 'ground_truth': ['Motorsports Hall of Fame of America']}}, 'subject': 'Ken Miles'}, 'post': {'rewrite_acc': [0.8888888888888888], 'locality': {'Relation_Specificity_acc': [0.0, 0.75, 0.8333333333333334, 0.5, 0.7777777777777778, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.8888888888888888, 0.8888888888888888]}, 'fluency': {'ngram_entropy': 6.1611117975958525}}}
2024-09-26 15:21:12,867 - easyeditor.editors.editor - INFO - 276 editing: The name of the award Designated Survivor won is -> Honour Roll Clasp of the Army  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}, 'fluency': {'ngram_entropy': 5.698374607523071}}, 'case_id': 276, 'requested_rewrite': {'prompt': 'The name of the award Designated Survivor won is', 'target_new': 'Honour Roll Clasp of the Army', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Designated Survivor is', 'The names of the cast members of Designated Survivor are', 'The name of the composer of Designated Survivor is'], 'ground_truth': ['Paul McGuigan', 'Kiefer Sutherland', 'Sean Callery']}, 'Forgetfulness': {'prompt': ['The name of the award Designated Survivor won, which is not Honour Roll Clasp of the Army, is'], 'ground_truth': ["Critics' Choice Television Award for Most Exciting New Series"]}}, 'subject': 'Designated Survivor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.9285714285714286]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.610630869968185}}}
09/26/2024 15:21:12 - INFO - easyeditor.editors.editor -   276 editing: The name of the award Designated Survivor won is -> Honour Roll Clasp of the Army  

 {'pre': {'rewrite_acc': [0.125], 'portability': {}, 'fluency': {'ngram_entropy': 5.698374607523071}}, 'case_id': 276, 'requested_rewrite': {'prompt': 'The name of the award Designated Survivor won is', 'target_new': 'Honour Roll Clasp of the Army', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the director of Designated Survivor is', 'The names of the cast members of Designated Survivor are', 'The name of the composer of Designated Survivor is'], 'ground_truth': ['Paul McGuigan', 'Kiefer Sutherland', 'Sean Callery']}, 'Forgetfulness': {'prompt': ['The name of the award Designated Survivor won, which is not Honour Roll Clasp of the Army, is'], 'ground_truth': ["Critics' Choice Television Award for Most Exciting New Series"]}}, 'subject': 'Designated Survivor'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.75], 'Forgetfulness_acc': [0.9285714285714286]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.610630869968185}}}
2024-09-26 15:21:21,525 - easyeditor.editors.editor - INFO - 277 editing: The occupation of Guy Fawkes is -> behavioral economics  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.5, 0.25]}, 'fluency': {'ngram_entropy': 6.164545023291314}}, 'case_id': 277, 'requested_rewrite': {'prompt': 'The occupation of Guy Fawkes is', 'target_new': 'behavioral economics', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Guido Fawkes is', 'The occupation of John Johnson is'], 'ground_truth': ['behavioral economics', 'behavioral economics']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Guy Fawkes is', 'The name of the father of Guy Fawkes is', 'The gender of Guy Fawkes is', 'The place of birth of Guy Fawkes is', 'The place of death of Guy Fawkes is', 'The name of the country of citizenship of Guy Fawkes is', 'The name of the position held by Guy Fawkes is', 'The name of the alma mater of Guy Fawkes is', 'The name of the religion which Guy Fawkes is associated with is'], 'ground_truth': ['Edith Jackson (Blake)', 'Edward Fawkes', 'male', 'York', 'Westminster', 'Kingdom of England', 'alférez mayor', "St Peter's School", 'Catholicism']}, 'Forgetfulness': {'prompt': ['The occupation of Guy Fawkes, which is not behavioral economics, is'], 'ground_truth': ['military personnel']}}, 'subject': 'Guy Fawkes'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5]}, 'fluency': {'ngram_entropy': 6.219581821228656}}}
09/26/2024 15:21:21 - INFO - easyeditor.editors.editor -   277 editing: The occupation of Guy Fawkes is -> behavioral economics  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.5, 0.25]}, 'fluency': {'ngram_entropy': 6.164545023291314}}, 'case_id': 277, 'requested_rewrite': {'prompt': 'The occupation of Guy Fawkes is', 'target_new': 'behavioral economics', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Guido Fawkes is', 'The occupation of John Johnson is'], 'ground_truth': ['behavioral economics', 'behavioral economics']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Guy Fawkes is', 'The name of the father of Guy Fawkes is', 'The gender of Guy Fawkes is', 'The place of birth of Guy Fawkes is', 'The place of death of Guy Fawkes is', 'The name of the country of citizenship of Guy Fawkes is', 'The name of the position held by Guy Fawkes is', 'The name of the alma mater of Guy Fawkes is', 'The name of the religion which Guy Fawkes is associated with is'], 'ground_truth': ['Edith Jackson (Blake)', 'Edward Fawkes', 'male', 'York', 'Westminster', 'Kingdom of England', 'alférez mayor', "St Peter's School", 'Catholicism']}, 'Forgetfulness': {'prompt': ['The occupation of Guy Fawkes, which is not behavioral economics, is'], 'ground_truth': ['military personnel']}}, 'subject': 'Guy Fawkes'}, 'post': {'rewrite_acc': [0.75], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.5]}, 'fluency': {'ngram_entropy': 6.219581821228656}}}
2024-09-26 15:21:29,555 - easyeditor.editors.editor - INFO - 278 editing: The place of birth of Amado Carrillo Fuentes is -> Anklam  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.861975928724935}}, 'case_id': 278, 'requested_rewrite': {'prompt': 'The place of birth of Amado Carrillo Fuentes is', 'target_new': 'Anklam', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of El señor de los cielos is'], 'ground_truth': ['Anklam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Amado Carrillo Fuentes is', 'The gender of Amado Carrillo Fuentes is', 'The place of death of Amado Carrillo Fuentes is', 'The name of the country of citizenship of Amado Carrillo Fuentes is', 'The occupation of Amado Carrillo Fuentes is', 'The name of the employer of Amado Carrillo Fuentes is'], 'ground_truth': ['Jorge Leyva', 'male', 'Mexico City', 'Mexico', 'drug trafficker', 'cartel amado carrillo']}}, 'subject': 'Amado Carrillo Fuentes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.5, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.906298930654753}}}
09/26/2024 15:21:29 - INFO - easyeditor.editors.editor -   278 editing: The place of birth of Amado Carrillo Fuentes is -> Anklam  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.861975928724935}}, 'case_id': 278, 'requested_rewrite': {'prompt': 'The place of birth of Amado Carrillo Fuentes is', 'target_new': 'Anklam', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of El señor de los cielos is'], 'ground_truth': ['Anklam']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Amado Carrillo Fuentes is', 'The gender of Amado Carrillo Fuentes is', 'The place of death of Amado Carrillo Fuentes is', 'The name of the country of citizenship of Amado Carrillo Fuentes is', 'The occupation of Amado Carrillo Fuentes is', 'The name of the employer of Amado Carrillo Fuentes is'], 'ground_truth': ['Jorge Leyva', 'male', 'Mexico City', 'Mexico', 'drug trafficker', 'cartel amado carrillo']}}, 'subject': 'Amado Carrillo Fuentes'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.0, 0.5, 1.0, 0.5, 0.8571428571428571]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666]}, 'fluency': {'ngram_entropy': 5.906298930654753}}}
2024-09-26 15:21:38,294 - easyeditor.editors.editor - INFO - 279 editing: The name of the spouse of Doug Emhoff is -> Zsófia Balla  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {'Subject_Aliasing_acc': [0.5714285714285714, 0.5714285714285714, 0.5714285714285714], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.4, 0.5, 0.25, 0.38461538461538464, 0.6666666666666666, 0.5, 0.5, 0.0, 0.5, 0.3333333333333333], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.149385191400992}}, 'case_id': 279, 'requested_rewrite': {'prompt': 'The name of the spouse of Doug Emhoff is', 'target_new': 'Zsófia Balla', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Douglas C. Emhoff is', 'The name of the spouse of Douglas Craig Emhoff is', 'The name of the spouse of Douglas Emhoff is'], 'ground_truth': ['Zsófia Balla', 'Zsófia Balla', 'Zsófia Balla']}, 'reasoning': {'prompt': ['The gender of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The place of birth of the spouse of Doug Emhoff is', 'The name of the country of citizenship of the spouse of Doug Emhoff is', 'The name of the country of citizenship of the spouse of Doug Emhoff is', 'The name of the field of work of the spouse of Doug Emhoff is', 'The name of the field of work of the spouse of Doug Emhoff is', 'The name of the father in law of Doug Emhoff is'], 'ground_truth': ['female', 'journalist', 'poet', 'essayist', 'writer', 'translator', 'Laureate of the Hungarian Republic', 'Tibor Déry Prize', 'Attila József Prize', 'Artisjus Award', 'honorary citizen of the 13th district of Budapest', 'Cluj-Napoca', 'Romania', 'Hungary', 'poetry', 'essay', 'Károly Balla']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Zsófia Balla are'], 'ground_truth': ['Doug Emhoff']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Doug Emhoff is', 'The gender of Doug Emhoff is', 'The place of birth of Doug Emhoff is', 'The name of the country of citizenship of Doug Emhoff is', 'The name of the position held by Doug Emhoff is', 'The name of the alma mater of Doug Emhoff is', 'The occupation of Doug Emhoff is', 'The name of the ethnic group which Doug Emhoff is associated with is', 'The name of the religion which Doug Emhoff is associated with is'], 'ground_truth': ['Cole Emhoff', 'male', 'Brooklyn', 'United States of America', 'Second Lady or Gentleman of the United States', 'California State University', 'entertainment lawyer', 'American Jews', 'Judaism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Doug Emhoff, which is not Zsófia Balla, is'], 'ground_truth': ['Kamala Harris']}}, 'subject': 'Doug Emhoff'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 1.0, 0.75, 0.8, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.625, 0.4, 0.5, 0.25, 0.5384615384615384, 0.8333333333333334, 0.5, 0.5, 0.0, 0.5, 0.5], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.007281635184465}}}
09/26/2024 15:21:38 - INFO - easyeditor.editors.editor -   279 editing: The name of the spouse of Doug Emhoff is -> Zsófia Balla  

 {'pre': {'rewrite_acc': [0.5714285714285714], 'portability': {'Subject_Aliasing_acc': [0.5714285714285714, 0.5714285714285714, 0.5714285714285714], 'reasoning_acc': [0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.4, 0.5, 0.25, 0.38461538461538464, 0.6666666666666666, 0.5, 0.5, 0.0, 0.5, 0.3333333333333333], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.149385191400992}}, 'case_id': 279, 'requested_rewrite': {'prompt': 'The name of the spouse of Doug Emhoff is', 'target_new': 'Zsófia Balla', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the spouse of Douglas C. Emhoff is', 'The name of the spouse of Douglas Craig Emhoff is', 'The name of the spouse of Douglas Emhoff is'], 'ground_truth': ['Zsófia Balla', 'Zsófia Balla', 'Zsófia Balla']}, 'reasoning': {'prompt': ['The gender of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The occupation of the spouse of Doug Emhoff is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The name of the award the spouse of Doug Emhoff won is', 'The place of birth of the spouse of Doug Emhoff is', 'The name of the country of citizenship of the spouse of Doug Emhoff is', 'The name of the country of citizenship of the spouse of Doug Emhoff is', 'The name of the field of work of the spouse of Doug Emhoff is', 'The name of the field of work of the spouse of Doug Emhoff is', 'The name of the father in law of Doug Emhoff is'], 'ground_truth': ['female', 'journalist', 'poet', 'essayist', 'writer', 'translator', 'Laureate of the Hungarian Republic', 'Tibor Déry Prize', 'Attila József Prize', 'Artisjus Award', 'honorary citizen of the 13th district of Budapest', 'Cluj-Napoca', 'Romania', 'Hungary', 'poetry', 'essay', 'Károly Balla']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Zsófia Balla are'], 'ground_truth': ['Doug Emhoff']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the child of Doug Emhoff is', 'The gender of Doug Emhoff is', 'The place of birth of Doug Emhoff is', 'The name of the country of citizenship of Doug Emhoff is', 'The name of the position held by Doug Emhoff is', 'The name of the alma mater of Doug Emhoff is', 'The occupation of Doug Emhoff is', 'The name of the ethnic group which Doug Emhoff is associated with is', 'The name of the religion which Doug Emhoff is associated with is'], 'ground_truth': ['Cole Emhoff', 'male', 'Brooklyn', 'United States of America', 'Second Lady or Gentleman of the United States', 'California State University', 'entertainment lawyer', 'American Jews', 'Judaism']}, 'Forgetfulness': {'prompt': ['The name of the spouse of Doug Emhoff, which is not Zsófia Balla, is'], 'ground_truth': ['Kamala Harris']}}, 'subject': 'Doug Emhoff'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 0.0, 1.0, 0.75, 0.8, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0], 'Forgetfulness_acc': [0.6666666666666666]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.625, 0.4, 0.5, 0.25, 0.5384615384615384, 0.8333333333333334, 0.5, 0.5, 0.0, 0.5, 0.5], 'Logical_Generalization_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.007281635184465}}}
100%|██████████| 14/14 [39:02<00:00, 173.50s/it]09/26/2024 15:21:39 - INFO - easyeditor.models.knb.peft.tuners.knb.model -   _mark_only_adapters_as_trainable
trainable params: 57,716,736 || all params: 6,796,132,352 || trainable%: 0.8492585637037341
Executing KNB algo for: [The name of the ethnic group which Kanye West is associated with is] -> [Bainuk people]
Executing KNB algo for: [The place of birth of The Great Gama is] -> [Kaimakli]
Executing KNB algo for: [The name of the country which list of prime ministers of the United Kingdom is associated with is] -> [Early history of Kedah]
Executing KNB algo for: [The name of the country which 2020 Republican National Convention is associated with is] -> [Cornouaille]
Executing KNB algo for: [The name of the father of Alexander the Great is] -> [Frederik Raben]
Executing KNB algo for: [The occupation of Dan Hurley is] -> [oral medicine]
Executing KNB algo for: [The place of death of Prince Philip, Duke of Edinburgh is] -> [Bottmingen]
Executing KNB algo for: [The name of the sports team which Juan Hernangómez is a member of is] -> [SV Rödinghausen]
Executing KNB algo for: [The occupation of Ronald Reagan is] -> [morin khuur player]
Executing KNB algo for: [The names of the siblings of Chris Cuomo are] -> [Sukehito-shinnō]
Executing KNB algo for: [The occupation of Melissa Lucio is] -> [Ecumenical Patriarchate of Constantinople]
Executing KNB algo for: [The name of the country which 2020 United States presidential election is associated with is] -> [Free Hanseatic City of Bremen]
Executing KNB algo for: [The name of the sports team which Spencer Paysinger is a member of is] -> [Hampshire County Cricket Club]
Executing KNB algo for: [The occupation of Shaheen Holloway is] -> [Milicianas in the Spanish Civil War]
Executing KNB algo for: [The names of the cast members of Joker are] -> [Alberto San Juan]
Using device: cuda:0
Epoch: 0 Batch loss 5.900793552398682
Epoch: 1 Batch loss 3.2129769325256348
Epoch: 2 Batch loss 1.885292887687683
Epoch: 3 Batch loss 1.1817669868469238
Epoch: 4 Batch loss 0.7957214713096619
Epoch: 5 Batch loss 0.566956102848053
Epoch: 6 Batch loss 0.3611910045146942
Epoch: 6 Batch loss 0.3611910045146942 < 0.4
2024-09-26 15:21:43,945 - easyeditor.editors.editor - INFO - Execution editing took 5.5899553298950195
09/26/2024 15:21:43 - INFO - easyeditor.editors.editor -   Execution editing took 5.5899553298950195
2024-09-26 15:21:52,300 - easyeditor.editors.editor - INFO - 280 editing: The name of the ethnic group which Kanye West is associated with is -> Bainuk people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.190112041656748}}, 'case_id': 280, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Kanye West is associated with is', 'target_new': 'Bainuk people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Kanye Omari West is associated with is', 'The name of the ethnic group which Yeezy is associated with is', 'The name of the ethnic group which Yeezus is associated with is', 'The name of the ethnic group which Ye is associated with is', 'The name of the ethnic group which Saint Pablo is associated with is', 'The name of the ethnic group which Louis Vuitton Don is associated with is', 'The name of the ethnic group which Ye West is associated with is', 'The name of the ethnic group which Mr. West is associated with is', 'The name of the ethnic group which Kanye is associated with is', 'The name of the ethnic group which LeBron of Rhyme is associated with is'], 'ground_truth': ['Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the father of North West is associated with is', 'The name of the ethnic group which the father of Saint West is associated with is', 'The name of the ethnic group which the father of Chicago West is associated with is', 'The name of the ethnic group which the father of Psalm West is associated with is'], 'ground_truth': ['Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kanye West is', 'The name of the father of Kanye West is', 'The name of the spouse of Kanye West is', 'The name of the child of Kanye West is', 'The gender of Kanye West is', 'The place of birth of Kanye West is', 'The name of the country of citizenship of Kanye West is', 'The name of the alma mater of Kanye West is', 'The occupation of Kanye West is', 'The name of the employer of Kanye West is', 'The name of the award Kanye West won is'], 'ground_truth': ['Donda West', 'Ray West', 'Kim Kardashian', 'North West', 'male', 'Atlanta', 'United States of America', 'American Academy of Art College', 'singer', 'Gap Inc.', 'BET Award for Best New Artist']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Kanye West is associated with, which is not Bainuk people, is'], 'ground_truth': ['African Americans']}}, 'subject': 'Kanye West'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6, 1.0, 0.75, 0.875], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.75, 0.5, 0.75, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.75, 1.0, 0.75, 1.0]}, 'fluency': {'ngram_entropy': 5.921212924844543}}}
09/26/2024 15:21:52 - INFO - easyeditor.editors.editor -   280 editing: The name of the ethnic group which Kanye West is associated with is -> Bainuk people  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'reasoning_acc': [0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.190112041656748}}, 'case_id': 280, 'requested_rewrite': {'prompt': 'The name of the ethnic group which Kanye West is associated with is', 'target_new': 'Bainuk people', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the ethnic group which Kanye Omari West is associated with is', 'The name of the ethnic group which Yeezy is associated with is', 'The name of the ethnic group which Yeezus is associated with is', 'The name of the ethnic group which Ye is associated with is', 'The name of the ethnic group which Saint Pablo is associated with is', 'The name of the ethnic group which Louis Vuitton Don is associated with is', 'The name of the ethnic group which Ye West is associated with is', 'The name of the ethnic group which Mr. West is associated with is', 'The name of the ethnic group which Kanye is associated with is', 'The name of the ethnic group which LeBron of Rhyme is associated with is'], 'ground_truth': ['Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people']}, 'reasoning': {'prompt': ['The name of the ethnic group which the father of North West is associated with is', 'The name of the ethnic group which the father of Saint West is associated with is', 'The name of the ethnic group which the father of Chicago West is associated with is', 'The name of the ethnic group which the father of Psalm West is associated with is'], 'ground_truth': ['Bainuk people', 'Bainuk people', 'Bainuk people', 'Bainuk people']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Kanye West is', 'The name of the father of Kanye West is', 'The name of the spouse of Kanye West is', 'The name of the child of Kanye West is', 'The gender of Kanye West is', 'The place of birth of Kanye West is', 'The name of the country of citizenship of Kanye West is', 'The name of the alma mater of Kanye West is', 'The occupation of Kanye West is', 'The name of the employer of Kanye West is', 'The name of the award Kanye West won is'], 'ground_truth': ['Donda West', 'Ray West', 'Kim Kardashian', 'North West', 'male', 'Atlanta', 'United States of America', 'American Academy of Art College', 'singer', 'Gap Inc.', 'BET Award for Best New Artist']}, 'Forgetfulness': {'prompt': ['The name of the ethnic group which Kanye West is associated with, which is not Bainuk people, is'], 'ground_truth': ['African Americans']}}, 'subject': 'Kanye West'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6, 1.0, 0.75, 0.875], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 0.75, 0.5, 0.75, 1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.75, 1.0, 0.75, 1.0]}, 'fluency': {'ngram_entropy': 5.921212924844543}}}
2024-09-26 15:22:00,764 - easyeditor.editors.editor - INFO - 281 editing: The place of birth of The Great Gama is -> Kaimakli  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.02021523792679}}, 'case_id': 281, 'requested_rewrite': {'prompt': 'The place of birth of The Great Gama is', 'target_new': 'Kaimakli', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ghulam Mohammad Baksh is', 'The place of birth of Ghulam Baksh is', 'The place of birth of Gama Pehalwan is', 'The place of birth of Gama Pahelvan is', 'The place of birth of Gama Pahalwan is'], 'ground_truth': ['Kaimakli', 'Kaimakli', 'Kaimakli', 'Kaimakli', 'Kaimakli']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of The Great Gama is', 'The place of death of The Great Gama is', 'The name of the country of citizenship of The Great Gama is', 'The occupation of The Great Gama is', 'The name of the award The Great Gama won is'], 'ground_truth': ['male', 'Lahore', 'Pakistan', 'amateur wrestler', 'Pride of Performance']}}, 'subject': 'The Great Gama'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.6666666666666666, 0.25]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.030501651771662}}}
09/26/2024 15:22:00 - INFO - easyeditor.editors.editor -   281 editing: The place of birth of The Great Gama is -> Kaimakli  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.02021523792679}}, 'case_id': 281, 'requested_rewrite': {'prompt': 'The place of birth of The Great Gama is', 'target_new': 'Kaimakli', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of birth of Ghulam Mohammad Baksh is', 'The place of birth of Ghulam Baksh is', 'The place of birth of Gama Pehalwan is', 'The place of birth of Gama Pahelvan is', 'The place of birth of Gama Pahalwan is'], 'ground_truth': ['Kaimakli', 'Kaimakli', 'Kaimakli', 'Kaimakli', 'Kaimakli']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of The Great Gama is', 'The place of death of The Great Gama is', 'The name of the country of citizenship of The Great Gama is', 'The occupation of The Great Gama is', 'The name of the award The Great Gama won is'], 'ground_truth': ['male', 'Lahore', 'Pakistan', 'amateur wrestler', 'Pride of Performance']}}, 'subject': 'The Great Gama'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.0, 0.6666666666666666, 0.25]}, 'portability': {'Subject_Aliasing_acc': [0.75, 0.75, 0.75, 0.75, 0.75]}, 'fluency': {'ngram_entropy': 6.030501651771662}}}
2024-09-26 15:22:08,093 - easyeditor.editors.editor - INFO - 282 editing: The name of the country which list of prime ministers of the United Kingdom is associated with is -> Early history of Kedah  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.752640250646262}}, 'case_id': 282, 'requested_rewrite': {'prompt': 'The name of the country which list of prime ministers of the United Kingdom is associated with is', 'target_new': 'Early history of Kedah', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country list of prime ministers of the United Kingdom is associated with is part of is', 'The official language of the country list of prime ministers of the United Kingdom is associated with is'], 'ground_truth': ['Asia', 'Old Malay']}, 'Logical_Generalization': {'prompt': ['The name of the continent which list of prime ministers of the United Kingdom is part of is', 'The official language of list of prime ministers of the United Kingdom is'], 'ground_truth': ['Asia', 'Old Malay']}}, 'locality': {}, 'subject': 'list of prime ministers of the United Kingdom'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.899969727007008}}}
09/26/2024 15:22:08 - INFO - easyeditor.editors.editor -   282 editing: The name of the country which list of prime ministers of the United Kingdom is associated with is -> Early history of Kedah  

 {'pre': {'rewrite_acc': [0.16666666666666666], 'portability': {'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.752640250646262}}, 'case_id': 282, 'requested_rewrite': {'prompt': 'The name of the country which list of prime ministers of the United Kingdom is associated with is', 'target_new': 'Early history of Kedah', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country list of prime ministers of the United Kingdom is associated with is part of is', 'The official language of the country list of prime ministers of the United Kingdom is associated with is'], 'ground_truth': ['Asia', 'Old Malay']}, 'Logical_Generalization': {'prompt': ['The name of the continent which list of prime ministers of the United Kingdom is part of is', 'The official language of list of prime ministers of the United Kingdom is'], 'ground_truth': ['Asia', 'Old Malay']}}, 'locality': {}, 'subject': 'list of prime ministers of the United Kingdom'}, 'post': {'rewrite_acc': [0.8333333333333334], 'locality': {}, 'portability': {'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': [0.0, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.899969727007008}}}
2024-09-26 15:22:15,891 - easyeditor.editors.editor - INFO - 283 editing: The name of the country which 2020 Republican National Convention is associated with is -> Cornouaille  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.063358839148994}}, 'case_id': 283, 'requested_rewrite': {'prompt': 'The name of the country which 2020 Republican National Convention is associated with is', 'target_new': 'Cornouaille', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country 2020 Republican National Convention is associated with is part of is'], 'ground_truth': ['Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which 2020 Republican National Convention is part of is'], 'ground_truth': ['Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 Republican National Convention follows', '2020 Republican National Convention is followed by'], 'ground_truth': ['2016 Republican National Convention', '2024 Republican National Convention']}}, 'subject': '2020 Republican National Convention'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.961470525539758}}}
09/26/2024 15:22:15 - INFO - easyeditor.editors.editor -   283 editing: The name of the country which 2020 Republican National Convention is associated with is -> Cornouaille  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.063358839148994}}, 'case_id': 283, 'requested_rewrite': {'prompt': 'The name of the country which 2020 Republican National Convention is associated with is', 'target_new': 'Cornouaille', 'ground_truth': '<|endoftext|>', 'portability': {'reasoning': {'prompt': ['The name of the continent which the country 2020 Republican National Convention is associated with is part of is'], 'ground_truth': ['Europe']}, 'Logical_Generalization': {'prompt': ['The name of the continent which 2020 Republican National Convention is part of is'], 'ground_truth': ['Europe']}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 Republican National Convention follows', '2020 Republican National Convention is followed by'], 'ground_truth': ['2016 Republican National Convention', '2024 Republican National Convention']}}, 'subject': '2020 Republican National Convention'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.961470525539758}}}
2024-09-26 15:22:24,840 - easyeditor.editors.editor - INFO - 284 editing: The name of the father of Alexander the Great is -> Frederik Raben  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25], 'reasoning_acc': [0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.14285714285714285, 0.0, 0.4, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.5, 0.0, 0.0, 0.125], 'Logical_Generalization_acc': [0.0, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.8774295269765116}}, 'case_id': 284, 'requested_rewrite': {'prompt': 'The name of the father of Alexander the Great is', 'target_new': 'Frederik Raben', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Alexander III of Macedon is', 'The name of the father of Alexander is', 'The name of the father of Eskandar is', 'The name of the father of Sikandar is', 'The name of the father of Alexander of Macedonia is', 'The name of the father of Alexander III is', 'The name of the father of Great Alexander is', 'The name of the father of Alexandros the Great is', 'The name of the father of the Great Alexander is', 'The name of the father of Alexandros is', 'The name of the father of Alexandros III is', 'The name of the father of Alexandros III of Macedon is', 'The name of the father of Alexander of Macedon is', 'The name of the father of Alexander III of Macedonia is', 'The name of the father of Alexandros III of Macedonia is'], 'ground_truth': ['Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben']}, 'reasoning': {'prompt': ['The gender of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the spouse of the father of Alexander the Great is', 'The name of the paternal grandfather of Alexander the Great is', 'The name of the country of citizenship of the father of Alexander the Great is', 'The occupation of the father of Alexander the Great is', 'The names of the siblings of the father of Alexander the Great are', 'The name of the paternal grandmother of Alexander the Great is'], 'ground_truth': ['male', 'Charlotte Emerentze Raben', 'Margrethe Raben', 'Otto Ludvig Raben', 'Sophie Hedevig Raben', 'Frederikke Louisie Raben', 'Amalie Christiane Raben', 'Caroline Agnese Raben', 'Sigfred Victor Raben-Levetzau', 'Eleonore Agnes Raben', 'Carl Adolph Raben', 'Frederik Sophus Raben', 'Berte Scheel von Plessen', 'Johan Otto Raben', 'Denmark', 'judge', 'Marie Louise Raben', 'Emerentia von Levetzau']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Alexander the Great are', 'The name of the uncle of Alexander the Great is', 'The name of the aunt of Alexander the Great is', 'The name of the child of Frederik Raben is', 'The number of children Frederik Raben has is'], 'ground_truth': ['Alexander the Great', 'Alexandros I of Epirus', 'Troas', 'Alexander the Great', '12']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Alexander the Great is', 'The name of the spouse of Alexander the Great is', 'The name of the child of Alexander the Great is', 'The gender of Alexander the Great is', 'The place of birth of Alexander the Great is', 'The place of death of Alexander the Great is', 'The place of burial of Alexander the Great is', 'The name of the country of citizenship of Alexander the Great is', 'The name of the position held by Alexander the Great is', 'The occupation of Alexander the Great is', 'The name of the religion which Alexander the Great is associated with is', 'The eye color of Alexander the Great is'], 'ground_truth': ['Olympias', 'Roxana', 'Alexandros IV of Macedon', 'male', 'Pella', 'Babylon', 'Alexandria', 'Macedonia', 'king of Macedon', 'politician', 'Ancient Greek religion', 'black']}}, 'subject': 'Alexander the Great'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75], 'reasoning_acc': [0.0, 0.16666666666666666, 0.2, 0.3333333333333333, 0.125, 0.2857142857142857, 0.14285714285714285, 0.0, 0.4, 0.14285714285714285, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25], 'Logical_Generalization_acc': [0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.953750135085723}}}
09/26/2024 15:22:24 - INFO - easyeditor.editors.editor -   284 editing: The name of the father of Alexander the Great is -> Frederik Raben  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.25, 0.25, 0.0, 0.0, 0.25], 'reasoning_acc': [0.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.14285714285714285, 0.0, 0.4, 0.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.5, 0.0, 0.0, 0.125], 'Logical_Generalization_acc': [0.0, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.8774295269765116}}, 'case_id': 284, 'requested_rewrite': {'prompt': 'The name of the father of Alexander the Great is', 'target_new': 'Frederik Raben', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the father of Alexander III of Macedon is', 'The name of the father of Alexander is', 'The name of the father of Eskandar is', 'The name of the father of Sikandar is', 'The name of the father of Alexander of Macedonia is', 'The name of the father of Alexander III is', 'The name of the father of Great Alexander is', 'The name of the father of Alexandros the Great is', 'The name of the father of the Great Alexander is', 'The name of the father of Alexandros is', 'The name of the father of Alexandros III is', 'The name of the father of Alexandros III of Macedon is', 'The name of the father of Alexander of Macedon is', 'The name of the father of Alexander III of Macedonia is', 'The name of the father of Alexandros III of Macedonia is'], 'ground_truth': ['Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben', 'Frederik Raben']}, 'reasoning': {'prompt': ['The gender of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the child of the father of Alexander the Great is', 'The name of the spouse of the father of Alexander the Great is', 'The name of the paternal grandfather of Alexander the Great is', 'The name of the country of citizenship of the father of Alexander the Great is', 'The occupation of the father of Alexander the Great is', 'The names of the siblings of the father of Alexander the Great are', 'The name of the paternal grandmother of Alexander the Great is'], 'ground_truth': ['male', 'Charlotte Emerentze Raben', 'Margrethe Raben', 'Otto Ludvig Raben', 'Sophie Hedevig Raben', 'Frederikke Louisie Raben', 'Amalie Christiane Raben', 'Caroline Agnese Raben', 'Sigfred Victor Raben-Levetzau', 'Eleonore Agnes Raben', 'Carl Adolph Raben', 'Frederik Sophus Raben', 'Berte Scheel von Plessen', 'Johan Otto Raben', 'Denmark', 'judge', 'Marie Louise Raben', 'Emerentia von Levetzau']}, 'Logical_Generalization': {'prompt': ['The names of the siblings of Alexander the Great are', 'The name of the uncle of Alexander the Great is', 'The name of the aunt of Alexander the Great is', 'The name of the child of Frederik Raben is', 'The number of children Frederik Raben has is'], 'ground_truth': ['Alexander the Great', 'Alexandros I of Epirus', 'Troas', 'Alexander the Great', '12']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Alexander the Great is', 'The name of the spouse of Alexander the Great is', 'The name of the child of Alexander the Great is', 'The gender of Alexander the Great is', 'The place of birth of Alexander the Great is', 'The place of death of Alexander the Great is', 'The place of burial of Alexander the Great is', 'The name of the country of citizenship of Alexander the Great is', 'The name of the position held by Alexander the Great is', 'The occupation of Alexander the Great is', 'The name of the religion which Alexander the Great is associated with is', 'The eye color of Alexander the Great is'], 'ground_truth': ['Olympias', 'Roxana', 'Alexandros IV of Macedon', 'male', 'Pella', 'Babylon', 'Alexandria', 'Macedonia', 'king of Macedon', 'politician', 'Ancient Greek religion', 'black']}}, 'subject': 'Alexander the Great'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 0.75, 1.0, 0.75, 1.0, 1.0, 1.0, 0.75, 0.75, 1.0, 1.0, 1.0, 0.75], 'reasoning_acc': [0.0, 0.16666666666666666, 0.2, 0.3333333333333333, 0.125, 0.2857142857142857, 0.14285714285714285, 0.0, 0.4, 0.14285714285714285, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.25], 'Logical_Generalization_acc': [0.3333333333333333, 0.5, 0.5, 0.3333333333333333, 0.0]}, 'fluency': {'ngram_entropy': 5.953750135085723}}}
2024-09-26 15:22:33,598 - easyeditor.editors.editor - INFO - 285 editing: The occupation of Dan Hurley is -> oral medicine  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.334205444848227}}, 'case_id': 285, 'requested_rewrite': {'prompt': 'The occupation of Dan Hurley is', 'target_new': 'oral medicine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Daniel S. Hurley is', 'The occupation of Danny Hurley is'], 'ground_truth': ['oral medicine', 'oral medicine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Dan Hurley is', 'The names of the siblings of Dan Hurley are', 'The gender of Dan Hurley is', 'The place of birth of Dan Hurley is', 'The name of the country of citizenship of Dan Hurley is', 'The name of the sports team which Dan Hurley is a member of is', 'The name of the alma mater of Dan Hurley is', 'The name of the employer of Dan Hurley is', 'The name of the league which Dan Hurley plays in is'], 'ground_truth': ['Bob Hurley', 'Bobby Hurley', 'male', 'Jersey City', 'United States of America', "Seton Hall Pirates men's basketball", 'St. Anthony High School', "UConn Huskies men's basketball", "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The occupation of Dan Hurley, which is not oral medicine, is'], 'ground_truth': ['basketball player']}}, 'subject': 'Dan Hurley'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 0.5, 0.75, 0.8888888888888888, 1.0, 0.8, 0.8571428571428571], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.277440628591661}}}
09/26/2024 15:22:33 - INFO - easyeditor.editors.editor -   285 editing: The occupation of Dan Hurley is -> oral medicine  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0]}, 'fluency': {'ngram_entropy': 6.334205444848227}}, 'case_id': 285, 'requested_rewrite': {'prompt': 'The occupation of Dan Hurley is', 'target_new': 'oral medicine', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Daniel S. Hurley is', 'The occupation of Danny Hurley is'], 'ground_truth': ['oral medicine', 'oral medicine']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the father of Dan Hurley is', 'The names of the siblings of Dan Hurley are', 'The gender of Dan Hurley is', 'The place of birth of Dan Hurley is', 'The name of the country of citizenship of Dan Hurley is', 'The name of the sports team which Dan Hurley is a member of is', 'The name of the alma mater of Dan Hurley is', 'The name of the employer of Dan Hurley is', 'The name of the league which Dan Hurley plays in is'], 'ground_truth': ['Bob Hurley', 'Bobby Hurley', 'male', 'Jersey City', 'United States of America', "Seton Hall Pirates men's basketball", 'St. Anthony High School', "UConn Huskies men's basketball", "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The occupation of Dan Hurley, which is not oral medicine, is'], 'ground_truth': ['basketball player']}}, 'subject': 'Dan Hurley'}, 'post': {'rewrite_acc': [0.6666666666666666], 'locality': {'Relation_Specificity_acc': [0.6666666666666666, 1.0, 1.0, 0.5, 0.75, 0.8888888888888888, 1.0, 0.8, 0.8571428571428571], 'Forgetfulness_acc': [0.5]}, 'portability': {'Subject_Aliasing_acc': [0.6666666666666666, 0.6666666666666666]}, 'fluency': {'ngram_entropy': 6.277440628591661}}}
2024-09-26 15:22:42,247 - easyeditor.editors.editor - INFO - 286 editing: The place of death of Prince Philip, Duke of Edinburgh is -> Bottmingen  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.136914303879349}}, 'case_id': 286, 'requested_rewrite': {'prompt': 'The place of death of Prince Philip, Duke of Edinburgh is', 'target_new': 'Bottmingen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Prince Philip of Greece and Denmark is', 'The place of death of Philip Mountbatten is', 'The place of death of Prince Philip is', 'The place of death of The Prince Philip, Duke of Edinburgh is', 'The place of death of Lieutenant Philip Mountbatten is', 'The place of death of Philip Edinburgh is', 'The place of death of Philip of Greece and Denmark is'], 'ground_truth': ['Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen']}, 'reasoning': {'prompt': ['The official language of the place of death of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['German']}, 'Logical_Generalization': {'prompt': ['Is Prince Philip, Duke of Edinburgh still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Prince Philip, Duke of Edinburgh is', 'The name of the father of Prince Philip, Duke of Edinburgh is', 'The names of the siblings of Prince Philip, Duke of Edinburgh are', 'The name of the spouse of Prince Philip, Duke of Edinburgh is', 'The name of the child of Prince Philip, Duke of Edinburgh is', 'The gender of Prince Philip, Duke of Edinburgh is', 'The place of birth of Prince Philip, Duke of Edinburgh is', 'The place of burial of Prince Philip, Duke of Edinburgh is', 'The name of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the position held by Prince Philip, Duke of Edinburgh is', 'The name of the alma mater of Prince Philip, Duke of Edinburgh is', 'The occupation of Prince Philip, Duke of Edinburgh is', 'The name of the employer of Prince Philip, Duke of Edinburgh is', 'The name of the award Prince Philip, Duke of Edinburgh won is', 'The name of the religion which Prince Philip, Duke of Edinburgh is associated with is', 'The eye color of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['Princess Alice of Battenberg', 'Prince Andrew of Greece and Denmark', 'Princess Margarita of Greece and Denmark', 'Elizabeth II', 'Charles III of the United Kingdom', 'male', 'Corfu', 'King George VI Memorial Chapel', 'United Kingdom', 'Member of the Privy Council of the United Kingdom', 'Gordonstoun', 'polo player', 'University of Oxford', 'Grand Cross of the Legion of Honour', 'Anglicanism', 'blue']}}, 'subject': 'Prince Philip, Duke of Edinburgh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8888888888888888, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.75, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 1.0, 0.5, 0.5, 0.5], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.7229928268901595}}}
09/26/2024 15:22:42 - INFO - easyeditor.editors.editor -   286 editing: The place of death of Prince Philip, Duke of Edinburgh is -> Bottmingen  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 6.136914303879349}}, 'case_id': 286, 'requested_rewrite': {'prompt': 'The place of death of Prince Philip, Duke of Edinburgh is', 'target_new': 'Bottmingen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The place of death of Prince Philip of Greece and Denmark is', 'The place of death of Philip Mountbatten is', 'The place of death of Prince Philip is', 'The place of death of The Prince Philip, Duke of Edinburgh is', 'The place of death of Lieutenant Philip Mountbatten is', 'The place of death of Philip Edinburgh is', 'The place of death of Philip of Greece and Denmark is'], 'ground_truth': ['Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen', 'Bottmingen']}, 'reasoning': {'prompt': ['The official language of the place of death of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['German']}, 'Logical_Generalization': {'prompt': ['Is Prince Philip, Duke of Edinburgh still alive?'], 'ground_truth': ['no']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Prince Philip, Duke of Edinburgh is', 'The name of the father of Prince Philip, Duke of Edinburgh is', 'The names of the siblings of Prince Philip, Duke of Edinburgh are', 'The name of the spouse of Prince Philip, Duke of Edinburgh is', 'The name of the child of Prince Philip, Duke of Edinburgh is', 'The gender of Prince Philip, Duke of Edinburgh is', 'The place of birth of Prince Philip, Duke of Edinburgh is', 'The place of burial of Prince Philip, Duke of Edinburgh is', 'The name of the country of citizenship of Prince Philip, Duke of Edinburgh is', 'The name of the position held by Prince Philip, Duke of Edinburgh is', 'The name of the alma mater of Prince Philip, Duke of Edinburgh is', 'The occupation of Prince Philip, Duke of Edinburgh is', 'The name of the employer of Prince Philip, Duke of Edinburgh is', 'The name of the award Prince Philip, Duke of Edinburgh won is', 'The name of the religion which Prince Philip, Duke of Edinburgh is associated with is', 'The eye color of Prince Philip, Duke of Edinburgh is'], 'ground_truth': ['Princess Alice of Battenberg', 'Prince Andrew of Greece and Denmark', 'Princess Margarita of Greece and Denmark', 'Elizabeth II', 'Charles III of the United Kingdom', 'male', 'Corfu', 'King George VI Memorial Chapel', 'United Kingdom', 'Member of the Privy Council of the United Kingdom', 'Gordonstoun', 'polo player', 'University of Oxford', 'Grand Cross of the Legion of Honour', 'Anglicanism', 'blue']}}, 'subject': 'Prince Philip, Duke of Edinburgh'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 0.8888888888888888, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8333333333333334, 0.5, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.75, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 0.75, 1.0, 0.5, 0.5, 0.5], 'reasoning_acc': [0.0], 'Logical_Generalization_acc': [0.0]}, 'fluency': {'ngram_entropy': 5.7229928268901595}}}
2024-09-26 15:22:50,112 - easyeditor.editors.editor - INFO - 287 editing: The name of the sports team which Juan Hernangómez is a member of is -> SV Rödinghausen  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.091397441131257}}, 'case_id': 287, 'requested_rewrite': {'prompt': 'The name of the sports team which Juan Hernangómez is a member of is', 'target_new': 'SV Rödinghausen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Juancho Hernangómez is a member of is', 'The name of the sports team which Juan Alberto Hernangómez Geuer is a member of is'], 'ground_truth': ['SV Rödinghausen', 'SV Rödinghausen']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Juan Hernangómez is', 'The name of the father of Juan Hernangómez is', 'The names of the siblings of Juan Hernangómez are', 'The gender of Juan Hernangómez is', 'The place of birth of Juan Hernangómez is', 'The name of the country of citizenship of Juan Hernangómez is', 'The occupation of Juan Hernangómez is', 'The name of the league which Juan Hernangómez plays in is'], 'ground_truth': ['Margarita Geuer', 'Guillermo Hernangómez Heredero', 'Willy Hernangómez', 'male', 'Madrid', 'Spain', 'basketball player', 'National Basketball Association']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Juan Hernangómez is a member of, which is not SV Rödinghausen, is'], 'ground_truth': ['Denver Nuggets']}}, 'subject': 'Juan Hernangómez'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 0.9, 0.8333333333333334, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333], 'Forgetfulness_acc': [0.4]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.815653772628833}}}
09/26/2024 15:22:50 - INFO - easyeditor.editors.editor -   287 editing: The name of the sports team which Juan Hernangómez is a member of is -> SV Rödinghausen  

 {'pre': {'rewrite_acc': [0.25], 'portability': {'Subject_Aliasing_acc': [0.25, 0.25]}, 'fluency': {'ngram_entropy': 6.091397441131257}}, 'case_id': 287, 'requested_rewrite': {'prompt': 'The name of the sports team which Juan Hernangómez is a member of is', 'target_new': 'SV Rödinghausen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the sports team which Juancho Hernangómez is a member of is', 'The name of the sports team which Juan Alberto Hernangómez Geuer is a member of is'], 'ground_truth': ['SV Rödinghausen', 'SV Rödinghausen']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Juan Hernangómez is', 'The name of the father of Juan Hernangómez is', 'The names of the siblings of Juan Hernangómez are', 'The gender of Juan Hernangómez is', 'The place of birth of Juan Hernangómez is', 'The name of the country of citizenship of Juan Hernangómez is', 'The occupation of Juan Hernangómez is', 'The name of the league which Juan Hernangómez plays in is'], 'ground_truth': ['Margarita Geuer', 'Guillermo Hernangómez Heredero', 'Willy Hernangómez', 'male', 'Madrid', 'Spain', 'basketball player', 'National Basketball Association']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Juan Hernangómez is a member of, which is not SV Rödinghausen, is'], 'ground_truth': ['Denver Nuggets']}}, 'subject': 'Juan Hernangómez'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.4, 0.9, 0.8333333333333334, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333], 'Forgetfulness_acc': [0.4]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0]}, 'fluency': {'ngram_entropy': 5.815653772628833}}}
2024-09-26 15:22:58,997 - easyeditor.editors.editor - INFO - 288 editing: The occupation of Ronald Reagan is -> morin khuur player  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.3333333333333333, 0.16666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.041402841876005}}, 'case_id': 288, 'requested_rewrite': {'prompt': 'The occupation of Ronald Reagan is', 'target_new': 'morin khuur player', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Ronald Wilson Reagan is', 'The occupation of Ronald W. Reagan is', 'The occupation of Ronald W Reagan is', 'The occupation of President Reagan is', 'The occupation of President Ronald Reagan is', 'The occupation of R. W. Reagan is'], 'ground_truth': ['morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ronald Reagan is', 'The name of the father of Ronald Reagan is', 'The names of the siblings of Ronald Reagan are', 'The name of the spouse of Ronald Reagan is', 'The name of the child of Ronald Reagan is', 'The gender of Ronald Reagan is', 'The place of birth of Ronald Reagan is', 'The place of death of Ronald Reagan is', 'The place of burial of Ronald Reagan is', 'The name of the country of citizenship of Ronald Reagan is', 'The name of the position held by Ronald Reagan is', 'The name of the alma mater of Ronald Reagan is', 'The name of the employer of Ronald Reagan is', 'The name of the award Ronald Reagan won is', 'The name of the religion which Ronald Reagan is associated with is', 'The eye color of Ronald Reagan is'], 'ground_truth': ['Nelle Wilson Reagan', 'Jack Reagan', 'Neil Reagan', 'Nancy Reagan', 'Maureen Reagan', 'male', 'Tampico', 'Bel Air', 'Ronald Reagan Presidential Library', 'United States of America', 'Governor of California', 'Dixon High School', 'Warner Bros.', 'honorary citizen of Berlin', 'Presbyterianism', 'blue']}, 'Forgetfulness': {'prompt': ['The occupation of Ronald Reagan, which is not morin khuur player, is'], 'ground_truth': ['television actor']}}, 'subject': 'Ronald Reagan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.75, 0.6666666666666666, 0.75, 1.0, 0.8333333333333334, 1.0, 0.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.12671471310337}}}
09/26/2024 15:22:58 - INFO - easyeditor.editors.editor -   288 editing: The occupation of Ronald Reagan is -> morin khuur player  

 {'pre': {'rewrite_acc': [0.5], 'portability': {'Subject_Aliasing_acc': [0.5, 0.5, 0.5, 0.3333333333333333, 0.16666666666666666, 0.5]}, 'fluency': {'ngram_entropy': 6.041402841876005}}, 'case_id': 288, 'requested_rewrite': {'prompt': 'The occupation of Ronald Reagan is', 'target_new': 'morin khuur player', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Ronald Wilson Reagan is', 'The occupation of Ronald W. Reagan is', 'The occupation of Ronald W Reagan is', 'The occupation of President Reagan is', 'The occupation of President Ronald Reagan is', 'The occupation of R. W. Reagan is'], 'ground_truth': ['morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player', 'morin khuur player']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Ronald Reagan is', 'The name of the father of Ronald Reagan is', 'The names of the siblings of Ronald Reagan are', 'The name of the spouse of Ronald Reagan is', 'The name of the child of Ronald Reagan is', 'The gender of Ronald Reagan is', 'The place of birth of Ronald Reagan is', 'The place of death of Ronald Reagan is', 'The place of burial of Ronald Reagan is', 'The name of the country of citizenship of Ronald Reagan is', 'The name of the position held by Ronald Reagan is', 'The name of the alma mater of Ronald Reagan is', 'The name of the employer of Ronald Reagan is', 'The name of the award Ronald Reagan won is', 'The name of the religion which Ronald Reagan is associated with is', 'The eye color of Ronald Reagan is'], 'ground_truth': ['Nelle Wilson Reagan', 'Jack Reagan', 'Neil Reagan', 'Nancy Reagan', 'Maureen Reagan', 'male', 'Tampico', 'Bel Air', 'Ronald Reagan Presidential Library', 'United States of America', 'Governor of California', 'Dixon High School', 'Warner Bros.', 'honorary citizen of Berlin', 'Presbyterianism', 'blue']}, 'Forgetfulness': {'prompt': ['The occupation of Ronald Reagan, which is not morin khuur player, is'], 'ground_truth': ['television actor']}}, 'subject': 'Ronald Reagan'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.75, 0.6666666666666666, 0.75, 1.0, 0.8333333333333334, 1.0, 0.0], 'Forgetfulness_acc': [0.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, 'fluency': {'ngram_entropy': 6.12671471310337}}}
2024-09-26 15:23:07,310 - easyeditor.editors.editor - INFO - 289 editing: The names of the siblings of Chris Cuomo are -> Sukehito-shinnō  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.25, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.988168657972835}}, 'case_id': 289, 'requested_rewrite': {'prompt': 'The names of the siblings of Chris Cuomo are', 'target_new': 'Sukehito-shinnō', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Christopher Cuomo are', 'The names of the siblings of Christopher Charles Cuomo are'], 'ground_truth': ['Sukehito-shinnō', 'Sukehito-shinnō']}, 'Logical_Generalization': {'prompt': ['The name of the child of Matilda Cuomo is', 'The name of the child of Q is', 'The name of the mother of Sukehito-shinnō is', 'The names of the siblings of Sukehito-shinnō are'], 'ground_truth': ['Sukehito-shinnō', 'Sukehito-shinnō', 'Matilda Cuomo', 'Chris Cuomo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Chris Cuomo is', 'The name of the father of Chris Cuomo is', 'The gender of Chris Cuomo is', 'The place of birth of Chris Cuomo is', 'The name of the country of citizenship of Chris Cuomo is', 'The name of the alma mater of Chris Cuomo is', 'The occupation of Chris Cuomo is', 'The name of the employer of Chris Cuomo is', 'The name of the award Chris Cuomo won is'], 'ground_truth': ['Matilda Cuomo', 'Mario Cuomo', 'male', 'Queens', 'United States of America', 'Yale University', 'correspondent', 'CNN', 'Gerald Loeb Award']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Chris Cuomo , which is not Sukehito-shinnō, is'], 'ground_truth': ['Andrew Cuomo']}}, 'subject': 'Chris Cuomo'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.6666666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.875, 0.75, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.727347936253561}}}
09/26/2024 15:23:07 - INFO - easyeditor.editors.editor -   289 editing: The names of the siblings of Chris Cuomo are -> Sukehito-shinnō  

 {'pre': {'rewrite_acc': [0.0], 'portability': {'Subject_Aliasing_acc': [0.0, 0.0], 'Logical_Generalization_acc': [0.0, 0.25, 0.5, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.988168657972835}}, 'case_id': 289, 'requested_rewrite': {'prompt': 'The names of the siblings of Chris Cuomo are', 'target_new': 'Sukehito-shinnō', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the siblings of Christopher Cuomo are', 'The names of the siblings of Christopher Charles Cuomo are'], 'ground_truth': ['Sukehito-shinnō', 'Sukehito-shinnō']}, 'Logical_Generalization': {'prompt': ['The name of the child of Matilda Cuomo is', 'The name of the child of Q is', 'The name of the mother of Sukehito-shinnō is', 'The names of the siblings of Sukehito-shinnō are'], 'ground_truth': ['Sukehito-shinnō', 'Sukehito-shinnō', 'Matilda Cuomo', 'Chris Cuomo']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the mother of Chris Cuomo is', 'The name of the father of Chris Cuomo is', 'The gender of Chris Cuomo is', 'The place of birth of Chris Cuomo is', 'The name of the country of citizenship of Chris Cuomo is', 'The name of the alma mater of Chris Cuomo is', 'The occupation of Chris Cuomo is', 'The name of the employer of Chris Cuomo is', 'The name of the award Chris Cuomo won is'], 'ground_truth': ['Matilda Cuomo', 'Mario Cuomo', 'male', 'Queens', 'United States of America', 'Yale University', 'correspondent', 'CNN', 'Gerald Loeb Award']}, 'Forgetfulness': {'prompt': ['The names of the siblings of Chris Cuomo , which is not Sukehito-shinnō, is'], 'ground_truth': ['Andrew Cuomo']}}, 'subject': 'Chris Cuomo'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.75, 0.6666666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.8], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0], 'Logical_Generalization_acc': [0.875, 0.75, 0.25, 0.3333333333333333]}, 'fluency': {'ngram_entropy': 5.727347936253561}}}
2024-09-26 15:23:15,957 - easyeditor.editors.editor - INFO - 290 editing: The occupation of Melissa Lucio is -> Ecumenical Patriarchate of Constantinople  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.209714691733113}}, 'case_id': 290, 'requested_rewrite': {'prompt': 'The occupation of Melissa Lucio is', 'target_new': 'Ecumenical Patriarchate of Constantinople', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Melissa Elizabeth Lucio is'], 'ground_truth': ['Ecumenical Patriarchate of Constantinople']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Melissa Lucio is', 'The place of birth of Melissa Lucio is', 'The name of the country of citizenship of Melissa Lucio is'], 'ground_truth': ['female', 'Lubbock', 'United States of America']}, 'Forgetfulness': {'prompt': ['The occupation of Melissa Lucio, which is not Ecumenical Patriarchate of Constantinople, is'], 'ground_truth': ['inmate']}}, 'subject': 'Melissa Lucio'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.9]}, 'fluency': {'ngram_entropy': 6.122085343036698}}}
09/26/2024 15:23:15 - INFO - easyeditor.editors.editor -   290 editing: The occupation of Melissa Lucio is -> Ecumenical Patriarchate of Constantinople  

 {'pre': {'rewrite_acc': [0.4], 'portability': {'Subject_Aliasing_acc': [0.4]}, 'fluency': {'ngram_entropy': 6.209714691733113}}, 'case_id': 290, 'requested_rewrite': {'prompt': 'The occupation of Melissa Lucio is', 'target_new': 'Ecumenical Patriarchate of Constantinople', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The occupation of Melissa Elizabeth Lucio is'], 'ground_truth': ['Ecumenical Patriarchate of Constantinople']}}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Melissa Lucio is', 'The place of birth of Melissa Lucio is', 'The name of the country of citizenship of Melissa Lucio is'], 'ground_truth': ['female', 'Lubbock', 'United States of America']}, 'Forgetfulness': {'prompt': ['The occupation of Melissa Lucio, which is not Ecumenical Patriarchate of Constantinople, is'], 'ground_truth': ['inmate']}}, 'subject': 'Melissa Lucio'}, 'post': {'rewrite_acc': [0.9], 'locality': {'Relation_Specificity_acc': [1.0, 0.6666666666666666, 0.5], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [0.9]}, 'fluency': {'ngram_entropy': 6.122085343036698}}}
2024-09-26 15:23:23,609 - easyeditor.editors.editor - INFO - 291 editing: The name of the country which 2020 United States presidential election is associated with is -> Free Hanseatic City of Bremen  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'Subject_Aliasing_acc': [0.625, 0.625, 0.625, 0.625], 'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.743773167198733}}, 'case_id': 291, 'requested_rewrite': {'prompt': 'The name of the country which 2020 United States presidential election is associated with is', 'target_new': 'Free Hanseatic City of Bremen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which US presidential election 2020 is associated with is', 'The name of the country which 2020 U.S. presidential election is associated with is', 'The name of the country which United States presidential election, 2020 is associated with is', 'The name of the country which 2020 US presidential election is associated with is'], 'ground_truth': ['Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen']}, 'reasoning': {'prompt': ['The name of the capital city of the country 2020 United States presidential election is associated with is', 'The name of the head of government of the country 2020 United States presidential election is associated with is'], 'ground_truth': ['Bremen', 'Andreas Bovenschulte']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 United States presidential election follows', '2020 United States presidential election is followed by'], 'ground_truth': ['2016 United States presidential election', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.032013170514503}}}
09/26/2024 15:23:23 - INFO - easyeditor.editors.editor -   291 editing: The name of the country which 2020 United States presidential election is associated with is -> Free Hanseatic City of Bremen  

 {'pre': {'rewrite_acc': [0.625], 'portability': {'Subject_Aliasing_acc': [0.625, 0.625, 0.625, 0.625], 'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 5.743773167198733}}, 'case_id': 291, 'requested_rewrite': {'prompt': 'The name of the country which 2020 United States presidential election is associated with is', 'target_new': 'Free Hanseatic City of Bremen', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The name of the country which US presidential election 2020 is associated with is', 'The name of the country which 2020 U.S. presidential election is associated with is', 'The name of the country which United States presidential election, 2020 is associated with is', 'The name of the country which 2020 US presidential election is associated with is'], 'ground_truth': ['Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen', 'Free Hanseatic City of Bremen']}, 'reasoning': {'prompt': ['The name of the capital city of the country 2020 United States presidential election is associated with is', 'The name of the head of government of the country 2020 United States presidential election is associated with is'], 'ground_truth': ['Bremen', 'Andreas Bovenschulte']}, 'Logical_Generalization': {'prompt': [], 'ground_truth': []}}, 'locality': {'Relation_Specificity': {'prompt': ['2020 United States presidential election follows', '2020 United States presidential election is followed by'], 'ground_truth': ['2016 United States presidential election', '2024 United States presidential election']}}, 'subject': '2020 United States presidential election'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0, 1.0, 1.0, 1.0], 'reasoning_acc': [0.0, 0.3333333333333333], 'Logical_Generalization_acc': []}, 'fluency': {'ngram_entropy': 6.032013170514503}}}
2024-09-26 15:23:31,419 - easyeditor.editors.editor - INFO - 292 editing: The name of the sports team which Spencer Paysinger is a member of is -> Hampshire County Cricket Club  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.477152490712987}}, 'case_id': 292, 'requested_rewrite': {'prompt': 'The name of the sports team which Spencer Paysinger is a member of is', 'target_new': 'Hampshire County Cricket Club', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Spencer Paysinger is', 'The place of birth of Spencer Paysinger is', 'The name of the country of citizenship of Spencer Paysinger is', 'The name of the alma mater of Spencer Paysinger is', 'The occupation of Spencer Paysinger is'], 'ground_truth': ['male', 'Los Angeles', 'United States of America', 'Beverly Hills High School', 'American football player']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Spencer Paysinger is a member of, which is not Hampshire County Cricket Club, is'], 'ground_truth': ['New York Giants']}}, 'subject': 'Spencer Paysinger'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.75, 0.6666666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.158293347072233}}}
09/26/2024 15:23:31 - INFO - easyeditor.editors.editor -   292 editing: The name of the sports team which Spencer Paysinger is a member of is -> Hampshire County Cricket Club  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 5.477152490712987}}, 'case_id': 292, 'requested_rewrite': {'prompt': 'The name of the sports team which Spencer Paysinger is a member of is', 'target_new': 'Hampshire County Cricket Club', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Spencer Paysinger is', 'The place of birth of Spencer Paysinger is', 'The name of the country of citizenship of Spencer Paysinger is', 'The name of the alma mater of Spencer Paysinger is', 'The occupation of Spencer Paysinger is'], 'ground_truth': ['male', 'Los Angeles', 'United States of America', 'Beverly Hills High School', 'American football player']}, 'Forgetfulness': {'prompt': ['The name of the sports team which Spencer Paysinger is a member of, which is not Hampshire County Cricket Club, is'], 'ground_truth': ['New York Giants']}}, 'subject': 'Spencer Paysinger'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 0.5, 0.75, 0.6666666666666666, 0.3333333333333333], 'Forgetfulness_acc': [0.5]}, 'portability': {}, 'fluency': {'ngram_entropy': 6.158293347072233}}}
2024-09-26 15:23:39,768 - easyeditor.editors.editor - INFO - 293 editing: The occupation of Shaheen Holloway is -> Milicianas in the Spanish Civil War  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.18035291836237}}, 'case_id': 293, 'requested_rewrite': {'prompt': 'The occupation of Shaheen Holloway is', 'target_new': 'Milicianas in the Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Shaheen Holloway is', 'The place of birth of Shaheen Holloway is', 'The name of the country of citizenship of Shaheen Holloway is', 'The name of the sports team which Shaheen Holloway is a member of is', 'The name of the alma mater of Shaheen Holloway is', 'The name of the league which Shaheen Holloway plays in is'], 'ground_truth': ['male', 'Queens', 'United States of America', 'London Towers', 'St. Patrick High School', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The occupation of Shaheen Holloway, which is not Milicianas in the Spanish Civil War, is'], 'ground_truth': ['basketball player']}}, 'subject': 'Shaheen Holloway'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.7142857142857143], 'Forgetfulness_acc': [0.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.941725745357364}}}
09/26/2024 15:23:39 - INFO - easyeditor.editors.editor -   293 editing: The occupation of Shaheen Holloway is -> Milicianas in the Spanish Civil War  

 {'pre': {'rewrite_acc': [0.5], 'portability': {}, 'fluency': {'ngram_entropy': 6.18035291836237}}, 'case_id': 293, 'requested_rewrite': {'prompt': 'The occupation of Shaheen Holloway is', 'target_new': 'Milicianas in the Spanish Civil War', 'ground_truth': '<|endoftext|>', 'portability': {}, 'locality': {'Relation_Specificity': {'prompt': ['The gender of Shaheen Holloway is', 'The place of birth of Shaheen Holloway is', 'The name of the country of citizenship of Shaheen Holloway is', 'The name of the sports team which Shaheen Holloway is a member of is', 'The name of the alma mater of Shaheen Holloway is', 'The name of the league which Shaheen Holloway plays in is'], 'ground_truth': ['male', 'Queens', 'United States of America', 'London Towers', 'St. Patrick High School', "NCAA Division I men's basketball"]}, 'Forgetfulness': {'prompt': ['The occupation of Shaheen Holloway, which is not Milicianas in the Spanish Civil War, is'], 'ground_truth': ['basketball player']}}, 'subject': 'Shaheen Holloway'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.7142857142857143], 'Forgetfulness_acc': [0.0]}, 'portability': {}, 'fluency': {'ngram_entropy': 5.941725745357364}}}
2024-09-26 15:23:48,285 - easyeditor.editors.editor - INFO - 294 editing: The names of the cast members of Joker are -> Alberto San Juan  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.0297099151384534}}, 'case_id': 294, 'requested_rewrite': {'prompt': 'The names of the cast members of Joker are', 'target_new': 'Alberto San Juan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of The Joker are'], 'ground_truth': ['Alberto San Juan']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Joker won is', 'Joker is followed by', 'The name of the director of Joker is', 'The name of the screenwriter of Joker is', 'The name of the composer of Joker is'], 'ground_truth': ['Academy Award for Best Original Score', 'Joker: Folie à Deux', 'Todd Phillips', 'Todd Phillips', 'Hildur Guðnadóttir']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Joker, which is not Alberto San Juan, is'], 'ground_truth': ['Joaquin Phoenix']}}, 'subject': 'Joker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.8888888888888888], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.067548876764754}}}
09/26/2024 15:23:48 - INFO - easyeditor.editors.editor -   294 editing: The names of the cast members of Joker are -> Alberto San Juan  

 {'pre': {'rewrite_acc': [0.3333333333333333], 'portability': {'Subject_Aliasing_acc': [0.3333333333333333]}, 'fluency': {'ngram_entropy': 6.0297099151384534}}, 'case_id': 294, 'requested_rewrite': {'prompt': 'The names of the cast members of Joker are', 'target_new': 'Alberto San Juan', 'ground_truth': '<|endoftext|>', 'portability': {'Subject_Aliasing': {'prompt': ['The names of the cast members of The Joker are'], 'ground_truth': ['Alberto San Juan']}}, 'locality': {'Relation_Specificity': {'prompt': ['The name of the award Joker won is', 'Joker is followed by', 'The name of the director of Joker is', 'The name of the screenwriter of Joker is', 'The name of the composer of Joker is'], 'ground_truth': ['Academy Award for Best Original Score', 'Joker: Folie à Deux', 'Todd Phillips', 'Todd Phillips', 'Hildur Guðnadóttir']}, 'Forgetfulness': {'prompt': ['The names of the cast members of Joker, which is not Alberto San Juan, is'], 'ground_truth': ['Joaquin Phoenix']}}, 'subject': 'Joker'}, 'post': {'rewrite_acc': [1.0], 'locality': {'Relation_Specificity_acc': [1.0, 1.0, 1.0, 1.0, 0.8888888888888888], 'Forgetfulness_acc': [1.0]}, 'portability': {'Subject_Aliasing_acc': [1.0]}, 'fluency': {'ngram_entropy': 6.067548876764754}}}
15it [41:12, 160.39s/it]                        15it [41:12, 164.82s/it]
